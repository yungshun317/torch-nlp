{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac9ec03-3b62-414e-ae86-0ae82be1aa90",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "1. `torch.utils.data.Dataset`\n",
    "2. `torch.utils.data.DataLoader`\n",
    "   - Batching the data.\n",
    "   - Shuffling the data.\n",
    "   - Loading the data in parallel using `multiprocessing` workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e955d-41f3-4892-bbba-b19b573d5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "# create some data in numpy\n",
    "\n",
    "nObservations = 100\n",
    "nFeatures = 20\n",
    "\n",
    "data = np.random.randn(nObservations,nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a94437-e69a-464d-8dd9-b41f61ddcd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pytorch tensor\n",
    "dataT = torch.tensor( data ) \n",
    "\n",
    "# print out some information\n",
    "print('Numpy data:')\n",
    "print(type(data))\n",
    "print(data.shape) # numpy -> .shape\n",
    "print(data.dtype)\n",
    "print(' ')\n",
    "\n",
    "print('Tensor data:')\n",
    "print(type(dataT))\n",
    "print(dataT.size()) # torch -> .size()\n",
    "print(dataT.dtype)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb48f33-4dbc-44c7-ae6e-06d1ed28c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes you need to convert data types\n",
    "\n",
    "dataT2 = torch.tensor( data ).float()\n",
    "print(dataT2.dtype)\n",
    "\n",
    "# \"long\" is for ints\n",
    "dataT3 = torch.tensor( data ).long()\n",
    "print(dataT3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d90d9-dd41-4099-b13c-fea6ebe1b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensor into PyTorch Datasets\n",
    "\n",
    "# dataset = TensorDataset(data) # not a tensor!\n",
    "dataset = TensorDataset(dataT)\n",
    "\n",
    "# dataset is a two-element tuple comprising data,labels\n",
    "dataset.tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ed820-6fa7-47cd-a232-b67dd7ef7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try again with labels\n",
    "labels = torch.ceil(torch.linspace(.01,4,nObservations))\n",
    "\n",
    "# transform to an actual matrix (column vector)\n",
    "labels = labels.reshape(( len(labels),1 ))\n",
    "# print( labels )\n",
    "\n",
    "# now make another dataset\n",
    "dataset = TensorDataset(dataT,labels)\n",
    "print( dataset.tensors[0].size() )\n",
    "print( dataset.tensors[1].size() )\n",
    "\n",
    "# for comparison\n",
    "print( np.shape(np.random.randint(5,size=nObservations)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240d4e1-7f8a-42bf-b1f5-226ed148d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "# create a dataloader object\n",
    "batchsize = 25\n",
    "dataloader = DataLoader(dataset,batch_size=batchsize)#,shuffle=True,drop_last=True)\n",
    "\n",
    "dataloader.dataset.tensors[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ef450-e737-4468-995d-d4cf227d40a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes of each batch\n",
    "for dat,labs in dataloader:\n",
    "  print('BATCH INFO:')\n",
    "  print(dat.size())\n",
    "  print(labs.size())\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a4ea1-653f-400f-9bec-442c081d2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the labels\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7aa229-dd7d-44e6-82fd-bd4afcf5cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try again with shuffling (shuffling happens during iterations)\n",
    "# dataloader = DataLoader(dataset,batch_size=batchsize,shuffle=True)\n",
    "\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab19a7a-67dc-4e1d-8f80-f73be81518ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get only one batch (e.g., for testing)\n",
    "\n",
    "dat,labs = next(iter(dataloader))\n",
    "\n",
    "labs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bdc30a-101b-4b65-80d7-0671a10ee864",
   "metadata": {},
   "source": [
    "## 1-1. Cross Validation\n",
    "# 1-1-1. Cross Validation with Manual Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988fd295-f785-4b00-8d74-1b5f57050bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many training examples\n",
    "propTraining = .8 # in proportion, not percent\n",
    "nTraining = int(len(labels)*propTraining)\n",
    "\n",
    "# initialize a boolean vector to select data and labels\n",
    "traintestBool = np.zeros(len(labels),dtype=bool)\n",
    "\n",
    "# is this the correct way to select samples?\n",
    "# traintestBool[range(nTraining)] = True\n",
    "\n",
    "# this is better, but why?\n",
    "items2use4train = np.random.choice(range(len(labels)),nTraining,replace=False)\n",
    "traintestBool[items2use4train] = True\n",
    "\n",
    "traintestBool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a7b22-d66d-44f0-91ec-75498a217ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether it's balanced\n",
    "print('Average of full data:')\n",
    "print( torch.mean(labels.float()) ) # =1 by definition\n",
    "print(' ')\n",
    "\n",
    "print('Average of training data:')\n",
    "print( torch.mean(labels[traintestBool].float()) ) # should be 1...\n",
    "print(' ')\n",
    "\n",
    "print('Average of test data:')\n",
    "print( torch.mean(labels[~traintestBool].float()) ) # should also be 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178e31b-d75c-4531-8e5c-fe05f02ac9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire dataset\n",
    "print( data.shape )\n",
    "\n",
    "# training set\n",
    "print( data[traintestBool,:].shape )\n",
    "\n",
    "# test set\n",
    "print( data[~traintestBool,:].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740dcbdb-4d1c-47d2-9c78-11959cd71391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ANN model\n",
    "\n",
    "# model architecture\n",
    "ANNiris = nn.Sequential(\n",
    "    nn.Linear(4,64),   # input layer\n",
    "    nn.ReLU(),         # activation unit\n",
    "    nn.Linear(64,64),  # hidden layer\n",
    "    nn.ReLU(),         # activation unit\n",
    "    nn.Linear(64,3),   # output units\n",
    "      )\n",
    "\n",
    "# loss function\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8583a3-e636-4008-b1a7-c56e7af2da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "numepochs = 1000\n",
    "\n",
    "# initialize losses\n",
    "losses = torch.zeros(numepochs)\n",
    "ongoingAcc = []\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # forward pass\n",
    "  yHat = ANNiris(data[traintestBool,:])\n",
    "\n",
    "  # compute accuracy (note: denser than previous code!)\n",
    "  ongoingAcc.append( 100*torch.mean(\n",
    "              (torch.argmax(yHat,axis=1) == labels[traintestBool]).float()) )\n",
    "\n",
    "  # compute loss\n",
    "  loss = lossfun(yHat,labels[traintestBool])\n",
    "  losses[epochi] = loss\n",
    "\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb315bd-a0f7-43fb-b83e-154478496f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute train and test accuracies\n",
    "\n",
    "# final forward pass USING TRAINING DATA\n",
    "predictions = ANNiris(data[traintestBool,:])\n",
    "trainacc = 100*torch.mean((torch.argmax(predictions,axis=1) == labels[traintestBool]).float())\n",
    "\n",
    "\n",
    "# final forward pass USING TEST DATA!\n",
    "predictions = ANNiris(data[~traintestBool,:])\n",
    "testacc = 100*torch.mean((torch.argmax(predictions,axis=1) == labels[~traintestBool]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e89e22-a1ab-47de-bfc4-490f0afd5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report accuracies\n",
    "\n",
    "print('Final TRAIN accuracy: %g%%' %trainacc)\n",
    "print('Final TEST accuracy:  %g%%' %testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a347c-2692-4bcd-af78-a4c533f8950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
    "fakelabels = np.arange(10)>4\n",
    "print(fakedata), print(' ')\n",
    "print(fakelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05543a-65ee-48e6-89fa-8a7df91930e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition sizes in proportion\n",
    "partitions = np.array([.8,.1,.1])\n",
    "print('Partition proportions:')\n",
    "print(partitions)\n",
    "print(' ')\n",
    "\n",
    "# convert those into integers\n",
    "partitionBnd = np.cumsum(partitions*len(fakelabels)).astype(int)\n",
    "print('Partition boundaries:')\n",
    "print(partitionBnd)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "# random indices\n",
    "randindices = np.random.permutation(range(len(fakelabels)))\n",
    "print('Randomized data indices:')\n",
    "print(randindices)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19afe7d-ee3f-4444-82fd-38a29176d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows for the training data\n",
    "train_dataN   = fakedata[randindices[:partitionBnd[0]],:]\n",
    "train_labelsN = fakelabels[randindices[:partitionBnd[0]]]\n",
    "\n",
    "# select rows for the devset data\n",
    "devset_dataN   = fakedata[randindices[partitionBnd[0]:partitionBnd[1]],:]\n",
    "devset_labelsN = fakelabels[randindices[partitionBnd[0]:partitionBnd[1]]]\n",
    "\n",
    "# select rows for the test data\n",
    "test_dataN   = fakedata[randindices[partitionBnd[1]:],:]\n",
    "test_labelsN = fakelabels[randindices[partitionBnd[1]:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675c257-13f4-4f91-9d73-7834956ec91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the sizes\n",
    "print('Training data size: ' + str(train_dataN.shape))\n",
    "print('Devset size: '        + str(devset_dataN.shape))\n",
    "print('Test data size: '     + str(test_dataN.shape))\n",
    "print(' ')\n",
    "\n",
    "# print out the train/test data\n",
    "print('Training data: ')\n",
    "print(train_dataN)\n",
    "print(' ')\n",
    "\n",
    "print('Devset data: ')\n",
    "print(devset_dataN)\n",
    "print(' ')\n",
    "\n",
    "print('Test data: ')\n",
    "print(test_dataN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558116c-d133-4f80-b4de-f7d56330734a",
   "metadata": {},
   "source": [
    "### 1-1-2. Cross Validation with scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b989a-0bc0-43a5-a859-9f0c4c74e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(fakedata, fakelabels, test_size=.2)\n",
    "\n",
    "# print out the sizes\n",
    "print('Training data size: ' + str(train_data.shape))\n",
    "print('Test data size: ' + str(test_data.shape))\n",
    "print(' ')\n",
    "\n",
    "# print out the train/test data\n",
    "print('Training data: ')\n",
    "print(train_data)\n",
    "print(' ')\n",
    "\n",
    "print('Test data: ')\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea7ca11-98ca-42f7-85ee-6612770cc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createANewModel():\n",
    "\n",
    "  # model architecture\n",
    "  ANNiris = nn.Sequential(\n",
    "      nn.Linear(4,64),   # input layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,64),  # hidden layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,3),   # output units\n",
    "        )\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)\n",
    "\n",
    "  return ANNiris,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04557c52-3947-4f39-b2b2-f5fa20d4ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 200\n",
    "\n",
    "def trainTheModel(trainProp):\n",
    "\n",
    "  # initialize losses\n",
    "  losses = torch.zeros(numepochs)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # separate train from test data\n",
    "    # Note 1: unique split for each epoch!\n",
    "    # Note 2: here we specify the training size, not the testing size!\n",
    "    X_train,X_test, y_train,y_test = train_test_split(data,labels, train_size=trainProp)\n",
    "\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat = ANNiris(X_train)\n",
    "    loss = lossfun(yHat,y_train)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # compute training accuracy\n",
    "    trainAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y_train).float()).item() )\n",
    "\n",
    "    # test accuracy\n",
    "    predlabels = torch.argmax( ANNiris(X_test),axis=1 )\n",
    "    testAcc.append( 100*torch.mean((predlabels == y_test).float()).item() )\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85fc957-e90e-4bd2-9edb-4980e92d8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "ANNiris,lossfun,optimizer = createANewModel()\n",
    "\n",
    "# train the model\n",
    "# NOTE: the input is the training proportion, not the test proportion!\n",
    "trainAcc,testAcc = trainTheModel(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec349f-76c9-4bc4-b830-2b877aa58f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(trainAcc,'ro-')\n",
    "plt.plot(testAcc,'bs-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaaff96-7946-408d-a516-d7f6750579a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSetSizes = np.linspace(.2,.95,10)\n",
    "\n",
    "allTrainAcc = np.zeros((len(trainSetSizes),numepochs))\n",
    "allTestAcc = np.zeros((len(trainSetSizes),numepochs))\n",
    "\n",
    "for i in range(len(trainSetSizes)):\n",
    "\n",
    "  # create a model\n",
    "  ANNiris,lossfun,optimizer = createANewModel()\n",
    "\n",
    "  # train the model\n",
    "  trainAcc,testAcc = trainTheModel(trainSetSizes[i])\n",
    "\n",
    "  # store the results\n",
    "  allTrainAcc[i,:] = trainAcc\n",
    "  allTestAcc[i,:] = testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4f1a8-525a-4e86-81f8-f75379a6cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(13,5))\n",
    "\n",
    "ax[0].imshow(allTrainAcc,aspect='auto',\n",
    "             vmin=50,vmax=90, extent=[0,numepochs,trainSetSizes[-1],trainSetSizes[0]])\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Training size proportion')\n",
    "ax[0].set_title('Training accuracy')\n",
    "\n",
    "p = ax[1].imshow(allTestAcc,aspect='auto',\n",
    "             vmin=50,vmax=90, extent=[0,numepochs,trainSetSizes[-1],trainSetSizes[0]])\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Training size proportion')\n",
    "ax[1].set_title('Test accuracy')\n",
    "fig.colorbar(p,ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf331f3-4341-48ed-9526-8e70dd27aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "### create fake dataset (same as in previous videos)\n",
    "\n",
    "fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
    "fakelabels = np.arange(10)>4\n",
    "print(fakedata), print(' ')\n",
    "print(fakelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e8ad3-bbf4-49ac-a1c1-2077b17298de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify sizes of the partitions\n",
    "# order is train,devset,test\n",
    "partitions = [.8,.1,.1]\n",
    "\n",
    "# split the data (note the third input, and the TMP in the variable name)\n",
    "train_data,testTMP_data, train_labels,testTMP_labels = \\\n",
    "                   train_test_split(fakedata, fakelabels, train_size=partitions[0])\n",
    "\n",
    "# now split the TMP data\n",
    "split = partitions[1] / np.sum(partitions[1:])\n",
    "devset_data,test_data, devset_labels,test_labels = \\\n",
    "              train_test_split(testTMP_data, testTMP_labels, train_size=partitions[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print out the sizes\n",
    "print('Training data size: ' + str(train_data.shape))\n",
    "print('Devset data size: '   + str(devset_data.shape))\n",
    "print('Test data size: '     + str(test_data.shape))\n",
    "print(' ')\n",
    "\n",
    "# print out the train/test data\n",
    "print('Training data: ')\n",
    "print(train_data)\n",
    "print(' ')\n",
    "\n",
    "print('Devset data: ')\n",
    "print(devset_data)\n",
    "print(' ')\n",
    "\n",
    "print('Test data: ')\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b4154-2c8a-4529-8e57-17e9cb73c65d",
   "metadata": {},
   "source": [
    "### 1-1-3. Cross Validation with Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a9f78-c9b6-4edf-b65d-b558369c9d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "# create our fake dataset\n",
    "\n",
    "fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
    "fakelabels = np.arange(10)>4\n",
    "print(fakedata), print(' ')\n",
    "print(fakelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82888e38-c1df-4710-b637-c011edc741cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader object with all data\n",
    "fakedataLdr = DataLoader(fakedata, shuffle=True)\n",
    "print( fakedataLdr )\n",
    "print( fakedataLdr.batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94c48e-7df4-43a0-b598-eae2edde21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the data\n",
    "for i,oneSample in enumerate(fakedataLdr):\n",
    "  print(i,oneSample,oneSample.shape)\n",
    "\n",
    "# but where are the labels??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6db20b-8a5d-43c1-a30e-bf72552970ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a Dataset that contains the data and labels\n",
    "fakeDataset = torch.utils.data.TensorDataset(torch.Tensor(fakedata),torch.Tensor(fakelabels))\n",
    "print( fakeDataset.tensors ), print(' ')\n",
    "\n",
    "# then create another DataLoader\n",
    "fakedataLdr = DataLoader(fakeDataset, shuffle=True)\n",
    "\n",
    "# iterate through the data\n",
    "for dat,lab in fakedataLdr:\n",
    "  print(dat,lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59271fdf-74d5-4398-b07d-767be64c2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(fakedata, fakelabels, test_size=.2)\n",
    "\n",
    "# then convert them into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(\n",
    "     torch.Tensor(train_data),torch.Tensor(train_labels))\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(\n",
    "     torch.Tensor(test_data),torch.Tensor(test_labels))\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "# notice the batches (see next cell)!\n",
    "train_loader = DataLoader(train_data,batch_size=4)\n",
    "test_loader  = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c39452f-d5d5-42b4-946d-36d38e50d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the contents of the dataloader (batching is an advantage of dataloader!)\n",
    "print('TRAINING DATA')\n",
    "for batch,label in train_loader: # iterable\n",
    "  print(batch,label)\n",
    "  print(' ')\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print('TESTING DATA')\n",
    "for batch,label in test_loader: # iterable\n",
    "  print(batch,label)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02c134-f114-46d2-9c43-47b249cf4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] \n",
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = \\\n",
    "                              train_test_split(data, labels, train_size=.8)\n",
    "\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "train_loader = DataLoader(train_data,shuffle=True,batch_size=12)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4871f-a7f8-467e-9680-051f1e06fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes of data batches\n",
    "for X,y in train_loader:\n",
    "  print(X.shape,y.shape)\n",
    "\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af83b06-92a0-4d35-8beb-9b2566558e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates the ANN model\n",
    "\n",
    "def createANewModel():\n",
    "\n",
    "  # model architecture\n",
    "  ANNiris = nn.Sequential(\n",
    "      nn.Linear(4,64),   # input layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,64),  # hidden layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,3),   # output units\n",
    "        )\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)\n",
    "\n",
    "  return ANNiris,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2205a-b41f-4558-b58a-e85ceada2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 500\n",
    "\n",
    "def trainTheModel():\n",
    "\n",
    "  # initialize accuracies as empties (not storing losses here)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = ANNiris(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # compute training accuracy just for this batch\n",
    "      batchAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    predlabels = torch.argmax( ANNiris(X),axis=1 )\n",
    "    testAcc.append( 100*torch.mean((predlabels == y).float()).item() )\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a4117-2cac-4d73-ab90-caebe14adba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "ANNiris,lossfun,optimizer = createANewModel()\n",
    "\n",
    "# train the model\n",
    "trainAcc,testAcc = trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44762f3-657b-4665-a52e-50cfe519cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(trainAcc,'ro-')\n",
    "plt.plot(testAcc,'bs-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Train','Test'])\n",
    "\n",
    "# optional zoom-in to final epochs\n",
    "# plt.xlim([300,500])\n",
    "# plt.ylim([90,100.5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff503c87-2483-42ef-94ba-1386c4dca0de",
   "metadata": {},
   "source": [
    "## 1-2. Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111afe4f-f8a3-48a5-a480-beefb955e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract only the first 8\n",
    "labels = data[:8,0]\n",
    "data   = data[:8,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "# reshape to 2D!\n",
    "dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)\n",
    "\n",
    "# check sizes\n",
    "print(dataNorm.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# convert to torch tensor format\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6fd703-1809-4b44-a6d4-7be41ac190ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My custom dataset class is modeled after the official class\n",
    "??torch.utils.data.TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1c7df-6179-4269-8a2a-8a0342f25c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "  def __init__(self, tensors, transform=None):\n",
    "\n",
    "    # check that sizes of data and labels match\n",
    "    assert all(tensors[0].size(0)==t.size(0) for t in tensors), \"Size mismatch between tensors\"\n",
    "    \n",
    "    # assign inputs\n",
    "    self.tensors   = tensors\n",
    "    self.transform = transform\n",
    "\n",
    "  # what to do when someone wants and item from the dataset\n",
    "  def __getitem__(self, index): \n",
    "\n",
    "    # return transformed version of x if there are transforms\n",
    "    if self.transform:\n",
    "      x = self.transform(self.tensors[0][index])\n",
    "    else:\n",
    "      x = self.tensors[0][index]\n",
    "\n",
    "    # and return label\n",
    "    y = self.tensors[1][index]\n",
    "\n",
    "    return x,y # return the (data,label) tuple\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc98535-8ef7-48ec-835b-82b3ba96e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: several transforms work only on PIL-format data, so it's common to transform\n",
    "#       to PIL, apply transformations, then transform back to tensor.\n",
    "\n",
    "# create a list of transforms to apply to the image\n",
    "imgtrans = T.Compose([ \n",
    "                      T.ToPILImage(),\n",
    "                      T.RandomVerticalFlip(p=.5),\n",
    "                      # T.RandomRotation(90), \n",
    "                      T.ToTensor()\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa515836-80d1-4b27-9c52-c7f382c25899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert the data into datasets and then dataloaders\n",
    "\n",
    "# convert into PyTorch Datasets\n",
    "# NOTE: we have no test data here, but you should apply the same transformations to the test data\n",
    "train_data = customDataset((dataT,labelsT),imgtrans)\n",
    "\n",
    "# translate into dataloader objects\n",
    "dataLoaded = DataLoader(train_data,batch_size=8,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46fa8f-0fb4-42c2-8ab2-7a52fa488833",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44073477-fa7c-4620-aa4d-588575c49255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from the dataloader, just like during training\n",
    "X,y = next(iter(dataLoaded))\n",
    "\n",
    "\n",
    "# create a figure\n",
    "fig,axs = plt.subplots(2,8,figsize=(16,4))\n",
    "\n",
    "\n",
    "# loop over images in the dataset\n",
    "for i in range(8):\n",
    "\n",
    "  # draw images\n",
    "  axs[0,i].imshow(dataT[i,0,:,:].detach(),cmap='gray')\n",
    "  axs[1,i].imshow(X[i,0,:,:].detach(),cmap='gray')\n",
    "\n",
    "  # some niceties\n",
    "  for row in range(2):\n",
    "    axs[row,i].set_xticks([])\n",
    "    axs[row,i].set_yticks([])\n",
    "\n",
    "# row labels\n",
    "axs[0,0].set_ylabel('Original')\n",
    "axs[1,0].set_ylabel('torch dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d47c45-5f35-434f-abe5-372b10219773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to know: we haven't actually increased the amount of data\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4bdbf-eafe-46c0-9d55-35dcad874d0c",
   "metadata": {},
   "source": [
    "# 2. Model Building\n",
    "## 2-1. Sequential\n",
    "The `torch.nn.Sequential` class is easy to set up & read but with limited flexibility & interactivity. Suitable for creating small models.  \n",
    "1. `torch.nn.Sequential(*args: Module)`: Modules will be added to the sequential container in the order they are passed in the constructor.\n",
    "2. `torch.nn.Sequential(arg: OrderedDict[str, Module])`: Passes in an `OrderedDict` of modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a25ec1b-c574-4aa6-bc9c-da8f36304099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 20, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(20, 64, 5),\n",
    "    torch.nn.ReLU()\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a4621-e249-410f-830a-80f00e80fc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv_1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu_2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "model = torch.nn.Sequential(OrderedDict([\n",
    "    (\"conv_1\", torch.nn.Conv2d(1, 20, 5)),\n",
    "    (\"relu_1\", torch.nn.ReLU()),\n",
    "    (\"conv_2\", torch.nn.Conv2d(20, 64, 5)),\n",
    "    (\"relu_2\", torch.nn.ReLU())\n",
    "]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119f018-0e5f-4728-8487-c58a718bebbd",
   "metadata": {},
   "source": [
    "## 2-2. Class\n",
    "Your model should subclass `torch.nn.Module`. `torch.nn` holds basic build blocks for graphs.\n",
    "1. `torch.nn.Module.parameters(recurse=True)`: Returns an iterator over module learnable parameters (weights & biases). This is typically passed to an optimizer.\n",
    "2. `torch.nn.Module.named_parameters(prefix='', recurse=True, remove_duplicate=True)`: Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\n",
    "3. `torch.nn.Module.to(device=None, dtype=None, non_blocking=False)`: Moves and/or casts the parameters and buffers.\n",
    "4. `torch.nn.Module.load_state_dict(state_dict, strict=True, assign=False)`: Copies parameters and buffers from `state_dict` into this module and its descendants.\n",
    "5. `torch.nn.Module.state_dict(*, destination: T_destination, prefix: str = '', keep_vars: bool = False)`: A Python dictionary object contains parameters & persistent buffers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "266b7fec-079e-47a0-97c5-136e9bf5e45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 20, 5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(20, 64, 5),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "  \n",
    "    def forward(self, X):\n",
    "        out = self.conv_layers(X)\n",
    "        return out\n",
    "\n",
    "model = CNNModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8faa0f65-b7a6-458a-82d5-67ef23c5fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 1.3241e-01,  1.5604e-01, -1.0033e-01,  1.9216e-01, -6.9605e-02],\n",
      "          [ 1.7387e-01, -8.7238e-02, -8.7400e-02, -6.6454e-03, -1.3710e-02],\n",
      "          [ 4.7818e-02, -1.3161e-01, -1.2073e-01, -8.0846e-02, -1.4806e-01],\n",
      "          [ 1.5466e-01,  1.7643e-01,  6.8757e-02, -1.3546e-01,  8.1396e-02],\n",
      "          [ 1.4838e-01, -1.3129e-01, -3.4942e-02,  1.3256e-01,  1.8711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7838e-01,  9.0442e-02,  9.4969e-02,  1.9040e-01, -5.6426e-02],\n",
      "          [ 1.4222e-01,  1.0127e-01, -9.1116e-03, -2.4985e-02, -1.6505e-01],\n",
      "          [ 1.7914e-01, -7.6648e-02, -1.7809e-01,  1.2110e-01, -5.1342e-02],\n",
      "          [ 2.2690e-02,  1.5465e-01, -8.5308e-02, -4.7745e-02,  3.1571e-02],\n",
      "          [ 2.8867e-02, -3.0587e-02, -3.1570e-02, -1.9829e-01, -4.0238e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3186e-01, -1.4602e-01,  9.5862e-02, -8.8489e-02, -9.6553e-02],\n",
      "          [-1.3332e-01,  1.1675e-02,  1.6270e-01,  1.4342e-01,  1.4186e-02],\n",
      "          [ 6.7934e-02,  1.0176e-02,  5.6962e-02,  1.9649e-01,  1.5693e-01],\n",
      "          [-1.7073e-01, -2.1391e-02,  2.3361e-02,  3.1500e-02, -6.6577e-02],\n",
      "          [ 7.7104e-02,  1.4623e-01, -7.9448e-03,  3.1214e-02, -7.6848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7350e-02, -1.1280e-01, -1.1613e-01,  3.4520e-02, -9.1342e-03],\n",
      "          [-1.3996e-01, -1.8361e-01,  1.1601e-01, -5.5225e-02, -5.4041e-02],\n",
      "          [ 1.9208e-01, -9.1202e-02,  1.3636e-01,  7.3855e-02, -6.5894e-02],\n",
      "          [ 1.3723e-02,  1.5521e-01,  7.8226e-02, -1.1209e-01, -1.5964e-01],\n",
      "          [-6.5851e-02, -1.5129e-01, -5.2712e-02,  8.9967e-02, -1.8500e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2484e-01, -1.8534e-01,  3.6886e-02,  8.3262e-02,  6.8633e-02],\n",
      "          [ 1.4270e-02,  1.6860e-01,  4.8610e-02, -1.8697e-01, -1.5962e-01],\n",
      "          [-6.1016e-02, -1.6345e-02, -1.1608e-01, -1.8487e-01, -1.6567e-01],\n",
      "          [-4.0601e-02,  8.8121e-02, -1.8425e-02, -3.8099e-02, -1.9318e-01],\n",
      "          [-9.6685e-02,  4.7574e-02,  7.1982e-02,  1.3283e-01, -1.3550e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2990e-01, -1.8027e-02, -1.9720e-01, -1.0266e-01,  1.9599e-01],\n",
      "          [ 2.3637e-03,  8.8786e-02, -3.4413e-02, -1.1878e-01,  1.4574e-01],\n",
      "          [-1.1365e-01, -1.6888e-01,  5.0974e-05, -9.2363e-02, -4.1784e-02],\n",
      "          [ 1.6196e-01,  1.4280e-01, -8.2476e-02,  1.4793e-01,  9.5471e-02],\n",
      "          [ 9.4619e-02, -5.1215e-02,  7.4179e-02, -9.6469e-02, -8.7771e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1201e-01,  1.9360e-01, -1.8400e-01, -3.8823e-02,  1.8009e-01],\n",
      "          [ 1.5503e-01, -1.8852e-01,  2.5678e-02,  1.9906e-01, -1.4539e-01],\n",
      "          [-1.4287e-01, -1.7903e-01,  2.2451e-02,  1.4313e-01,  1.8826e-01],\n",
      "          [ 1.1788e-01,  1.4232e-01, -2.2371e-02, -4.0267e-02,  1.7885e-01],\n",
      "          [-9.0347e-02, -2.7690e-03, -5.3224e-02, -5.5934e-02, -1.3836e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8000e-02, -6.3736e-02, -1.5082e-01,  3.6312e-02, -1.9862e-01],\n",
      "          [ 4.8823e-02, -8.4725e-02,  6.8034e-02,  1.8329e-01,  4.5708e-02],\n",
      "          [ 1.9683e-01, -5.6322e-02,  6.3535e-02,  3.6922e-02,  1.7151e-01],\n",
      "          [ 1.4225e-01, -1.6482e-01,  6.7343e-02,  1.3643e-01,  1.4066e-01],\n",
      "          [ 2.8197e-02, -1.7635e-01, -1.5050e-01,  3.3212e-03,  6.0210e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8715e-02, -1.2924e-01,  1.1012e-01,  8.7607e-03, -1.6257e-01],\n",
      "          [ 7.7766e-02, -1.5367e-01,  1.5281e-01, -5.8361e-02,  1.0171e-01],\n",
      "          [ 1.7840e-01, -1.7470e-01, -1.5965e-01,  5.9101e-02,  1.6743e-01],\n",
      "          [-1.0642e-01, -7.9235e-03, -1.2118e-01, -1.6437e-01, -1.5323e-01],\n",
      "          [ 1.4803e-01,  1.1819e-01, -2.5592e-02,  6.2606e-02,  4.4999e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6631e-01, -1.3663e-01, -1.0860e-01,  1.8708e-01, -1.7883e-01],\n",
      "          [ 1.1482e-02, -1.2443e-01, -1.0491e-01, -9.3156e-02,  6.7180e-02],\n",
      "          [ 8.2907e-02,  1.0562e-01, -3.0791e-02, -8.7147e-02, -2.5293e-02],\n",
      "          [ 6.1346e-03,  1.6903e-01,  3.4932e-02, -1.4125e-01,  1.1192e-02],\n",
      "          [ 1.1734e-01,  1.3849e-01,  1.8247e-01, -6.6997e-02,  1.4443e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5675e-02,  1.7151e-02,  1.8107e-01, -6.6976e-02, -1.6386e-01],\n",
      "          [ 1.8581e-01,  1.1274e-01,  7.9142e-02,  1.4690e-01, -1.3505e-01],\n",
      "          [ 1.1049e-01,  1.0505e-01, -1.2216e-02, -1.7340e-01,  1.1556e-01],\n",
      "          [-5.8734e-02, -7.1824e-02, -3.7298e-02,  1.0030e-01, -6.1381e-02],\n",
      "          [ 1.6798e-01,  2.4707e-02, -8.9779e-02, -3.4683e-02,  6.7887e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0472e-02, -1.6816e-01,  1.6501e-01, -1.4424e-01,  1.4948e-01],\n",
      "          [ 1.3995e-01, -6.1184e-02, -1.7629e-02, -7.1295e-02, -1.3393e-01],\n",
      "          [ 2.0582e-02,  1.8349e-01, -1.7890e-01,  1.5396e-01, -5.8100e-02],\n",
      "          [ 1.8454e-01, -1.3551e-02,  2.1506e-02, -1.6931e-01, -1.8765e-01],\n",
      "          [ 1.0588e-01, -9.1665e-02, -1.6879e-01, -1.2527e-01, -1.0091e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9449e-02,  1.2685e-01,  7.2299e-02,  4.6595e-02,  1.9679e-01],\n",
      "          [ 2.2285e-02,  2.2567e-02,  1.0742e-01, -6.6561e-02,  1.8148e-01],\n",
      "          [ 5.5963e-02,  1.6754e-01,  7.0529e-02,  4.2915e-02, -6.9040e-02],\n",
      "          [ 4.6791e-02,  1.9311e-01, -5.7044e-02, -7.8055e-02, -1.4386e-01],\n",
      "          [-1.7197e-01, -1.6560e-01,  8.5198e-02, -1.8517e-01, -2.0688e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3139e-01,  1.4070e-01,  2.7097e-02, -1.5805e-01,  1.2808e-01],\n",
      "          [-1.7832e-01,  6.4503e-02,  2.9197e-02,  1.6657e-01, -4.3565e-02],\n",
      "          [ 5.4102e-02, -3.9023e-02,  3.9094e-02,  1.2332e-01,  1.4203e-01],\n",
      "          [ 5.1546e-02, -5.7866e-02,  1.5820e-01,  1.4223e-03,  4.3801e-02],\n",
      "          [ 6.5623e-02, -1.4990e-01,  1.2141e-01, -1.3783e-02,  8.0581e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1322e-01, -1.9726e-01,  7.9353e-03, -4.4787e-02,  1.6848e-01],\n",
      "          [ 7.8345e-02, -4.2794e-02,  1.8022e-01,  1.5772e-01,  7.7809e-02],\n",
      "          [ 1.0495e-01, -1.7089e-01,  1.3323e-01,  2.5954e-02,  9.5799e-04],\n",
      "          [ 1.4828e-01,  1.6508e-01, -7.2082e-03,  1.0186e-01, -1.7378e-01],\n",
      "          [-1.1721e-01,  3.0324e-04, -2.0825e-02,  9.1728e-02,  7.0678e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9776e-02, -1.3168e-01,  2.4154e-02, -4.5304e-02,  6.8677e-02],\n",
      "          [-1.8232e-01,  9.1022e-02, -7.2123e-02, -9.7199e-03, -3.1094e-02],\n",
      "          [ 2.8557e-02,  3.9763e-02, -3.2785e-02,  1.2154e-01, -1.2906e-01],\n",
      "          [ 1.1970e-01, -2.9830e-02, -1.2073e-01,  1.4320e-01, -1.1444e-01],\n",
      "          [ 1.5797e-01, -1.8464e-02, -5.0214e-02, -4.5412e-02, -1.5845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2919e-01, -2.3971e-02,  1.6241e-01, -1.2552e-01,  1.0633e-01],\n",
      "          [-1.7193e-01, -8.4782e-02,  1.5894e-01,  3.8409e-02, -1.8693e-01],\n",
      "          [-1.0562e-01,  6.0506e-02,  6.0093e-02,  2.5464e-02, -1.2752e-01],\n",
      "          [-1.6392e-02, -5.1873e-02,  1.9090e-01,  1.1538e-01, -1.1494e-02],\n",
      "          [ 4.7702e-02,  9.9459e-04, -1.1322e-01,  1.0613e-01, -9.6574e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4468e-02, -1.9568e-01, -8.3747e-02,  2.1697e-02, -1.6775e-01],\n",
      "          [-9.4823e-03,  6.9211e-02, -1.5341e-01,  9.8999e-02,  1.9264e-01],\n",
      "          [-5.4513e-02, -4.0235e-02, -1.1080e-01,  3.4654e-02, -1.1992e-01],\n",
      "          [ 1.6636e-01,  8.5964e-02,  5.3202e-02,  1.4344e-01,  9.3552e-02],\n",
      "          [ 1.8168e-01,  9.4864e-02, -6.3565e-02,  1.6350e-01, -7.3253e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7767e-01,  9.4857e-02,  1.3126e-01,  1.3162e-01, -1.8681e-01],\n",
      "          [-1.5823e-01, -1.1111e-02,  1.1166e-01,  4.4050e-02,  1.4993e-01],\n",
      "          [ 9.4183e-02, -7.8399e-02,  6.6749e-02, -1.6290e-02,  1.2230e-01],\n",
      "          [ 1.7485e-01, -4.1142e-02,  1.3335e-01, -1.4768e-01, -7.8840e-02],\n",
      "          [-1.3098e-01,  1.0426e-01, -6.6484e-02,  6.0214e-02,  1.2992e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9978e-01,  6.4416e-02,  6.5184e-02,  1.5113e-01, -1.5479e-01],\n",
      "          [-1.7515e-01, -4.4054e-02,  1.1378e-01,  1.7940e-01, -1.7875e-01],\n",
      "          [ 8.9578e-02,  1.9231e-01,  1.4054e-01,  1.6426e-01,  2.6875e-02],\n",
      "          [-5.9233e-02,  1.1354e-01,  1.5061e-01,  5.0135e-02, -3.3059e-02],\n",
      "          [ 1.8981e-01, -9.1344e-02,  9.9926e-02,  1.9885e-01, -6.9535e-02]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0573,  0.0840, -0.1971, -0.0123,  0.0091,  0.1132,  0.1386, -0.1841,\n",
      "        -0.0115, -0.0262,  0.0195,  0.1285, -0.0273, -0.1999, -0.1102, -0.1538,\n",
      "         0.1940,  0.1120,  0.1132,  0.0043], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-1.3871e-02,  1.8138e-03,  2.7409e-02,  1.9202e-03,  3.5283e-02],\n",
      "          [ 2.6181e-02, -1.2598e-03, -7.3440e-03,  4.4750e-03,  4.2259e-02],\n",
      "          [ 1.3897e-02, -3.8882e-02,  2.5302e-02,  9.9060e-03, -1.5260e-02],\n",
      "          [ 3.9157e-02, -4.0127e-02, -4.2976e-02,  3.9782e-02, -1.5026e-02],\n",
      "          [-1.7793e-02, -1.1287e-02, -4.0245e-02, -2.5290e-02, -1.5126e-03]],\n",
      "\n",
      "         [[-1.8095e-02, -2.9858e-02,  1.8384e-02,  4.2637e-03, -1.4755e-02],\n",
      "          [-2.0695e-02,  1.8060e-02, -1.5756e-02,  2.3952e-02, -4.2352e-02],\n",
      "          [ 2.3106e-02,  6.3974e-03,  6.0189e-04,  1.3654e-02, -1.3639e-02],\n",
      "          [-3.7988e-03, -3.6270e-02,  2.3508e-02, -6.1616e-03, -2.5438e-02],\n",
      "          [-1.7730e-02,  2.2161e-02,  1.6720e-02, -3.2676e-02,  9.0513e-03]],\n",
      "\n",
      "         [[ 1.4793e-02,  1.6415e-02, -2.8927e-02,  8.1149e-03,  3.6316e-02],\n",
      "          [ 1.8483e-02, -1.4564e-02,  4.2133e-02,  2.2380e-02, -1.8128e-02],\n",
      "          [-1.4943e-02, -3.3563e-02, -1.0543e-02,  2.4182e-02,  3.5721e-02],\n",
      "          [ 1.2420e-02, -9.2878e-03, -4.2604e-02,  3.0411e-02,  8.3704e-03],\n",
      "          [-3.6704e-02, -1.4528e-02, -8.2998e-03, -1.6295e-02, -1.3609e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0465e-03,  1.7051e-02,  7.7259e-03, -3.8155e-03,  3.9476e-03],\n",
      "          [ 3.1129e-02, -4.3741e-02, -2.0728e-02, -8.6993e-03,  2.7008e-02],\n",
      "          [-9.1237e-03, -3.5947e-02, -2.1752e-03, -1.9814e-02,  2.8245e-02],\n",
      "          [ 3.9406e-03,  3.3105e-03, -1.5305e-03,  2.5063e-02, -4.6007e-03],\n",
      "          [ 3.7993e-02, -1.6980e-02, -2.2232e-02, -1.1428e-02,  2.9301e-02]],\n",
      "\n",
      "         [[-6.4159e-03,  2.1685e-02,  8.6689e-03,  8.6723e-03,  1.8453e-02],\n",
      "          [-3.0057e-02,  4.0051e-02,  4.1262e-02,  2.9822e-02,  2.1606e-02],\n",
      "          [-2.1487e-02, -3.8540e-02, -9.6918e-03,  3.5614e-02,  2.3266e-02],\n",
      "          [ 4.3648e-02, -1.2313e-02,  4.0020e-02, -9.2189e-03, -2.5507e-02],\n",
      "          [ 2.3909e-02,  2.4166e-02,  2.8090e-02,  4.0647e-02, -2.8616e-02]],\n",
      "\n",
      "         [[ 2.0415e-03,  2.2509e-03,  2.5001e-02,  3.0924e-02, -3.3789e-03],\n",
      "          [ 8.6982e-03,  3.3180e-02, -1.8352e-02, -4.1864e-02, -3.5893e-02],\n",
      "          [ 3.2103e-02,  1.0422e-02, -2.7926e-02, -3.0336e-02, -2.0639e-02],\n",
      "          [-3.0402e-02, -1.1929e-02,  2.1070e-02,  8.6693e-03, -3.4097e-02],\n",
      "          [-3.5102e-02,  1.8101e-02, -2.5006e-02, -2.2366e-02,  3.0084e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9222e-02, -2.4327e-02,  1.3645e-02,  2.3390e-02,  3.0595e-02],\n",
      "          [ 2.6715e-02, -3.6614e-03, -2.1772e-02,  2.7429e-03,  1.1749e-02],\n",
      "          [ 2.4263e-02,  1.7774e-02,  3.4740e-02, -1.4598e-02, -3.5157e-02],\n",
      "          [ 2.4948e-03,  1.8638e-02, -2.5367e-02, -1.5732e-02,  3.7917e-03],\n",
      "          [-3.5909e-03,  3.6041e-02, -3.8344e-02, -4.1491e-02,  1.9854e-02]],\n",
      "\n",
      "         [[-2.6491e-02,  4.0159e-02, -4.1427e-02, -7.6170e-03, -7.3140e-03],\n",
      "          [-3.9630e-02, -1.1807e-02,  2.3813e-02,  1.7934e-03, -2.2907e-02],\n",
      "          [-3.9195e-02, -3.7322e-03,  4.9031e-03,  4.1874e-02,  2.5364e-02],\n",
      "          [ 3.0963e-02,  1.8185e-02,  3.2395e-02, -3.2413e-02, -1.2818e-02],\n",
      "          [ 4.6185e-03, -1.5100e-02, -8.0613e-03,  6.8208e-03, -2.4075e-02]],\n",
      "\n",
      "         [[-2.1455e-02, -2.7057e-03, -7.7437e-03,  2.6733e-04, -2.0691e-02],\n",
      "          [ 1.2371e-02,  1.2946e-02, -5.9853e-03, -5.1840e-03,  4.3210e-02],\n",
      "          [ 4.7497e-03,  2.1726e-02,  3.7029e-03,  4.0085e-02, -2.3352e-02],\n",
      "          [ 2.9196e-02, -1.6861e-02, -3.5422e-02, -4.9593e-03,  2.1213e-02],\n",
      "          [-8.5790e-03, -1.9741e-02, -2.4979e-02,  8.3580e-03, -3.0003e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2219e-02, -3.6488e-02,  8.1911e-03,  4.0574e-02,  2.7663e-02],\n",
      "          [ 3.8541e-02,  1.7447e-02,  3.3555e-02,  3.9525e-02,  1.2404e-02],\n",
      "          [-2.7404e-02,  1.0433e-03, -4.2537e-02,  3.6915e-03, -4.2093e-02],\n",
      "          [-1.0742e-02, -3.7113e-02,  8.2909e-03, -3.8922e-02, -3.9269e-02],\n",
      "          [-3.8352e-02,  1.9914e-02, -2.2876e-02, -4.3953e-02,  3.2267e-02]],\n",
      "\n",
      "         [[ 2.7342e-02, -2.2636e-02,  3.7276e-02, -2.6170e-02,  3.8131e-02],\n",
      "          [-4.1702e-02,  3.6494e-02,  3.4553e-02,  8.2889e-03, -1.3203e-02],\n",
      "          [ 2.1594e-02, -1.0232e-03, -1.3677e-02,  3.9646e-02,  6.8112e-03],\n",
      "          [ 3.0746e-02,  2.3654e-02, -2.5046e-02, -4.6949e-03, -1.2915e-02],\n",
      "          [ 2.7509e-02, -7.8877e-03,  7.3765e-03, -4.2027e-03,  8.1646e-03]],\n",
      "\n",
      "         [[ 3.4163e-02, -2.6366e-02,  4.4121e-02,  3.1600e-02, -1.1947e-02],\n",
      "          [-3.8639e-02,  3.0027e-02, -1.1069e-03,  3.3161e-02, -3.9655e-02],\n",
      "          [ 1.7341e-02,  3.0755e-02, -1.2879e-02,  5.1505e-05, -2.0856e-02],\n",
      "          [-1.0053e-02, -8.5097e-03, -2.5528e-02,  4.2424e-02, -1.7655e-02],\n",
      "          [-1.9958e-03,  4.2383e-02, -2.0389e-02, -2.1955e-02, -2.9821e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9111e-02, -9.8587e-03,  2.2674e-02,  4.1752e-02, -3.0308e-02],\n",
      "          [ 1.4281e-03,  1.4835e-02, -1.1873e-02, -4.3554e-02, -1.6282e-02],\n",
      "          [ 1.7979e-02,  3.7161e-03,  1.1927e-02, -3.1373e-02, -3.8399e-03],\n",
      "          [-1.7560e-02, -2.3035e-02, -1.8226e-03,  3.1850e-02,  2.0427e-02],\n",
      "          [ 3.7227e-02, -4.2418e-03, -4.5080e-03,  2.4929e-02,  7.2678e-04]],\n",
      "\n",
      "         [[ 1.8624e-02,  2.1771e-03,  2.9543e-03,  1.5655e-03, -1.9216e-02],\n",
      "          [-3.0592e-02,  4.6970e-03, -5.1550e-03, -3.1509e-02, -2.5539e-02],\n",
      "          [ 5.2691e-03,  1.1452e-02,  3.5991e-03, -5.6211e-03,  1.7269e-02],\n",
      "          [ 1.1463e-02, -1.9230e-02,  1.3327e-02, -2.2483e-02, -2.9959e-02],\n",
      "          [ 1.6108e-03, -4.0144e-02,  2.3154e-02,  2.1032e-02,  3.6967e-02]],\n",
      "\n",
      "         [[-1.7662e-02,  1.2009e-02,  6.9824e-03,  5.0339e-03, -2.3007e-02],\n",
      "          [-2.9563e-02, -2.0134e-02,  2.3330e-02, -1.2088e-02,  1.4290e-02],\n",
      "          [ 3.1472e-02,  1.1480e-02,  1.6631e-03,  7.0405e-03, -1.3417e-02],\n",
      "          [ 3.3113e-02,  8.7944e-03,  2.0377e-02,  3.7911e-02,  3.1440e-02],\n",
      "          [-1.7023e-03, -5.8193e-03, -1.3485e-02, -2.9056e-02, -1.9129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8464e-02,  4.3393e-03,  1.4314e-02,  1.9514e-02,  2.2890e-02],\n",
      "          [ 1.6913e-02,  3.6645e-03, -1.6260e-02, -3.3765e-02, -1.4770e-02],\n",
      "          [ 3.5910e-02, -7.2799e-03,  3.3204e-02, -2.5386e-02,  3.6073e-02],\n",
      "          [-3.1312e-02, -6.2849e-03,  4.0375e-02, -2.1666e-02, -1.0114e-02],\n",
      "          [-9.8907e-03,  3.4569e-02,  4.0549e-02, -1.1892e-02, -2.4159e-02]],\n",
      "\n",
      "         [[ 6.6576e-03, -3.2157e-02,  3.6202e-02,  2.8732e-02, -2.2077e-03],\n",
      "          [ 3.8741e-03,  4.4562e-03, -1.1733e-02, -1.8566e-02, -2.0058e-02],\n",
      "          [-2.6554e-02, -4.1024e-02, -1.7292e-02, -1.0175e-02,  9.5437e-03],\n",
      "          [-1.4051e-02,  4.0718e-02,  3.4673e-02,  2.5243e-02, -1.0394e-02],\n",
      "          [ 4.9209e-03,  3.1385e-02, -2.1820e-02, -1.2295e-02, -3.2178e-02]],\n",
      "\n",
      "         [[ 4.0259e-02, -1.1299e-02, -1.4106e-02,  3.2192e-02, -1.2603e-02],\n",
      "          [ 1.1950e-02,  4.2668e-02,  2.2611e-02, -4.0604e-02, -3.7600e-02],\n",
      "          [-1.7960e-02,  2.4670e-02, -3.2335e-02, -4.2435e-02,  8.7845e-03],\n",
      "          [-1.5702e-02,  1.0560e-02,  4.0255e-02,  1.9973e-02, -2.9173e-02],\n",
      "          [-2.9245e-02,  4.3673e-02, -2.9623e-02, -2.6126e-02,  3.6229e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3782e-02, -3.2018e-02, -4.1422e-02,  4.2965e-02,  4.1290e-02],\n",
      "          [ 2.6014e-02,  3.5790e-02, -3.1674e-02,  2.1011e-02, -3.2987e-02],\n",
      "          [-3.8864e-02, -3.4980e-02, -3.9175e-02,  2.2159e-02,  2.7862e-02],\n",
      "          [-1.5315e-02, -3.0641e-02,  2.4972e-02, -2.6885e-02, -1.8860e-02],\n",
      "          [-3.7953e-02, -2.5055e-03,  1.6515e-02, -3.8565e-03, -3.4413e-02]],\n",
      "\n",
      "         [[ 5.2746e-03, -5.7524e-03,  8.7690e-04,  2.1129e-02, -3.3714e-02],\n",
      "          [-2.5097e-02, -9.1407e-03, -1.2493e-02, -2.8287e-02,  8.1022e-03],\n",
      "          [-3.4974e-02, -8.4004e-03,  6.5616e-03, -3.1915e-02, -1.8039e-03],\n",
      "          [ 4.3422e-02,  2.5244e-02, -3.7508e-02, -1.5715e-04,  2.8635e-03],\n",
      "          [ 4.0159e-02, -1.0451e-02,  3.3808e-02,  2.2487e-03,  2.3882e-02]],\n",
      "\n",
      "         [[ 8.0380e-03,  3.9348e-02,  3.6196e-02, -1.2740e-02,  8.8485e-03],\n",
      "          [-2.9744e-02,  3.9094e-02,  2.5479e-02,  3.2697e-02,  3.4737e-02],\n",
      "          [-3.5794e-02, -4.2454e-02, -2.3609e-02,  1.8149e-02,  4.2802e-02],\n",
      "          [ 1.9548e-03,  3.2146e-02,  1.7434e-02, -2.2222e-02, -4.3828e-02],\n",
      "          [ 4.4119e-04,  2.0332e-02, -1.5830e-02,  3.0345e-02,  2.7871e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4941e-03,  2.4571e-02, -4.0033e-03, -2.4643e-02,  2.4928e-02],\n",
      "          [-2.4729e-02, -3.4175e-02,  1.5217e-02, -6.8067e-03, -1.5605e-02],\n",
      "          [-1.5520e-02,  1.3591e-02, -1.6952e-02,  2.3149e-02, -3.5015e-02],\n",
      "          [-3.8227e-02,  2.4797e-03, -1.7207e-02,  1.7616e-02,  3.8088e-02],\n",
      "          [ 3.7997e-02, -3.6835e-02, -2.2072e-02,  3.5769e-02,  1.6814e-02]],\n",
      "\n",
      "         [[-2.5929e-02, -1.4625e-02, -2.8879e-02, -3.1932e-03,  2.6450e-02],\n",
      "          [ 2.6795e-03,  3.4002e-02, -7.2258e-03,  2.3569e-02, -1.0126e-02],\n",
      "          [-1.3826e-02, -1.5366e-02, -2.0826e-02, -4.2160e-02,  2.9605e-02],\n",
      "          [-2.9491e-02, -5.9204e-04,  3.0640e-02, -3.2850e-02,  4.6293e-03],\n",
      "          [ 8.2218e-03,  3.3545e-02,  2.2686e-02,  3.7325e-02,  4.3212e-02]],\n",
      "\n",
      "         [[ 2.2121e-02, -1.0479e-02,  3.5456e-02,  1.9301e-02, -1.2956e-03],\n",
      "          [ 1.5912e-03,  2.9417e-03,  2.9833e-02,  4.1424e-02, -2.1308e-02],\n",
      "          [ 3.1825e-02,  2.2558e-02, -8.4701e-03,  3.9350e-02,  2.2740e-02],\n",
      "          [ 1.8655e-02,  9.8191e-03,  1.6428e-02, -4.1089e-02, -2.5863e-02],\n",
      "          [ 1.6437e-02,  4.3713e-02, -7.8577e-03,  4.3015e-02, -2.6737e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7608e-03, -4.1001e-02, -2.9989e-02,  5.7242e-03,  1.6483e-02],\n",
      "          [-2.1141e-02, -3.8201e-02,  2.6190e-03,  2.5314e-02,  6.5599e-03],\n",
      "          [ 7.4922e-03,  3.1143e-03,  3.9642e-02,  2.0673e-03, -1.5567e-02],\n",
      "          [-2.0046e-04,  2.7596e-02,  9.6397e-03,  1.6137e-02,  8.5051e-03],\n",
      "          [-2.9986e-02,  1.8297e-02, -3.6378e-03,  2.2362e-03, -1.7651e-02]],\n",
      "\n",
      "         [[-1.2912e-02, -2.2029e-02, -2.4961e-02, -1.9687e-02, -2.0274e-02],\n",
      "          [-1.8502e-02, -1.8732e-02, -1.6331e-02,  1.4594e-02,  2.7315e-02],\n",
      "          [ 2.7607e-02,  3.3074e-02, -2.5466e-02, -1.5396e-02,  4.2149e-03],\n",
      "          [ 4.2130e-02, -1.2793e-02,  1.5324e-02, -4.1559e-02, -2.1596e-02],\n",
      "          [-3.1985e-02,  4.2327e-02,  3.0103e-02, -1.8856e-02, -4.3335e-02]],\n",
      "\n",
      "         [[-8.8148e-03, -1.9361e-02, -2.7197e-02, -1.4601e-02,  2.9393e-02],\n",
      "          [-4.1036e-02, -4.0184e-02,  3.2189e-02, -2.5799e-02, -2.6795e-02],\n",
      "          [ 7.8577e-04, -1.6912e-02,  2.6480e-02,  6.3703e-03,  1.0465e-02],\n",
      "          [ 3.6253e-03, -2.3415e-02, -2.0984e-02, -1.4698e-02,  2.4545e-02],\n",
      "          [-2.6590e-02,  1.5386e-02, -4.5269e-03,  8.9440e-03,  2.8833e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9688e-02,  3.1305e-02,  1.0911e-02, -3.1096e-03, -6.1476e-03],\n",
      "          [ 4.4522e-02, -4.1974e-02,  1.4086e-03,  1.3176e-02, -3.5228e-02],\n",
      "          [ 4.3846e-02, -1.2587e-03, -3.4890e-02, -6.4030e-03,  3.9697e-03],\n",
      "          [-4.0698e-02,  1.3210e-02,  1.1198e-02, -1.1474e-02,  3.7271e-02],\n",
      "          [-1.7921e-02,  1.9403e-02, -1.1318e-02, -3.4611e-02,  4.0208e-02]],\n",
      "\n",
      "         [[-4.5511e-04, -3.8761e-02,  3.1732e-02,  2.4404e-03,  4.3232e-02],\n",
      "          [ 1.8153e-02, -2.1967e-02, -3.2062e-02, -2.4471e-02,  4.0476e-02],\n",
      "          [-2.7757e-02,  3.4205e-02,  3.3019e-02,  1.4792e-02,  9.9620e-04],\n",
      "          [ 9.9321e-03, -3.5928e-02,  1.7252e-02,  1.6250e-02,  4.9671e-03],\n",
      "          [ 4.3295e-04, -3.8847e-02, -4.0153e-02,  3.0456e-02,  5.4879e-03]],\n",
      "\n",
      "         [[-3.8609e-03,  3.3571e-02, -3.1285e-02, -2.3129e-02,  1.5465e-02],\n",
      "          [ 3.8651e-02,  3.4275e-02,  3.1002e-02,  2.8591e-04,  1.5209e-02],\n",
      "          [-8.5173e-03, -4.0278e-02,  8.8405e-03, -4.1458e-02, -2.9139e-02],\n",
      "          [-1.0918e-02,  1.5830e-02,  1.1770e-02, -2.9171e-02,  3.7284e-02],\n",
      "          [-3.1970e-03,  1.7156e-02, -4.3869e-02, -2.8430e-03, -4.6179e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5426e-03, -3.3489e-02,  4.3182e-02,  4.4257e-02,  2.2910e-02],\n",
      "          [ 1.0588e-02, -3.6287e-03, -1.2841e-02,  4.2236e-02,  2.1910e-02],\n",
      "          [ 2.5113e-02,  1.7791e-02, -2.8582e-02, -8.2183e-03,  4.2715e-02],\n",
      "          [-4.4355e-02, -8.3076e-03, -3.8030e-02,  1.8744e-02, -2.5378e-02],\n",
      "          [-3.6300e-02,  3.6503e-02,  4.3366e-02, -2.6602e-02,  4.5671e-04]],\n",
      "\n",
      "         [[-8.0117e-03,  1.2479e-02, -1.1636e-02, -2.2237e-02,  6.4645e-03],\n",
      "          [ 3.3277e-02, -2.6507e-02,  1.4027e-02, -3.5600e-02, -9.1320e-03],\n",
      "          [-2.6892e-02,  1.8206e-02, -1.3648e-02,  1.4801e-02, -1.0142e-02],\n",
      "          [ 3.2587e-02,  1.5215e-02,  1.8212e-02,  2.0784e-02, -2.4829e-02],\n",
      "          [-2.7623e-02, -2.1331e-02,  1.8614e-02,  8.3137e-03, -2.5571e-02]],\n",
      "\n",
      "         [[ 3.3985e-02,  2.0536e-02, -3.6736e-02, -3.4242e-02, -3.5011e-02],\n",
      "          [-1.2837e-02, -1.6274e-02, -3.8104e-02,  1.5304e-02,  3.1169e-02],\n",
      "          [ 3.7217e-02, -1.7904e-02,  1.4214e-03,  4.3906e-02,  4.3218e-02],\n",
      "          [ 4.9224e-03,  4.0308e-02,  3.9056e-02, -8.4914e-03, -7.2897e-03],\n",
      "          [ 3.2487e-02, -6.0824e-03,  3.4568e-02, -1.0007e-02, -2.7042e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8313e-02,  3.8931e-02,  4.1518e-02, -1.0579e-02, -3.9042e-02],\n",
      "          [ 2.4156e-02,  2.3572e-02,  3.4003e-02, -3.2104e-03,  4.0552e-02],\n",
      "          [ 1.9444e-02,  4.9861e-04, -1.0498e-02, -3.3191e-02,  3.1968e-02],\n",
      "          [-4.3698e-02, -4.1204e-02,  2.2203e-02, -3.6378e-02, -4.1366e-02],\n",
      "          [ 3.2657e-02, -1.2996e-02, -1.8007e-02, -2.5327e-02,  3.8129e-02]],\n",
      "\n",
      "         [[ 4.3869e-02, -1.5969e-02, -2.7958e-02, -4.0428e-02,  4.4211e-02],\n",
      "          [-1.4945e-02,  1.7142e-03,  2.9844e-03, -4.1683e-02, -1.0541e-02],\n",
      "          [-3.0339e-03, -3.9557e-02,  1.9041e-02,  1.3259e-02,  2.7224e-02],\n",
      "          [-5.7078e-03,  2.4114e-02,  2.3944e-02, -2.3861e-03, -3.2904e-02],\n",
      "          [ 2.6463e-02,  3.4529e-02,  6.5505e-03,  5.5897e-03, -3.4591e-02]],\n",
      "\n",
      "         [[-8.8023e-03, -1.4111e-02,  3.6047e-02, -2.7741e-02,  1.5809e-03],\n",
      "          [ 3.5177e-02,  1.1588e-02, -1.2560e-03,  4.1529e-02,  1.7147e-02],\n",
      "          [-3.4687e-02,  5.2443e-03,  2.3536e-02, -2.4470e-02, -7.5177e-03],\n",
      "          [ 1.8502e-02, -3.6382e-03,  3.0699e-02,  4.1438e-02, -6.3115e-04],\n",
      "          [-3.1555e-02, -4.1446e-02,  2.6937e-02,  2.7350e-02,  6.8305e-03]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0208, -0.0087,  0.0362, -0.0220, -0.0256,  0.0095,  0.0186, -0.0136,\n",
      "         0.0177, -0.0041,  0.0170, -0.0027, -0.0196,  0.0234, -0.0405, -0.0135,\n",
      "        -0.0309, -0.0404, -0.0075,  0.0444,  0.0423, -0.0372, -0.0131, -0.0381,\n",
      "         0.0133, -0.0289, -0.0221,  0.0352, -0.0110, -0.0044, -0.0370, -0.0284,\n",
      "         0.0397,  0.0232,  0.0216,  0.0064,  0.0168,  0.0110, -0.0194,  0.0445,\n",
      "         0.0036, -0.0137,  0.0069, -0.0088, -0.0233,  0.0234, -0.0068,  0.0105,\n",
      "        -0.0371, -0.0273, -0.0152, -0.0081,  0.0421,  0.0137, -0.0174, -0.0296,\n",
      "        -0.0234,  0.0100,  0.0340, -0.0171,  0.0026,  0.0309,  0.0317,  0.0267],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# `parameters()`\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10c66076-e8b5-4fda-b813-5910c4ce4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: conv_layers.0.weight\n",
      "Parameter containing:\n",
      "tensor([[[[ 1.3241e-01,  1.5604e-01, -1.0033e-01,  1.9216e-01, -6.9605e-02],\n",
      "          [ 1.7387e-01, -8.7238e-02, -8.7400e-02, -6.6454e-03, -1.3710e-02],\n",
      "          [ 4.7818e-02, -1.3161e-01, -1.2073e-01, -8.0846e-02, -1.4806e-01],\n",
      "          [ 1.5466e-01,  1.7643e-01,  6.8757e-02, -1.3546e-01,  8.1396e-02],\n",
      "          [ 1.4838e-01, -1.3129e-01, -3.4942e-02,  1.3256e-01,  1.8711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7838e-01,  9.0442e-02,  9.4969e-02,  1.9040e-01, -5.6426e-02],\n",
      "          [ 1.4222e-01,  1.0127e-01, -9.1116e-03, -2.4985e-02, -1.6505e-01],\n",
      "          [ 1.7914e-01, -7.6648e-02, -1.7809e-01,  1.2110e-01, -5.1342e-02],\n",
      "          [ 2.2690e-02,  1.5465e-01, -8.5308e-02, -4.7745e-02,  3.1571e-02],\n",
      "          [ 2.8867e-02, -3.0587e-02, -3.1570e-02, -1.9829e-01, -4.0238e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3186e-01, -1.4602e-01,  9.5862e-02, -8.8489e-02, -9.6553e-02],\n",
      "          [-1.3332e-01,  1.1675e-02,  1.6270e-01,  1.4342e-01,  1.4186e-02],\n",
      "          [ 6.7934e-02,  1.0176e-02,  5.6962e-02,  1.9649e-01,  1.5693e-01],\n",
      "          [-1.7073e-01, -2.1391e-02,  2.3361e-02,  3.1500e-02, -6.6577e-02],\n",
      "          [ 7.7104e-02,  1.4623e-01, -7.9448e-03,  3.1214e-02, -7.6848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7350e-02, -1.1280e-01, -1.1613e-01,  3.4520e-02, -9.1342e-03],\n",
      "          [-1.3996e-01, -1.8361e-01,  1.1601e-01, -5.5225e-02, -5.4041e-02],\n",
      "          [ 1.9208e-01, -9.1202e-02,  1.3636e-01,  7.3855e-02, -6.5894e-02],\n",
      "          [ 1.3723e-02,  1.5521e-01,  7.8226e-02, -1.1209e-01, -1.5964e-01],\n",
      "          [-6.5851e-02, -1.5129e-01, -5.2712e-02,  8.9967e-02, -1.8500e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2484e-01, -1.8534e-01,  3.6886e-02,  8.3262e-02,  6.8633e-02],\n",
      "          [ 1.4270e-02,  1.6860e-01,  4.8610e-02, -1.8697e-01, -1.5962e-01],\n",
      "          [-6.1016e-02, -1.6345e-02, -1.1608e-01, -1.8487e-01, -1.6567e-01],\n",
      "          [-4.0601e-02,  8.8121e-02, -1.8425e-02, -3.8099e-02, -1.9318e-01],\n",
      "          [-9.6685e-02,  4.7574e-02,  7.1982e-02,  1.3283e-01, -1.3550e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2990e-01, -1.8027e-02, -1.9720e-01, -1.0266e-01,  1.9599e-01],\n",
      "          [ 2.3637e-03,  8.8786e-02, -3.4413e-02, -1.1878e-01,  1.4574e-01],\n",
      "          [-1.1365e-01, -1.6888e-01,  5.0974e-05, -9.2363e-02, -4.1784e-02],\n",
      "          [ 1.6196e-01,  1.4280e-01, -8.2476e-02,  1.4793e-01,  9.5471e-02],\n",
      "          [ 9.4619e-02, -5.1215e-02,  7.4179e-02, -9.6469e-02, -8.7771e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1201e-01,  1.9360e-01, -1.8400e-01, -3.8823e-02,  1.8009e-01],\n",
      "          [ 1.5503e-01, -1.8852e-01,  2.5678e-02,  1.9906e-01, -1.4539e-01],\n",
      "          [-1.4287e-01, -1.7903e-01,  2.2451e-02,  1.4313e-01,  1.8826e-01],\n",
      "          [ 1.1788e-01,  1.4232e-01, -2.2371e-02, -4.0267e-02,  1.7885e-01],\n",
      "          [-9.0347e-02, -2.7690e-03, -5.3224e-02, -5.5934e-02, -1.3836e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8000e-02, -6.3736e-02, -1.5082e-01,  3.6312e-02, -1.9862e-01],\n",
      "          [ 4.8823e-02, -8.4725e-02,  6.8034e-02,  1.8329e-01,  4.5708e-02],\n",
      "          [ 1.9683e-01, -5.6322e-02,  6.3535e-02,  3.6922e-02,  1.7151e-01],\n",
      "          [ 1.4225e-01, -1.6482e-01,  6.7343e-02,  1.3643e-01,  1.4066e-01],\n",
      "          [ 2.8197e-02, -1.7635e-01, -1.5050e-01,  3.3212e-03,  6.0210e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8715e-02, -1.2924e-01,  1.1012e-01,  8.7607e-03, -1.6257e-01],\n",
      "          [ 7.7766e-02, -1.5367e-01,  1.5281e-01, -5.8361e-02,  1.0171e-01],\n",
      "          [ 1.7840e-01, -1.7470e-01, -1.5965e-01,  5.9101e-02,  1.6743e-01],\n",
      "          [-1.0642e-01, -7.9235e-03, -1.2118e-01, -1.6437e-01, -1.5323e-01],\n",
      "          [ 1.4803e-01,  1.1819e-01, -2.5592e-02,  6.2606e-02,  4.4999e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6631e-01, -1.3663e-01, -1.0860e-01,  1.8708e-01, -1.7883e-01],\n",
      "          [ 1.1482e-02, -1.2443e-01, -1.0491e-01, -9.3156e-02,  6.7180e-02],\n",
      "          [ 8.2907e-02,  1.0562e-01, -3.0791e-02, -8.7147e-02, -2.5293e-02],\n",
      "          [ 6.1346e-03,  1.6903e-01,  3.4932e-02, -1.4125e-01,  1.1192e-02],\n",
      "          [ 1.1734e-01,  1.3849e-01,  1.8247e-01, -6.6997e-02,  1.4443e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5675e-02,  1.7151e-02,  1.8107e-01, -6.6976e-02, -1.6386e-01],\n",
      "          [ 1.8581e-01,  1.1274e-01,  7.9142e-02,  1.4690e-01, -1.3505e-01],\n",
      "          [ 1.1049e-01,  1.0505e-01, -1.2216e-02, -1.7340e-01,  1.1556e-01],\n",
      "          [-5.8734e-02, -7.1824e-02, -3.7298e-02,  1.0030e-01, -6.1381e-02],\n",
      "          [ 1.6798e-01,  2.4707e-02, -8.9779e-02, -3.4683e-02,  6.7887e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0472e-02, -1.6816e-01,  1.6501e-01, -1.4424e-01,  1.4948e-01],\n",
      "          [ 1.3995e-01, -6.1184e-02, -1.7629e-02, -7.1295e-02, -1.3393e-01],\n",
      "          [ 2.0582e-02,  1.8349e-01, -1.7890e-01,  1.5396e-01, -5.8100e-02],\n",
      "          [ 1.8454e-01, -1.3551e-02,  2.1506e-02, -1.6931e-01, -1.8765e-01],\n",
      "          [ 1.0588e-01, -9.1665e-02, -1.6879e-01, -1.2527e-01, -1.0091e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9449e-02,  1.2685e-01,  7.2299e-02,  4.6595e-02,  1.9679e-01],\n",
      "          [ 2.2285e-02,  2.2567e-02,  1.0742e-01, -6.6561e-02,  1.8148e-01],\n",
      "          [ 5.5963e-02,  1.6754e-01,  7.0529e-02,  4.2915e-02, -6.9040e-02],\n",
      "          [ 4.6791e-02,  1.9311e-01, -5.7044e-02, -7.8055e-02, -1.4386e-01],\n",
      "          [-1.7197e-01, -1.6560e-01,  8.5198e-02, -1.8517e-01, -2.0688e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3139e-01,  1.4070e-01,  2.7097e-02, -1.5805e-01,  1.2808e-01],\n",
      "          [-1.7832e-01,  6.4503e-02,  2.9197e-02,  1.6657e-01, -4.3565e-02],\n",
      "          [ 5.4102e-02, -3.9023e-02,  3.9094e-02,  1.2332e-01,  1.4203e-01],\n",
      "          [ 5.1546e-02, -5.7866e-02,  1.5820e-01,  1.4223e-03,  4.3801e-02],\n",
      "          [ 6.5623e-02, -1.4990e-01,  1.2141e-01, -1.3783e-02,  8.0581e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1322e-01, -1.9726e-01,  7.9353e-03, -4.4787e-02,  1.6848e-01],\n",
      "          [ 7.8345e-02, -4.2794e-02,  1.8022e-01,  1.5772e-01,  7.7809e-02],\n",
      "          [ 1.0495e-01, -1.7089e-01,  1.3323e-01,  2.5954e-02,  9.5799e-04],\n",
      "          [ 1.4828e-01,  1.6508e-01, -7.2082e-03,  1.0186e-01, -1.7378e-01],\n",
      "          [-1.1721e-01,  3.0324e-04, -2.0825e-02,  9.1728e-02,  7.0678e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9776e-02, -1.3168e-01,  2.4154e-02, -4.5304e-02,  6.8677e-02],\n",
      "          [-1.8232e-01,  9.1022e-02, -7.2123e-02, -9.7199e-03, -3.1094e-02],\n",
      "          [ 2.8557e-02,  3.9763e-02, -3.2785e-02,  1.2154e-01, -1.2906e-01],\n",
      "          [ 1.1970e-01, -2.9830e-02, -1.2073e-01,  1.4320e-01, -1.1444e-01],\n",
      "          [ 1.5797e-01, -1.8464e-02, -5.0214e-02, -4.5412e-02, -1.5845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2919e-01, -2.3971e-02,  1.6241e-01, -1.2552e-01,  1.0633e-01],\n",
      "          [-1.7193e-01, -8.4782e-02,  1.5894e-01,  3.8409e-02, -1.8693e-01],\n",
      "          [-1.0562e-01,  6.0506e-02,  6.0093e-02,  2.5464e-02, -1.2752e-01],\n",
      "          [-1.6392e-02, -5.1873e-02,  1.9090e-01,  1.1538e-01, -1.1494e-02],\n",
      "          [ 4.7702e-02,  9.9459e-04, -1.1322e-01,  1.0613e-01, -9.6574e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4468e-02, -1.9568e-01, -8.3747e-02,  2.1697e-02, -1.6775e-01],\n",
      "          [-9.4823e-03,  6.9211e-02, -1.5341e-01,  9.8999e-02,  1.9264e-01],\n",
      "          [-5.4513e-02, -4.0235e-02, -1.1080e-01,  3.4654e-02, -1.1992e-01],\n",
      "          [ 1.6636e-01,  8.5964e-02,  5.3202e-02,  1.4344e-01,  9.3552e-02],\n",
      "          [ 1.8168e-01,  9.4864e-02, -6.3565e-02,  1.6350e-01, -7.3253e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7767e-01,  9.4857e-02,  1.3126e-01,  1.3162e-01, -1.8681e-01],\n",
      "          [-1.5823e-01, -1.1111e-02,  1.1166e-01,  4.4050e-02,  1.4993e-01],\n",
      "          [ 9.4183e-02, -7.8399e-02,  6.6749e-02, -1.6290e-02,  1.2230e-01],\n",
      "          [ 1.7485e-01, -4.1142e-02,  1.3335e-01, -1.4768e-01, -7.8840e-02],\n",
      "          [-1.3098e-01,  1.0426e-01, -6.6484e-02,  6.0214e-02,  1.2992e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9978e-01,  6.4416e-02,  6.5184e-02,  1.5113e-01, -1.5479e-01],\n",
      "          [-1.7515e-01, -4.4054e-02,  1.1378e-01,  1.7940e-01, -1.7875e-01],\n",
      "          [ 8.9578e-02,  1.9231e-01,  1.4054e-01,  1.6426e-01,  2.6875e-02],\n",
      "          [-5.9233e-02,  1.1354e-01,  1.5061e-01,  5.0135e-02, -3.3059e-02],\n",
      "          [ 1.8981e-01, -9.1344e-02,  9.9926e-02,  1.9885e-01, -6.9535e-02]]]],\n",
      "       requires_grad=True)\n",
      "Name: conv_layers.0.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0573,  0.0840, -0.1971, -0.0123,  0.0091,  0.1132,  0.1386, -0.1841,\n",
      "        -0.0115, -0.0262,  0.0195,  0.1285, -0.0273, -0.1999, -0.1102, -0.1538,\n",
      "         0.1940,  0.1120,  0.1132,  0.0043], requires_grad=True)\n",
      "Name: conv_layers.2.weight\n",
      "Parameter containing:\n",
      "tensor([[[[-1.3871e-02,  1.8138e-03,  2.7409e-02,  1.9202e-03,  3.5283e-02],\n",
      "          [ 2.6181e-02, -1.2598e-03, -7.3440e-03,  4.4750e-03,  4.2259e-02],\n",
      "          [ 1.3897e-02, -3.8882e-02,  2.5302e-02,  9.9060e-03, -1.5260e-02],\n",
      "          [ 3.9157e-02, -4.0127e-02, -4.2976e-02,  3.9782e-02, -1.5026e-02],\n",
      "          [-1.7793e-02, -1.1287e-02, -4.0245e-02, -2.5290e-02, -1.5126e-03]],\n",
      "\n",
      "         [[-1.8095e-02, -2.9858e-02,  1.8384e-02,  4.2637e-03, -1.4755e-02],\n",
      "          [-2.0695e-02,  1.8060e-02, -1.5756e-02,  2.3952e-02, -4.2352e-02],\n",
      "          [ 2.3106e-02,  6.3974e-03,  6.0189e-04,  1.3654e-02, -1.3639e-02],\n",
      "          [-3.7988e-03, -3.6270e-02,  2.3508e-02, -6.1616e-03, -2.5438e-02],\n",
      "          [-1.7730e-02,  2.2161e-02,  1.6720e-02, -3.2676e-02,  9.0513e-03]],\n",
      "\n",
      "         [[ 1.4793e-02,  1.6415e-02, -2.8927e-02,  8.1149e-03,  3.6316e-02],\n",
      "          [ 1.8483e-02, -1.4564e-02,  4.2133e-02,  2.2380e-02, -1.8128e-02],\n",
      "          [-1.4943e-02, -3.3563e-02, -1.0543e-02,  2.4182e-02,  3.5721e-02],\n",
      "          [ 1.2420e-02, -9.2878e-03, -4.2604e-02,  3.0411e-02,  8.3704e-03],\n",
      "          [-3.6704e-02, -1.4528e-02, -8.2998e-03, -1.6295e-02, -1.3609e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0465e-03,  1.7051e-02,  7.7259e-03, -3.8155e-03,  3.9476e-03],\n",
      "          [ 3.1129e-02, -4.3741e-02, -2.0728e-02, -8.6993e-03,  2.7008e-02],\n",
      "          [-9.1237e-03, -3.5947e-02, -2.1752e-03, -1.9814e-02,  2.8245e-02],\n",
      "          [ 3.9406e-03,  3.3105e-03, -1.5305e-03,  2.5063e-02, -4.6007e-03],\n",
      "          [ 3.7993e-02, -1.6980e-02, -2.2232e-02, -1.1428e-02,  2.9301e-02]],\n",
      "\n",
      "         [[-6.4159e-03,  2.1685e-02,  8.6689e-03,  8.6723e-03,  1.8453e-02],\n",
      "          [-3.0057e-02,  4.0051e-02,  4.1262e-02,  2.9822e-02,  2.1606e-02],\n",
      "          [-2.1487e-02, -3.8540e-02, -9.6918e-03,  3.5614e-02,  2.3266e-02],\n",
      "          [ 4.3648e-02, -1.2313e-02,  4.0020e-02, -9.2189e-03, -2.5507e-02],\n",
      "          [ 2.3909e-02,  2.4166e-02,  2.8090e-02,  4.0647e-02, -2.8616e-02]],\n",
      "\n",
      "         [[ 2.0415e-03,  2.2509e-03,  2.5001e-02,  3.0924e-02, -3.3789e-03],\n",
      "          [ 8.6982e-03,  3.3180e-02, -1.8352e-02, -4.1864e-02, -3.5893e-02],\n",
      "          [ 3.2103e-02,  1.0422e-02, -2.7926e-02, -3.0336e-02, -2.0639e-02],\n",
      "          [-3.0402e-02, -1.1929e-02,  2.1070e-02,  8.6693e-03, -3.4097e-02],\n",
      "          [-3.5102e-02,  1.8101e-02, -2.5006e-02, -2.2366e-02,  3.0084e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9222e-02, -2.4327e-02,  1.3645e-02,  2.3390e-02,  3.0595e-02],\n",
      "          [ 2.6715e-02, -3.6614e-03, -2.1772e-02,  2.7429e-03,  1.1749e-02],\n",
      "          [ 2.4263e-02,  1.7774e-02,  3.4740e-02, -1.4598e-02, -3.5157e-02],\n",
      "          [ 2.4948e-03,  1.8638e-02, -2.5367e-02, -1.5732e-02,  3.7917e-03],\n",
      "          [-3.5909e-03,  3.6041e-02, -3.8344e-02, -4.1491e-02,  1.9854e-02]],\n",
      "\n",
      "         [[-2.6491e-02,  4.0159e-02, -4.1427e-02, -7.6170e-03, -7.3140e-03],\n",
      "          [-3.9630e-02, -1.1807e-02,  2.3813e-02,  1.7934e-03, -2.2907e-02],\n",
      "          [-3.9195e-02, -3.7322e-03,  4.9031e-03,  4.1874e-02,  2.5364e-02],\n",
      "          [ 3.0963e-02,  1.8185e-02,  3.2395e-02, -3.2413e-02, -1.2818e-02],\n",
      "          [ 4.6185e-03, -1.5100e-02, -8.0613e-03,  6.8208e-03, -2.4075e-02]],\n",
      "\n",
      "         [[-2.1455e-02, -2.7057e-03, -7.7437e-03,  2.6733e-04, -2.0691e-02],\n",
      "          [ 1.2371e-02,  1.2946e-02, -5.9853e-03, -5.1840e-03,  4.3210e-02],\n",
      "          [ 4.7497e-03,  2.1726e-02,  3.7029e-03,  4.0085e-02, -2.3352e-02],\n",
      "          [ 2.9196e-02, -1.6861e-02, -3.5422e-02, -4.9593e-03,  2.1213e-02],\n",
      "          [-8.5790e-03, -1.9741e-02, -2.4979e-02,  8.3580e-03, -3.0003e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2219e-02, -3.6488e-02,  8.1911e-03,  4.0574e-02,  2.7663e-02],\n",
      "          [ 3.8541e-02,  1.7447e-02,  3.3555e-02,  3.9525e-02,  1.2404e-02],\n",
      "          [-2.7404e-02,  1.0433e-03, -4.2537e-02,  3.6915e-03, -4.2093e-02],\n",
      "          [-1.0742e-02, -3.7113e-02,  8.2909e-03, -3.8922e-02, -3.9269e-02],\n",
      "          [-3.8352e-02,  1.9914e-02, -2.2876e-02, -4.3953e-02,  3.2267e-02]],\n",
      "\n",
      "         [[ 2.7342e-02, -2.2636e-02,  3.7276e-02, -2.6170e-02,  3.8131e-02],\n",
      "          [-4.1702e-02,  3.6494e-02,  3.4553e-02,  8.2889e-03, -1.3203e-02],\n",
      "          [ 2.1594e-02, -1.0232e-03, -1.3677e-02,  3.9646e-02,  6.8112e-03],\n",
      "          [ 3.0746e-02,  2.3654e-02, -2.5046e-02, -4.6949e-03, -1.2915e-02],\n",
      "          [ 2.7509e-02, -7.8877e-03,  7.3765e-03, -4.2027e-03,  8.1646e-03]],\n",
      "\n",
      "         [[ 3.4163e-02, -2.6366e-02,  4.4121e-02,  3.1600e-02, -1.1947e-02],\n",
      "          [-3.8639e-02,  3.0027e-02, -1.1069e-03,  3.3161e-02, -3.9655e-02],\n",
      "          [ 1.7341e-02,  3.0755e-02, -1.2879e-02,  5.1505e-05, -2.0856e-02],\n",
      "          [-1.0053e-02, -8.5097e-03, -2.5528e-02,  4.2424e-02, -1.7655e-02],\n",
      "          [-1.9958e-03,  4.2383e-02, -2.0389e-02, -2.1955e-02, -2.9821e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9111e-02, -9.8587e-03,  2.2674e-02,  4.1752e-02, -3.0308e-02],\n",
      "          [ 1.4281e-03,  1.4835e-02, -1.1873e-02, -4.3554e-02, -1.6282e-02],\n",
      "          [ 1.7979e-02,  3.7161e-03,  1.1927e-02, -3.1373e-02, -3.8399e-03],\n",
      "          [-1.7560e-02, -2.3035e-02, -1.8226e-03,  3.1850e-02,  2.0427e-02],\n",
      "          [ 3.7227e-02, -4.2418e-03, -4.5080e-03,  2.4929e-02,  7.2678e-04]],\n",
      "\n",
      "         [[ 1.8624e-02,  2.1771e-03,  2.9543e-03,  1.5655e-03, -1.9216e-02],\n",
      "          [-3.0592e-02,  4.6970e-03, -5.1550e-03, -3.1509e-02, -2.5539e-02],\n",
      "          [ 5.2691e-03,  1.1452e-02,  3.5991e-03, -5.6211e-03,  1.7269e-02],\n",
      "          [ 1.1463e-02, -1.9230e-02,  1.3327e-02, -2.2483e-02, -2.9959e-02],\n",
      "          [ 1.6108e-03, -4.0144e-02,  2.3154e-02,  2.1032e-02,  3.6967e-02]],\n",
      "\n",
      "         [[-1.7662e-02,  1.2009e-02,  6.9824e-03,  5.0339e-03, -2.3007e-02],\n",
      "          [-2.9563e-02, -2.0134e-02,  2.3330e-02, -1.2088e-02,  1.4290e-02],\n",
      "          [ 3.1472e-02,  1.1480e-02,  1.6631e-03,  7.0405e-03, -1.3417e-02],\n",
      "          [ 3.3113e-02,  8.7944e-03,  2.0377e-02,  3.7911e-02,  3.1440e-02],\n",
      "          [-1.7023e-03, -5.8193e-03, -1.3485e-02, -2.9056e-02, -1.9129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8464e-02,  4.3393e-03,  1.4314e-02,  1.9514e-02,  2.2890e-02],\n",
      "          [ 1.6913e-02,  3.6645e-03, -1.6260e-02, -3.3765e-02, -1.4770e-02],\n",
      "          [ 3.5910e-02, -7.2799e-03,  3.3204e-02, -2.5386e-02,  3.6073e-02],\n",
      "          [-3.1312e-02, -6.2849e-03,  4.0375e-02, -2.1666e-02, -1.0114e-02],\n",
      "          [-9.8907e-03,  3.4569e-02,  4.0549e-02, -1.1892e-02, -2.4159e-02]],\n",
      "\n",
      "         [[ 6.6576e-03, -3.2157e-02,  3.6202e-02,  2.8732e-02, -2.2077e-03],\n",
      "          [ 3.8741e-03,  4.4562e-03, -1.1733e-02, -1.8566e-02, -2.0058e-02],\n",
      "          [-2.6554e-02, -4.1024e-02, -1.7292e-02, -1.0175e-02,  9.5437e-03],\n",
      "          [-1.4051e-02,  4.0718e-02,  3.4673e-02,  2.5243e-02, -1.0394e-02],\n",
      "          [ 4.9209e-03,  3.1385e-02, -2.1820e-02, -1.2295e-02, -3.2178e-02]],\n",
      "\n",
      "         [[ 4.0259e-02, -1.1299e-02, -1.4106e-02,  3.2192e-02, -1.2603e-02],\n",
      "          [ 1.1950e-02,  4.2668e-02,  2.2611e-02, -4.0604e-02, -3.7600e-02],\n",
      "          [-1.7960e-02,  2.4670e-02, -3.2335e-02, -4.2435e-02,  8.7845e-03],\n",
      "          [-1.5702e-02,  1.0560e-02,  4.0255e-02,  1.9973e-02, -2.9173e-02],\n",
      "          [-2.9245e-02,  4.3673e-02, -2.9623e-02, -2.6126e-02,  3.6229e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3782e-02, -3.2018e-02, -4.1422e-02,  4.2965e-02,  4.1290e-02],\n",
      "          [ 2.6014e-02,  3.5790e-02, -3.1674e-02,  2.1011e-02, -3.2987e-02],\n",
      "          [-3.8864e-02, -3.4980e-02, -3.9175e-02,  2.2159e-02,  2.7862e-02],\n",
      "          [-1.5315e-02, -3.0641e-02,  2.4972e-02, -2.6885e-02, -1.8860e-02],\n",
      "          [-3.7953e-02, -2.5055e-03,  1.6515e-02, -3.8565e-03, -3.4413e-02]],\n",
      "\n",
      "         [[ 5.2746e-03, -5.7524e-03,  8.7690e-04,  2.1129e-02, -3.3714e-02],\n",
      "          [-2.5097e-02, -9.1407e-03, -1.2493e-02, -2.8287e-02,  8.1022e-03],\n",
      "          [-3.4974e-02, -8.4004e-03,  6.5616e-03, -3.1915e-02, -1.8039e-03],\n",
      "          [ 4.3422e-02,  2.5244e-02, -3.7508e-02, -1.5715e-04,  2.8635e-03],\n",
      "          [ 4.0159e-02, -1.0451e-02,  3.3808e-02,  2.2487e-03,  2.3882e-02]],\n",
      "\n",
      "         [[ 8.0380e-03,  3.9348e-02,  3.6196e-02, -1.2740e-02,  8.8485e-03],\n",
      "          [-2.9744e-02,  3.9094e-02,  2.5479e-02,  3.2697e-02,  3.4737e-02],\n",
      "          [-3.5794e-02, -4.2454e-02, -2.3609e-02,  1.8149e-02,  4.2802e-02],\n",
      "          [ 1.9548e-03,  3.2146e-02,  1.7434e-02, -2.2222e-02, -4.3828e-02],\n",
      "          [ 4.4119e-04,  2.0332e-02, -1.5830e-02,  3.0345e-02,  2.7871e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4941e-03,  2.4571e-02, -4.0033e-03, -2.4643e-02,  2.4928e-02],\n",
      "          [-2.4729e-02, -3.4175e-02,  1.5217e-02, -6.8067e-03, -1.5605e-02],\n",
      "          [-1.5520e-02,  1.3591e-02, -1.6952e-02,  2.3149e-02, -3.5015e-02],\n",
      "          [-3.8227e-02,  2.4797e-03, -1.7207e-02,  1.7616e-02,  3.8088e-02],\n",
      "          [ 3.7997e-02, -3.6835e-02, -2.2072e-02,  3.5769e-02,  1.6814e-02]],\n",
      "\n",
      "         [[-2.5929e-02, -1.4625e-02, -2.8879e-02, -3.1932e-03,  2.6450e-02],\n",
      "          [ 2.6795e-03,  3.4002e-02, -7.2258e-03,  2.3569e-02, -1.0126e-02],\n",
      "          [-1.3826e-02, -1.5366e-02, -2.0826e-02, -4.2160e-02,  2.9605e-02],\n",
      "          [-2.9491e-02, -5.9204e-04,  3.0640e-02, -3.2850e-02,  4.6293e-03],\n",
      "          [ 8.2218e-03,  3.3545e-02,  2.2686e-02,  3.7325e-02,  4.3212e-02]],\n",
      "\n",
      "         [[ 2.2121e-02, -1.0479e-02,  3.5456e-02,  1.9301e-02, -1.2956e-03],\n",
      "          [ 1.5912e-03,  2.9417e-03,  2.9833e-02,  4.1424e-02, -2.1308e-02],\n",
      "          [ 3.1825e-02,  2.2558e-02, -8.4701e-03,  3.9350e-02,  2.2740e-02],\n",
      "          [ 1.8655e-02,  9.8191e-03,  1.6428e-02, -4.1089e-02, -2.5863e-02],\n",
      "          [ 1.6437e-02,  4.3713e-02, -7.8577e-03,  4.3015e-02, -2.6737e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7608e-03, -4.1001e-02, -2.9989e-02,  5.7242e-03,  1.6483e-02],\n",
      "          [-2.1141e-02, -3.8201e-02,  2.6190e-03,  2.5314e-02,  6.5599e-03],\n",
      "          [ 7.4922e-03,  3.1143e-03,  3.9642e-02,  2.0673e-03, -1.5567e-02],\n",
      "          [-2.0046e-04,  2.7596e-02,  9.6397e-03,  1.6137e-02,  8.5051e-03],\n",
      "          [-2.9986e-02,  1.8297e-02, -3.6378e-03,  2.2362e-03, -1.7651e-02]],\n",
      "\n",
      "         [[-1.2912e-02, -2.2029e-02, -2.4961e-02, -1.9687e-02, -2.0274e-02],\n",
      "          [-1.8502e-02, -1.8732e-02, -1.6331e-02,  1.4594e-02,  2.7315e-02],\n",
      "          [ 2.7607e-02,  3.3074e-02, -2.5466e-02, -1.5396e-02,  4.2149e-03],\n",
      "          [ 4.2130e-02, -1.2793e-02,  1.5324e-02, -4.1559e-02, -2.1596e-02],\n",
      "          [-3.1985e-02,  4.2327e-02,  3.0103e-02, -1.8856e-02, -4.3335e-02]],\n",
      "\n",
      "         [[-8.8148e-03, -1.9361e-02, -2.7197e-02, -1.4601e-02,  2.9393e-02],\n",
      "          [-4.1036e-02, -4.0184e-02,  3.2189e-02, -2.5799e-02, -2.6795e-02],\n",
      "          [ 7.8577e-04, -1.6912e-02,  2.6480e-02,  6.3703e-03,  1.0465e-02],\n",
      "          [ 3.6253e-03, -2.3415e-02, -2.0984e-02, -1.4698e-02,  2.4545e-02],\n",
      "          [-2.6590e-02,  1.5386e-02, -4.5269e-03,  8.9440e-03,  2.8833e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9688e-02,  3.1305e-02,  1.0911e-02, -3.1096e-03, -6.1476e-03],\n",
      "          [ 4.4522e-02, -4.1974e-02,  1.4086e-03,  1.3176e-02, -3.5228e-02],\n",
      "          [ 4.3846e-02, -1.2587e-03, -3.4890e-02, -6.4030e-03,  3.9697e-03],\n",
      "          [-4.0698e-02,  1.3210e-02,  1.1198e-02, -1.1474e-02,  3.7271e-02],\n",
      "          [-1.7921e-02,  1.9403e-02, -1.1318e-02, -3.4611e-02,  4.0208e-02]],\n",
      "\n",
      "         [[-4.5511e-04, -3.8761e-02,  3.1732e-02,  2.4404e-03,  4.3232e-02],\n",
      "          [ 1.8153e-02, -2.1967e-02, -3.2062e-02, -2.4471e-02,  4.0476e-02],\n",
      "          [-2.7757e-02,  3.4205e-02,  3.3019e-02,  1.4792e-02,  9.9620e-04],\n",
      "          [ 9.9321e-03, -3.5928e-02,  1.7252e-02,  1.6250e-02,  4.9671e-03],\n",
      "          [ 4.3295e-04, -3.8847e-02, -4.0153e-02,  3.0456e-02,  5.4879e-03]],\n",
      "\n",
      "         [[-3.8609e-03,  3.3571e-02, -3.1285e-02, -2.3129e-02,  1.5465e-02],\n",
      "          [ 3.8651e-02,  3.4275e-02,  3.1002e-02,  2.8591e-04,  1.5209e-02],\n",
      "          [-8.5173e-03, -4.0278e-02,  8.8405e-03, -4.1458e-02, -2.9139e-02],\n",
      "          [-1.0918e-02,  1.5830e-02,  1.1770e-02, -2.9171e-02,  3.7284e-02],\n",
      "          [-3.1970e-03,  1.7156e-02, -4.3869e-02, -2.8430e-03, -4.6179e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5426e-03, -3.3489e-02,  4.3182e-02,  4.4257e-02,  2.2910e-02],\n",
      "          [ 1.0588e-02, -3.6287e-03, -1.2841e-02,  4.2236e-02,  2.1910e-02],\n",
      "          [ 2.5113e-02,  1.7791e-02, -2.8582e-02, -8.2183e-03,  4.2715e-02],\n",
      "          [-4.4355e-02, -8.3076e-03, -3.8030e-02,  1.8744e-02, -2.5378e-02],\n",
      "          [-3.6300e-02,  3.6503e-02,  4.3366e-02, -2.6602e-02,  4.5671e-04]],\n",
      "\n",
      "         [[-8.0117e-03,  1.2479e-02, -1.1636e-02, -2.2237e-02,  6.4645e-03],\n",
      "          [ 3.3277e-02, -2.6507e-02,  1.4027e-02, -3.5600e-02, -9.1320e-03],\n",
      "          [-2.6892e-02,  1.8206e-02, -1.3648e-02,  1.4801e-02, -1.0142e-02],\n",
      "          [ 3.2587e-02,  1.5215e-02,  1.8212e-02,  2.0784e-02, -2.4829e-02],\n",
      "          [-2.7623e-02, -2.1331e-02,  1.8614e-02,  8.3137e-03, -2.5571e-02]],\n",
      "\n",
      "         [[ 3.3985e-02,  2.0536e-02, -3.6736e-02, -3.4242e-02, -3.5011e-02],\n",
      "          [-1.2837e-02, -1.6274e-02, -3.8104e-02,  1.5304e-02,  3.1169e-02],\n",
      "          [ 3.7217e-02, -1.7904e-02,  1.4214e-03,  4.3906e-02,  4.3218e-02],\n",
      "          [ 4.9224e-03,  4.0308e-02,  3.9056e-02, -8.4914e-03, -7.2897e-03],\n",
      "          [ 3.2487e-02, -6.0824e-03,  3.4568e-02, -1.0007e-02, -2.7042e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8313e-02,  3.8931e-02,  4.1518e-02, -1.0579e-02, -3.9042e-02],\n",
      "          [ 2.4156e-02,  2.3572e-02,  3.4003e-02, -3.2104e-03,  4.0552e-02],\n",
      "          [ 1.9444e-02,  4.9861e-04, -1.0498e-02, -3.3191e-02,  3.1968e-02],\n",
      "          [-4.3698e-02, -4.1204e-02,  2.2203e-02, -3.6378e-02, -4.1366e-02],\n",
      "          [ 3.2657e-02, -1.2996e-02, -1.8007e-02, -2.5327e-02,  3.8129e-02]],\n",
      "\n",
      "         [[ 4.3869e-02, -1.5969e-02, -2.7958e-02, -4.0428e-02,  4.4211e-02],\n",
      "          [-1.4945e-02,  1.7142e-03,  2.9844e-03, -4.1683e-02, -1.0541e-02],\n",
      "          [-3.0339e-03, -3.9557e-02,  1.9041e-02,  1.3259e-02,  2.7224e-02],\n",
      "          [-5.7078e-03,  2.4114e-02,  2.3944e-02, -2.3861e-03, -3.2904e-02],\n",
      "          [ 2.6463e-02,  3.4529e-02,  6.5505e-03,  5.5897e-03, -3.4591e-02]],\n",
      "\n",
      "         [[-8.8023e-03, -1.4111e-02,  3.6047e-02, -2.7741e-02,  1.5809e-03],\n",
      "          [ 3.5177e-02,  1.1588e-02, -1.2560e-03,  4.1529e-02,  1.7147e-02],\n",
      "          [-3.4687e-02,  5.2443e-03,  2.3536e-02, -2.4470e-02, -7.5177e-03],\n",
      "          [ 1.8502e-02, -3.6382e-03,  3.0699e-02,  4.1438e-02, -6.3115e-04],\n",
      "          [-3.1555e-02, -4.1446e-02,  2.6937e-02,  2.7350e-02,  6.8305e-03]]]],\n",
      "       requires_grad=True)\n",
      "Name: conv_layers.2.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0208, -0.0087,  0.0362, -0.0220, -0.0256,  0.0095,  0.0186, -0.0136,\n",
      "         0.0177, -0.0041,  0.0170, -0.0027, -0.0196,  0.0234, -0.0405, -0.0135,\n",
      "        -0.0309, -0.0404, -0.0075,  0.0444,  0.0423, -0.0372, -0.0131, -0.0381,\n",
      "         0.0133, -0.0289, -0.0221,  0.0352, -0.0110, -0.0044, -0.0370, -0.0284,\n",
      "         0.0397,  0.0232,  0.0216,  0.0064,  0.0168,  0.0110, -0.0194,  0.0445,\n",
      "         0.0036, -0.0137,  0.0069, -0.0088, -0.0233,  0.0234, -0.0068,  0.0105,\n",
      "        -0.0371, -0.0273, -0.0152, -0.0081,  0.0421,  0.0137, -0.0174, -0.0296,\n",
      "        -0.0234,  0.0100,  0.0340, -0.0171,  0.0026,  0.0309,  0.0317,  0.0267],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# `named_parameters()`\n",
    "for name, param in model.named_parameters():\n",
    "    print(\"Name:\", name)\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "500f1454-6912-43c7-8dfc-fb8d9df49380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: conv_layers.0.weight\n",
      "Parameters: tensor([[[[ 1.3241e-01,  1.5604e-01, -1.0033e-01,  1.9216e-01, -6.9605e-02],\n",
      "          [ 1.7387e-01, -8.7238e-02, -8.7400e-02, -6.6454e-03, -1.3710e-02],\n",
      "          [ 4.7818e-02, -1.3161e-01, -1.2073e-01, -8.0846e-02, -1.4806e-01],\n",
      "          [ 1.5466e-01,  1.7643e-01,  6.8757e-02, -1.3546e-01,  8.1396e-02],\n",
      "          [ 1.4838e-01, -1.3129e-01, -3.4942e-02,  1.3256e-01,  1.8711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7838e-01,  9.0442e-02,  9.4969e-02,  1.9040e-01, -5.6426e-02],\n",
      "          [ 1.4222e-01,  1.0127e-01, -9.1116e-03, -2.4985e-02, -1.6505e-01],\n",
      "          [ 1.7914e-01, -7.6648e-02, -1.7809e-01,  1.2110e-01, -5.1342e-02],\n",
      "          [ 2.2690e-02,  1.5465e-01, -8.5308e-02, -4.7745e-02,  3.1571e-02],\n",
      "          [ 2.8867e-02, -3.0587e-02, -3.1570e-02, -1.9829e-01, -4.0238e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3186e-01, -1.4602e-01,  9.5862e-02, -8.8489e-02, -9.6553e-02],\n",
      "          [-1.3332e-01,  1.1675e-02,  1.6270e-01,  1.4342e-01,  1.4186e-02],\n",
      "          [ 6.7934e-02,  1.0176e-02,  5.6962e-02,  1.9649e-01,  1.5693e-01],\n",
      "          [-1.7073e-01, -2.1391e-02,  2.3361e-02,  3.1500e-02, -6.6577e-02],\n",
      "          [ 7.7104e-02,  1.4623e-01, -7.9448e-03,  3.1214e-02, -7.6848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7350e-02, -1.1280e-01, -1.1613e-01,  3.4520e-02, -9.1342e-03],\n",
      "          [-1.3996e-01, -1.8361e-01,  1.1601e-01, -5.5225e-02, -5.4041e-02],\n",
      "          [ 1.9208e-01, -9.1202e-02,  1.3636e-01,  7.3855e-02, -6.5894e-02],\n",
      "          [ 1.3723e-02,  1.5521e-01,  7.8226e-02, -1.1209e-01, -1.5964e-01],\n",
      "          [-6.5851e-02, -1.5129e-01, -5.2712e-02,  8.9967e-02, -1.8500e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2484e-01, -1.8534e-01,  3.6886e-02,  8.3262e-02,  6.8633e-02],\n",
      "          [ 1.4270e-02,  1.6860e-01,  4.8610e-02, -1.8697e-01, -1.5962e-01],\n",
      "          [-6.1016e-02, -1.6345e-02, -1.1608e-01, -1.8487e-01, -1.6567e-01],\n",
      "          [-4.0601e-02,  8.8121e-02, -1.8425e-02, -3.8099e-02, -1.9318e-01],\n",
      "          [-9.6685e-02,  4.7574e-02,  7.1982e-02,  1.3283e-01, -1.3550e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2990e-01, -1.8027e-02, -1.9720e-01, -1.0266e-01,  1.9599e-01],\n",
      "          [ 2.3637e-03,  8.8786e-02, -3.4413e-02, -1.1878e-01,  1.4574e-01],\n",
      "          [-1.1365e-01, -1.6888e-01,  5.0974e-05, -9.2363e-02, -4.1784e-02],\n",
      "          [ 1.6196e-01,  1.4280e-01, -8.2476e-02,  1.4793e-01,  9.5471e-02],\n",
      "          [ 9.4619e-02, -5.1215e-02,  7.4179e-02, -9.6469e-02, -8.7771e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1201e-01,  1.9360e-01, -1.8400e-01, -3.8823e-02,  1.8009e-01],\n",
      "          [ 1.5503e-01, -1.8852e-01,  2.5678e-02,  1.9906e-01, -1.4539e-01],\n",
      "          [-1.4287e-01, -1.7903e-01,  2.2451e-02,  1.4313e-01,  1.8826e-01],\n",
      "          [ 1.1788e-01,  1.4232e-01, -2.2371e-02, -4.0267e-02,  1.7885e-01],\n",
      "          [-9.0347e-02, -2.7690e-03, -5.3224e-02, -5.5934e-02, -1.3836e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8000e-02, -6.3736e-02, -1.5082e-01,  3.6312e-02, -1.9862e-01],\n",
      "          [ 4.8823e-02, -8.4725e-02,  6.8034e-02,  1.8329e-01,  4.5708e-02],\n",
      "          [ 1.9683e-01, -5.6322e-02,  6.3535e-02,  3.6922e-02,  1.7151e-01],\n",
      "          [ 1.4225e-01, -1.6482e-01,  6.7343e-02,  1.3643e-01,  1.4066e-01],\n",
      "          [ 2.8197e-02, -1.7635e-01, -1.5050e-01,  3.3212e-03,  6.0210e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8715e-02, -1.2924e-01,  1.1012e-01,  8.7607e-03, -1.6257e-01],\n",
      "          [ 7.7766e-02, -1.5367e-01,  1.5281e-01, -5.8361e-02,  1.0171e-01],\n",
      "          [ 1.7840e-01, -1.7470e-01, -1.5965e-01,  5.9101e-02,  1.6743e-01],\n",
      "          [-1.0642e-01, -7.9235e-03, -1.2118e-01, -1.6437e-01, -1.5323e-01],\n",
      "          [ 1.4803e-01,  1.1819e-01, -2.5592e-02,  6.2606e-02,  4.4999e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6631e-01, -1.3663e-01, -1.0860e-01,  1.8708e-01, -1.7883e-01],\n",
      "          [ 1.1482e-02, -1.2443e-01, -1.0491e-01, -9.3156e-02,  6.7180e-02],\n",
      "          [ 8.2907e-02,  1.0562e-01, -3.0791e-02, -8.7147e-02, -2.5293e-02],\n",
      "          [ 6.1346e-03,  1.6903e-01,  3.4932e-02, -1.4125e-01,  1.1192e-02],\n",
      "          [ 1.1734e-01,  1.3849e-01,  1.8247e-01, -6.6997e-02,  1.4443e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5675e-02,  1.7151e-02,  1.8107e-01, -6.6976e-02, -1.6386e-01],\n",
      "          [ 1.8581e-01,  1.1274e-01,  7.9142e-02,  1.4690e-01, -1.3505e-01],\n",
      "          [ 1.1049e-01,  1.0505e-01, -1.2216e-02, -1.7340e-01,  1.1556e-01],\n",
      "          [-5.8734e-02, -7.1824e-02, -3.7298e-02,  1.0030e-01, -6.1381e-02],\n",
      "          [ 1.6798e-01,  2.4707e-02, -8.9779e-02, -3.4683e-02,  6.7887e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0472e-02, -1.6816e-01,  1.6501e-01, -1.4424e-01,  1.4948e-01],\n",
      "          [ 1.3995e-01, -6.1184e-02, -1.7629e-02, -7.1295e-02, -1.3393e-01],\n",
      "          [ 2.0582e-02,  1.8349e-01, -1.7890e-01,  1.5396e-01, -5.8100e-02],\n",
      "          [ 1.8454e-01, -1.3551e-02,  2.1506e-02, -1.6931e-01, -1.8765e-01],\n",
      "          [ 1.0588e-01, -9.1665e-02, -1.6879e-01, -1.2527e-01, -1.0091e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9449e-02,  1.2685e-01,  7.2299e-02,  4.6595e-02,  1.9679e-01],\n",
      "          [ 2.2285e-02,  2.2567e-02,  1.0742e-01, -6.6561e-02,  1.8148e-01],\n",
      "          [ 5.5963e-02,  1.6754e-01,  7.0529e-02,  4.2915e-02, -6.9040e-02],\n",
      "          [ 4.6791e-02,  1.9311e-01, -5.7044e-02, -7.8055e-02, -1.4386e-01],\n",
      "          [-1.7197e-01, -1.6560e-01,  8.5198e-02, -1.8517e-01, -2.0688e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3139e-01,  1.4070e-01,  2.7097e-02, -1.5805e-01,  1.2808e-01],\n",
      "          [-1.7832e-01,  6.4503e-02,  2.9197e-02,  1.6657e-01, -4.3565e-02],\n",
      "          [ 5.4102e-02, -3.9023e-02,  3.9094e-02,  1.2332e-01,  1.4203e-01],\n",
      "          [ 5.1546e-02, -5.7866e-02,  1.5820e-01,  1.4223e-03,  4.3801e-02],\n",
      "          [ 6.5623e-02, -1.4990e-01,  1.2141e-01, -1.3783e-02,  8.0581e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1322e-01, -1.9726e-01,  7.9353e-03, -4.4787e-02,  1.6848e-01],\n",
      "          [ 7.8345e-02, -4.2794e-02,  1.8022e-01,  1.5772e-01,  7.7809e-02],\n",
      "          [ 1.0495e-01, -1.7089e-01,  1.3323e-01,  2.5954e-02,  9.5799e-04],\n",
      "          [ 1.4828e-01,  1.6508e-01, -7.2082e-03,  1.0186e-01, -1.7378e-01],\n",
      "          [-1.1721e-01,  3.0324e-04, -2.0825e-02,  9.1728e-02,  7.0678e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9776e-02, -1.3168e-01,  2.4154e-02, -4.5304e-02,  6.8677e-02],\n",
      "          [-1.8232e-01,  9.1022e-02, -7.2123e-02, -9.7199e-03, -3.1094e-02],\n",
      "          [ 2.8557e-02,  3.9763e-02, -3.2785e-02,  1.2154e-01, -1.2906e-01],\n",
      "          [ 1.1970e-01, -2.9830e-02, -1.2073e-01,  1.4320e-01, -1.1444e-01],\n",
      "          [ 1.5797e-01, -1.8464e-02, -5.0214e-02, -4.5412e-02, -1.5845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2919e-01, -2.3971e-02,  1.6241e-01, -1.2552e-01,  1.0633e-01],\n",
      "          [-1.7193e-01, -8.4782e-02,  1.5894e-01,  3.8409e-02, -1.8693e-01],\n",
      "          [-1.0562e-01,  6.0506e-02,  6.0093e-02,  2.5464e-02, -1.2752e-01],\n",
      "          [-1.6392e-02, -5.1873e-02,  1.9090e-01,  1.1538e-01, -1.1494e-02],\n",
      "          [ 4.7702e-02,  9.9459e-04, -1.1322e-01,  1.0613e-01, -9.6574e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4468e-02, -1.9568e-01, -8.3747e-02,  2.1697e-02, -1.6775e-01],\n",
      "          [-9.4823e-03,  6.9211e-02, -1.5341e-01,  9.8999e-02,  1.9264e-01],\n",
      "          [-5.4513e-02, -4.0235e-02, -1.1080e-01,  3.4654e-02, -1.1992e-01],\n",
      "          [ 1.6636e-01,  8.5964e-02,  5.3202e-02,  1.4344e-01,  9.3552e-02],\n",
      "          [ 1.8168e-01,  9.4864e-02, -6.3565e-02,  1.6350e-01, -7.3253e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7767e-01,  9.4857e-02,  1.3126e-01,  1.3162e-01, -1.8681e-01],\n",
      "          [-1.5823e-01, -1.1111e-02,  1.1166e-01,  4.4050e-02,  1.4993e-01],\n",
      "          [ 9.4183e-02, -7.8399e-02,  6.6749e-02, -1.6290e-02,  1.2230e-01],\n",
      "          [ 1.7485e-01, -4.1142e-02,  1.3335e-01, -1.4768e-01, -7.8840e-02],\n",
      "          [-1.3098e-01,  1.0426e-01, -6.6484e-02,  6.0214e-02,  1.2992e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9978e-01,  6.4416e-02,  6.5184e-02,  1.5113e-01, -1.5479e-01],\n",
      "          [-1.7515e-01, -4.4054e-02,  1.1378e-01,  1.7940e-01, -1.7875e-01],\n",
      "          [ 8.9578e-02,  1.9231e-01,  1.4054e-01,  1.6426e-01,  2.6875e-02],\n",
      "          [-5.9233e-02,  1.1354e-01,  1.5061e-01,  5.0135e-02, -3.3059e-02],\n",
      "          [ 1.8981e-01, -9.1344e-02,  9.9926e-02,  1.9885e-01, -6.9535e-02]]]])\n",
      "Name: conv_layers.0.bias\n",
      "Parameters: tensor([-0.0573,  0.0840, -0.1971, -0.0123,  0.0091,  0.1132,  0.1386, -0.1841,\n",
      "        -0.0115, -0.0262,  0.0195,  0.1285, -0.0273, -0.1999, -0.1102, -0.1538,\n",
      "         0.1940,  0.1120,  0.1132,  0.0043])\n",
      "Name: conv_layers.2.weight\n",
      "Parameters: tensor([[[[-1.3871e-02,  1.8138e-03,  2.7409e-02,  1.9202e-03,  3.5283e-02],\n",
      "          [ 2.6181e-02, -1.2598e-03, -7.3440e-03,  4.4750e-03,  4.2259e-02],\n",
      "          [ 1.3897e-02, -3.8882e-02,  2.5302e-02,  9.9060e-03, -1.5260e-02],\n",
      "          [ 3.9157e-02, -4.0127e-02, -4.2976e-02,  3.9782e-02, -1.5026e-02],\n",
      "          [-1.7793e-02, -1.1287e-02, -4.0245e-02, -2.5290e-02, -1.5126e-03]],\n",
      "\n",
      "         [[-1.8095e-02, -2.9858e-02,  1.8384e-02,  4.2637e-03, -1.4755e-02],\n",
      "          [-2.0695e-02,  1.8060e-02, -1.5756e-02,  2.3952e-02, -4.2352e-02],\n",
      "          [ 2.3106e-02,  6.3974e-03,  6.0189e-04,  1.3654e-02, -1.3639e-02],\n",
      "          [-3.7988e-03, -3.6270e-02,  2.3508e-02, -6.1616e-03, -2.5438e-02],\n",
      "          [-1.7730e-02,  2.2161e-02,  1.6720e-02, -3.2676e-02,  9.0513e-03]],\n",
      "\n",
      "         [[ 1.4793e-02,  1.6415e-02, -2.8927e-02,  8.1149e-03,  3.6316e-02],\n",
      "          [ 1.8483e-02, -1.4564e-02,  4.2133e-02,  2.2380e-02, -1.8128e-02],\n",
      "          [-1.4943e-02, -3.3563e-02, -1.0543e-02,  2.4182e-02,  3.5721e-02],\n",
      "          [ 1.2420e-02, -9.2878e-03, -4.2604e-02,  3.0411e-02,  8.3704e-03],\n",
      "          [-3.6704e-02, -1.4528e-02, -8.2998e-03, -1.6295e-02, -1.3609e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0465e-03,  1.7051e-02,  7.7259e-03, -3.8155e-03,  3.9476e-03],\n",
      "          [ 3.1129e-02, -4.3741e-02, -2.0728e-02, -8.6993e-03,  2.7008e-02],\n",
      "          [-9.1237e-03, -3.5947e-02, -2.1752e-03, -1.9814e-02,  2.8245e-02],\n",
      "          [ 3.9406e-03,  3.3105e-03, -1.5305e-03,  2.5063e-02, -4.6007e-03],\n",
      "          [ 3.7993e-02, -1.6980e-02, -2.2232e-02, -1.1428e-02,  2.9301e-02]],\n",
      "\n",
      "         [[-6.4159e-03,  2.1685e-02,  8.6689e-03,  8.6723e-03,  1.8453e-02],\n",
      "          [-3.0057e-02,  4.0051e-02,  4.1262e-02,  2.9822e-02,  2.1606e-02],\n",
      "          [-2.1487e-02, -3.8540e-02, -9.6918e-03,  3.5614e-02,  2.3266e-02],\n",
      "          [ 4.3648e-02, -1.2313e-02,  4.0020e-02, -9.2189e-03, -2.5507e-02],\n",
      "          [ 2.3909e-02,  2.4166e-02,  2.8090e-02,  4.0647e-02, -2.8616e-02]],\n",
      "\n",
      "         [[ 2.0415e-03,  2.2509e-03,  2.5001e-02,  3.0924e-02, -3.3789e-03],\n",
      "          [ 8.6982e-03,  3.3180e-02, -1.8352e-02, -4.1864e-02, -3.5893e-02],\n",
      "          [ 3.2103e-02,  1.0422e-02, -2.7926e-02, -3.0336e-02, -2.0639e-02],\n",
      "          [-3.0402e-02, -1.1929e-02,  2.1070e-02,  8.6693e-03, -3.4097e-02],\n",
      "          [-3.5102e-02,  1.8101e-02, -2.5006e-02, -2.2366e-02,  3.0084e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9222e-02, -2.4327e-02,  1.3645e-02,  2.3390e-02,  3.0595e-02],\n",
      "          [ 2.6715e-02, -3.6614e-03, -2.1772e-02,  2.7429e-03,  1.1749e-02],\n",
      "          [ 2.4263e-02,  1.7774e-02,  3.4740e-02, -1.4598e-02, -3.5157e-02],\n",
      "          [ 2.4948e-03,  1.8638e-02, -2.5367e-02, -1.5732e-02,  3.7917e-03],\n",
      "          [-3.5909e-03,  3.6041e-02, -3.8344e-02, -4.1491e-02,  1.9854e-02]],\n",
      "\n",
      "         [[-2.6491e-02,  4.0159e-02, -4.1427e-02, -7.6170e-03, -7.3140e-03],\n",
      "          [-3.9630e-02, -1.1807e-02,  2.3813e-02,  1.7934e-03, -2.2907e-02],\n",
      "          [-3.9195e-02, -3.7322e-03,  4.9031e-03,  4.1874e-02,  2.5364e-02],\n",
      "          [ 3.0963e-02,  1.8185e-02,  3.2395e-02, -3.2413e-02, -1.2818e-02],\n",
      "          [ 4.6185e-03, -1.5100e-02, -8.0613e-03,  6.8208e-03, -2.4075e-02]],\n",
      "\n",
      "         [[-2.1455e-02, -2.7057e-03, -7.7437e-03,  2.6733e-04, -2.0691e-02],\n",
      "          [ 1.2371e-02,  1.2946e-02, -5.9853e-03, -5.1840e-03,  4.3210e-02],\n",
      "          [ 4.7497e-03,  2.1726e-02,  3.7029e-03,  4.0085e-02, -2.3352e-02],\n",
      "          [ 2.9196e-02, -1.6861e-02, -3.5422e-02, -4.9593e-03,  2.1213e-02],\n",
      "          [-8.5790e-03, -1.9741e-02, -2.4979e-02,  8.3580e-03, -3.0003e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2219e-02, -3.6488e-02,  8.1911e-03,  4.0574e-02,  2.7663e-02],\n",
      "          [ 3.8541e-02,  1.7447e-02,  3.3555e-02,  3.9525e-02,  1.2404e-02],\n",
      "          [-2.7404e-02,  1.0433e-03, -4.2537e-02,  3.6915e-03, -4.2093e-02],\n",
      "          [-1.0742e-02, -3.7113e-02,  8.2909e-03, -3.8922e-02, -3.9269e-02],\n",
      "          [-3.8352e-02,  1.9914e-02, -2.2876e-02, -4.3953e-02,  3.2267e-02]],\n",
      "\n",
      "         [[ 2.7342e-02, -2.2636e-02,  3.7276e-02, -2.6170e-02,  3.8131e-02],\n",
      "          [-4.1702e-02,  3.6494e-02,  3.4553e-02,  8.2889e-03, -1.3203e-02],\n",
      "          [ 2.1594e-02, -1.0232e-03, -1.3677e-02,  3.9646e-02,  6.8112e-03],\n",
      "          [ 3.0746e-02,  2.3654e-02, -2.5046e-02, -4.6949e-03, -1.2915e-02],\n",
      "          [ 2.7509e-02, -7.8877e-03,  7.3765e-03, -4.2027e-03,  8.1646e-03]],\n",
      "\n",
      "         [[ 3.4163e-02, -2.6366e-02,  4.4121e-02,  3.1600e-02, -1.1947e-02],\n",
      "          [-3.8639e-02,  3.0027e-02, -1.1069e-03,  3.3161e-02, -3.9655e-02],\n",
      "          [ 1.7341e-02,  3.0755e-02, -1.2879e-02,  5.1505e-05, -2.0856e-02],\n",
      "          [-1.0053e-02, -8.5097e-03, -2.5528e-02,  4.2424e-02, -1.7655e-02],\n",
      "          [-1.9958e-03,  4.2383e-02, -2.0389e-02, -2.1955e-02, -2.9821e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9111e-02, -9.8587e-03,  2.2674e-02,  4.1752e-02, -3.0308e-02],\n",
      "          [ 1.4281e-03,  1.4835e-02, -1.1873e-02, -4.3554e-02, -1.6282e-02],\n",
      "          [ 1.7979e-02,  3.7161e-03,  1.1927e-02, -3.1373e-02, -3.8399e-03],\n",
      "          [-1.7560e-02, -2.3035e-02, -1.8226e-03,  3.1850e-02,  2.0427e-02],\n",
      "          [ 3.7227e-02, -4.2418e-03, -4.5080e-03,  2.4929e-02,  7.2678e-04]],\n",
      "\n",
      "         [[ 1.8624e-02,  2.1771e-03,  2.9543e-03,  1.5655e-03, -1.9216e-02],\n",
      "          [-3.0592e-02,  4.6970e-03, -5.1550e-03, -3.1509e-02, -2.5539e-02],\n",
      "          [ 5.2691e-03,  1.1452e-02,  3.5991e-03, -5.6211e-03,  1.7269e-02],\n",
      "          [ 1.1463e-02, -1.9230e-02,  1.3327e-02, -2.2483e-02, -2.9959e-02],\n",
      "          [ 1.6108e-03, -4.0144e-02,  2.3154e-02,  2.1032e-02,  3.6967e-02]],\n",
      "\n",
      "         [[-1.7662e-02,  1.2009e-02,  6.9824e-03,  5.0339e-03, -2.3007e-02],\n",
      "          [-2.9563e-02, -2.0134e-02,  2.3330e-02, -1.2088e-02,  1.4290e-02],\n",
      "          [ 3.1472e-02,  1.1480e-02,  1.6631e-03,  7.0405e-03, -1.3417e-02],\n",
      "          [ 3.3113e-02,  8.7944e-03,  2.0377e-02,  3.7911e-02,  3.1440e-02],\n",
      "          [-1.7023e-03, -5.8193e-03, -1.3485e-02, -2.9056e-02, -1.9129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8464e-02,  4.3393e-03,  1.4314e-02,  1.9514e-02,  2.2890e-02],\n",
      "          [ 1.6913e-02,  3.6645e-03, -1.6260e-02, -3.3765e-02, -1.4770e-02],\n",
      "          [ 3.5910e-02, -7.2799e-03,  3.3204e-02, -2.5386e-02,  3.6073e-02],\n",
      "          [-3.1312e-02, -6.2849e-03,  4.0375e-02, -2.1666e-02, -1.0114e-02],\n",
      "          [-9.8907e-03,  3.4569e-02,  4.0549e-02, -1.1892e-02, -2.4159e-02]],\n",
      "\n",
      "         [[ 6.6576e-03, -3.2157e-02,  3.6202e-02,  2.8732e-02, -2.2077e-03],\n",
      "          [ 3.8741e-03,  4.4562e-03, -1.1733e-02, -1.8566e-02, -2.0058e-02],\n",
      "          [-2.6554e-02, -4.1024e-02, -1.7292e-02, -1.0175e-02,  9.5437e-03],\n",
      "          [-1.4051e-02,  4.0718e-02,  3.4673e-02,  2.5243e-02, -1.0394e-02],\n",
      "          [ 4.9209e-03,  3.1385e-02, -2.1820e-02, -1.2295e-02, -3.2178e-02]],\n",
      "\n",
      "         [[ 4.0259e-02, -1.1299e-02, -1.4106e-02,  3.2192e-02, -1.2603e-02],\n",
      "          [ 1.1950e-02,  4.2668e-02,  2.2611e-02, -4.0604e-02, -3.7600e-02],\n",
      "          [-1.7960e-02,  2.4670e-02, -3.2335e-02, -4.2435e-02,  8.7845e-03],\n",
      "          [-1.5702e-02,  1.0560e-02,  4.0255e-02,  1.9973e-02, -2.9173e-02],\n",
      "          [-2.9245e-02,  4.3673e-02, -2.9623e-02, -2.6126e-02,  3.6229e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3782e-02, -3.2018e-02, -4.1422e-02,  4.2965e-02,  4.1290e-02],\n",
      "          [ 2.6014e-02,  3.5790e-02, -3.1674e-02,  2.1011e-02, -3.2987e-02],\n",
      "          [-3.8864e-02, -3.4980e-02, -3.9175e-02,  2.2159e-02,  2.7862e-02],\n",
      "          [-1.5315e-02, -3.0641e-02,  2.4972e-02, -2.6885e-02, -1.8860e-02],\n",
      "          [-3.7953e-02, -2.5055e-03,  1.6515e-02, -3.8565e-03, -3.4413e-02]],\n",
      "\n",
      "         [[ 5.2746e-03, -5.7524e-03,  8.7690e-04,  2.1129e-02, -3.3714e-02],\n",
      "          [-2.5097e-02, -9.1407e-03, -1.2493e-02, -2.8287e-02,  8.1022e-03],\n",
      "          [-3.4974e-02, -8.4004e-03,  6.5616e-03, -3.1915e-02, -1.8039e-03],\n",
      "          [ 4.3422e-02,  2.5244e-02, -3.7508e-02, -1.5715e-04,  2.8635e-03],\n",
      "          [ 4.0159e-02, -1.0451e-02,  3.3808e-02,  2.2487e-03,  2.3882e-02]],\n",
      "\n",
      "         [[ 8.0380e-03,  3.9348e-02,  3.6196e-02, -1.2740e-02,  8.8485e-03],\n",
      "          [-2.9744e-02,  3.9094e-02,  2.5479e-02,  3.2697e-02,  3.4737e-02],\n",
      "          [-3.5794e-02, -4.2454e-02, -2.3609e-02,  1.8149e-02,  4.2802e-02],\n",
      "          [ 1.9548e-03,  3.2146e-02,  1.7434e-02, -2.2222e-02, -4.3828e-02],\n",
      "          [ 4.4119e-04,  2.0332e-02, -1.5830e-02,  3.0345e-02,  2.7871e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4941e-03,  2.4571e-02, -4.0033e-03, -2.4643e-02,  2.4928e-02],\n",
      "          [-2.4729e-02, -3.4175e-02,  1.5217e-02, -6.8067e-03, -1.5605e-02],\n",
      "          [-1.5520e-02,  1.3591e-02, -1.6952e-02,  2.3149e-02, -3.5015e-02],\n",
      "          [-3.8227e-02,  2.4797e-03, -1.7207e-02,  1.7616e-02,  3.8088e-02],\n",
      "          [ 3.7997e-02, -3.6835e-02, -2.2072e-02,  3.5769e-02,  1.6814e-02]],\n",
      "\n",
      "         [[-2.5929e-02, -1.4625e-02, -2.8879e-02, -3.1932e-03,  2.6450e-02],\n",
      "          [ 2.6795e-03,  3.4002e-02, -7.2258e-03,  2.3569e-02, -1.0126e-02],\n",
      "          [-1.3826e-02, -1.5366e-02, -2.0826e-02, -4.2160e-02,  2.9605e-02],\n",
      "          [-2.9491e-02, -5.9204e-04,  3.0640e-02, -3.2850e-02,  4.6293e-03],\n",
      "          [ 8.2218e-03,  3.3545e-02,  2.2686e-02,  3.7325e-02,  4.3212e-02]],\n",
      "\n",
      "         [[ 2.2121e-02, -1.0479e-02,  3.5456e-02,  1.9301e-02, -1.2956e-03],\n",
      "          [ 1.5912e-03,  2.9417e-03,  2.9833e-02,  4.1424e-02, -2.1308e-02],\n",
      "          [ 3.1825e-02,  2.2558e-02, -8.4701e-03,  3.9350e-02,  2.2740e-02],\n",
      "          [ 1.8655e-02,  9.8191e-03,  1.6428e-02, -4.1089e-02, -2.5863e-02],\n",
      "          [ 1.6437e-02,  4.3713e-02, -7.8577e-03,  4.3015e-02, -2.6737e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7608e-03, -4.1001e-02, -2.9989e-02,  5.7242e-03,  1.6483e-02],\n",
      "          [-2.1141e-02, -3.8201e-02,  2.6190e-03,  2.5314e-02,  6.5599e-03],\n",
      "          [ 7.4922e-03,  3.1143e-03,  3.9642e-02,  2.0673e-03, -1.5567e-02],\n",
      "          [-2.0046e-04,  2.7596e-02,  9.6397e-03,  1.6137e-02,  8.5051e-03],\n",
      "          [-2.9986e-02,  1.8297e-02, -3.6378e-03,  2.2362e-03, -1.7651e-02]],\n",
      "\n",
      "         [[-1.2912e-02, -2.2029e-02, -2.4961e-02, -1.9687e-02, -2.0274e-02],\n",
      "          [-1.8502e-02, -1.8732e-02, -1.6331e-02,  1.4594e-02,  2.7315e-02],\n",
      "          [ 2.7607e-02,  3.3074e-02, -2.5466e-02, -1.5396e-02,  4.2149e-03],\n",
      "          [ 4.2130e-02, -1.2793e-02,  1.5324e-02, -4.1559e-02, -2.1596e-02],\n",
      "          [-3.1985e-02,  4.2327e-02,  3.0103e-02, -1.8856e-02, -4.3335e-02]],\n",
      "\n",
      "         [[-8.8148e-03, -1.9361e-02, -2.7197e-02, -1.4601e-02,  2.9393e-02],\n",
      "          [-4.1036e-02, -4.0184e-02,  3.2189e-02, -2.5799e-02, -2.6795e-02],\n",
      "          [ 7.8577e-04, -1.6912e-02,  2.6480e-02,  6.3703e-03,  1.0465e-02],\n",
      "          [ 3.6253e-03, -2.3415e-02, -2.0984e-02, -1.4698e-02,  2.4545e-02],\n",
      "          [-2.6590e-02,  1.5386e-02, -4.5269e-03,  8.9440e-03,  2.8833e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9688e-02,  3.1305e-02,  1.0911e-02, -3.1096e-03, -6.1476e-03],\n",
      "          [ 4.4522e-02, -4.1974e-02,  1.4086e-03,  1.3176e-02, -3.5228e-02],\n",
      "          [ 4.3846e-02, -1.2587e-03, -3.4890e-02, -6.4030e-03,  3.9697e-03],\n",
      "          [-4.0698e-02,  1.3210e-02,  1.1198e-02, -1.1474e-02,  3.7271e-02],\n",
      "          [-1.7921e-02,  1.9403e-02, -1.1318e-02, -3.4611e-02,  4.0208e-02]],\n",
      "\n",
      "         [[-4.5511e-04, -3.8761e-02,  3.1732e-02,  2.4404e-03,  4.3232e-02],\n",
      "          [ 1.8153e-02, -2.1967e-02, -3.2062e-02, -2.4471e-02,  4.0476e-02],\n",
      "          [-2.7757e-02,  3.4205e-02,  3.3019e-02,  1.4792e-02,  9.9620e-04],\n",
      "          [ 9.9321e-03, -3.5928e-02,  1.7252e-02,  1.6250e-02,  4.9671e-03],\n",
      "          [ 4.3295e-04, -3.8847e-02, -4.0153e-02,  3.0456e-02,  5.4879e-03]],\n",
      "\n",
      "         [[-3.8609e-03,  3.3571e-02, -3.1285e-02, -2.3129e-02,  1.5465e-02],\n",
      "          [ 3.8651e-02,  3.4275e-02,  3.1002e-02,  2.8591e-04,  1.5209e-02],\n",
      "          [-8.5173e-03, -4.0278e-02,  8.8405e-03, -4.1458e-02, -2.9139e-02],\n",
      "          [-1.0918e-02,  1.5830e-02,  1.1770e-02, -2.9171e-02,  3.7284e-02],\n",
      "          [-3.1970e-03,  1.7156e-02, -4.3869e-02, -2.8430e-03, -4.6179e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5426e-03, -3.3489e-02,  4.3182e-02,  4.4257e-02,  2.2910e-02],\n",
      "          [ 1.0588e-02, -3.6287e-03, -1.2841e-02,  4.2236e-02,  2.1910e-02],\n",
      "          [ 2.5113e-02,  1.7791e-02, -2.8582e-02, -8.2183e-03,  4.2715e-02],\n",
      "          [-4.4355e-02, -8.3076e-03, -3.8030e-02,  1.8744e-02, -2.5378e-02],\n",
      "          [-3.6300e-02,  3.6503e-02,  4.3366e-02, -2.6602e-02,  4.5671e-04]],\n",
      "\n",
      "         [[-8.0117e-03,  1.2479e-02, -1.1636e-02, -2.2237e-02,  6.4645e-03],\n",
      "          [ 3.3277e-02, -2.6507e-02,  1.4027e-02, -3.5600e-02, -9.1320e-03],\n",
      "          [-2.6892e-02,  1.8206e-02, -1.3648e-02,  1.4801e-02, -1.0142e-02],\n",
      "          [ 3.2587e-02,  1.5215e-02,  1.8212e-02,  2.0784e-02, -2.4829e-02],\n",
      "          [-2.7623e-02, -2.1331e-02,  1.8614e-02,  8.3137e-03, -2.5571e-02]],\n",
      "\n",
      "         [[ 3.3985e-02,  2.0536e-02, -3.6736e-02, -3.4242e-02, -3.5011e-02],\n",
      "          [-1.2837e-02, -1.6274e-02, -3.8104e-02,  1.5304e-02,  3.1169e-02],\n",
      "          [ 3.7217e-02, -1.7904e-02,  1.4214e-03,  4.3906e-02,  4.3218e-02],\n",
      "          [ 4.9224e-03,  4.0308e-02,  3.9056e-02, -8.4914e-03, -7.2897e-03],\n",
      "          [ 3.2487e-02, -6.0824e-03,  3.4568e-02, -1.0007e-02, -2.7042e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8313e-02,  3.8931e-02,  4.1518e-02, -1.0579e-02, -3.9042e-02],\n",
      "          [ 2.4156e-02,  2.3572e-02,  3.4003e-02, -3.2104e-03,  4.0552e-02],\n",
      "          [ 1.9444e-02,  4.9861e-04, -1.0498e-02, -3.3191e-02,  3.1968e-02],\n",
      "          [-4.3698e-02, -4.1204e-02,  2.2203e-02, -3.6378e-02, -4.1366e-02],\n",
      "          [ 3.2657e-02, -1.2996e-02, -1.8007e-02, -2.5327e-02,  3.8129e-02]],\n",
      "\n",
      "         [[ 4.3869e-02, -1.5969e-02, -2.7958e-02, -4.0428e-02,  4.4211e-02],\n",
      "          [-1.4945e-02,  1.7142e-03,  2.9844e-03, -4.1683e-02, -1.0541e-02],\n",
      "          [-3.0339e-03, -3.9557e-02,  1.9041e-02,  1.3259e-02,  2.7224e-02],\n",
      "          [-5.7078e-03,  2.4114e-02,  2.3944e-02, -2.3861e-03, -3.2904e-02],\n",
      "          [ 2.6463e-02,  3.4529e-02,  6.5505e-03,  5.5897e-03, -3.4591e-02]],\n",
      "\n",
      "         [[-8.8023e-03, -1.4111e-02,  3.6047e-02, -2.7741e-02,  1.5809e-03],\n",
      "          [ 3.5177e-02,  1.1588e-02, -1.2560e-03,  4.1529e-02,  1.7147e-02],\n",
      "          [-3.4687e-02,  5.2443e-03,  2.3536e-02, -2.4470e-02, -7.5177e-03],\n",
      "          [ 1.8502e-02, -3.6382e-03,  3.0699e-02,  4.1438e-02, -6.3115e-04],\n",
      "          [-3.1555e-02, -4.1446e-02,  2.6937e-02,  2.7350e-02,  6.8305e-03]]]])\n",
      "Name: conv_layers.2.bias\n",
      "Parameters: tensor([ 0.0208, -0.0087,  0.0362, -0.0220, -0.0256,  0.0095,  0.0186, -0.0136,\n",
      "         0.0177, -0.0041,  0.0170, -0.0027, -0.0196,  0.0234, -0.0405, -0.0135,\n",
      "        -0.0309, -0.0404, -0.0075,  0.0444,  0.0423, -0.0372, -0.0131, -0.0381,\n",
      "         0.0133, -0.0289, -0.0221,  0.0352, -0.0110, -0.0044, -0.0370, -0.0284,\n",
      "         0.0397,  0.0232,  0.0216,  0.0064,  0.0168,  0.0110, -0.0194,  0.0445,\n",
      "         0.0036, -0.0137,  0.0069, -0.0088, -0.0233,  0.0234, -0.0068,  0.0105,\n",
      "        -0.0371, -0.0273, -0.0152, -0.0081,  0.0421,  0.0137, -0.0174, -0.0296,\n",
      "        -0.0234,  0.0100,  0.0340, -0.0171,  0.0026,  0.0309,  0.0317,  0.0267])\n"
     ]
    }
   ],
   "source": [
    "# `named_parameters()` & `data` attribute\n",
    "for name, param in model.named_parameters():\n",
    "    print(\"Name:\", name)\n",
    "    print(\"Parameters:\", param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a77c2157-f8b9-45d9-a3f8-ae182b742690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_layers.0.weight',\n",
       "              tensor([[[[ 1.3241e-01,  1.5604e-01, -1.0033e-01,  1.9216e-01, -6.9605e-02],\n",
       "                        [ 1.7387e-01, -8.7238e-02, -8.7400e-02, -6.6454e-03, -1.3710e-02],\n",
       "                        [ 4.7818e-02, -1.3161e-01, -1.2073e-01, -8.0846e-02, -1.4806e-01],\n",
       "                        [ 1.5466e-01,  1.7643e-01,  6.8757e-02, -1.3546e-01,  8.1396e-02],\n",
       "                        [ 1.4838e-01, -1.3129e-01, -3.4942e-02,  1.3256e-01,  1.8711e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7838e-01,  9.0442e-02,  9.4969e-02,  1.9040e-01, -5.6426e-02],\n",
       "                        [ 1.4222e-01,  1.0127e-01, -9.1116e-03, -2.4985e-02, -1.6505e-01],\n",
       "                        [ 1.7914e-01, -7.6648e-02, -1.7809e-01,  1.2110e-01, -5.1342e-02],\n",
       "                        [ 2.2690e-02,  1.5465e-01, -8.5308e-02, -4.7745e-02,  3.1571e-02],\n",
       "                        [ 2.8867e-02, -3.0587e-02, -3.1570e-02, -1.9829e-01, -4.0238e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3186e-01, -1.4602e-01,  9.5862e-02, -8.8489e-02, -9.6553e-02],\n",
       "                        [-1.3332e-01,  1.1675e-02,  1.6270e-01,  1.4342e-01,  1.4186e-02],\n",
       "                        [ 6.7934e-02,  1.0176e-02,  5.6962e-02,  1.9649e-01,  1.5693e-01],\n",
       "                        [-1.7073e-01, -2.1391e-02,  2.3361e-02,  3.1500e-02, -6.6577e-02],\n",
       "                        [ 7.7104e-02,  1.4623e-01, -7.9448e-03,  3.1214e-02, -7.6848e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7350e-02, -1.1280e-01, -1.1613e-01,  3.4520e-02, -9.1342e-03],\n",
       "                        [-1.3996e-01, -1.8361e-01,  1.1601e-01, -5.5225e-02, -5.4041e-02],\n",
       "                        [ 1.9208e-01, -9.1202e-02,  1.3636e-01,  7.3855e-02, -6.5894e-02],\n",
       "                        [ 1.3723e-02,  1.5521e-01,  7.8226e-02, -1.1209e-01, -1.5964e-01],\n",
       "                        [-6.5851e-02, -1.5129e-01, -5.2712e-02,  8.9967e-02, -1.8500e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2484e-01, -1.8534e-01,  3.6886e-02,  8.3262e-02,  6.8633e-02],\n",
       "                        [ 1.4270e-02,  1.6860e-01,  4.8610e-02, -1.8697e-01, -1.5962e-01],\n",
       "                        [-6.1016e-02, -1.6345e-02, -1.1608e-01, -1.8487e-01, -1.6567e-01],\n",
       "                        [-4.0601e-02,  8.8121e-02, -1.8425e-02, -3.8099e-02, -1.9318e-01],\n",
       "                        [-9.6685e-02,  4.7574e-02,  7.1982e-02,  1.3283e-01, -1.3550e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2990e-01, -1.8027e-02, -1.9720e-01, -1.0266e-01,  1.9599e-01],\n",
       "                        [ 2.3637e-03,  8.8786e-02, -3.4413e-02, -1.1878e-01,  1.4574e-01],\n",
       "                        [-1.1365e-01, -1.6888e-01,  5.0974e-05, -9.2363e-02, -4.1784e-02],\n",
       "                        [ 1.6196e-01,  1.4280e-01, -8.2476e-02,  1.4793e-01,  9.5471e-02],\n",
       "                        [ 9.4619e-02, -5.1215e-02,  7.4179e-02, -9.6469e-02, -8.7771e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1201e-01,  1.9360e-01, -1.8400e-01, -3.8823e-02,  1.8009e-01],\n",
       "                        [ 1.5503e-01, -1.8852e-01,  2.5678e-02,  1.9906e-01, -1.4539e-01],\n",
       "                        [-1.4287e-01, -1.7903e-01,  2.2451e-02,  1.4313e-01,  1.8826e-01],\n",
       "                        [ 1.1788e-01,  1.4232e-01, -2.2371e-02, -4.0267e-02,  1.7885e-01],\n",
       "                        [-9.0347e-02, -2.7690e-03, -5.3224e-02, -5.5934e-02, -1.3836e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.8000e-02, -6.3736e-02, -1.5082e-01,  3.6312e-02, -1.9862e-01],\n",
       "                        [ 4.8823e-02, -8.4725e-02,  6.8034e-02,  1.8329e-01,  4.5708e-02],\n",
       "                        [ 1.9683e-01, -5.6322e-02,  6.3535e-02,  3.6922e-02,  1.7151e-01],\n",
       "                        [ 1.4225e-01, -1.6482e-01,  6.7343e-02,  1.3643e-01,  1.4066e-01],\n",
       "                        [ 2.8197e-02, -1.7635e-01, -1.5050e-01,  3.3212e-03,  6.0210e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8715e-02, -1.2924e-01,  1.1012e-01,  8.7607e-03, -1.6257e-01],\n",
       "                        [ 7.7766e-02, -1.5367e-01,  1.5281e-01, -5.8361e-02,  1.0171e-01],\n",
       "                        [ 1.7840e-01, -1.7470e-01, -1.5965e-01,  5.9101e-02,  1.6743e-01],\n",
       "                        [-1.0642e-01, -7.9235e-03, -1.2118e-01, -1.6437e-01, -1.5323e-01],\n",
       "                        [ 1.4803e-01,  1.1819e-01, -2.5592e-02,  6.2606e-02,  4.4999e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6631e-01, -1.3663e-01, -1.0860e-01,  1.8708e-01, -1.7883e-01],\n",
       "                        [ 1.1482e-02, -1.2443e-01, -1.0491e-01, -9.3156e-02,  6.7180e-02],\n",
       "                        [ 8.2907e-02,  1.0562e-01, -3.0791e-02, -8.7147e-02, -2.5293e-02],\n",
       "                        [ 6.1346e-03,  1.6903e-01,  3.4932e-02, -1.4125e-01,  1.1192e-02],\n",
       "                        [ 1.1734e-01,  1.3849e-01,  1.8247e-01, -6.6997e-02,  1.4443e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5675e-02,  1.7151e-02,  1.8107e-01, -6.6976e-02, -1.6386e-01],\n",
       "                        [ 1.8581e-01,  1.1274e-01,  7.9142e-02,  1.4690e-01, -1.3505e-01],\n",
       "                        [ 1.1049e-01,  1.0505e-01, -1.2216e-02, -1.7340e-01,  1.1556e-01],\n",
       "                        [-5.8734e-02, -7.1824e-02, -3.7298e-02,  1.0030e-01, -6.1381e-02],\n",
       "                        [ 1.6798e-01,  2.4707e-02, -8.9779e-02, -3.4683e-02,  6.7887e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0472e-02, -1.6816e-01,  1.6501e-01, -1.4424e-01,  1.4948e-01],\n",
       "                        [ 1.3995e-01, -6.1184e-02, -1.7629e-02, -7.1295e-02, -1.3393e-01],\n",
       "                        [ 2.0582e-02,  1.8349e-01, -1.7890e-01,  1.5396e-01, -5.8100e-02],\n",
       "                        [ 1.8454e-01, -1.3551e-02,  2.1506e-02, -1.6931e-01, -1.8765e-01],\n",
       "                        [ 1.0588e-01, -9.1665e-02, -1.6879e-01, -1.2527e-01, -1.0091e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9449e-02,  1.2685e-01,  7.2299e-02,  4.6595e-02,  1.9679e-01],\n",
       "                        [ 2.2285e-02,  2.2567e-02,  1.0742e-01, -6.6561e-02,  1.8148e-01],\n",
       "                        [ 5.5963e-02,  1.6754e-01,  7.0529e-02,  4.2915e-02, -6.9040e-02],\n",
       "                        [ 4.6791e-02,  1.9311e-01, -5.7044e-02, -7.8055e-02, -1.4386e-01],\n",
       "                        [-1.7197e-01, -1.6560e-01,  8.5198e-02, -1.8517e-01, -2.0688e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3139e-01,  1.4070e-01,  2.7097e-02, -1.5805e-01,  1.2808e-01],\n",
       "                        [-1.7832e-01,  6.4503e-02,  2.9197e-02,  1.6657e-01, -4.3565e-02],\n",
       "                        [ 5.4102e-02, -3.9023e-02,  3.9094e-02,  1.2332e-01,  1.4203e-01],\n",
       "                        [ 5.1546e-02, -5.7866e-02,  1.5820e-01,  1.4223e-03,  4.3801e-02],\n",
       "                        [ 6.5623e-02, -1.4990e-01,  1.2141e-01, -1.3783e-02,  8.0581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1322e-01, -1.9726e-01,  7.9353e-03, -4.4787e-02,  1.6848e-01],\n",
       "                        [ 7.8345e-02, -4.2794e-02,  1.8022e-01,  1.5772e-01,  7.7809e-02],\n",
       "                        [ 1.0495e-01, -1.7089e-01,  1.3323e-01,  2.5954e-02,  9.5799e-04],\n",
       "                        [ 1.4828e-01,  1.6508e-01, -7.2082e-03,  1.0186e-01, -1.7378e-01],\n",
       "                        [-1.1721e-01,  3.0324e-04, -2.0825e-02,  9.1728e-02,  7.0678e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.9776e-02, -1.3168e-01,  2.4154e-02, -4.5304e-02,  6.8677e-02],\n",
       "                        [-1.8232e-01,  9.1022e-02, -7.2123e-02, -9.7199e-03, -3.1094e-02],\n",
       "                        [ 2.8557e-02,  3.9763e-02, -3.2785e-02,  1.2154e-01, -1.2906e-01],\n",
       "                        [ 1.1970e-01, -2.9830e-02, -1.2073e-01,  1.4320e-01, -1.1444e-01],\n",
       "                        [ 1.5797e-01, -1.8464e-02, -5.0214e-02, -4.5412e-02, -1.5845e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2919e-01, -2.3971e-02,  1.6241e-01, -1.2552e-01,  1.0633e-01],\n",
       "                        [-1.7193e-01, -8.4782e-02,  1.5894e-01,  3.8409e-02, -1.8693e-01],\n",
       "                        [-1.0562e-01,  6.0506e-02,  6.0093e-02,  2.5464e-02, -1.2752e-01],\n",
       "                        [-1.6392e-02, -5.1873e-02,  1.9090e-01,  1.1538e-01, -1.1494e-02],\n",
       "                        [ 4.7702e-02,  9.9459e-04, -1.1322e-01,  1.0613e-01, -9.6574e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4468e-02, -1.9568e-01, -8.3747e-02,  2.1697e-02, -1.6775e-01],\n",
       "                        [-9.4823e-03,  6.9211e-02, -1.5341e-01,  9.8999e-02,  1.9264e-01],\n",
       "                        [-5.4513e-02, -4.0235e-02, -1.1080e-01,  3.4654e-02, -1.1992e-01],\n",
       "                        [ 1.6636e-01,  8.5964e-02,  5.3202e-02,  1.4344e-01,  9.3552e-02],\n",
       "                        [ 1.8168e-01,  9.4864e-02, -6.3565e-02,  1.6350e-01, -7.3253e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7767e-01,  9.4857e-02,  1.3126e-01,  1.3162e-01, -1.8681e-01],\n",
       "                        [-1.5823e-01, -1.1111e-02,  1.1166e-01,  4.4050e-02,  1.4993e-01],\n",
       "                        [ 9.4183e-02, -7.8399e-02,  6.6749e-02, -1.6290e-02,  1.2230e-01],\n",
       "                        [ 1.7485e-01, -4.1142e-02,  1.3335e-01, -1.4768e-01, -7.8840e-02],\n",
       "                        [-1.3098e-01,  1.0426e-01, -6.6484e-02,  6.0214e-02,  1.2992e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9978e-01,  6.4416e-02,  6.5184e-02,  1.5113e-01, -1.5479e-01],\n",
       "                        [-1.7515e-01, -4.4054e-02,  1.1378e-01,  1.7940e-01, -1.7875e-01],\n",
       "                        [ 8.9578e-02,  1.9231e-01,  1.4054e-01,  1.6426e-01,  2.6875e-02],\n",
       "                        [-5.9233e-02,  1.1354e-01,  1.5061e-01,  5.0135e-02, -3.3059e-02],\n",
       "                        [ 1.8981e-01, -9.1344e-02,  9.9926e-02,  1.9885e-01, -6.9535e-02]]]])),\n",
       "             ('conv_layers.0.bias',\n",
       "              tensor([-0.0573,  0.0840, -0.1971, -0.0123,  0.0091,  0.1132,  0.1386, -0.1841,\n",
       "                      -0.0115, -0.0262,  0.0195,  0.1285, -0.0273, -0.1999, -0.1102, -0.1538,\n",
       "                       0.1940,  0.1120,  0.1132,  0.0043])),\n",
       "             ('conv_layers.2.weight',\n",
       "              tensor([[[[-1.3871e-02,  1.8138e-03,  2.7409e-02,  1.9202e-03,  3.5283e-02],\n",
       "                        [ 2.6181e-02, -1.2598e-03, -7.3440e-03,  4.4750e-03,  4.2259e-02],\n",
       "                        [ 1.3897e-02, -3.8882e-02,  2.5302e-02,  9.9060e-03, -1.5260e-02],\n",
       "                        [ 3.9157e-02, -4.0127e-02, -4.2976e-02,  3.9782e-02, -1.5026e-02],\n",
       "                        [-1.7793e-02, -1.1287e-02, -4.0245e-02, -2.5290e-02, -1.5126e-03]],\n",
       "              \n",
       "                       [[-1.8095e-02, -2.9858e-02,  1.8384e-02,  4.2637e-03, -1.4755e-02],\n",
       "                        [-2.0695e-02,  1.8060e-02, -1.5756e-02,  2.3952e-02, -4.2352e-02],\n",
       "                        [ 2.3106e-02,  6.3974e-03,  6.0189e-04,  1.3654e-02, -1.3639e-02],\n",
       "                        [-3.7988e-03, -3.6270e-02,  2.3508e-02, -6.1616e-03, -2.5438e-02],\n",
       "                        [-1.7730e-02,  2.2161e-02,  1.6720e-02, -3.2676e-02,  9.0513e-03]],\n",
       "              \n",
       "                       [[ 1.4793e-02,  1.6415e-02, -2.8927e-02,  8.1149e-03,  3.6316e-02],\n",
       "                        [ 1.8483e-02, -1.4564e-02,  4.2133e-02,  2.2380e-02, -1.8128e-02],\n",
       "                        [-1.4943e-02, -3.3563e-02, -1.0543e-02,  2.4182e-02,  3.5721e-02],\n",
       "                        [ 1.2420e-02, -9.2878e-03, -4.2604e-02,  3.0411e-02,  8.3704e-03],\n",
       "                        [-3.6704e-02, -1.4528e-02, -8.2998e-03, -1.6295e-02, -1.3609e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.0465e-03,  1.7051e-02,  7.7259e-03, -3.8155e-03,  3.9476e-03],\n",
       "                        [ 3.1129e-02, -4.3741e-02, -2.0728e-02, -8.6993e-03,  2.7008e-02],\n",
       "                        [-9.1237e-03, -3.5947e-02, -2.1752e-03, -1.9814e-02,  2.8245e-02],\n",
       "                        [ 3.9406e-03,  3.3105e-03, -1.5305e-03,  2.5063e-02, -4.6007e-03],\n",
       "                        [ 3.7993e-02, -1.6980e-02, -2.2232e-02, -1.1428e-02,  2.9301e-02]],\n",
       "              \n",
       "                       [[-6.4159e-03,  2.1685e-02,  8.6689e-03,  8.6723e-03,  1.8453e-02],\n",
       "                        [-3.0057e-02,  4.0051e-02,  4.1262e-02,  2.9822e-02,  2.1606e-02],\n",
       "                        [-2.1487e-02, -3.8540e-02, -9.6918e-03,  3.5614e-02,  2.3266e-02],\n",
       "                        [ 4.3648e-02, -1.2313e-02,  4.0020e-02, -9.2189e-03, -2.5507e-02],\n",
       "                        [ 2.3909e-02,  2.4166e-02,  2.8090e-02,  4.0647e-02, -2.8616e-02]],\n",
       "              \n",
       "                       [[ 2.0415e-03,  2.2509e-03,  2.5001e-02,  3.0924e-02, -3.3789e-03],\n",
       "                        [ 8.6982e-03,  3.3180e-02, -1.8352e-02, -4.1864e-02, -3.5893e-02],\n",
       "                        [ 3.2103e-02,  1.0422e-02, -2.7926e-02, -3.0336e-02, -2.0639e-02],\n",
       "                        [-3.0402e-02, -1.1929e-02,  2.1070e-02,  8.6693e-03, -3.4097e-02],\n",
       "                        [-3.5102e-02,  1.8101e-02, -2.5006e-02, -2.2366e-02,  3.0084e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9222e-02, -2.4327e-02,  1.3645e-02,  2.3390e-02,  3.0595e-02],\n",
       "                        [ 2.6715e-02, -3.6614e-03, -2.1772e-02,  2.7429e-03,  1.1749e-02],\n",
       "                        [ 2.4263e-02,  1.7774e-02,  3.4740e-02, -1.4598e-02, -3.5157e-02],\n",
       "                        [ 2.4948e-03,  1.8638e-02, -2.5367e-02, -1.5732e-02,  3.7917e-03],\n",
       "                        [-3.5909e-03,  3.6041e-02, -3.8344e-02, -4.1491e-02,  1.9854e-02]],\n",
       "              \n",
       "                       [[-2.6491e-02,  4.0159e-02, -4.1427e-02, -7.6170e-03, -7.3140e-03],\n",
       "                        [-3.9630e-02, -1.1807e-02,  2.3813e-02,  1.7934e-03, -2.2907e-02],\n",
       "                        [-3.9195e-02, -3.7322e-03,  4.9031e-03,  4.1874e-02,  2.5364e-02],\n",
       "                        [ 3.0963e-02,  1.8185e-02,  3.2395e-02, -3.2413e-02, -1.2818e-02],\n",
       "                        [ 4.6185e-03, -1.5100e-02, -8.0613e-03,  6.8208e-03, -2.4075e-02]],\n",
       "              \n",
       "                       [[-2.1455e-02, -2.7057e-03, -7.7437e-03,  2.6733e-04, -2.0691e-02],\n",
       "                        [ 1.2371e-02,  1.2946e-02, -5.9853e-03, -5.1840e-03,  4.3210e-02],\n",
       "                        [ 4.7497e-03,  2.1726e-02,  3.7029e-03,  4.0085e-02, -2.3352e-02],\n",
       "                        [ 2.9196e-02, -1.6861e-02, -3.5422e-02, -4.9593e-03,  2.1213e-02],\n",
       "                        [-8.5790e-03, -1.9741e-02, -2.4979e-02,  8.3580e-03, -3.0003e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2219e-02, -3.6488e-02,  8.1911e-03,  4.0574e-02,  2.7663e-02],\n",
       "                        [ 3.8541e-02,  1.7447e-02,  3.3555e-02,  3.9525e-02,  1.2404e-02],\n",
       "                        [-2.7404e-02,  1.0433e-03, -4.2537e-02,  3.6915e-03, -4.2093e-02],\n",
       "                        [-1.0742e-02, -3.7113e-02,  8.2909e-03, -3.8922e-02, -3.9269e-02],\n",
       "                        [-3.8352e-02,  1.9914e-02, -2.2876e-02, -4.3953e-02,  3.2267e-02]],\n",
       "              \n",
       "                       [[ 2.7342e-02, -2.2636e-02,  3.7276e-02, -2.6170e-02,  3.8131e-02],\n",
       "                        [-4.1702e-02,  3.6494e-02,  3.4553e-02,  8.2889e-03, -1.3203e-02],\n",
       "                        [ 2.1594e-02, -1.0232e-03, -1.3677e-02,  3.9646e-02,  6.8112e-03],\n",
       "                        [ 3.0746e-02,  2.3654e-02, -2.5046e-02, -4.6949e-03, -1.2915e-02],\n",
       "                        [ 2.7509e-02, -7.8877e-03,  7.3765e-03, -4.2027e-03,  8.1646e-03]],\n",
       "              \n",
       "                       [[ 3.4163e-02, -2.6366e-02,  4.4121e-02,  3.1600e-02, -1.1947e-02],\n",
       "                        [-3.8639e-02,  3.0027e-02, -1.1069e-03,  3.3161e-02, -3.9655e-02],\n",
       "                        [ 1.7341e-02,  3.0755e-02, -1.2879e-02,  5.1505e-05, -2.0856e-02],\n",
       "                        [-1.0053e-02, -8.5097e-03, -2.5528e-02,  4.2424e-02, -1.7655e-02],\n",
       "                        [-1.9958e-03,  4.2383e-02, -2.0389e-02, -2.1955e-02, -2.9821e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9111e-02, -9.8587e-03,  2.2674e-02,  4.1752e-02, -3.0308e-02],\n",
       "                        [ 1.4281e-03,  1.4835e-02, -1.1873e-02, -4.3554e-02, -1.6282e-02],\n",
       "                        [ 1.7979e-02,  3.7161e-03,  1.1927e-02, -3.1373e-02, -3.8399e-03],\n",
       "                        [-1.7560e-02, -2.3035e-02, -1.8226e-03,  3.1850e-02,  2.0427e-02],\n",
       "                        [ 3.7227e-02, -4.2418e-03, -4.5080e-03,  2.4929e-02,  7.2678e-04]],\n",
       "              \n",
       "                       [[ 1.8624e-02,  2.1771e-03,  2.9543e-03,  1.5655e-03, -1.9216e-02],\n",
       "                        [-3.0592e-02,  4.6970e-03, -5.1550e-03, -3.1509e-02, -2.5539e-02],\n",
       "                        [ 5.2691e-03,  1.1452e-02,  3.5991e-03, -5.6211e-03,  1.7269e-02],\n",
       "                        [ 1.1463e-02, -1.9230e-02,  1.3327e-02, -2.2483e-02, -2.9959e-02],\n",
       "                        [ 1.6108e-03, -4.0144e-02,  2.3154e-02,  2.1032e-02,  3.6967e-02]],\n",
       "              \n",
       "                       [[-1.7662e-02,  1.2009e-02,  6.9824e-03,  5.0339e-03, -2.3007e-02],\n",
       "                        [-2.9563e-02, -2.0134e-02,  2.3330e-02, -1.2088e-02,  1.4290e-02],\n",
       "                        [ 3.1472e-02,  1.1480e-02,  1.6631e-03,  7.0405e-03, -1.3417e-02],\n",
       "                        [ 3.3113e-02,  8.7944e-03,  2.0377e-02,  3.7911e-02,  3.1440e-02],\n",
       "                        [-1.7023e-03, -5.8193e-03, -1.3485e-02, -2.9056e-02, -1.9129e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8464e-02,  4.3393e-03,  1.4314e-02,  1.9514e-02,  2.2890e-02],\n",
       "                        [ 1.6913e-02,  3.6645e-03, -1.6260e-02, -3.3765e-02, -1.4770e-02],\n",
       "                        [ 3.5910e-02, -7.2799e-03,  3.3204e-02, -2.5386e-02,  3.6073e-02],\n",
       "                        [-3.1312e-02, -6.2849e-03,  4.0375e-02, -2.1666e-02, -1.0114e-02],\n",
       "                        [-9.8907e-03,  3.4569e-02,  4.0549e-02, -1.1892e-02, -2.4159e-02]],\n",
       "              \n",
       "                       [[ 6.6576e-03, -3.2157e-02,  3.6202e-02,  2.8732e-02, -2.2077e-03],\n",
       "                        [ 3.8741e-03,  4.4562e-03, -1.1733e-02, -1.8566e-02, -2.0058e-02],\n",
       "                        [-2.6554e-02, -4.1024e-02, -1.7292e-02, -1.0175e-02,  9.5437e-03],\n",
       "                        [-1.4051e-02,  4.0718e-02,  3.4673e-02,  2.5243e-02, -1.0394e-02],\n",
       "                        [ 4.9209e-03,  3.1385e-02, -2.1820e-02, -1.2295e-02, -3.2178e-02]],\n",
       "              \n",
       "                       [[ 4.0259e-02, -1.1299e-02, -1.4106e-02,  3.2192e-02, -1.2603e-02],\n",
       "                        [ 1.1950e-02,  4.2668e-02,  2.2611e-02, -4.0604e-02, -3.7600e-02],\n",
       "                        [-1.7960e-02,  2.4670e-02, -3.2335e-02, -4.2435e-02,  8.7845e-03],\n",
       "                        [-1.5702e-02,  1.0560e-02,  4.0255e-02,  1.9973e-02, -2.9173e-02],\n",
       "                        [-2.9245e-02,  4.3673e-02, -2.9623e-02, -2.6126e-02,  3.6229e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.3782e-02, -3.2018e-02, -4.1422e-02,  4.2965e-02,  4.1290e-02],\n",
       "                        [ 2.6014e-02,  3.5790e-02, -3.1674e-02,  2.1011e-02, -3.2987e-02],\n",
       "                        [-3.8864e-02, -3.4980e-02, -3.9175e-02,  2.2159e-02,  2.7862e-02],\n",
       "                        [-1.5315e-02, -3.0641e-02,  2.4972e-02, -2.6885e-02, -1.8860e-02],\n",
       "                        [-3.7953e-02, -2.5055e-03,  1.6515e-02, -3.8565e-03, -3.4413e-02]],\n",
       "              \n",
       "                       [[ 5.2746e-03, -5.7524e-03,  8.7690e-04,  2.1129e-02, -3.3714e-02],\n",
       "                        [-2.5097e-02, -9.1407e-03, -1.2493e-02, -2.8287e-02,  8.1022e-03],\n",
       "                        [-3.4974e-02, -8.4004e-03,  6.5616e-03, -3.1915e-02, -1.8039e-03],\n",
       "                        [ 4.3422e-02,  2.5244e-02, -3.7508e-02, -1.5715e-04,  2.8635e-03],\n",
       "                        [ 4.0159e-02, -1.0451e-02,  3.3808e-02,  2.2487e-03,  2.3882e-02]],\n",
       "              \n",
       "                       [[ 8.0380e-03,  3.9348e-02,  3.6196e-02, -1.2740e-02,  8.8485e-03],\n",
       "                        [-2.9744e-02,  3.9094e-02,  2.5479e-02,  3.2697e-02,  3.4737e-02],\n",
       "                        [-3.5794e-02, -4.2454e-02, -2.3609e-02,  1.8149e-02,  4.2802e-02],\n",
       "                        [ 1.9548e-03,  3.2146e-02,  1.7434e-02, -2.2222e-02, -4.3828e-02],\n",
       "                        [ 4.4119e-04,  2.0332e-02, -1.5830e-02,  3.0345e-02,  2.7871e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.4941e-03,  2.4571e-02, -4.0033e-03, -2.4643e-02,  2.4928e-02],\n",
       "                        [-2.4729e-02, -3.4175e-02,  1.5217e-02, -6.8067e-03, -1.5605e-02],\n",
       "                        [-1.5520e-02,  1.3591e-02, -1.6952e-02,  2.3149e-02, -3.5015e-02],\n",
       "                        [-3.8227e-02,  2.4797e-03, -1.7207e-02,  1.7616e-02,  3.8088e-02],\n",
       "                        [ 3.7997e-02, -3.6835e-02, -2.2072e-02,  3.5769e-02,  1.6814e-02]],\n",
       "              \n",
       "                       [[-2.5929e-02, -1.4625e-02, -2.8879e-02, -3.1932e-03,  2.6450e-02],\n",
       "                        [ 2.6795e-03,  3.4002e-02, -7.2258e-03,  2.3569e-02, -1.0126e-02],\n",
       "                        [-1.3826e-02, -1.5366e-02, -2.0826e-02, -4.2160e-02,  2.9605e-02],\n",
       "                        [-2.9491e-02, -5.9204e-04,  3.0640e-02, -3.2850e-02,  4.6293e-03],\n",
       "                        [ 8.2218e-03,  3.3545e-02,  2.2686e-02,  3.7325e-02,  4.3212e-02]],\n",
       "              \n",
       "                       [[ 2.2121e-02, -1.0479e-02,  3.5456e-02,  1.9301e-02, -1.2956e-03],\n",
       "                        [ 1.5912e-03,  2.9417e-03,  2.9833e-02,  4.1424e-02, -2.1308e-02],\n",
       "                        [ 3.1825e-02,  2.2558e-02, -8.4701e-03,  3.9350e-02,  2.2740e-02],\n",
       "                        [ 1.8655e-02,  9.8191e-03,  1.6428e-02, -4.1089e-02, -2.5863e-02],\n",
       "                        [ 1.6437e-02,  4.3713e-02, -7.8577e-03,  4.3015e-02, -2.6737e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7608e-03, -4.1001e-02, -2.9989e-02,  5.7242e-03,  1.6483e-02],\n",
       "                        [-2.1141e-02, -3.8201e-02,  2.6190e-03,  2.5314e-02,  6.5599e-03],\n",
       "                        [ 7.4922e-03,  3.1143e-03,  3.9642e-02,  2.0673e-03, -1.5567e-02],\n",
       "                        [-2.0046e-04,  2.7596e-02,  9.6397e-03,  1.6137e-02,  8.5051e-03],\n",
       "                        [-2.9986e-02,  1.8297e-02, -3.6378e-03,  2.2362e-03, -1.7651e-02]],\n",
       "              \n",
       "                       [[-1.2912e-02, -2.2029e-02, -2.4961e-02, -1.9687e-02, -2.0274e-02],\n",
       "                        [-1.8502e-02, -1.8732e-02, -1.6331e-02,  1.4594e-02,  2.7315e-02],\n",
       "                        [ 2.7607e-02,  3.3074e-02, -2.5466e-02, -1.5396e-02,  4.2149e-03],\n",
       "                        [ 4.2130e-02, -1.2793e-02,  1.5324e-02, -4.1559e-02, -2.1596e-02],\n",
       "                        [-3.1985e-02,  4.2327e-02,  3.0103e-02, -1.8856e-02, -4.3335e-02]],\n",
       "              \n",
       "                       [[-8.8148e-03, -1.9361e-02, -2.7197e-02, -1.4601e-02,  2.9393e-02],\n",
       "                        [-4.1036e-02, -4.0184e-02,  3.2189e-02, -2.5799e-02, -2.6795e-02],\n",
       "                        [ 7.8577e-04, -1.6912e-02,  2.6480e-02,  6.3703e-03,  1.0465e-02],\n",
       "                        [ 3.6253e-03, -2.3415e-02, -2.0984e-02, -1.4698e-02,  2.4545e-02],\n",
       "                        [-2.6590e-02,  1.5386e-02, -4.5269e-03,  8.9440e-03,  2.8833e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.9688e-02,  3.1305e-02,  1.0911e-02, -3.1096e-03, -6.1476e-03],\n",
       "                        [ 4.4522e-02, -4.1974e-02,  1.4086e-03,  1.3176e-02, -3.5228e-02],\n",
       "                        [ 4.3846e-02, -1.2587e-03, -3.4890e-02, -6.4030e-03,  3.9697e-03],\n",
       "                        [-4.0698e-02,  1.3210e-02,  1.1198e-02, -1.1474e-02,  3.7271e-02],\n",
       "                        [-1.7921e-02,  1.9403e-02, -1.1318e-02, -3.4611e-02,  4.0208e-02]],\n",
       "              \n",
       "                       [[-4.5511e-04, -3.8761e-02,  3.1732e-02,  2.4404e-03,  4.3232e-02],\n",
       "                        [ 1.8153e-02, -2.1967e-02, -3.2062e-02, -2.4471e-02,  4.0476e-02],\n",
       "                        [-2.7757e-02,  3.4205e-02,  3.3019e-02,  1.4792e-02,  9.9620e-04],\n",
       "                        [ 9.9321e-03, -3.5928e-02,  1.7252e-02,  1.6250e-02,  4.9671e-03],\n",
       "                        [ 4.3295e-04, -3.8847e-02, -4.0153e-02,  3.0456e-02,  5.4879e-03]],\n",
       "              \n",
       "                       [[-3.8609e-03,  3.3571e-02, -3.1285e-02, -2.3129e-02,  1.5465e-02],\n",
       "                        [ 3.8651e-02,  3.4275e-02,  3.1002e-02,  2.8591e-04,  1.5209e-02],\n",
       "                        [-8.5173e-03, -4.0278e-02,  8.8405e-03, -4.1458e-02, -2.9139e-02],\n",
       "                        [-1.0918e-02,  1.5830e-02,  1.1770e-02, -2.9171e-02,  3.7284e-02],\n",
       "                        [-3.1970e-03,  1.7156e-02, -4.3869e-02, -2.8430e-03, -4.6179e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5426e-03, -3.3489e-02,  4.3182e-02,  4.4257e-02,  2.2910e-02],\n",
       "                        [ 1.0588e-02, -3.6287e-03, -1.2841e-02,  4.2236e-02,  2.1910e-02],\n",
       "                        [ 2.5113e-02,  1.7791e-02, -2.8582e-02, -8.2183e-03,  4.2715e-02],\n",
       "                        [-4.4355e-02, -8.3076e-03, -3.8030e-02,  1.8744e-02, -2.5378e-02],\n",
       "                        [-3.6300e-02,  3.6503e-02,  4.3366e-02, -2.6602e-02,  4.5671e-04]],\n",
       "              \n",
       "                       [[-8.0117e-03,  1.2479e-02, -1.1636e-02, -2.2237e-02,  6.4645e-03],\n",
       "                        [ 3.3277e-02, -2.6507e-02,  1.4027e-02, -3.5600e-02, -9.1320e-03],\n",
       "                        [-2.6892e-02,  1.8206e-02, -1.3648e-02,  1.4801e-02, -1.0142e-02],\n",
       "                        [ 3.2587e-02,  1.5215e-02,  1.8212e-02,  2.0784e-02, -2.4829e-02],\n",
       "                        [-2.7623e-02, -2.1331e-02,  1.8614e-02,  8.3137e-03, -2.5571e-02]],\n",
       "              \n",
       "                       [[ 3.3985e-02,  2.0536e-02, -3.6736e-02, -3.4242e-02, -3.5011e-02],\n",
       "                        [-1.2837e-02, -1.6274e-02, -3.8104e-02,  1.5304e-02,  3.1169e-02],\n",
       "                        [ 3.7217e-02, -1.7904e-02,  1.4214e-03,  4.3906e-02,  4.3218e-02],\n",
       "                        [ 4.9224e-03,  4.0308e-02,  3.9056e-02, -8.4914e-03, -7.2897e-03],\n",
       "                        [ 3.2487e-02, -6.0824e-03,  3.4568e-02, -1.0007e-02, -2.7042e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.8313e-02,  3.8931e-02,  4.1518e-02, -1.0579e-02, -3.9042e-02],\n",
       "                        [ 2.4156e-02,  2.3572e-02,  3.4003e-02, -3.2104e-03,  4.0552e-02],\n",
       "                        [ 1.9444e-02,  4.9861e-04, -1.0498e-02, -3.3191e-02,  3.1968e-02],\n",
       "                        [-4.3698e-02, -4.1204e-02,  2.2203e-02, -3.6378e-02, -4.1366e-02],\n",
       "                        [ 3.2657e-02, -1.2996e-02, -1.8007e-02, -2.5327e-02,  3.8129e-02]],\n",
       "              \n",
       "                       [[ 4.3869e-02, -1.5969e-02, -2.7958e-02, -4.0428e-02,  4.4211e-02],\n",
       "                        [-1.4945e-02,  1.7142e-03,  2.9844e-03, -4.1683e-02, -1.0541e-02],\n",
       "                        [-3.0339e-03, -3.9557e-02,  1.9041e-02,  1.3259e-02,  2.7224e-02],\n",
       "                        [-5.7078e-03,  2.4114e-02,  2.3944e-02, -2.3861e-03, -3.2904e-02],\n",
       "                        [ 2.6463e-02,  3.4529e-02,  6.5505e-03,  5.5897e-03, -3.4591e-02]],\n",
       "              \n",
       "                       [[-8.8023e-03, -1.4111e-02,  3.6047e-02, -2.7741e-02,  1.5809e-03],\n",
       "                        [ 3.5177e-02,  1.1588e-02, -1.2560e-03,  4.1529e-02,  1.7147e-02],\n",
       "                        [-3.4687e-02,  5.2443e-03,  2.3536e-02, -2.4470e-02, -7.5177e-03],\n",
       "                        [ 1.8502e-02, -3.6382e-03,  3.0699e-02,  4.1438e-02, -6.3115e-04],\n",
       "                        [-3.1555e-02, -4.1446e-02,  2.6937e-02,  2.7350e-02,  6.8305e-03]]]])),\n",
       "             ('conv_layers.2.bias',\n",
       "              tensor([ 0.0208, -0.0087,  0.0362, -0.0220, -0.0256,  0.0095,  0.0186, -0.0136,\n",
       "                       0.0177, -0.0041,  0.0170, -0.0027, -0.0196,  0.0234, -0.0405, -0.0135,\n",
       "                      -0.0309, -0.0404, -0.0075,  0.0444,  0.0423, -0.0372, -0.0131, -0.0381,\n",
       "                       0.0133, -0.0289, -0.0221,  0.0352, -0.0110, -0.0044, -0.0370, -0.0284,\n",
       "                       0.0397,  0.0232,  0.0216,  0.0064,  0.0168,  0.0110, -0.0194,  0.0445,\n",
       "                       0.0036, -0.0137,  0.0069, -0.0088, -0.0233,  0.0234, -0.0068,  0.0105,\n",
       "                      -0.0371, -0.0273, -0.0152, -0.0081,  0.0421,  0.0137, -0.0174, -0.0296,\n",
       "                      -0.0234,  0.0100,  0.0340, -0.0171,  0.0026,  0.0309,  0.0317,  0.0267]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `state_dict()`\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67e60a-08b4-429d-b947-347280bd0973",
   "metadata": {},
   "source": [
    "## 2-3. Activation Functions\n",
    "- [Non-Linear Activations](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a7b4c-1e47-4d90-b93f-1ccc9e8a4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "# import libraries\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939eebf-2647-4c47-a96b-86b19f313e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable to evaluate over\n",
    "x = torch.linspace(-3,3,101)\n",
    "\n",
    "# create a function that returns the activated output\n",
    "def NNoutputx(actfun):\n",
    "  # get activation function type\n",
    "  # this code replaces torch.relu with torch.<actfun>\n",
    "  actfun = getattr(torch,actfun)\n",
    "  return actfun( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b87acc-8d01-4c20-ad89-0ef166ff0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the activation functions\n",
    "activation_funs = [ 'relu', 'sigmoid', 'tanh' ]\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for actfun in activation_funs:\n",
    "  plt.plot(x,NNoutputx(actfun),label=actfun,linewidth=3)\n",
    "\n",
    "# add reference lines\n",
    "dashlinecol = [.7,.7,.7]\n",
    "plt.plot(x[[0,-1]],[0,0],'--',color=dashlinecol)\n",
    "plt.plot(x[[0,-1]],[1,1],'--',color=dashlinecol)\n",
    "plt.plot([0,0],[-1,3],'--',color=dashlinecol)\n",
    "\n",
    "# make the plot look nicer\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('$\\sigma(x)$')\n",
    "plt.title('Various activation functions')\n",
    "plt.xlim(x[[0,-1]])\n",
    "plt.ylim([-1,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a6945-9cd5-4910-986c-559df61657ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that returns the activated output FUNCTION\n",
    "# this is different from the previous function\n",
    "def NNoutput(actfun):\n",
    "  # get activation function type\n",
    "  # this code replaces torch.nn.relu with torch.nn.<actfun>\n",
    "  actfun = getattr(torch.nn,actfun)\n",
    "  return actfun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3b5d2-4feb-4f41-9d4a-5b15d4120143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the activation functions\n",
    "activation_funs = [ 'ReLU6', 'Hardshrink', 'LeakyReLU' ]\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for actfun in activation_funs:\n",
    "  plt.plot(x,NNoutput(actfun)(x),label=actfun,linewidth=3)\n",
    "\n",
    "# add reference lines\n",
    "dashlinecol = [.7,.7,.7]\n",
    "plt.plot(x[[0,-1]],[0,0],'--',color=dashlinecol)\n",
    "plt.plot(x[[0,-1]],[1,1],'--',color=dashlinecol)\n",
    "plt.plot([0,0],[-1,3],'--',color=dashlinecol)\n",
    "\n",
    "# make the plot look nicer\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('$\\sigma(x)$')\n",
    "plt.title('Various activation functions')\n",
    "plt.xlim(x[[0,-1]])\n",
    "plt.ylim([-1,3])\n",
    "# plt.ylim([-.1,.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65adada-cf93-40e9-b2df-6cc661076b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu6 in more detail\n",
    "x = torch.linspace(-3,9,101)\n",
    "relu6 = torch.nn.ReLU6()\n",
    "\n",
    "plt.plot(x,relu6(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a4315-3583-4b96-8db8-07ee867c9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine x (fewer points to facilitate visualization)\n",
    "x = torch.linspace(-3,3,21)\n",
    "\n",
    "# in torch\n",
    "y1 = torch.relu(x)\n",
    "\n",
    "# in torch.nn\n",
    "f = torch.nn.ReLU()\n",
    "y2 = f(x)\n",
    "\n",
    "\n",
    "# the results are the same\n",
    "plt.plot(x,y1,'ro',label='torch.relu')\n",
    "plt.plot(x,y2,'bx',label='torch.nn.ReLU')\n",
    "plt.legend()\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d9d7b-d56a-4235-91cc-70d15a5bbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input vectors\n",
    "x1 = torch.linspace(-1,1,20)\n",
    "x2 = 2*x1\n",
    "\n",
    "# and corresponding weights\n",
    "w1 = -.3\n",
    "w2 = .5\n",
    "\n",
    "# their linear combination\n",
    "linpart = x1*w1 + x2*w2\n",
    "\n",
    "# and the nonlinear output\n",
    "y = torch.relu(linpart)\n",
    "\n",
    "# and plot!\n",
    "plt.plot(x1,linpart,'bo-',label='Linear input')\n",
    "plt.plot(x1,y,'rs',label='Nonlinear output')\n",
    "plt.ylabel('$\\\\hat{y}$ (output of activation function)')\n",
    "plt.xlabel('x1 variable')\n",
    "# plt.ylim([-.1,.1]) # optional -- uncomment and modify to zoom in\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dd12c-8287-49b6-b4b2-2dafbb9f90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "# import the data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url,sep=';')\n",
    "data = data[data['total sulfur dioxide']<200] # drop a few outliers\n",
    "\n",
    "# z-score all columns except for quality\n",
    "cols2zscore = data.keys()\n",
    "cols2zscore = cols2zscore.drop('quality')\n",
    "data[cols2zscore] = data[cols2zscore].apply(stats.zscore)\n",
    "\n",
    "# create a new column for binarized (boolean) quality\n",
    "data['boolQuality'] = 0\n",
    "# data['boolQuality'][data['quality']<6] = 0 # implicit in the code! just here for clarity\n",
    "data['boolQuality'][data['quality']>5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36ef38-5a1c-4a94-91af-81610d81d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from pandas dataframe to tensor\n",
    "dataT  = torch.tensor( data[cols2zscore].values ).float()\n",
    "labels = torch.tensor( data['boolQuality'].values ).float()\n",
    "labels = labels[:,None] # transform to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1d4df-36ee-44d8-a7e5-18374115ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labels, test_size=.1)\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db06f7-ba6d-46c9-96fc-7f3ba0688c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "\n",
    "class ANNwine(nn.Module):\n",
    "  def __init__(self,actfun):\n",
    "    super().__init__()\n",
    "\n",
    "    ### input layer\n",
    "    self.input = nn.Linear(11,16)\n",
    "    \n",
    "    ### hidden layers\n",
    "    self.fc1 = nn.Linear(16,32)\n",
    "    self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "    ### output layer\n",
    "    self.output = nn.Linear(32,1)\n",
    "\n",
    "    # activation funcion to pass through\n",
    "    self.actfun = actfun\n",
    "  \n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    # get activation function type\n",
    "    # this code replaces torch.relu with torch.<self.actfun>\n",
    "    actfun = getattr(torch,self.actfun)\n",
    "    x = actfun( self.input(x) )\n",
    "    x = actfun( self.fc1(x) )\n",
    "    x = actfun( self.fc2(x) )\n",
    "    return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a314f3-9406-4b29-b317-b3d56fa5e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "# use sigmoid, relu, tanh\n",
    "net = ANNwine('sigmoid')\n",
    "net( torch.randn(10,11) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e3412-77f5-44e6-b462-8f5ef8c6e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 1000\n",
    "\n",
    "def trainTheModel():\n",
    "\n",
    "  # loss function and optimizer\n",
    "  lossfun = nn.BCEWithLogitsLoss()\n",
    "  optimizer = torch.optim.SGD(winenet.parameters(),lr=.01)\n",
    "\n",
    "  # initialize losses\n",
    "  losses   = torch.zeros(numepochs)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # turn on training mode\n",
    "    winenet.train()\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = winenet(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute training accuracy for this batch\n",
    "      batchAcc.append( 100*torch.mean(((yHat>0) == y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    winenet.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = winenet(X)\n",
    "    testAcc.append( 100*torch.mean(((yHat>0) == y).float()).item() )\n",
    "  \n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b796173-6993-4dcf-84d2-9efb74c3080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell takes ~2 mins\n",
    "\n",
    "# list activation functions to test\n",
    "activation_funs = [ 'relu', 'tanh', 'sigmoid' ]\n",
    "\n",
    "trainByAct = np.zeros((numepochs,len(activation_funs)))\n",
    "testByAct  = np.zeros((numepochs,len(activation_funs)))\n",
    "\n",
    "for ai,actfun in enumerate(activation_funs):\n",
    "  # create a model and train it\n",
    "  winenet = ANNwine(actfun)\n",
    "  trainByAct[:,ai],testByAct[:,ai],losses = trainTheModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff550ae5-a657-44a0-ba23-e6910ca982d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some results\n",
    "fig,ax = plt.subplots(1,2,figsize=(20,7))\n",
    "\n",
    "ax[0].plot(trainByAct)\n",
    "ax[0].set_title('Train accuracy')\n",
    "ax[1].plot(testByAct)\n",
    "ax[1].set_title('Test accuracy')\n",
    "\n",
    "# common features\n",
    "for i in range(2):\n",
    "  ax[i].legend(activation_funs)\n",
    "  ax[i].set_xlabel('Epoch')\n",
    "  ax[i].set_ylabel('Accuracy (%)')\n",
    "  ax[i].set_ylim([50,100])\n",
    "  ax[i].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3736fe1-bd47-464b-9d4c-6d6c9b6637ec",
   "metadata": {},
   "source": [
    "## 2-4. Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bf4e7-83b6-48e9-ac1e-5caf80412251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "aModel = nn.Sequential(\n",
    "    nn.Linear(10,14),  # input layer\n",
    "    nn.Linear(14,19),  # hidden layer\n",
    "    nn.Linear(19,8),   # output layer\n",
    "      )\n",
    "\n",
    "aModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4177c-e940-40ec-be93-61f760a468ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the sizes of the weights matrices in each layer\n",
    "for i in range(len(aModel)):\n",
    "  print( aModel[i].weight.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f17c0-ad5d-4cee-8248-b0362eb223c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = nn.Sequential(\n",
    "    nn.Linear(10,14),  # input layer\n",
    "    nn.Linear(14,9),   # hidden layer\n",
    "    nn.Linear(19,8),   # output layer\n",
    "      )\n",
    "\n",
    "for i in range(len(M2)):\n",
    "  print( M2[i].weight.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f926efc9-e26e-44df-8724-011e9dd160ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the data\n",
    "nsamples = 5\n",
    "nfeatures = 10\n",
    "\n",
    "fakedata = torch.randn(nsamples,nfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520e07f-0574-4ef9-ad8f-1432361f0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the first model\n",
    "\n",
    "# does the size of the output make sense?\n",
    "aModel(fakedata).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46e637-02ff-4b91-bc1f-0f676cd41502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the second model\n",
    "\n",
    "# does the size of the output make sense?\n",
    "M2(fakedata).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e8503-96dd-4cf1-ac4f-0ec5feb541fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2a33a-f45c-4fed-b5d7-e100da1d5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de681962-897f-4e0d-84a7-68c8a6655a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973d1c0-4baf-43ff-bf27-8dffd6eb1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpnet = createTheMNISTNet()[0]\n",
    "print(tmpnet)\n",
    "\n",
    "print('\\n\\nWeights for layer fc1:')\n",
    "print(tmpnet.fc1.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77150c5e-4a5c-4fc0-9d03-33b492367c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel(net,lossfun,optimizer):\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "  \n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # switch on train mode\n",
    "    net.train()\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259408de-78ec-4d02-9807-be9c44e29cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model without changing the weights; this will be the baseline performance.\n",
    "# Notice the model creation is outside the function2train\n",
    "net_base,lossfun,optimizer = createTheMNISTNet()\n",
    "trainAcc_base,testAcc_base,losses,net_base = function2trainTheModel(net_base,lossfun,optimizer)\n",
    "\n",
    "# plot the results\n",
    "plt.plot(range(len(trainAcc_base)),trainAcc_base,'o-', range(len(testAcc_base)),testAcc_base ,'s-')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1ffc4-8ad7-4313-b8e7-1b6cd8483049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the weights before training\n",
    "net_zero,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "# set to zeros\n",
    "net_zero.fc1.weight.data = torch.zeros_like( net_zero.fc1.weight )\n",
    "\n",
    "# confirm\n",
    "net_zero.fc1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2912ecc-35d4-49c1-9b2a-1d291f78b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model and show the results\n",
    "trainAcc_zero,testAcc_zero,losses,net_zero = function2trainTheModel(net_zero,lossfun,optimizer)\n",
    "\n",
    "plt.plot(range(len(trainAcc_base)),trainAcc_base,'b-', range(len(testAcc_base)),testAcc_base ,'b:')\n",
    "plt.plot(range(len(trainAcc_zero)),trainAcc_zero,'r-', range(len(testAcc_zero)),testAcc_zero ,'r:')\n",
    "plt.legend(['Train base','Test base','Train fc1=zero','Test fc1=zero'])\n",
    "plt.title('Accuracy comparison with layer FC1 init to zeros')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52c364-df1f-493b-9831-76201671b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the weights still zeros?\n",
    "print(net_zero.fc1.weight.data)\n",
    "\n",
    "# show the distributions in a histogram\n",
    "y,x = np.histogram(net_base.fc2.weight.data.flatten(),30)\n",
    "plt.plot((x[1:]+x[:-1])/2,y,'r',label='Baseline')\n",
    "\n",
    "y,x = np.histogram(net_zero.fc2.weight.data.flatten(),30)\n",
    "plt.plot((x[1:]+x[:-1])/2,y,'b',label='FC1=zeros')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Weight value')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50ab8e-51e9-46cc-b401-025d3cd979b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the weights before training\n",
    "net_allzero,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "# loop over parameters and set them all to zeros\n",
    "for p in net_allzero.named_parameters():\n",
    "  p[1].data = torch.zeros_like( p[1].data )\n",
    "\n",
    "\n",
    "# and confirm for a few select parameters (y-axis offset for visibility)\n",
    "plt.plot(0+net_allzero.fc1.weight.data.flatten(),'bo')\n",
    "plt.plot(1+net_allzero.fc2.weight.data.flatten(),'rx')\n",
    "plt.plot(2+net_allzero.fc1.bias.data.flatten(),'g^')\n",
    "plt.xlabel('Parameter index')\n",
    "plt.ylim([-1,3])\n",
    "plt.ylabel('Parameter value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f4055-dd49-4a58-ae7a-ebaed32d7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model and show the results\n",
    "trainAcc_allzero,testAcc_allzero,losses,net_allzero = function2trainTheModel(net_allzero,lossfun,optimizer)\n",
    "\n",
    "plt.plot(range(len(trainAcc_base)),trainAcc_base,'b-', range(len(testAcc_base)),testAcc_base ,'b:')\n",
    "plt.plot(range(len(trainAcc_allzero)),trainAcc_allzero,'r-', range(len(testAcc_allzero)),testAcc_allzero ,'r:')\n",
    "plt.legend(['Train base','Test base','Train all zero','Test all zero'])\n",
    "plt.title('Accuracy comparison with all layers init to zeros')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aef1d8-9910-46cc-9e7c-51eb6ca1394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distributions in a histogram\n",
    "y,x = np.histogram(net_base.fc1.weight.data.flatten(),30)\n",
    "plt.plot((x[1:]+x[:-1])/2,y,'r',label='Baseline')\n",
    "\n",
    "y,x = np.histogram(net_allzero.fc1.weight.data.flatten(),30)\n",
    "plt.plot((x[1:]+x[:-1])/2,y,'b',label='All zeros')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Weight value')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06603ca5-fc78-4549-a2f2-93968bb94fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# woah, not even a single non-zero weight value?!?!!?!!??\n",
    "plt.plot(net_allzero.fc1.weight.data.flatten(),'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7efe21-03af-4a06-b809-5d6f6d60f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the weights before training\n",
    "net_allone,lossfun,optimizer = createTheMNISTNet()\n",
    "for p in net_allone.named_parameters():\n",
    "  p[1].data = torch.zeros_like( p[1].data ) + 1\n",
    "  #p[1].data = torch.zeros( p[1].data.shape ) + 1 # equivalent to the previous line!\n",
    "\n",
    "\n",
    "# run the model and show the results\n",
    "trainAcc_allone,testAcc_allone,losses,net_allone = function2trainTheModel(net_allone,lossfun,optimizer)\n",
    "\n",
    "plt.plot(range(len(trainAcc_base)),trainAcc_base,'b-', range(len(testAcc_base)),testAcc_base ,'b:')\n",
    "plt.plot(range(len(trainAcc_allone)),trainAcc_allone,'r-', range(len(testAcc_allone)),testAcc_allone ,'r:')\n",
    "plt.legend(['Train base','Test base','Train all ones','Test all ones'])\n",
    "plt.title('Accuracy comparison with all layers init to ones')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f83055-2776-4412-b61a-3db19b222787",
   "metadata": {},
   "source": [
    "## 2-4-1. Kaiming Uniform Distribution\n",
    "1. `torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu', generator=None)`: Fills the input `torch.Tensor` with values sampled from $\\mathcal{U}(-bound, bound)$ where $bound=gain \\times \\sqrt{\\frac{3}{fan\\_mode}}$. `a` indicates the negative slope of the rectifier, `leaky_relu`, used after this layer. `mode` is either `fan_in`, preserving the magnitude of the variance of the weights in the forward pass, or `fan_out`, preserving the magnitudes in the backwards pass. `nonlinearity` is the `torch.nn.functional` name, recommended to use only with `relu` or `leaky_relu`. \n",
    "    - Take `torch.nn.Linear` with `torch.nn.functional.leaky_relu` for example, it intializes weights using `torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))` so that $negative\\_slope$ is $5$. The $gain$ is $\\sqrt{\\frac{2}{1+negative\\_slope^{2}}}=\\sqrt{\\frac{2}{1+5}}=\\frac{1}{\\sqrt{3}}$, and the $bound$ is $\\frac{1}{\\sqrt{3}} \\times \\sqrt{\\frac{3}{fan\\_in}} = \\frac{1}{\\sqrt{fan\\_in}}$. Therefore, the learnable weights are initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k=\\frac{1}{in\\_features}=\\frac{1}{fan\\_in}=bound^{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebcebd-e219-4fbd-82fe-5b132db43ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# create a class for the model\n",
    "class thenet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    ### input layer\n",
    "    self.input = nn.Linear(100,100)\n",
    "    \n",
    "    ### hidden layer\n",
    "    self.fc1 = nn.Linear(100,100)\n",
    "    self.fc2 = nn.Linear(100,100)\n",
    "    self.fc3 = nn.Linear(100,100)\n",
    "\n",
    "    ### output layer\n",
    "    self.output = nn.Linear(100,2)\n",
    "\n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    x = F.relu( self.input(x) )\n",
    "    x = F.relu( self.fc1(x) )\n",
    "    x = F.relu( self.fc2(x) )\n",
    "    x = F.relu( self.fc3(x) )\n",
    "    return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f43f24-d497-4bd7-8a9b-56b06f89487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the model\n",
    "net = thenet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425ff28-f5a1-4937-817f-6c9f977af17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all weights and biases\n",
    "allweight = np.array([])\n",
    "allbiases = np.array([])\n",
    "\n",
    "for p in net.named_parameters():\n",
    "  if 'bias' in p[0]:\n",
    "    allbiases = np.concatenate( (allbiases,p[1].data.numpy().flatten()),axis=0 )\n",
    "  elif 'weight' in p[0]:\n",
    "    allweight = np.concatenate( (allweight,p[1].data.numpy().flatten()),axis=0 )\n",
    "\n",
    "\n",
    "# how many are there?\n",
    "print(f'There are {len(allbiases)} bias parameters.')\n",
    "print(f'There are {len(allweight)} weight parameters.')\n",
    "\n",
    "\n",
    "# show their histograms\n",
    "fig,ax = plt.subplots(1,3,figsize=(18,4))\n",
    "\n",
    "ax[0].hist(allbiases,40)\n",
    "ax[0].set_title('Histogram of initial biases')\n",
    "\n",
    "\n",
    "ax[1].hist(allweight,40)\n",
    "ax[1].set_title('Histogram of initial weights')\n",
    "\n",
    "\n",
    "\n",
    "# collect histogram data to show as line plots\n",
    "yB,xB = np.histogram(allbiases,30)\n",
    "yW,xW = np.histogram(allweight,30)\n",
    "\n",
    "ax[2].plot((xB[1:]+xB[:-1])/2,yB/np.sum(yB),label='Bias')\n",
    "ax[2].plot((xW[1:]+xW[:-1])/2,yW/np.sum(yW),label='Weight')\n",
    "ax[2].set_title('Density estimate for both')\n",
    "ax[2].legend()\n",
    "\n",
    "\n",
    "# plot adjustments common to all subplots\n",
    "for i in range(3):\n",
    "  ax[i].set_xlabel('Initial value')\n",
    "  ax[i].set_ylabel('Count')\n",
    "ax[2].set_ylabel('Probability')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4ab93-5412-4f26-b97c-68bbc4f03d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(15,4))\n",
    "\n",
    "for p in net.named_parameters():\n",
    "\n",
    "  # get the data and compute their histogram\n",
    "  thesedata = p[1].data.numpy().flatten()\n",
    "  y,x = np.histogram(thesedata,10)\n",
    "\n",
    "  # for the bias\n",
    "  if 'bias' in p[0]:\n",
    "    ax[0].plot((x[1:]+x[:-1])/2,y/np.sum(y),label='%s bias (N=%g)'%(p[0][:-5],len(thesedata)))\n",
    "\n",
    "  # for the weights\n",
    "  elif 'weight' in p[0]:\n",
    "    ax[1].plot((x[1:]+x[:-1])/2,y/np.sum(y),label='%s weight (N=%g)'%(p[0][:-7],len(thesedata)))\n",
    "\n",
    "\n",
    "\n",
    "ax[0].set_title('Biases per layer')\n",
    "ax[0].legend()\n",
    "ax[1].set_title('Weights per layer')\n",
    "ax[1].legend(bbox_to_anchor=(1,1),loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a82c4-a16a-484c-b7db-97bedba3e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's up with the weird output bias distribution??\n",
    "print( net.output.bias.data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd226e2-386b-4394-8a6a-cee6d5a61b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the docstring for linear layers\n",
    "nn.Linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b9e15-857a-470a-9f31-557417c07e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test whether the numbers match our prediction from the formula\n",
    "\n",
    "# empirical bias range\n",
    "biasrange = [ torch.min(net.fc1.bias.data).item(), torch.max(net.fc1.bias.data).item() ]\n",
    "biascount = len(net.fc1.bias.data)\n",
    "\n",
    "# theoretical expected value\n",
    "sigma = np.sqrt(1/biascount)\n",
    "\n",
    "# drum rolllllll.....\n",
    "print('Theoretical sigma = ' + str(sigma))\n",
    "print('Empirical range = ' + str(biasrange))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1546053-b72e-4c15-9d82-54b2b981ed8f",
   "metadata": {},
   "source": [
    "## 2-4-2. Xavier Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76ac55-9786-4c66-a0b8-9987caa5e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new instance of the model\n",
    "net = thenet()\n",
    "\n",
    "# change the weights (leave biases as Kaiming [default])\n",
    "for p in net.named_parameters():\n",
    "  if 'weight' in p[0]:\n",
    "    nn.init.xavier_normal_(p[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355924b-ce2b-46d1-8528-84f71fa3cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll up and re-run the previous weights visualization cells with the new network.\n",
    "# Then continue below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e8f9a-9e0a-4290-b377-a9a3b9389bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test whether the numbers match our prediction from the formula\n",
    "\n",
    "# empirical weight standard deviation\n",
    "weightvar   = torch.var(net.fc1.weight.data.flatten()).item()\n",
    "weightcount = len(net.fc1.weight.data)\n",
    "\n",
    "# theoretical expected value\n",
    "sigma2 = 2 / (weightcount+weightcount)\n",
    "\n",
    "# drum rolllllll.....\n",
    "print('Theoretical sigma = ' + str(sigma2))\n",
    "print('Empirical variance = ' + str(weightvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009f9af-8f0c-411b-81d9-ce297e91a347",
   "metadata": {},
   "source": [
    "## 2-5. Summary\n",
    "- [torchinfo](https://github.com/TylerYep/torchinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f167aa44-e272-41ff-acf5-2b3c88895ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CNNModel                                 --\n",
       "Sequential: 1-1                        --\n",
       "    Conv2d: 2-1                       520\n",
       "    ReLU: 2-2                         --\n",
       "    Conv2d: 2-3                       32,064\n",
       "    ReLU: 2-4                         --\n",
       "=================================================================\n",
       "Total params: 32,584\n",
       "Trainable params: 32,584\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e41b8f83-96fc-49e0-97d9-d13462a16940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNModel                                 [32, 64, 20, 20]          --\n",
       "Sequential: 1-1                        [32, 64, 20, 20]          --\n",
       "    Conv2d: 2-1                       [32, 20, 24, 24]          520\n",
       "    ReLU: 2-2                         [32, 20, 24, 24]          --\n",
       "    Conv2d: 2-3                       [32, 64, 20, 20]          32,064\n",
       "    ReLU: 2-4                         [32, 64, 20, 20]          --\n",
       "==========================================================================================\n",
       "Total params: 32,584\n",
       "Trainable params: 32,584\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 420.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 9.50\n",
       "Params size (MB): 0.13\n",
       "Estimated Total Size (MB): 9.73\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(32, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed72acc-c3a7-4214-81da-99802b2d2f0b",
   "metadata": {},
   "source": [
    "# 3. Training\n",
    "## 3-1. Loss Functions\n",
    "1. Each PyTorch Loss function creates a criterion that measures the loss between `output` from a model and `target`, returning a `torch.Tensor`.\n",
    "   - [Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "   - Metrics supporting backpropagation (`is_differentiable == True`) in **TorchMetrics** can be used. More details in [Metrics & Differentiability](https://lightning.ai/docs/torchmetrics/stable/pages/overview.html#metrics-and-differentiability).\n",
    "2. `torch.Tensor.backward(gradient=None, retain_graph=None, create_graph=False, inputs=None)`: Computes the gradient of current tensor with reference to graph leaves. The graph is differentiated using the chain rule. This function accumulates gradients in the leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72365525-def0-4046-886a-4cbc7fc15bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6368,  0.6902, -1.1642,  1.7340,  0.3089],\n",
      "        [-0.5741, -2.2496,  0.1549,  0.2255, -0.5959],\n",
      "        [ 0.6467,  0.2575,  1.8013,  0.4424, -0.4409]], requires_grad=True)\n",
      "tensor([[-0.7584,  0.2138, -0.3933,  0.1054,  0.2149],\n",
      "        [ 0.2793,  0.7960, -0.1902,  2.1231, -0.5180],\n",
      "        [ 1.6648, -0.5898,  2.1185,  0.5762,  1.2281]])\n",
      "tensor(1.4591, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 0.0162,  0.0635, -0.1028,  0.2171,  0.0125],\n",
      "        [-0.1138, -0.4061,  0.0460, -0.2530, -0.0104],\n",
      "        [-0.1358,  0.1130, -0.0423, -0.0178, -0.2225]])\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "# Model output\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.randn(3, 5)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1d009-513f-4c3a-b10e-447c9e85eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-squared error\n",
    "# loss function\n",
    "lossfunMSE = nn.MSELoss()\n",
    "\n",
    "# create predictions and real answer\n",
    "yHat = torch.linspace(-2,2,101)\n",
    "y = torch.tensor(.5)\n",
    "\n",
    "# compute MSE loss function\n",
    "L = np.zeros(101)\n",
    "for i,yy in enumerate(yHat):\n",
    "  L[i] = lossfunMSE(yy,y)\n",
    "\n",
    "plt.plot(yHat,L,label='Loss')\n",
    "plt.plot([y,y],[0,np.max(L)],'r--',label='True value')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca99aa0-05ae-4e99-b7e1-e7c529cb1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross-entropy\n",
    "# loss function\n",
    "lossfunBCE = nn.BCELoss()\n",
    "\n",
    "# create predictions and real answer\n",
    "yHat = torch.linspace(.001,.999,101)\n",
    "y1 = torch.tensor(0.)\n",
    "y2 = torch.tensor(1.)\n",
    "\n",
    "# compute MSE loss function\n",
    "L = np.zeros((101,2))\n",
    "for i,yy in enumerate(yHat):\n",
    "  L[i,0] = lossfunBCE(yy,y1) # 0 is the correct answer\n",
    "  L[i,1] = lossfunBCE(yy,y2) # 1 is the correct answer\n",
    "\n",
    "plt.plot(yHat,L)\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['correct=0','correct=1'])\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78e6d5-f845-40fa-8d14-619ec25abcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example above shows data already in probabilities. Raw outputs will need to be converted to probabilities:\n",
    "\n",
    "# \"raw\" output of a model\n",
    "yHat = torch.tensor(2.)\n",
    "print(lossfunBCE(yHat,y2))\n",
    "\n",
    "# convert to prob via sigmoid\n",
    "sig = nn.Sigmoid()\n",
    "print(lossfunBCE( sig(yHat) ,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480e8cf-c46b-4dfd-89e7-0cdf2b51f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, PyTorch recommends using a single function that incorporates sigmoid+BCE due to increased numerical stability.\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html?highlight=nn%20bcewithlogitsloss#torch.nn.BCEWithLogitsLoss\n",
    "\n",
    "\n",
    "# Thus, the recommended way to do it:\n",
    "lossfunBCE = nn.BCEWithLogitsLoss()\n",
    "yHat = torch.tensor(2.)\n",
    "print(lossfunBCE(yHat,y2))\n",
    "\n",
    "# In toy examples, numerical accuracy usually isn't a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798189e6-3627-4d18-bc91-546822c82803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical cross-entropy\n",
    "# loss function\n",
    "lossfunCCE = nn.CrossEntropyLoss()\n",
    "\n",
    "# vector of output layer (pre-softmax)\n",
    "yHat = torch.tensor([[1.,4,3]])\n",
    "\n",
    "for i in range(3):\n",
    "  correctAnswer = torch.tensor([i])\n",
    "  thisloss = lossfunCCE(yHat,correctAnswer).item()\n",
    "  print( 'Loss when correct answer is %g: %g' %(i,thisloss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920c38b-9107-413c-9275-4319d3ffa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat using pre-softmaxified output\n",
    "sm = nn.Softmax(dim=1)\n",
    "yHat_sm = sm(yHat)\n",
    "\n",
    "for i in range(3):\n",
    "  correctAnswer = torch.tensor([i])\n",
    "  thisloss = lossfunCCE(yHat_sm,correctAnswer).item()\n",
    "  print( 'Loss when correct answer is %g: %g' %(i,thisloss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038178f-7db8-42e2-9a23-e761c0ef76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare raw, softmax, and log-softmax outputs\n",
    "sm = nn.LogSoftmax(dim=1)\n",
    "yHat_logsm = sm(yHat)\n",
    "\n",
    "# print them\n",
    "print(yHat)\n",
    "print(yHat_sm)\n",
    "print(yHat_logsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aeccb4-28dc-4b36-a8b8-be33d1fa13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss functions\n",
    "class myLoss(nn.Module): # inherent info from nn.Module\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "      \n",
    "  def forward(self,x,y):\n",
    "    loss = torch.abs(x-y)\n",
    "    return loss\n",
    "\n",
    "# test it out!\n",
    "lfun = myLoss()\n",
    "lfun(torch.tensor(4),torch.tensor(5.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8186341c-4204-451a-8c54-89cbf35d5fec",
   "metadata": {},
   "source": [
    "## 3-2. Optimizer\n",
    "1. `torch.optim` implements various [Optimization Algorithms](https://pytorch.org/docs/stable/optim.html#algorithms).\n",
    "2. `torch.optim.Optimizer.step(closure=None)`: Performs a single optimization step (parameter update).\n",
    "    - For example, [torch.optim.SGD.step(closure=None)](https://github.com/pytorch/pytorch/blob/cd9b27231b51633e76e28b6a34002ab83b0660fc/torch/optim/sgd.py#L63).\n",
    "3. `torch.optim.Optimizer.zero_grad(set_to_none=True)`: Resets the gradients of all optimized `torch.Tensor`s.\n",
    "4. `torch.optim.Optimizer.load_state_dict(state_dict)`: Loads the optimizer state. Uses this function when loading a general checkpoint for inference or resuming training.\n",
    "5. `torch.optim.Optimizer.state_dict`: Contains information about the optimizer's state (parameters to be optimized), as well as the hyperparameters used.\n",
    "6. `torch.optim.Optimizer.add_param_group(param_group)`: Adds a param group to the `Optimizer`'s `param_groups`. Uses this function when fine tuning a pre-trained network as frozen layers can be made trainable and added to the `Optimizer` as training progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ee11b-4aaf-49d5-806d-16b910234ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] Momentum\n",
    "# create data\n",
    "\n",
    "nPerClust = 300\n",
    "blur = 1\n",
    "\n",
    "A = [ 1, 1 ]\n",
    "B = [ 5, 1 ]\n",
    "C = [ 4, 3 ]\n",
    "\n",
    "# generate data\n",
    "a = [ A[0]+np.random.randn(nPerClust)*blur , A[1]+np.random.randn(nPerClust)*blur ]\n",
    "b = [ B[0]+np.random.randn(nPerClust)*blur , B[1]+np.random.randn(nPerClust)*blur ]\n",
    "c = [ C[0]+np.random.randn(nPerClust)*blur , C[1]+np.random.randn(nPerClust)*blur ]\n",
    "\n",
    "# true labels\n",
    "labels_np = np.hstack((  np.zeros((nPerClust)),\n",
    "                         np.ones( (nPerClust)),\n",
    "                       1+np.ones( (nPerClust))  ))\n",
    "\n",
    "# concatanate into a matrix\n",
    "data_np = np.hstack((a,b,c)).T\n",
    "\n",
    "# convert to a pytorch tensor\n",
    "data = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).long() # note: \"long\" format for CCE\n",
    "\n",
    "# show the data\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'bs',alpha=.5)\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'ko',alpha=.5)\n",
    "plt.plot(data[np.where(labels==2)[0],0],data[np.where(labels==2)[0],1],'r^',alpha=.5)\n",
    "plt.title('The qwerties!')\n",
    "plt.xlabel('qwerty dimension 1')\n",
    "plt.ylabel('qwerty dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc1603-3962-470c-8dd8-227d099316dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(data, labels, test_size=.1)\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "batchsize    = 16\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86431894-aeac-4cca-b5cf-111064a7be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(train_loader)} batches, each with {batchsize} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5b1b9-e6fb-47ca-a135-f9ed6bcec106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheQwertyNet(momentum):\n",
    "\n",
    "  class qwertyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(2,8)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(8,8)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(8,3)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = qwertyNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer (note extra input!)\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=.01,momentum=momentum)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fbbc66-af62-4eb1-9be6-732a35ad0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that the optimizer has momentum\n",
    "optim = createTheQwertyNet(.9)[2]\n",
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2b901-0e78-4746-80e1-4c60108df7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "\n",
    "# number of epochs\n",
    "numepochs = 50\n",
    "\n",
    "\n",
    "def function2trainTheModel(momentum):\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheQwertyNet(momentum)\n",
    "\n",
    "  # initialize losses\n",
    "  losses   = torch.zeros(numepochs)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # switch on training mode\n",
    "    net.train()\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100 \n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) ) \n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916fa51-3e75-4e0b-8a9d-cd30b4c43e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum values to use\n",
    "momenta = [0,.5,.9,.95,.999]\n",
    "\n",
    "# initialize results matrix\n",
    "results = np.zeros((numepochs,len(momenta),3))\n",
    "\n",
    "# test all momentum values on the same data (different model instances)\n",
    "for idx,mom in enumerate(momenta):\n",
    "  trainAcc,testAcc,losses,net = function2trainTheModel(mom)\n",
    "  results[:,idx,0] = losses\n",
    "  results[:,idx,1] = trainAcc\n",
    "  results[:,idx,2] = testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5ef09-3d4e-4dda-9a66-f2992ff2cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(16,5))\n",
    "\n",
    "for i in range(3):\n",
    "  ax[i].plot(results[:,:,i])\n",
    "  ax[i].legend(momenta)\n",
    "  ax[i].set_xlabel('Epochs')\n",
    "  if i==0:\n",
    "    ax[i].set_ylabel('Loss')\n",
    "  else:\n",
    "    ax[i].set_ylabel('Accuracy (%)')\n",
    "    ax[i].set_ylim([20,100])\n",
    "\n",
    "ax[0].set_title('Losses')\n",
    "ax[1].set_title('Train')\n",
    "ax[2].set_title('Test')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44231924-4f1d-41d6-b3c0-f1e4823791b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] Comparison\n",
    "# create a class for the model\n",
    "def createTheQwertyNet(optimizerAlgo):\n",
    "\n",
    "  class qwertyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(2,8)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(8,8)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(8,3)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = qwertyNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optifun = getattr( torch.optim,optimizerAlgo )\n",
    "  optimizer = optifun(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1904842-ed4d-4572-9fa1-83dbaea39fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with optimizer type as input\n",
    "\n",
    "# try 'SGD', 'RMSprop', and 'Adam'\n",
    "optim = createTheQwertyNet('RMSprop')[2]\n",
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3cdbd-8757-4dd5-969f-abc54fc8a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel(optimizerType):\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 50\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheQwertyNet(optimizerType)\n",
    "\n",
    "  # initialize losses\n",
    "  losses   = torch.zeros(numepochs)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # switch on training mode\n",
    "    net.train()\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100 \n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) ) \n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4152b79-767c-43da-b166-8d9ca4749da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that plots the results\n",
    "def plotTheResults(optimizerType):\n",
    "\n",
    "  # compute accuracy over entire dataset (train+test)\n",
    "  yHat = net(data)\n",
    "  predictions = torch.argmax(yHat,axis=1)\n",
    "  accuracy = (predictions == labels).float()\n",
    "  totalAcc = torch.mean(100*accuracy).item()\n",
    "\n",
    "  # and accuracy by group\n",
    "  accuracyByGroup = np.zeros(3)\n",
    "  for i in range(3):\n",
    "    accuracyByGroup[i] = 100*torch.mean(accuracy[labels==i])\n",
    "\n",
    "\n",
    "  # create the figure\n",
    "  fig,ax = plt.subplots(2,2,figsize=(10,6))\n",
    "\n",
    "  # plot the loss function\n",
    "  ax[0,0].plot(losses.detach())\n",
    "  ax[0,0].set_ylabel('Loss')\n",
    "  ax[0,0].set_xlabel('epoch')\n",
    "  ax[0,0].set_title(f'{optimizerType}: Losses')\n",
    "\n",
    "  # plot the accuracy functions\n",
    "  ax[0,1].plot(trainAcc,label='Train')\n",
    "  ax[0,1].plot(testAcc,label='Test')\n",
    "  ax[0,1].set_ylabel('Accuracy (%)')\n",
    "  ax[0,1].set_xlabel('Epoch')\n",
    "  ax[0,1].set_title(f'{optimizerType}: Accuracy')\n",
    "  ax[0,1].legend()\n",
    "\n",
    "  # plot overall accuracy by group\n",
    "  ax[1,0].bar(range(3),accuracyByGroup)\n",
    "  ax[1,0].set_ylim([np.min(accuracyByGroup)-5,np.max(accuracyByGroup)+5])\n",
    "  ax[1,0].set_xticks([0,1,2])\n",
    "  ax[1,0].set_xlabel('Group')\n",
    "  ax[1,0].set_ylabel('Accuracy (%)')\n",
    "  ax[1,0].set_title(f'{optimizerType}: Accuracy by group')\n",
    "\n",
    "  # scatterplot of correct and incorrect labeled data\n",
    "  colorShapes = [ 'bs','ko','g^' ] # data markers\n",
    "  for i in range(3):\n",
    "    # plot all data points\n",
    "    ax[1,1].plot(data[labels==i,0],data[labels==i,1],colorShapes[i],\n",
    "                 alpha=.3,label=f'Group {i}')\n",
    "    \n",
    "    # cross-out the incorrect ones\n",
    "    idxErr = (accuracy==0) & (labels==i)\n",
    "    ax[1,1].plot(data[idxErr,0],data[idxErr,1],'rx')\n",
    "\n",
    "  ax[1,1].set_title(f'{optimizerType}: Total accuracy: {totalAcc:.2f}%')\n",
    "  ax[1,1].set_xlabel('qwerty dimension 1')\n",
    "  ax[1,1].set_ylabel('qwerty dimension 2')\n",
    "  ax[1,1].legend()\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f6fcab-02e1-4444-a3d6-4d62406f1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model for one optimizer\n",
    "optimizerType = 'Adam'\n",
    "trainAcc,testAcc,losses,net = function2trainTheModel(optimizerType)\n",
    "\n",
    "# visualize!\n",
    "plotTheResults(optimizerType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdf0b9-4992-4347-8266-bf19dd0f1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run through all of them\n",
    "\n",
    "# average performance\n",
    "performance = []\n",
    "\n",
    "for opto in ['SGD','RMSprop','Adam']:\n",
    "  trainAcc,testAcc,losses,net = function2trainTheModel(opto)\n",
    "  plotTheResults(opto)\n",
    "\n",
    "  # store the final results\n",
    "  train = np.mean(trainAcc[-10:])\n",
    "  test  = np.mean(testAcc[-10:])\n",
    "\n",
    "  performance.append( f'{opto}: train {train:.1f}%, test {test:.1f}%' )\n",
    "    \n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d4054-5da2-467c-8fb3-3f1048644998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] Learning rate decay\n",
    "# create a class for the model\n",
    "def createTheQwertyNet(initialLR):\n",
    "\n",
    "  class qwertyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(2,8)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(8,8)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(8,3)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = qwertyNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer and LR scheduler\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=initialLR)\n",
    "  stepsize  = batchsize*len(train_loader)\n",
    "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=stepsize,gamma=.5)\n",
    "\n",
    "  return net,lossfun,optimizer,scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf52699-6477-497b-96c8-f50c72dce5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many steps until the learning rate changes?\n",
    "len(train_loader)*batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8382f-5a74-435a-8eb6-cf68fb264dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a network\n",
    "net = createTheQwertyNet(.01)[0]\n",
    "\n",
    "# a new optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=5,gamma=1/2)\n",
    "\n",
    "# test the change in learning rate\n",
    "for epoch in range(3):\n",
    "  for batchnum in range(10):\n",
    "    print(f'Batch {batchnum}, epoch {epoch}: LR={scheduler.get_last_lr()[0]}')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abec2ce-6d40-434f-ad04-0fce0a621109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel(initialLR,toggleDynamicLR):\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 50\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer,scheduler = createTheQwertyNet(initialLR)\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "  currentLR = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # switch on training mode\n",
    "    net.train()\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # step the learning-rate scheduler\n",
    "      if toggleDynamicLR:\n",
    "        scheduler.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100 \n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "\n",
    "      currentLR.append( scheduler.get_last_lr()[0] )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net,currentLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f024f-7df4-4b33-9a12-ef8cdb7bc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that the learning rate is really working\n",
    "trainAcc,testAcc,losses,net,currentLR = function2trainTheModel(.01,True)\n",
    "plt.plot(currentLR)\n",
    "plt.title('Learning rate should change')\n",
    "plt.show()\n",
    "\n",
    "trainAcc,testAcc,losses,net,currentLR = function2trainTheModel(.01,False)\n",
    "plt.plot(currentLR)\n",
    "plt.title('Learning rate should stay fixed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cbeafe-81b1-4f37-8e56-4cb93f0a3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now test with and without dynamic LR\n",
    "trainAccDynamic,testAccDynamic,losses,net,currentLR = function2trainTheModel(.01,True)\n",
    "trainAccStatic,testAccStatic,losses,net,currentLR   = function2trainTheModel(.01,False)\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.plot(trainAccDynamic,'r',label='Dyn: Train')\n",
    "plt.plot(testAccDynamic,'r--',label='Dyn: Test')\n",
    "\n",
    "plt.plot(trainAccStatic,'b',label='Stat: Train')\n",
    "plt.plot(testAccStatic,'b--',label='Stat: Test')\n",
    "\n",
    "plt.xlabel('Training epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077774c-eebd-439b-aa55-77d37ea16794",
   "metadata": {},
   "source": [
    "## 3-3. Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbc941-9048-4ab3-ba4b-d3b300c7645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "# import dataset\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53517c3-4a3d-4d07-82aa-485cf0131b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "iris.plot(marker='o',linestyle='none',figsize=(12,6))\n",
    "plt.xlabel('Sample number')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f12a3-6c65-441f-826e-531b071edd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize the data\n",
    "\n",
    "# convert from pandas dataframe to tensor\n",
    "data = torch.tensor( iris[iris.columns[0:4]].values ).float()\n",
    "\n",
    "# transform species to number\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "# labels[iris.species=='setosa']   = 0 # don't need!\n",
    "labels[iris.species=='versicolor'] = 1\n",
    "labels[iris.species=='virginica']  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90856652-1012-4478-a2a9-d944f098fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(data, labels, test_size=.2)\n",
    "\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "batchsize    = 16\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0]) # how big should these batches be??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955c1c2-43cd-4ba8-8d87-302df28d610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes of data batches\n",
    "for X,y in train_loader:\n",
    "  print(X.shape,y.shape)\n",
    "\n",
    "# go back and set drop_last=True in training DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be21595-d10e-4dc9-a73d-40965b4cf21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates the ANN model\n",
    "\n",
    "def createANewModel():\n",
    "\n",
    "  # model architecture\n",
    "  ANNiris = nn.Sequential(\n",
    "      nn.Linear(4,64),   # input layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,64),  # hidden layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,3),   # output units\n",
    "        )\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.0005)\n",
    "\n",
    "  return ANNiris,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc8a3d6-af1b-492a-a92b-875fec8bfedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 2500\n",
    "\n",
    "def trainTheModel():\n",
    "\n",
    "  # initialize accuracies as empties\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "  losses   = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = ANNiris(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # compute training accuracy just for this batch\n",
    "      batchAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "      batchLoss.append( loss.item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "    losses.append( np.mean(batchLoss) )\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    predlabels = torch.argmax( ANNiris(X),axis=1 )\n",
    "    testAcc.append( 100*torch.mean((predlabels == y).float()).item() )\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844352f-be17-415b-9919-d1ce43b0274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "ANNiris,lossfun,optimizer = createANewModel()\n",
    "\n",
    "# train the model\n",
    "trainAcc,testAcc,losses = trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab9130-b9a9-4b4e-9622-695725d38d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "\n",
    "ax[0].plot(losses,'k^-')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_title('Losses with minibatch size=' + str(batchsize))\n",
    "\n",
    "ax[1].plot(trainAcc,'ro-')\n",
    "ax[1].plot(testAcc,'bs-')\n",
    "ax[1].set_title('Accuracy with minibatch size=' + str(batchsize))\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].legend(['Train','Test'])\n",
    "ax[1].set_ylim([27,103])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299c848-58ba-4052-8a75-bac960f62b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] Normalization\n",
    "# # z-score the data\n",
    "# import scipy.stats as stats\n",
    "# cols2zscore = iris.keys()\n",
    "# cols2zscore = cols2zscore.drop('species')\n",
    "# iris[cols2zscore] = iris[cols2zscore].apply(stats.zscore)\n",
    "\n",
    "# iris.plot(marker='o',linestyle='none',figsize=(12,6))\n",
    "# plt.xlabel('Sample number')\n",
    "# plt.ylabel('Value')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4d614-d8c9-4023-be2f-b4ccbb225f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3]\n",
    "# create data\n",
    "\n",
    "nPerClust = 200\n",
    "\n",
    "th = np.linspace(0,4*np.pi,nPerClust)\n",
    "r1 = 10\n",
    "r2 = 15\n",
    "\n",
    "# generate data\n",
    "a = [ r1*np.cos(th) + np.random.randn(nPerClust)*3 ,\n",
    "      r1*np.sin(th) + np.random.randn(nPerClust) ]\n",
    "b = [ r2*np.cos(th) + np.random.randn(nPerClust) ,\n",
    "      r2*np.sin(th) + np.random.randn(nPerClust)*3 ]\n",
    "\n",
    "# true labels\n",
    "labels_np = np.vstack((np.zeros((nPerClust,1)),np.ones((nPerClust,1))))\n",
    "\n",
    "# concatanate into a matrix\n",
    "data_np = np.hstack((a,b)).T\n",
    "\n",
    "# convert to a pytorch tensor\n",
    "data = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).float()\n",
    "\n",
    "# show the data\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'bs')\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'ko')\n",
    "plt.title(\"The qwerties' doughnuts!\")\n",
    "plt.xlabel('qwerty dimension 1')\n",
    "plt.ylabel('qwerty dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5f3ab-1924-4ec0-944e-73d450ccc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(data, labels, test_size=.1)\n",
    "\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "train_batchsize = 16\n",
    "test_batchsize  = test_data.tensors[0].shape[0]-2\n",
    "train_loader = DataLoader(train_data,batch_size=train_batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539de07-8938-4224-ad9e-4a8ff75a5583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes of data batches\n",
    "for X,y in test_loader:\n",
    "  print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc3167-6b3a-4522-b894-e2657c3c285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class theModelClass(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    ### layers\n",
    "    self.input  = nn.Linear(  2,128)\n",
    "    self.hidden = nn.Linear(128,128)\n",
    "    self.output = nn.Linear(128, 1)\n",
    "\n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    x = F.relu( self.input(x) )\n",
    "    x = F.relu( self.hidden(x) )\n",
    "    x = self.output(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5a97a-5f5d-4763-9682-d4126ea535a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates the ANN model\n",
    "\n",
    "def createANewModel():\n",
    "\n",
    "  # grab an instance of the model class\n",
    "  ANNQC = theModelClass()\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(ANNQC.parameters(),lr=.01)\n",
    "\n",
    "  return ANNQC,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38951141-ac42-49fc-80c0-d82d2eb4ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 500\n",
    "\n",
    "# NOTE: this time, the model, lossfun, and optimizer are inputs into the function!\n",
    "def trainTheModel(ANNQC,lossfun,optimizer):\n",
    "\n",
    "  # initialize accuracies as empties (not storing losses here)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = ANNQC(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "      \n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # compute training accuracy just for this batch\n",
    "      batchAcc.append( 100*torch.mean(((yHat>0)==y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # test accuracy (NOTE: testing in batches!)\n",
    "    tstacc = []\n",
    "    for X,y in test_loader:\n",
    "      yHat = ANNQC(X)\n",
    "      tstacc.append( 100*torch.mean(((yHat>0) == y).float()).item() )\n",
    "    # now get the average accuracy over test-batches\n",
    "    testAcc.append(np.mean(tstacc))\n",
    "  \n",
    "  # function output\n",
    "  return trainAcc,testAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0356e-2672-4bef-bc4e-56294da62ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "ANNQC,lossfun,optimizer = createANewModel()\n",
    "\n",
    "# train the model (note the inputs!)\n",
    "trainAcc,testAcc = trainTheModel(ANNQC,lossfun,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346ae98-cd51-4204-a1c9-b450a63e7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(trainAcc,'bs')\n",
    "plt.plot(testAcc,'ro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Train','Test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada311fe-e718-4911-8efc-513ee7002e75",
   "metadata": {},
   "source": [
    "## 3-4. Weight Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b45611-93f8-43a4-9cfa-a866ad9c95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe0176-12ae-4954-8b07-c466a5ea29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad9fe2-6f9e-4e52-bf32-c52394268e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer (Note: SGD to slow down learning!)\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e61f9-7adf-446e-9285-de8361c1dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel(net,lossfun,optimizer):\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 60\n",
    "  \n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "  # initialize weight change matrices\n",
    "  weightChange = np.zeros((numepochs,4))\n",
    "  weightConds  = np.zeros((numepochs,4))\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # store the weights for each layer\n",
    "    preW = []\n",
    "    for p in net.named_parameters():\n",
    "      if 'weight' in p[0]:\n",
    "        preW.append( copy.deepcopy(p[1].data.numpy()) )\n",
    "\n",
    "\n",
    "    # loop over training data batches\n",
    "    net.train()\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "\n",
    "    # finally, get the post-learning state of the weights\n",
    "    for (i,p) in enumerate(net.named_parameters()):\n",
    "      if 'weight' in p[0]:\n",
    "        # condition number\n",
    "        weightConds[epochi,int(i/2)]  = np.linalg.cond(p[1].data)\n",
    "\n",
    "        # Frobenius norm of the weight change from pre-learning\n",
    "        weightChange[epochi,int(i/2)] = np.linalg.norm( preW[int(i/2)]-p[1].data.numpy(), ord='fro')\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net,weightChange,weightConds,preW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e5f4c-3273-4ff3-82f6-c06e84e10efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network\n",
    "net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "# train the model\n",
    "trainAcc,testAcc,losses,net,weightChange,weightConds,preW = function2trainTheModel(net,lossfun,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc29a97-200f-49e2-9e1c-d4b6b5621173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results!\n",
    "\n",
    "# get a list of layer names\n",
    "layername = []\n",
    "for (i,p) in enumerate(net.named_parameters()):\n",
    "  if 'weight' in p[0]:\n",
    "    layername.append(p[0][:-7])\n",
    "\n",
    "\n",
    "# set up the plot\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,3))\n",
    "\n",
    "# accuracy\n",
    "ax[0].plot(trainAcc)\n",
    "ax[0].plot(testAcc)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy (%)')\n",
    "ax[0].set_title('Accuracy')\n",
    "ax[0].legend(['Train','Test'])\n",
    "\n",
    "# weight changes\n",
    "ax[1].plot(weightChange)\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_title('Weight change from previous epoch')\n",
    "ax[1].legend(layername)\n",
    "\n",
    "# weight condition numbers\n",
    "ax[2].plot(weightConds)\n",
    "ax[2].set_xlabel('Epochs')\n",
    "ax[2].set_title('Condition number')\n",
    "ax[2].legend(layername)\n",
    "ax[2].set_ylim([0,20])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd20ee3-5b6f-438a-aa99-b6576b9ab0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final inspection: check the derivative of accuracy against the weight change\n",
    "from scipy.stats import zscore # normalize for scaling offsets\n",
    "\n",
    "plt.plot(zscore(np.diff(trainAcc)),label='d(trainAcc)')\n",
    "plt.plot(zscore(np.mean(weightChange,axis=1)),label='Weight change')\n",
    "plt.legend()\n",
    "plt.title('Change in weights by change in accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7430ef-1497-4966-81eb-88b16bec52a4",
   "metadata": {},
   "source": [
    "## 3-5. Gradient Accumulation\n",
    "\n",
    "**Gradient Accumulation** refers to the situation, where multiple backwards passes are performed before updating the parameters. The goal is to have the same model parameters for multiple inputs (batches) and then update the model's parameters based on all these batches, instead of performing an update after every single batch. This technique is used to overcome GPU memory limitations when training neural networks. \n",
    "\n",
    "Gradient accumulation adds gradients over an effective batch of size, `batch_per_iter * iters_to_accumulate` (`* num_procs` if distributed). Steps including:\n",
    "- Specify the `iters_to_accumulate` parameter, indicating how many batches we would like to update the network weights.\n",
    "- Condition the weight update on the index of the running batch. This requires using `enumerate(DataLoader)` to store the batch index when looping through the data.\n",
    "- Divide the running loss by `iters_to_accumulate`. This normalizes the loss to reduce the contribution of each mini-batch we are actually processing. Depending on the way you compute the loss, you might not need this step. If you average loss within each batch, the division is already correct and there is no need for extra normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba2b20-8111-41b1-950c-3eec57c7fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ...\n",
    "\n",
    "for epoch in range(...):\n",
    "    # loop through batches\n",
    "    for inputs, labels in data_loader:\n",
    "        # extract inputs and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # passes and weights update\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # forward pass\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, labels)\n",
    "    \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "    \n",
    "            # weights update\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6a7bc-304b-4054-9fa4-95d639415f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch accumulation parameter\n",
    "iters_to_accumulate = 4\n",
    "optimizer = ...\n",
    "\n",
    "for epoch in range(...):\n",
    "    # loop through enumaretad batches\n",
    "    for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "        # extract inputs and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # passes and weights update\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # forward pass\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, labels)\n",
    "    \n",
    "            # normalize loss to account for batch accumulation\n",
    "            loss = loss / iters_to_accumulate\n",
    "    \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "    \n",
    "            # weights update\n",
    "            if ((batch_idx + 1) % iters_to_accumulate == 0) or (batch_idx + 1 == len(data_loader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d967f5ac-c9f9-422c-a4b2-642bfdd2bb13",
   "metadata": {},
   "source": [
    "## 3-6. Automatic Mixed Precision\n",
    "\n",
    "NVIDIA researchers created a methodology that combines single precision with the half precision floating point numbers for training deep learning models, that achieves the same level of accuracy as `float32`. Main advantages include less training time, enabling larger batch sizes, larger models & inputs, lower memory requirements. \n",
    "\n",
    "In PyTorch, **Automatic Mixed Precision Training** means training with `torch.autocast` & `torch.amp.GradScaler` together.\n",
    "- Instances of `torch.autocast` enable autocasting for chosen regions. Autocasting automatically chooses the precision for GPU operations to improve performance while maintaining accuracy.\n",
    "- Instances of `torch.amp.GradScaler` help perform the steps of gradient scaling conveniently. Gradient scaling improves convergence for networks with `float16` gradients by minimizing gradient underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792f4fa-7ad2-4ae2-9ae6-c55b5b6a0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for input, target in data:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target)\n",
    "\t\t\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52513cc0-1ad8-4c10-84aa-0979e02ef442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler()\n",
    "batch_size = 4\n",
    "iters_to_accumulate = 16\n",
    "# this means training will be done for affective batch size of 4 * 16 = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (input, target) in enumerate(data):\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss = loss / iters_to_accumulate\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (batch_idx + 1) % iters_to_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dcf049-2281-4799-b40f-3889f32d7cc8",
   "metadata": {},
   "source": [
    "# 4. Evaluation\n",
    "## 4-1. Accuracy, Precision, Recall & F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ef57b-157f-4b90-847a-8c7155a2ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run experiment\n",
    "\n",
    "# number of 'trials' in the experiment\n",
    "N = 50 # actual trials is 2N\n",
    "\n",
    "# number of experiment repetitions\n",
    "numExps = 10000\n",
    "\n",
    "# initialize\n",
    "accuracy  = np.zeros(numExps)\n",
    "precision = np.zeros(numExps)\n",
    "recall    = np.zeros(numExps)\n",
    "F1score   = np.zeros(numExps)\n",
    "\n",
    "\n",
    "### run the experiment!\n",
    "for expi in range(numExps):\n",
    "    \n",
    "  # generate data\n",
    "  TP = np.random.randint(1,N)  # true positives,  aka hits\n",
    "  FN = N-TP                    # false negatives, aka misses\n",
    "  TN = np.random.randint(1,N)  # true negatives,  aka correct rejections\n",
    "  FP = N-TN                    # false positives, aka false alarms\n",
    "  \n",
    "\n",
    "  ### the four performance measures discussed in lecture\n",
    "\n",
    "  # accuracy\n",
    "  accuracy[expi]  = (TP+TN) / (2*N)\n",
    "\n",
    "  # precision\n",
    "  precision[expi] = TP / (TP+FP)\n",
    "\n",
    "  # recall\n",
    "  recall[expi]    = TP / (TP+FN)\n",
    "\n",
    "  # Fscore\n",
    "  F1score[expi]   = TP / (TP+(FP+FN)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bf93c-8570-4259-bcaf-65f524990e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's see how they relate to each other!\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(18,6))\n",
    "\n",
    "ax[0].scatter(accuracy,F1score,s=5,c=precision)\n",
    "ax[0].plot([0,1],[.5,.5],'k--',linewidth=.5)\n",
    "ax[0].plot([.5,.5],[0,1],'k--',linewidth=.5)\n",
    "ax[0].set_xlabel('Accuracy')\n",
    "ax[0].set_ylabel('F1-score')\n",
    "ax[0].set_title('F1-Accuracy by precision')\n",
    "\n",
    "\n",
    "ax[1].scatter(accuracy,F1score,s=5,c=recall)\n",
    "ax[1].plot([0,1],[.5,.5],'k--',linewidth=.5)\n",
    "ax[1].plot([.5,.5],[0,1],'k--',linewidth=.5)\n",
    "ax[1].set_xlabel('Accuracy')\n",
    "ax[1].set_ylabel('F1-score')\n",
    "ax[1].set_title('F1-Accuracy by recall')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02443c-8800-4780-ba27-96695f2548f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] Wine quality\n",
    "# import the data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url,sep=';')\n",
    "data = data[data['total sulfur dioxide']<200] # drop a few outliers\n",
    "\n",
    "# z-score all columns except for quality\n",
    "cols2zscore = data.keys()\n",
    "cols2zscore = cols2zscore.drop('quality')\n",
    "data[cols2zscore] = data[cols2zscore].apply(stats.zscore)\n",
    "\n",
    "# create a new column for binarized (boolean) quality\n",
    "data['boolQuality'] = 0\n",
    "# data['boolQuality'][data['quality']<6] = 0 # implicit in the code! just here for clarity\n",
    "data['boolQuality'][data['quality']>5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca925f-a6c2-432a-b0b4-63926e5a80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from pandas dataframe to tensor\n",
    "dataT  = torch.tensor( data[cols2zscore].values ).float()\n",
    "labels = torch.tensor( data['boolQuality'].values ).float()\n",
    "labels = labels[:,None] # transform to matrix\n",
    "\n",
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labels, test_size=.1)\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_dataDataset = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_dataDataset  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# finally, create dataloaders\n",
    "train_loader = DataLoader(train_dataDataset,batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_dataDataset,batch_size=test_dataDataset.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40681c7f-6a5d-48cf-bedd-1276e62fc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "\n",
    "class ANNwine(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    ### input layer\n",
    "    self.input = nn.Linear(11,16)\n",
    "    \n",
    "    ### hidden layers\n",
    "    self.fc1 = nn.Linear(16,32)\n",
    "    self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "    ### output layer\n",
    "    self.output = nn.Linear(32,1)\n",
    "  \n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    x = F.relu( self.input(x) )\n",
    "    x = F.relu( self.fc1(x) )\n",
    "    x = F.relu( self.fc2(x) )\n",
    "    return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b39caf-d6fe-4148-8bed-3a0bb2afc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameter\n",
    "numepochs = 1000\n",
    "\n",
    "def trainTheModel():\n",
    "\n",
    "  # loss function and optimizer\n",
    "  lossfun = nn.BCEWithLogitsLoss()\n",
    "  optimizer = torch.optim.SGD(winenet.parameters(),lr=.01)\n",
    "\n",
    "  # initialize losses\n",
    "  losses   = torch.zeros(numepochs)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = winenet(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute training accuracy for this batch\n",
    "      batchAcc.append( 100*torch.mean(((yHat>0) == y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = winenet(X)\n",
    "    testAcc.append( 100*torch.mean(((yHat>0) == y).float()).item() )\n",
    "  \n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfa099-9482-42a2-af3e-6444434fbd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train a model\n",
    "winenet = ANNwine()\n",
    "trainAcc,testAcc,losses = trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a8c7d-3189-4b66-97ab-0480ca7a9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for training data\n",
    "train_predictions = winenet(train_loader.dataset.tensors[0])\n",
    "train_predictions\n",
    "\n",
    "# predictions for test data\n",
    "test_predictions = winenet(test_loader.dataset.tensors[0])\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a2136-bce7-4fa5-8df5-8bb2c932975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW! using scikitlearn to compute ARPF\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# initialize vectors\n",
    "train_metrics = [0,0,0,0]\n",
    "test_metrics  = [0,0,0,0]\n",
    "\n",
    "# training\n",
    "train_metrics[0] = skm.accuracy_score (train_loader.dataset.tensors[1],train_predictions>0)\n",
    "train_metrics[1] = skm.precision_score(train_loader.dataset.tensors[1],train_predictions>0)\n",
    "train_metrics[2] = skm.recall_score   (train_loader.dataset.tensors[1],train_predictions>0)\n",
    "train_metrics[3] = skm.f1_score       (train_loader.dataset.tensors[1],train_predictions>0)\n",
    "\n",
    "\n",
    "# test\n",
    "test_metrics[0] = skm.accuracy_score (test_loader.dataset.tensors[1],test_predictions>0)\n",
    "test_metrics[1] = skm.precision_score(test_loader.dataset.tensors[1],test_predictions>0)\n",
    "test_metrics[2] = skm.recall_score   (test_loader.dataset.tensors[1],test_predictions>0)\n",
    "test_metrics[3] = skm.f1_score       (test_loader.dataset.tensors[1],test_predictions>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19daa8-808b-4a10-bf18-64713f03ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(4)-.1,train_metrics,.5)\n",
    "plt.bar(np.arange(4)+.1,test_metrics,.5)\n",
    "plt.xticks([0,1,2,3],['Accuracy','Precision','Recall','F1-score'])\n",
    "plt.ylim([.6,1])\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Performance metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d05a4-d86b-4eb9-bf20-dc7bcf006fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "trainConf = skm.confusion_matrix(train_loader.dataset.tensors[1],train_predictions>0)\n",
    "testConf  = skm.confusion_matrix(test_loader.dataset.tensors[1], test_predictions>0)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "# confmat during TRAIN\n",
    "ax[0].imshow(trainConf,'Blues',vmax=len(train_predictions)/2)\n",
    "ax[0].set_xticks([0,1])\n",
    "ax[0].set_yticks([0,1])\n",
    "ax[0].set_xticklabels(['bad','good'])\n",
    "ax[0].set_yticklabels(['bad','good'])\n",
    "ax[0].set_xlabel('Predicted quality')\n",
    "ax[0].set_ylabel('True quality')\n",
    "ax[0].set_title('TRAIN confusion matrix')\n",
    "\n",
    "# add text labels\n",
    "ax[0].text(0,0,f'True negatives:\\n{trainConf[0,0]}' ,ha='center',va='center')\n",
    "ax[0].text(0,1,f'False negatives:\\n{trainConf[1,0]}',ha='center',va='center')\n",
    "ax[0].text(1,1,f'True positives:\\n{trainConf[1,1]}' ,ha='center',va='center')\n",
    "ax[0].text(1,0,f'False positives:\\n{trainConf[0,1]}',ha='center',va='center')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# confmat during TEST\n",
    "ax[1].imshow(testConf,'Blues',vmax=len(test_predictions)/2)\n",
    "ax[1].set_xticks([0,1])\n",
    "ax[1].set_yticks([0,1])\n",
    "ax[1].set_xticklabels(['bad','good'])\n",
    "ax[1].set_yticklabels(['bad','good'])\n",
    "ax[1].set_xlabel('Predicted quality')\n",
    "ax[1].set_ylabel('True quality')\n",
    "ax[1].set_title('TEST confusion matrix')\n",
    "\n",
    "# add text labels\n",
    "ax[1].text(0,0,f'True negatives:\\n{testConf[0,0]}' ,ha='center',va='center')\n",
    "ax[1].text(0,1,f'False negatives:\\n{testConf[1,0]}',ha='center',va='center')\n",
    "ax[1].text(1,1,f'True positives:\\n{testConf[1,1]}' ,ha='center',va='center')\n",
    "ax[1].text(1,0,f'False positives:\\n{testConf[0,1]}',ha='center',va='center')\n",
    "plt.show()\n",
    "\n",
    "trainConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9c843-06d3-4835-a7ba-7516f4e0e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] MNIST\n",
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a803e5-677e-4252-80f9-ca4d895ee1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30780b1b-4b4b-418f-9b6d-545b2cf87ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d8783-6009-433e-8115-965a6b5aebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae51a71-3556-46c6-9bd6-bee7f2c48e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and train the model\n",
    "trainAcc,testAcc,losses,net = function2trainTheModel()\n",
    "\n",
    "\n",
    "# visualization starts here\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,3))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aadeba-a05f-429b-8362-90ea14af0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted digits for training data\n",
    "yHat = net(train_loader.dataset.tensors[0])\n",
    "train_predictions = torch.argmax(yHat,axis=1)\n",
    "\n",
    "# predictions for test data\n",
    "yHat = net(test_loader.dataset.tensors[0])\n",
    "test_predictions = torch.argmax(yHat,axis=1)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf7d36-3019-44fe-b21c-d5a66d4576c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brief aside on computing precision et al. in multiclass data:\n",
    "# There are now 10 classes, so there are 10 precision values.\n",
    "\n",
    "\n",
    "## option 1: compute precision for each class (each number)\n",
    "skm.precision_score(train_loader.dataset.tensors[1],train_predictions,average=None)\n",
    "\n",
    "## option 2: compute average precision, weighted by N\n",
    "skm.precision_score(train_loader.dataset.tensors[1],train_predictions,average='weighted')\n",
    "\n",
    "## option 3: compute average precision, unweighted (same as 'weighted' if category N's are equal)\n",
    "skm.precision_score(train_loader.dataset.tensors[1],train_predictions,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785d95e-b305-491e-bb1b-7a71cd66d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize vectors\n",
    "train_metrics = [0,0,0,0]\n",
    "test_metrics  = [0,0,0,0]\n",
    "\n",
    "# training\n",
    "train_metrics[0] = skm.accuracy_score (train_loader.dataset.tensors[1],train_predictions) # accuracy is overall\n",
    "train_metrics[1] = skm.precision_score(train_loader.dataset.tensors[1],train_predictions,average='weighted')\n",
    "train_metrics[2] = skm.recall_score   (train_loader.dataset.tensors[1],train_predictions,average='weighted')\n",
    "train_metrics[3] = skm.f1_score       (train_loader.dataset.tensors[1],train_predictions,average='weighted')\n",
    "\n",
    "\n",
    "# test\n",
    "test_metrics[0] = skm.accuracy_score (test_loader.dataset.tensors[1],test_predictions)\n",
    "test_metrics[1] = skm.precision_score(test_loader.dataset.tensors[1],test_predictions,average='weighted')\n",
    "test_metrics[2] = skm.recall_score   (test_loader.dataset.tensors[1],test_predictions,average='weighted')\n",
    "test_metrics[3] = skm.f1_score       (test_loader.dataset.tensors[1],test_predictions,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bdc8e0-370c-440e-96bb-1eb29a03d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(4)-.1,train_metrics,.5)\n",
    "plt.bar(np.arange(4)+.1,test_metrics,.5)\n",
    "plt.xticks([0,1,2,3],['Accuracy','Precision','Recall','F1-score'])\n",
    "plt.ylim([.9,1])\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Performance metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a76c0e-6871-446d-8ab9-c8ed4b564dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graphs of class-specific precision and recall for test data\n",
    "\n",
    "precision = skm.precision_score(test_loader.dataset.tensors[1],test_predictions,average=None)\n",
    "recall    = skm.recall_score   (test_loader.dataset.tensors[1],test_predictions,average=None)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.bar(np.arange(10)-.15,precision,.5)\n",
    "plt.bar(np.arange(10)+.15,recall,.5)\n",
    "plt.xticks(range(10),range(10))\n",
    "plt.ylim([.5,1])\n",
    "plt.xlabel('Number')\n",
    "plt.legend(['Precision','Recall'])\n",
    "plt.title('Category-specific performance metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381ff0d-1c07-43a8-850b-2f41339c127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "trainConf = skm.confusion_matrix(train_loader.dataset.tensors[1],train_predictions,normalize='true')\n",
    "testConf  = skm.confusion_matrix(test_loader.dataset.tensors[1], test_predictions,normalize='true')\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "# confmat during TRAIN\n",
    "ax[0].imshow(trainConf,'Blues',vmax=.05)\n",
    "ax[0].set_xticks(range(10))\n",
    "ax[0].set_yticks(range(10))\n",
    "ax[0].set_title('TRAIN confusion matrix')\n",
    "ax[0].set_xlabel('True number')\n",
    "ax[0].set_xlabel('Predicted number')\n",
    "ax[0].set_ylabel('True number')\n",
    "\n",
    "# confmat during TEST\n",
    "a = ax[1].imshow(testConf,cmap='Blues',vmax=.05)\n",
    "ax[1].set_xticks(range(10))\n",
    "ax[1].set_yticks(range(10))\n",
    "ax[1].set_title('TEST confusion matrix')\n",
    "ax[1].set_xlabel('Predicted number')\n",
    "ax[1].set_ylabel('True number')\n",
    "\n",
    "fig.colorbar(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ff3d3c-580b-4196-8c67-1e8e0d3849b3",
   "metadata": {},
   "source": [
    "## 4-2. Computation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea222aed-8bdf-40a3-b313-9631d0e71f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel():\n",
    "\n",
    "  # Start the timer!\n",
    "  timerInFunction = time.process_time()\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "    # Finally, report the epoch number, computation time, and accuracy\n",
    "    comptime = time.process_time() - timerInFunction\n",
    "    print(f'Epoch {epochi+1}/{numepochs}, elapsed time: {comptime:.2f} sec, test accuracy {testAcc[-1]:.0f}%')\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1c764-bd09-4f6e-a01b-fcc67bbcad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7ce6c-f168-484b-834b-c4589c55b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run a second timer over repeated iterations\n",
    "\n",
    "# Start the timer! (note the different variable name)\n",
    "timerOutsideFunction = time.process_time()\n",
    "\n",
    "for i in range(10):\n",
    "  function2trainTheModel()\n",
    "\n",
    "TotalExperimentTime = time.process_time() - timerOutsideFunction\n",
    "print(f'\\n\\n\\nTotal elapsed experiment time: {TotalExperimentTime/60:.2f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791b620-38d4-4b95-b463-42dbfe2030f9",
   "metadata": {},
   "source": [
    "# 5. Save & Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1dfc1f-c890-46c5-998b-4846f3ba62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] save the model\n",
    "torch.save(net.state_dict(),'trainedModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093732a-87d0-426e-9f70-6c75014bc7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] Load\n",
    "# create two new models of the same class\n",
    "model1 = createTheMNISTNet()[0]\n",
    "model2 = createTheMNISTNet()[0]\n",
    "\n",
    "# replace one model's parameters with those of the trained net\n",
    "model1.load_state_dict(torch.load('trainedModel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face40fe-84f9-470b-851f-0199d6e955e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] Compare\n",
    "# get some data from the test loader\n",
    "X,y = next(iter(test_loader))\n",
    "\n",
    "# run the data through both models\n",
    "yHatNet    = net(X)\n",
    "yHatModel1 = model1(X)\n",
    "yHatModel2 = model2(X)\n",
    "\n",
    "\n",
    "# show that the results overlap\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.plot(yHatNet[:,5].detach(),'b',label='Original')\n",
    "plt.plot(yHatModel1[:,5].detach(),'ro',label='Loaded')\n",
    "plt.plot(yHatModel2[:,5].detach(),'mx',label='Not loaded')\n",
    "plt.legend()\n",
    "plt.xlabel('Stimulus index')\n",
    "plt.ylabel('Model output for node \"6\"')\n",
    "plt.xlim([1000,1100])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad648bb0-f8d8-416f-86b2-a1fe2f17de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] Best model\n",
    "theBest = [0,0]\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "  # \"train the model\"\n",
    "  accuracy = np.random.rand()\n",
    "\n",
    "  # see if this is better than any previous runs\n",
    "  if accuracy>theBest[0]:\n",
    "    theBest = [accuracy,i]\n",
    "\n",
    "\n",
    "print(f'Highest \"accuracy\" was {100*theBest[0]:.2f}% in run {theBest[1]+1}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc536dc-01e4-4f82-96dc-f053c3507c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel():\n",
    "\n",
    "  # New! initialize a dictionary for the best model\n",
    "  theBestModel = {'Accuracy':0, 'net':None}\n",
    "\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 100\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheQwertyNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses   = torch.zeros(numepochs)\n",
    "  trainAcc = []\n",
    "  devAcc   = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # switch on training mode\n",
    "    net.train()\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100 \n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    net.eval()\n",
    "    X,y = next(iter(dev_loader)) # extract X,y from devset dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    devAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "\n",
    "    # New! Store this model if it's the best so far\n",
    "    if devAcc[-1]>theBestModel['Accuracy']:\n",
    "      \n",
    "      # new best accuracy\n",
    "      theBestModel['Accuracy'] = devAcc[-1].item()\n",
    "      \n",
    "      # model's internal state\n",
    "      theBestModel['net'] = copy.deepcopy( net.state_dict() )\n",
    "      \n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,devAcc,losses,theBestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a66043-e7de-472b-a2d3-e5a59c9de957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model\n",
    "trainAcc,devAcc,losses,theBestModel = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cebfc8-5670-4020-a491-3769d68186c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses.detach(),'o-')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_title('Losses')\n",
    "\n",
    "ax[1].plot(trainAcc,'o-',label='Train')\n",
    "ax[1].plot(devAcc,'o-',label='Devset')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].set_ylim([85,95])\n",
    "ax[1].set_xlim([80,105])\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70857b46-e235-4171-92e8-645cc5d4548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "theBestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314562bb-5dfa-4561-aecd-1055d52aec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract X,y from test dataloader\n",
    "X,y = next(iter(test_loader)) \n",
    "\n",
    "# yHat = theBestModel['net'](X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5beff47-28fd-4b87-865f-59a6b780c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the best-performing model\n",
    "bestnet = createTheQwertyNet()[0]\n",
    "bestnet.load_state_dict(theBestModel['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794b22a-d0a1-4eab-998e-37e5a35616cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and run the data through TEST\n",
    "X,y = next(iter(test_loader)) \n",
    "yHat = bestnet(X)\n",
    "\n",
    "bestAcc = 100*torch.mean((torch.argmax(yHat,axis=1)==y).float())\n",
    "bestAcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348e51b-28cc-43a9-95ac-86de4a72d700",
   "metadata": {},
   "source": [
    "# 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff3e5a-041b-4426-940f-a49700691f72",
   "metadata": {},
   "source": [
    "## 7. Optimization\n",
    "PyTorch introduces the inference speedups.\n",
    "\n",
    "1. `torch.compile(model=None, *, fullgraph=False, dynamic=None, backend='inductor', mode=None, options=None, disable=False)`: Optimizes given model/function using TorchDynamo & specified backend.\n",
    "   - Running TorchInductor on GPU requires [Triton](https://github.com/triton-lang/triton). Check the installation instructions. Update NVIDIA drivers & PyTorch to the latest versions.\n",
    "   - An arbitrary Python function can be optimized by passing the callable to `torch.compile` or decorating the function with `@torch.compile`.\n",
    "   - Nested function calls & submodules will also be compiled. Or you can disable compilation using `@torch.compiler.disable(recursive=False)`.\n",
    "   - [TorchDynamo APIs for Fine-Grained Tracing](https://pytorch.org/docs/stable/torch.compiler_fine_grain_apis.html#torchdynamo-apis-for-fine-grained-tracing)\n",
    "\n",
    "Best practices:\n",
    "- **Top-Level Compilation:** One approach is to compile at the highest level possible (i.e., when the top-level module is initialized/called) and selectively disable compilation when encountering excessive graph breaks or errors. If there are still many compile issues, compile individual subcomponents instead.\n",
    "- **Modular Testing:** Test individual functions and modules with `torch.compile` before integrating them into larger models to isolate potential issues.\n",
    "- **Disable Compilation Selectively:** If certain functions or sub-modules cannot be handled by `torch.compile`, use the `torch.compiler.disable` context managers to recursively exclude them from compilation.\n",
    "- **Compile Leaf Functions First:** In complex models with multiple nested functions and modules, start by compiling the leaf functions or modules first. For more information see TorchDynamo APIs for fine-grained tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e65132d-685d-4728-a2eb-8e787d0a3b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> quantize_per_tensor\n",
      "refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> quantize_per_tensor\n",
      "refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> dequantize_per_tensor\n",
      "refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> dequantize_per_tensor\n",
      "tensor([[ 8.6933e-01,  7.5847e-04,  3.9209e-01,  8.7964e-01,  9.0168e-02,\n",
      "          1.8997e+00,  6.3927e-02,  1.9821e+00,  1.0241e+00,  2.5646e-01],\n",
      "        [ 5.8212e-02,  1.1917e+00, -3.9244e-01,  4.9394e-01,  1.0135e+00,\n",
      "         -5.8056e-02,  4.3636e-01,  3.7796e-02, -8.9714e-01,  7.5028e-01],\n",
      "        [ 8.4038e-01,  5.7328e-01, -9.5642e-02,  4.7605e-02,  2.5690e-01,\n",
      "         -1.4153e-01,  6.5757e-01,  4.1083e-01,  1.5635e+00,  9.8605e-01],\n",
      "        [ 3.4656e-01,  2.0036e-01,  8.9890e-02,  1.6248e+00,  6.8143e-01,\n",
      "          1.7246e+00,  3.4969e-01, -1.1370e+00,  1.7010e+00, -6.9169e-02],\n",
      "        [-1.8587e-01,  1.9307e+00,  1.6062e+00,  5.6829e-01, -2.2361e-01,\n",
      "          6.7700e-02, -2.3033e-01,  1.6427e+00,  6.9321e-01,  1.9857e+00],\n",
      "        [ 2.4839e-01,  2.2238e-01, -3.3283e-01,  1.4502e+00,  5.6896e-02,\n",
      "          7.6480e-01,  1.5154e+00,  9.8800e-02,  1.1502e+00,  1.9455e+00],\n",
      "        [ 8.0042e-01,  1.2376e+00, -4.9435e-03,  1.6363e+00,  1.1950e+00,\n",
      "          8.6264e-01,  5.7797e-01,  2.1018e-01,  2.4096e-02,  7.4641e-02],\n",
      "        [ 4.0109e-01,  5.3398e-01,  3.5497e-02,  1.1745e-01,  3.7927e-01,\n",
      "         -4.4563e-01,  9.5947e-02,  1.4713e+00, -8.6062e-01,  2.0885e-01],\n",
      "        [ 5.9912e-01,  1.3075e-02, -1.1133e+00, -1.1433e-01,  7.7315e-01,\n",
      "         -3.3709e-01, -2.5222e-01,  8.2125e-01, -4.7753e-02, -2.4673e-01],\n",
      "        [ 1.9559e-01,  5.3607e-01,  9.6211e-01, -1.4481e-03, -4.5880e-01,\n",
      "          9.4744e-03,  1.6845e+00,  1.6216e+00,  1.5713e+00,  3.5508e-01]])\n"
     ]
    }
   ],
   "source": [
    "# `torch.compile()`\n",
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "opt_foo1 = torch.compile(foo)\n",
    "print(opt_foo1(torch.randn(10, 10), torch.randn(10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "666748ec-a026-47c5-b948-3878ce8a35d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.5126e-01,  8.7730e-02, -1.5393e-03,  6.8282e-01,  1.5495e+00,\n",
      "         -1.1766e-01,  4.8922e-01,  5.2666e-01,  2.9069e-01, -3.9022e-02],\n",
      "        [ 1.4289e+00,  6.8740e-02,  6.8203e-01,  1.4575e+00,  1.6099e+00,\n",
      "          1.9043e+00,  9.8577e-01, -1.5439e-01,  1.4233e+00, -2.6519e-01],\n",
      "        [ 4.2308e-01,  1.8493e+00,  3.9818e-01,  4.7927e-01, -9.0105e-02,\n",
      "          6.0482e-01,  1.2752e+00, -2.6861e-01, -3.1696e-01,  7.3602e-01],\n",
      "        [ 8.0196e-01,  3.5524e-01,  1.8555e+00,  9.0838e-01, -3.1011e-01,\n",
      "         -7.7550e-01,  9.3343e-01,  7.4526e-01, -3.8135e-02,  6.0181e-01],\n",
      "        [ 1.6538e+00,  1.3102e+00,  3.3101e-01,  1.7505e+00,  4.6171e-01,\n",
      "          8.5225e-01,  9.6259e-01,  5.2586e-01,  1.6967e+00, -2.6893e-01],\n",
      "        [ 7.6992e-01,  1.0677e+00,  1.1792e-01,  1.1183e-01,  1.2136e+00,\n",
      "          9.9022e-01,  1.0098e+00,  4.9332e-01, -8.8015e-01,  1.0438e+00],\n",
      "        [ 1.6655e+00,  1.8387e+00,  5.5634e-01,  1.4005e-01, -6.5086e-01,\n",
      "          8.6880e-01,  1.5779e+00,  3.1937e-01,  1.5763e+00,  9.4115e-01],\n",
      "        [ 1.5085e-01,  6.5551e-01,  3.2504e-01,  1.7724e-01,  2.7040e-01,\n",
      "          1.1358e+00,  9.6705e-01,  7.2777e-01,  1.6561e+00, -3.8364e-02],\n",
      "        [ 1.5939e+00,  1.5664e+00, -2.7975e-01, -2.1025e-01,  1.3504e+00,\n",
      "         -7.7260e-02,  6.1707e-01,  6.0979e-01,  2.2117e-01, -1.5377e+00],\n",
      "        [ 4.4446e-01,  1.2673e+00,  1.9353e+00,  1.6581e+00,  9.2520e-01,\n",
      "          1.6581e+00,  5.6697e-01, -1.5729e-01,  8.6051e-01, -3.9237e-01]])\n"
     ]
    }
   ],
   "source": [
    "# `@torch.compile`\n",
    "t1 = torch.randn(10, 10)\n",
    "t2 = torch.randn(10, 10)\n",
    "\n",
    "@torch.compile\n",
    "def opt_foo2(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "print(opt_foo2(t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24aceefe-8e56-4693-a38e-da8da1e8a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.5126e-01,  8.7730e-02, -1.5393e-03,  6.8282e-01,  1.5495e+00,\n",
      "         -1.1766e-01,  4.8922e-01,  5.2666e-01,  2.9069e-01, -3.9022e-02],\n",
      "        [ 1.4289e+00,  6.8740e-02,  6.8203e-01,  1.4575e+00,  1.6099e+00,\n",
      "          1.9043e+00,  9.8577e-01, -1.5439e-01,  1.4233e+00, -2.6519e-01],\n",
      "        [ 4.2308e-01,  1.8493e+00,  3.9818e-01,  4.7927e-01, -9.0105e-02,\n",
      "          6.0482e-01,  1.2752e+00, -2.6861e-01, -3.1696e-01,  7.3602e-01],\n",
      "        [ 8.0196e-01,  3.5524e-01,  1.8555e+00,  9.0838e-01, -3.1011e-01,\n",
      "         -7.7550e-01,  9.3343e-01,  7.4526e-01, -3.8135e-02,  6.0181e-01],\n",
      "        [ 1.6538e+00,  1.3102e+00,  3.3101e-01,  1.7505e+00,  4.6171e-01,\n",
      "          8.5225e-01,  9.6259e-01,  5.2586e-01,  1.6967e+00, -2.6893e-01],\n",
      "        [ 7.6992e-01,  1.0677e+00,  1.1792e-01,  1.1183e-01,  1.2136e+00,\n",
      "          9.9022e-01,  1.0098e+00,  4.9332e-01, -8.8015e-01,  1.0438e+00],\n",
      "        [ 1.6655e+00,  1.8387e+00,  5.5634e-01,  1.4005e-01, -6.5086e-01,\n",
      "          8.6880e-01,  1.5779e+00,  3.1937e-01,  1.5763e+00,  9.4115e-01],\n",
      "        [ 1.5085e-01,  6.5551e-01,  3.2504e-01,  1.7724e-01,  2.7040e-01,\n",
      "          1.1358e+00,  9.6705e-01,  7.2777e-01,  1.6561e+00, -3.8364e-02],\n",
      "        [ 1.5939e+00,  1.5664e+00, -2.7975e-01, -2.1025e-01,  1.3504e+00,\n",
      "         -7.7260e-02,  6.1707e-01,  6.0979e-01,  2.2117e-01, -1.5377e+00],\n",
      "        [ 4.4446e-01,  1.2673e+00,  1.9353e+00,  1.6581e+00,  9.2520e-01,\n",
      "          1.6581e+00,  5.6697e-01, -1.5729e-01,  8.6051e-01, -3.9237e-01]])\n"
     ]
    }
   ],
   "source": [
    "# `@torch.compile` with nested functions\n",
    "def nested_function(x):\n",
    "    return torch.sin(x)\n",
    "\n",
    "@torch.compile\n",
    "def outer_function(x, y):\n",
    "    a = nested_function(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "print(outer_function(t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92e43b1a-549a-4483-8de6-4c29ec8318fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5393, 0.2917, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000, 0.4562, 0.3549,\n",
      "         0.5634],\n",
      "        [0.2787, 0.0000, 0.0000, 0.1695, 0.4874, 0.0000, 0.0000, 0.0000, 0.9075,\n",
      "         0.3468],\n",
      "        [0.1160, 0.0000, 0.0000, 0.7212, 0.6043, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.4435],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6279, 0.1041, 0.0000, 0.0000, 0.0000, 0.4334,\n",
      "         0.0000],\n",
      "        [0.0119, 0.0000, 1.0767, 0.7205, 0.3798, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2850, 0.6219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0924, 0.6958,\n",
      "         0.3071],\n",
      "        [0.0000, 0.3307, 0.1828, 0.0000, 0.0000, 0.0000, 0.8457, 0.0000, 0.0000,\n",
      "         0.2721],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1516, 0.0000, 0.2325, 0.3455,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0032, 0.0000, 0.0000, 0.0000, 0.0000, 0.7204, 0.0000, 0.0000,\n",
      "         0.4558],\n",
      "        [0.0000, 0.0000, 0.0000, 1.2350, 0.6283, 0.6489, 0.0000, 0.6369, 0.1068,\n",
      "         0.0835]], grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# `torch.compile()` with `torch.nn.Module` instances\n",
    "t = torch.randn(10, 100)\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.lin(x))\n",
    "\n",
    "mod = MyModule()\n",
    "opt_mod = torch.compile(mod)\n",
    "print(opt_mod(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "528e44b8-b838-4c42-bd29-8a03de4ca1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0747],\n",
      "        [0.0000, 0.1943],\n",
      "        [0.0000, 0.2722],\n",
      "        [0.0000, 0.2669],\n",
      "        [0.0000, 0.4329],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0878],\n",
      "        [0.0000, 0.2325],\n",
      "        [0.0000, 0.2807],\n",
      "        [0.0000, 0.6843]], grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# `torch.compile()` with submodules\n",
    "class OuterModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inner_module = MyModule()\n",
    "        self.outer_lin = torch.nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inner_module(x)\n",
    "        return torch.nn.functional.relu(self.outer_lin(x))\n",
    "\n",
    "outer_mod = OuterModule()\n",
    "opt_outer_mod = torch.compile(outer_mod)\n",
    "print(opt_outer_mod(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178a9aac-2dda-476e-97ed-24444cfc1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Speedups\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "# Generates random input and targets data for the model, where `b` is batch size.\n",
    "def generate_data(b):\n",
    "    return (\n",
    "        torch.randn(b, 3, 128, 128).to(torch.float32).cuda(),\n",
    "        torch.randint(1000, (b,)).cuda(),\n",
    "    )\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "def init_model():\n",
    "    return densenet121().to(torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c7b0d4-6989-4cd4-b591-f521029d2367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager train time 0: 0.02529996871948242\n",
      "eager train time 1: 0.021381824493408204\n",
      "eager train time 2: 0.023163679122924805\n",
      "eager train time 3: 0.022937599182128905\n",
      "eager train time 4: 0.022953983306884765\n",
      "eager train time 5: 0.022991840362548827\n",
      "eager train time 6: 0.023912256240844726\n",
      "eager train time 7: 0.023015552520751954\n",
      "eager train time 8: 0.022227968215942383\n",
      "eager train time 9: 0.019496864318847656\n",
      "~~~~~~~~~~\n",
      "compile train time 0: 51.86091796875\n",
      "compile train time 1: 5.8743623046875\n",
      "compile train time 2: 0.018679807662963867\n",
      "compile train time 3: 0.01844121551513672\n",
      "compile train time 4: 0.017512447357177736\n",
      "compile train time 5: 0.0174704647064209\n",
      "compile train time 6: 0.017583103179931642\n",
      "compile train time 7: 0.017505151748657227\n",
      "compile train time 8: 0.017543167114257813\n",
      "compile train time 9: 0.0174653434753418\n",
      "~~~~~~~~~~\n",
      "(train) eager median: 0.022972911834716794, compile median: 0.017563135147094726, speedup: 1.308018849841678x\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# [1] Eager\n",
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def train(mod, data):\n",
    "    opt.zero_grad(True)\n",
    "    pred = mod(data[0])\n",
    "    loss = torch.nn.CrossEntropyLoss()(pred, data[1])\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "eager_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)\n",
    "    _, eager_time = timed(lambda: train(model, inp))\n",
    "    eager_times.append(eager_time)\n",
    "    print(f\"eager train time {i}: {eager_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "# [2] `torch.compile()`\n",
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_opt = torch.compile(train, mode=\"reduce-overhead\")\n",
    "\n",
    "compile_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)\n",
    "    _, compile_time = timed(lambda: train_opt(model, inp))\n",
    "    compile_times.append(compile_time)\n",
    "    print(f\"compile train time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "eager_med = np.median(eager_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = eager_med / compile_med\n",
    "assert(speedup > 1)\n",
    "print(f\"(train) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\")\n",
    "print(\"~\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310841d-839d-44e2-b616-7a5f5e743ecf",
   "metadata": {},
   "source": [
    "## 8. PyTorch Lightning Trainer\n",
    "1. `pytorch_lightning.Trainer(*, accelerator='auto', strategy='auto', devices='auto', num_nodes=1, precision=None, logger=None, callbacks=None, fast_dev_run=False, max_epochs=None, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, overfit_batches=0.0, val_check_interval=None, check_val_every_n_epoch=1, num_sanity_val_steps=None, log_every_n_steps=None, enable_checkpointing=None, enable_progress_bar=None, enable_model_summary=None, accumulate_grad_batches=1, gradient_clip_val=None, gradient_clip_algorithm=None, deterministic=None, benchmark=None, inference_mode=True, use_distributed_sampler=True, profiler=None, detect_anomaly=False, barebones=False, plugins=None, sync_batchnorm=False, reload_dataloaders_every_n_epochs=0, default_root_dir=None)`\n",
    "   - [Trainer Class API](https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api)\n",
    "3. `Trainer.fit()`\n",
    "4. `Trainer.validate()`\n",
    "5. `Trainer.test()`\n",
    "6. `Trainer.predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1652f-41a6-4382-88a4-a0e54eb2e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLightningModule()\n",
    "\n",
    "trainer = Trainer()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ac98c-289e-41db-9633-119d5b9b1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model=model, dataloaders=val_dataloaders)\n",
    "trainer.test(dataloaders=test_dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc95c5-9d7e-40bd-9527-aeff46b9e5a6",
   "metadata": {},
   "source": [
    "## 9. Accelerate Accelerator\n",
    "**Accelerate** is a library, developed by Hugging Face, that makes training & inference at scale simple, efficient & adaptable. 3 main features of Accelerate:\n",
    "- **Unified Launch Interface:** A unified command line launching interface for distributed training scripts.\n",
    "- **Adapt Training Code:** Enables the same PyTorch code to be run across different distributed configurations.\n",
    "- **Big Model Inference:** Loads large models for inference that typically don't fit into memory.\n",
    "1. `accelerate.Accelerator(gradient_accumulation_steps)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e2ca4-00a2-4ee7-b1c5-203ed0f2cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd11ffa-9208-42de-825b-5f414e4483a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1b5f6-6de6-49a4-9e9a-5164b5c52f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = accelerator.device\n",
    "\n",
    "model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7698e8a-2029-49ae-9a6d-94b221eb7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in dataloader:\n",
    "    # inputs = inputs.to(device)\n",
    "    # targets = targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    # loss.backward()\n",
    "    #\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07711fd-2b43-47e2-ad5f-a382d031ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "import evaluate\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "train_dataloader, eval_dataloader, model, optimizer, scheduler = (\n",
    "    accelerator.prepare(\n",
    "        train_dataloader, eval_dataloader, \n",
    "        model, optimizer, scheduler\n",
    "    )\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "for inputs, targets in train_dataloader:\n",
    "    # inputs = inputs.to(device)\n",
    "    # targets = targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "model.eval()\n",
    "for inputs, targets in eval_dataloader:\n",
    "    # inputs = inputs.to(device)\n",
    "    # targets = targets.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    predictions = outputs.argmax(dim=-1)\n",
    "    # \n",
    "    predictions, references = accelerator.gather_for_metrics(\n",
    "        (predictions, references)\n",
    "    )\n",
    "    metric.add_batch(\n",
    "        predictions = predictions,\n",
    "        references = references\n",
    "    )\n",
    "print(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc2e49-609d-4f78-a8d8-0648a04465b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient accumulation\n",
    "from accelerate import Accelerator\n",
    "\n",
    "#\n",
    "accelerator = Accelerator(gradient_accumulation_steps=2)\n",
    "dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)\n",
    "\n",
    "for batch in dataloader:\n",
    "    #\n",
    "    with accelerator.accumulate(model):\n",
    "        inputs, targets = batch\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d66920-398a-4890-9005-0a336d467952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "dataloader, model, optimizer, scheduler = accelerator.prepare(\n",
    "    dataloader, model, optimizer, scheduler\n",
    ")\n",
    "  \n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "#\n",
    "accelerator.save_state(\"checkpoint_dir\")\n",
    "#\n",
    "accelerator.load_state(\"checkpoint_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9660cfab-bec4-4af8-ae07-f1598444ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Tracking\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator(log_with=\"wandb\")\n",
    "train_dataloader, model, optimizer, scheduler = accelerator.prepare(\n",
    "    dataloader, model, optimizer, scheduler\n",
    ")\n",
    "#\n",
    "accelerator.init_trackers()\n",
    "model.train()\n",
    "for batch in train_dataloader:\n",
    "    inputs, targets = batch\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    #\n",
    "    accelerator.log({\"loss\":loss})\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "#\n",
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086b7d4-9b0a-4b1f-8849-4e984057e434",
   "metadata": {},
   "source": [
    "## 10. Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512193-998a-41f1-8a16-5de2368a3cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
