{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac9ec03-3b62-414e-ae86-0ae82be1aa90",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "1. `torch.utils.data.Dataset`\n",
    "2. `torch.utils.data.DataLoader`\n",
    "   - Batching the data.\n",
    "   - Shuffling the data.\n",
    "   - Loading the data in parallel using `multiprocessing` workers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bdc30a-101b-4b65-80d7-0671a10ee864",
   "metadata": {},
   "source": [
    "## 1-1. Cross Validation with Manual Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988fd295-f785-4b00-8d74-1b5f57050bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many training examples\n",
    "propTraining = .8 # in proportion, not percent\n",
    "nTraining = int(len(labels)*propTraining)\n",
    "\n",
    "# initialize a boolean vector to select data and labels\n",
    "traintestBool = np.zeros(len(labels),dtype=bool)\n",
    "\n",
    "# is this the correct way to select samples?\n",
    "# traintestBool[range(nTraining)] = True\n",
    "\n",
    "# this is better, but why?\n",
    "items2use4train = np.random.choice(range(len(labels)),nTraining,replace=False)\n",
    "traintestBool[items2use4train] = True\n",
    "\n",
    "traintestBool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a7b22-d66d-44f0-91ec-75498a217ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether it's balanced\n",
    "print('Average of full data:')\n",
    "print( torch.mean(labels.float()) ) # =1 by definition\n",
    "print(' ')\n",
    "\n",
    "print('Average of training data:')\n",
    "print( torch.mean(labels[traintestBool].float()) ) # should be 1...\n",
    "print(' ')\n",
    "\n",
    "print('Average of test data:')\n",
    "print( torch.mean(labels[~traintestBool].float()) ) # should also be 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178e31b-d75c-4531-8e5c-fe05f02ac9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire dataset\n",
    "print( data.shape )\n",
    "\n",
    "# training set\n",
    "print( data[traintestBool,:].shape )\n",
    "\n",
    "# test set\n",
    "print( data[~traintestBool,:].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740dcbdb-4d1c-47d2-9c78-11959cd71391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ANN model\n",
    "\n",
    "# model architecture\n",
    "ANNiris = nn.Sequential(\n",
    "    nn.Linear(4,64),   # input layer\n",
    "    nn.ReLU(),         # activation unit\n",
    "    nn.Linear(64,64),  # hidden layer\n",
    "    nn.ReLU(),         # activation unit\n",
    "    nn.Linear(64,3),   # output units\n",
    "      )\n",
    "\n",
    "# loss function\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8583a3-e636-4008-b1a7-c56e7af2da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "numepochs = 1000\n",
    "\n",
    "# initialize losses\n",
    "losses = torch.zeros(numepochs)\n",
    "ongoingAcc = []\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # forward pass\n",
    "  yHat = ANNiris(data[traintestBool,:])\n",
    "\n",
    "  # compute accuracy (note: denser than previous code!)\n",
    "  ongoingAcc.append( 100*torch.mean(\n",
    "              (torch.argmax(yHat,axis=1) == labels[traintestBool]).float()) )\n",
    "\n",
    "  # compute loss\n",
    "  loss = lossfun(yHat,labels[traintestBool])\n",
    "  losses[epochi] = loss\n",
    "\n",
    "  # backprop\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb315bd-a0f7-43fb-b83e-154478496f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute train and test accuracies\n",
    "\n",
    "# final forward pass USING TRAINING DATA\n",
    "predictions = ANNiris(data[traintestBool,:])\n",
    "trainacc = 100*torch.mean((torch.argmax(predictions,axis=1) == labels[traintestBool]).float())\n",
    "\n",
    "\n",
    "# final forward pass USING TEST DATA!\n",
    "predictions = ANNiris(data[~traintestBool,:])\n",
    "testacc = 100*torch.mean((torch.argmax(predictions,axis=1) == labels[~traintestBool]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e89e22-a1ab-47de-bfc4-490f0afd5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report accuracies\n",
    "\n",
    "print('Final TRAIN accuracy: %g%%' %trainacc)\n",
    "print('Final TEST accuracy:  %g%%' %testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a347c-2692-4bcd-af78-a4c533f8950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
    "fakelabels = np.arange(10)>4\n",
    "print(fakedata), print(' ')\n",
    "print(fakelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05543a-65ee-48e6-89fa-8a7df91930e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition sizes in proportion\n",
    "partitions = np.array([.8,.1,.1])\n",
    "print('Partition proportions:')\n",
    "print(partitions)\n",
    "print(' ')\n",
    "\n",
    "# convert those into integers\n",
    "partitionBnd = np.cumsum(partitions*len(fakelabels)).astype(int)\n",
    "print('Partition boundaries:')\n",
    "print(partitionBnd)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "# random indices\n",
    "randindices = np.random.permutation(range(len(fakelabels)))\n",
    "print('Randomized data indices:')\n",
    "print(randindices)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19afe7d-ee3f-4444-82fd-38a29176d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows for the training data\n",
    "train_dataN   = fakedata[randindices[:partitionBnd[0]],:]\n",
    "train_labelsN = fakelabels[randindices[:partitionBnd[0]]]\n",
    "\n",
    "# select rows for the devset data\n",
    "devset_dataN   = fakedata[randindices[partitionBnd[0]:partitionBnd[1]],:]\n",
    "devset_labelsN = fakelabels[randindices[partitionBnd[0]:partitionBnd[1]]]\n",
    "\n",
    "# select rows for the test data\n",
    "test_dataN   = fakedata[randindices[partitionBnd[1]:],:]\n",
    "test_labelsN = fakelabels[randindices[partitionBnd[1]:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675c257-13f4-4f91-9d73-7834956ec91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the sizes\n",
    "print('Training data size: ' + str(train_dataN.shape))\n",
    "print('Devset size: '        + str(devset_dataN.shape))\n",
    "print('Test data size: '     + str(test_dataN.shape))\n",
    "print(' ')\n",
    "\n",
    "# print out the train/test data\n",
    "print('Training data: ')\n",
    "print(train_dataN)\n",
    "print(' ')\n",
    "\n",
    "print('Devset data: ')\n",
    "print(devset_dataN)\n",
    "print(' ')\n",
    "\n",
    "print('Test data: ')\n",
    "print(test_dataN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558116c-d133-4f80-b4de-f7d56330734a",
   "metadata": {},
   "source": [
    "## 1-2. Cross Validation with scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b989a-0bc0-43a5-a859-9f0c4c74e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(fakedata, fakelabels, test_size=.2)\n",
    "\n",
    "# print out the sizes\n",
    "print('Training data size: ' + str(train_data.shape))\n",
    "print('Test data size: ' + str(test_data.shape))\n",
    "print(' ')\n",
    "\n",
    "# print out the train/test data\n",
    "print('Training data: ')\n",
    "print(train_data)\n",
    "print(' ')\n",
    "\n",
    "print('Test data: ')\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea7ca11-98ca-42f7-85ee-6612770cc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createANewModel():\n",
    "\n",
    "  # model architecture\n",
    "  ANNiris = nn.Sequential(\n",
    "      nn.Linear(4,64),   # input layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,64),  # hidden layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,3),   # output units\n",
    "        )\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)\n",
    "\n",
    "  return ANNiris,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04557c52-3947-4f39-b2b2-f5fa20d4ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 200\n",
    "\n",
    "def trainTheModel(trainProp):\n",
    "\n",
    "  # initialize losses\n",
    "  losses = torch.zeros(numepochs)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # separate train from test data\n",
    "    # Note 1: unique split for each epoch!\n",
    "    # Note 2: here we specify the training size, not the testing size!\n",
    "    X_train,X_test, y_train,y_test = train_test_split(data,labels, train_size=trainProp)\n",
    "\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat = ANNiris(X_train)\n",
    "    loss = lossfun(yHat,y_train)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # compute training accuracy\n",
    "    trainAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y_train).float()).item() )\n",
    "\n",
    "    # test accuracy\n",
    "    predlabels = torch.argmax( ANNiris(X_test),axis=1 )\n",
    "    testAcc.append( 100*torch.mean((predlabels == y_test).float()).item() )\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85fc957-e90e-4bd2-9edb-4980e92d8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "ANNiris,lossfun,optimizer = createANewModel()\n",
    "\n",
    "# train the model\n",
    "# NOTE: the input is the training proportion, not the test proportion!\n",
    "trainAcc,testAcc = trainTheModel(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec349f-76c9-4bc4-b830-2b877aa58f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(trainAcc,'ro-')\n",
    "plt.plot(testAcc,'bs-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaaff96-7946-408d-a516-d7f6750579a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSetSizes = np.linspace(.2,.95,10)\n",
    "\n",
    "allTrainAcc = np.zeros((len(trainSetSizes),numepochs))\n",
    "allTestAcc = np.zeros((len(trainSetSizes),numepochs))\n",
    "\n",
    "for i in range(len(trainSetSizes)):\n",
    "\n",
    "  # create a model\n",
    "  ANNiris,lossfun,optimizer = createANewModel()\n",
    "\n",
    "  # train the model\n",
    "  trainAcc,testAcc = trainTheModel(trainSetSizes[i])\n",
    "\n",
    "  # store the results\n",
    "  allTrainAcc[i,:] = trainAcc\n",
    "  allTestAcc[i,:] = testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4f1a8-525a-4e86-81f8-f75379a6cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(13,5))\n",
    "\n",
    "ax[0].imshow(allTrainAcc,aspect='auto',\n",
    "             vmin=50,vmax=90, extent=[0,numepochs,trainSetSizes[-1],trainSetSizes[0]])\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Training size proportion')\n",
    "ax[0].set_title('Training accuracy')\n",
    "\n",
    "p = ax[1].imshow(allTestAcc,aspect='auto',\n",
    "             vmin=50,vmax=90, extent=[0,numepochs,trainSetSizes[-1],trainSetSizes[0]])\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Training size proportion')\n",
    "ax[1].set_title('Test accuracy')\n",
    "fig.colorbar(p,ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf331f3-4341-48ed-9526-8e70dd27aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "### create fake dataset (same as in previous videos)\n",
    "\n",
    "fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
    "fakelabels = np.arange(10)>4\n",
    "print(fakedata), print(' ')\n",
    "print(fakelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e8ad3-bbf4-49ac-a1c1-2077b17298de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify sizes of the partitions\n",
    "# order is train,devset,test\n",
    "partitions = [.8,.1,.1]\n",
    "\n",
    "# split the data (note the third input, and the TMP in the variable name)\n",
    "train_data,testTMP_data, train_labels,testTMP_labels = \\\n",
    "                   train_test_split(fakedata, fakelabels, train_size=partitions[0])\n",
    "\n",
    "# now split the TMP data\n",
    "split = partitions[1] / np.sum(partitions[1:])\n",
    "devset_data,test_data, devset_labels,test_labels = \\\n",
    "              train_test_split(testTMP_data, testTMP_labels, train_size=partitions[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print out the sizes\n",
    "print('Training data size: ' + str(train_data.shape))\n",
    "print('Devset data size: '   + str(devset_data.shape))\n",
    "print('Test data size: '     + str(test_data.shape))\n",
    "print(' ')\n",
    "\n",
    "# print out the train/test data\n",
    "print('Training data: ')\n",
    "print(train_data)\n",
    "print(' ')\n",
    "\n",
    "print('Devset data: ')\n",
    "print(devset_data)\n",
    "print(' ')\n",
    "\n",
    "print('Test data: ')\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b4154-2c8a-4529-8e57-17e9cb73c65d",
   "metadata": {},
   "source": [
    "## 1-3. Cross Validation with Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a9f78-c9b6-4edf-b65d-b558369c9d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "# create our fake dataset\n",
    "\n",
    "fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
    "fakelabels = np.arange(10)>4\n",
    "print(fakedata), print(' ')\n",
    "print(fakelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82888e38-c1df-4710-b637-c011edc741cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader object with all data\n",
    "fakedataLdr = DataLoader(fakedata, shuffle=True)\n",
    "print( fakedataLdr )\n",
    "print( fakedataLdr.batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94c48e-7df4-43a0-b598-eae2edde21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the data\n",
    "for i,oneSample in enumerate(fakedataLdr):\n",
    "  print(i,oneSample,oneSample.shape)\n",
    "\n",
    "# but where are the labels??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6db20b-8a5d-43c1-a30e-bf72552970ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a Dataset that contains the data and labels\n",
    "fakeDataset = torch.utils.data.TensorDataset(torch.Tensor(fakedata),torch.Tensor(fakelabels))\n",
    "print( fakeDataset.tensors ), print(' ')\n",
    "\n",
    "# then create another DataLoader\n",
    "fakedataLdr = DataLoader(fakeDataset, shuffle=True)\n",
    "\n",
    "# iterate through the data\n",
    "for dat,lab in fakedataLdr:\n",
    "  print(dat,lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59271fdf-74d5-4398-b07d-767be64c2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(fakedata, fakelabels, test_size=.2)\n",
    "\n",
    "# then convert them into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(\n",
    "     torch.Tensor(train_data),torch.Tensor(train_labels))\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(\n",
    "     torch.Tensor(test_data),torch.Tensor(test_labels))\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "# notice the batches (see next cell)!\n",
    "train_loader = DataLoader(train_data,batch_size=4)\n",
    "test_loader  = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c39452f-d5d5-42b4-946d-36d38e50d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the contents of the dataloader (batching is an advantage of dataloader!)\n",
    "print('TRAINING DATA')\n",
    "for batch,label in train_loader: # iterable\n",
    "  print(batch,label)\n",
    "  print(' ')\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print('TESTING DATA')\n",
    "for batch,label in test_loader: # iterable\n",
    "  print(batch,label)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02c134-f114-46d2-9c43-47b249cf4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] \n",
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = \\\n",
    "                              train_test_split(data, labels, train_size=.8)\n",
    "\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "train_loader = DataLoader(train_data,shuffle=True,batch_size=12)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4871f-a7f8-467e-9680-051f1e06fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes of data batches\n",
    "for X,y in train_loader:\n",
    "  print(X.shape,y.shape)\n",
    "\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af83b06-92a0-4d35-8beb-9b2566558e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates the ANN model\n",
    "\n",
    "def createANewModel():\n",
    "\n",
    "  # model architecture\n",
    "  ANNiris = nn.Sequential(\n",
    "      nn.Linear(4,64),   # input layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,64),  # hidden layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,3),   # output units\n",
    "        )\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)\n",
    "\n",
    "  return ANNiris,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2205a-b41f-4558-b58a-e85ceada2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 500\n",
    "\n",
    "def trainTheModel():\n",
    "\n",
    "  # initialize accuracies as empties (not storing losses here)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = ANNiris(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # compute training accuracy just for this batch\n",
    "      batchAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    predlabels = torch.argmax( ANNiris(X),axis=1 )\n",
    "    testAcc.append( 100*torch.mean((predlabels == y).float()).item() )\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a4117-2cac-4d73-ab90-caebe14adba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "ANNiris,lossfun,optimizer = createANewModel()\n",
    "\n",
    "# train the model\n",
    "trainAcc,testAcc = trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44762f3-657b-4665-a52e-50cfe519cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(trainAcc,'ro-')\n",
    "plt.plot(testAcc,'bs-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Train','Test'])\n",
    "\n",
    "# optional zoom-in to final epochs\n",
    "# plt.xlim([300,500])\n",
    "# plt.ylim([90,100.5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4bdbf-eafe-46c0-9d55-35dcad874d0c",
   "metadata": {},
   "source": [
    "# 2. Model Building\n",
    "## 2-1. Sequential\n",
    "The `torch.nn.Sequential` class is easy to set up & read but with limited flexibility & interactivity. Suitable for creating small models.  \n",
    "1. `torch.nn.Sequential(*args: Module)`: Modules will be added to the sequential container in the order they are passed in the constructor.\n",
    "2. `torch.nn.Sequential(arg: OrderedDict[str, Module])`: Passes in an `OrderedDict` of modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a25ec1b-c574-4aa6-bc9c-da8f36304099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 20, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(20, 64, 5),\n",
    "    torch.nn.ReLU()\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a4621-e249-410f-830a-80f00e80fc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv_1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu_2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "model = torch.nn.Sequential(OrderedDict([\n",
    "    (\"conv_1\", torch.nn.Conv2d(1, 20, 5)),\n",
    "    (\"relu_1\", torch.nn.ReLU()),\n",
    "    (\"conv_2\", torch.nn.Conv2d(20, 64, 5)),\n",
    "    (\"relu_2\", torch.nn.ReLU())\n",
    "]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119f018-0e5f-4728-8487-c58a718bebbd",
   "metadata": {},
   "source": [
    "## 2-2. Class\n",
    "Your model should subclass `torch.nn.Module`. `torch.nn` holds basic build blocks for graphs.\n",
    "1. `torch.nn.Module.parameters(recurse=True)`: Returns an iterator over module learnable parameters (weights & biases). This is typically passed to an optimizer.\n",
    "2. `torch.nn.Module.named_parameters(prefix='', recurse=True, remove_duplicate=True)`: Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\n",
    "3. `torch.nn.Module.to(device=None, dtype=None, non_blocking=False)`: Moves and/or casts the parameters and buffers.\n",
    "4. `torch.nn.Module.load_state_dict(state_dict, strict=True, assign=False)`: Copies parameters and buffers from `state_dict` into this module and its descendants.\n",
    "5. `torch.nn.Module.state_dict(*, destination: T_destination, prefix: str = '', keep_vars: bool = False)`: A Python dictionary object contains parameters & persistent buffers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "266b7fec-079e-47a0-97c5-136e9bf5e45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 20, 5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(20, 64, 5),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "  \n",
    "    def forward(self, X):\n",
    "        out = self.conv_layers(X)\n",
    "        return out\n",
    "\n",
    "model = CNNModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8faa0f65-b7a6-458a-82d5-67ef23c5fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 1.3241e-01,  1.5604e-01, -1.0033e-01,  1.9216e-01, -6.9605e-02],\n",
      "          [ 1.7387e-01, -8.7238e-02, -8.7400e-02, -6.6454e-03, -1.3710e-02],\n",
      "          [ 4.7818e-02, -1.3161e-01, -1.2073e-01, -8.0846e-02, -1.4806e-01],\n",
      "          [ 1.5466e-01,  1.7643e-01,  6.8757e-02, -1.3546e-01,  8.1396e-02],\n",
      "          [ 1.4838e-01, -1.3129e-01, -3.4942e-02,  1.3256e-01,  1.8711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7838e-01,  9.0442e-02,  9.4969e-02,  1.9040e-01, -5.6426e-02],\n",
      "          [ 1.4222e-01,  1.0127e-01, -9.1116e-03, -2.4985e-02, -1.6505e-01],\n",
      "          [ 1.7914e-01, -7.6648e-02, -1.7809e-01,  1.2110e-01, -5.1342e-02],\n",
      "          [ 2.2690e-02,  1.5465e-01, -8.5308e-02, -4.7745e-02,  3.1571e-02],\n",
      "          [ 2.8867e-02, -3.0587e-02, -3.1570e-02, -1.9829e-01, -4.0238e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3186e-01, -1.4602e-01,  9.5862e-02, -8.8489e-02, -9.6553e-02],\n",
      "          [-1.3332e-01,  1.1675e-02,  1.6270e-01,  1.4342e-01,  1.4186e-02],\n",
      "          [ 6.7934e-02,  1.0176e-02,  5.6962e-02,  1.9649e-01,  1.5693e-01],\n",
      "          [-1.7073e-01, -2.1391e-02,  2.3361e-02,  3.1500e-02, -6.6577e-02],\n",
      "          [ 7.7104e-02,  1.4623e-01, -7.9448e-03,  3.1214e-02, -7.6848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7350e-02, -1.1280e-01, -1.1613e-01,  3.4520e-02, -9.1342e-03],\n",
      "          [-1.3996e-01, -1.8361e-01,  1.1601e-01, -5.5225e-02, -5.4041e-02],\n",
      "          [ 1.9208e-01, -9.1202e-02,  1.3636e-01,  7.3855e-02, -6.5894e-02],\n",
      "          [ 1.3723e-02,  1.5521e-01,  7.8226e-02, -1.1209e-01, -1.5964e-01],\n",
      "          [-6.5851e-02, -1.5129e-01, -5.2712e-02,  8.9967e-02, -1.8500e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2484e-01, -1.8534e-01,  3.6886e-02,  8.3262e-02,  6.8633e-02],\n",
      "          [ 1.4270e-02,  1.6860e-01,  4.8610e-02, -1.8697e-01, -1.5962e-01],\n",
      "          [-6.1016e-02, -1.6345e-02, -1.1608e-01, -1.8487e-01, -1.6567e-01],\n",
      "          [-4.0601e-02,  8.8121e-02, -1.8425e-02, -3.8099e-02, -1.9318e-01],\n",
      "          [-9.6685e-02,  4.7574e-02,  7.1982e-02,  1.3283e-01, -1.3550e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2990e-01, -1.8027e-02, -1.9720e-01, -1.0266e-01,  1.9599e-01],\n",
      "          [ 2.3637e-03,  8.8786e-02, -3.4413e-02, -1.1878e-01,  1.4574e-01],\n",
      "          [-1.1365e-01, -1.6888e-01,  5.0974e-05, -9.2363e-02, -4.1784e-02],\n",
      "          [ 1.6196e-01,  1.4280e-01, -8.2476e-02,  1.4793e-01,  9.5471e-02],\n",
      "          [ 9.4619e-02, -5.1215e-02,  7.4179e-02, -9.6469e-02, -8.7771e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1201e-01,  1.9360e-01, -1.8400e-01, -3.8823e-02,  1.8009e-01],\n",
      "          [ 1.5503e-01, -1.8852e-01,  2.5678e-02,  1.9906e-01, -1.4539e-01],\n",
      "          [-1.4287e-01, -1.7903e-01,  2.2451e-02,  1.4313e-01,  1.8826e-01],\n",
      "          [ 1.1788e-01,  1.4232e-01, -2.2371e-02, -4.0267e-02,  1.7885e-01],\n",
      "          [-9.0347e-02, -2.7690e-03, -5.3224e-02, -5.5934e-02, -1.3836e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8000e-02, -6.3736e-02, -1.5082e-01,  3.6312e-02, -1.9862e-01],\n",
      "          [ 4.8823e-02, -8.4725e-02,  6.8034e-02,  1.8329e-01,  4.5708e-02],\n",
      "          [ 1.9683e-01, -5.6322e-02,  6.3535e-02,  3.6922e-02,  1.7151e-01],\n",
      "          [ 1.4225e-01, -1.6482e-01,  6.7343e-02,  1.3643e-01,  1.4066e-01],\n",
      "          [ 2.8197e-02, -1.7635e-01, -1.5050e-01,  3.3212e-03,  6.0210e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8715e-02, -1.2924e-01,  1.1012e-01,  8.7607e-03, -1.6257e-01],\n",
      "          [ 7.7766e-02, -1.5367e-01,  1.5281e-01, -5.8361e-02,  1.0171e-01],\n",
      "          [ 1.7840e-01, -1.7470e-01, -1.5965e-01,  5.9101e-02,  1.6743e-01],\n",
      "          [-1.0642e-01, -7.9235e-03, -1.2118e-01, -1.6437e-01, -1.5323e-01],\n",
      "          [ 1.4803e-01,  1.1819e-01, -2.5592e-02,  6.2606e-02,  4.4999e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6631e-01, -1.3663e-01, -1.0860e-01,  1.8708e-01, -1.7883e-01],\n",
      "          [ 1.1482e-02, -1.2443e-01, -1.0491e-01, -9.3156e-02,  6.7180e-02],\n",
      "          [ 8.2907e-02,  1.0562e-01, -3.0791e-02, -8.7147e-02, -2.5293e-02],\n",
      "          [ 6.1346e-03,  1.6903e-01,  3.4932e-02, -1.4125e-01,  1.1192e-02],\n",
      "          [ 1.1734e-01,  1.3849e-01,  1.8247e-01, -6.6997e-02,  1.4443e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5675e-02,  1.7151e-02,  1.8107e-01, -6.6976e-02, -1.6386e-01],\n",
      "          [ 1.8581e-01,  1.1274e-01,  7.9142e-02,  1.4690e-01, -1.3505e-01],\n",
      "          [ 1.1049e-01,  1.0505e-01, -1.2216e-02, -1.7340e-01,  1.1556e-01],\n",
      "          [-5.8734e-02, -7.1824e-02, -3.7298e-02,  1.0030e-01, -6.1381e-02],\n",
      "          [ 1.6798e-01,  2.4707e-02, -8.9779e-02, -3.4683e-02,  6.7887e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0472e-02, -1.6816e-01,  1.6501e-01, -1.4424e-01,  1.4948e-01],\n",
      "          [ 1.3995e-01, -6.1184e-02, -1.7629e-02, -7.1295e-02, -1.3393e-01],\n",
      "          [ 2.0582e-02,  1.8349e-01, -1.7890e-01,  1.5396e-01, -5.8100e-02],\n",
      "          [ 1.8454e-01, -1.3551e-02,  2.1506e-02, -1.6931e-01, -1.8765e-01],\n",
      "          [ 1.0588e-01, -9.1665e-02, -1.6879e-01, -1.2527e-01, -1.0091e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9449e-02,  1.2685e-01,  7.2299e-02,  4.6595e-02,  1.9679e-01],\n",
      "          [ 2.2285e-02,  2.2567e-02,  1.0742e-01, -6.6561e-02,  1.8148e-01],\n",
      "          [ 5.5963e-02,  1.6754e-01,  7.0529e-02,  4.2915e-02, -6.9040e-02],\n",
      "          [ 4.6791e-02,  1.9311e-01, -5.7044e-02, -7.8055e-02, -1.4386e-01],\n",
      "          [-1.7197e-01, -1.6560e-01,  8.5198e-02, -1.8517e-01, -2.0688e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3139e-01,  1.4070e-01,  2.7097e-02, -1.5805e-01,  1.2808e-01],\n",
      "          [-1.7832e-01,  6.4503e-02,  2.9197e-02,  1.6657e-01, -4.3565e-02],\n",
      "          [ 5.4102e-02, -3.9023e-02,  3.9094e-02,  1.2332e-01,  1.4203e-01],\n",
      "          [ 5.1546e-02, -5.7866e-02,  1.5820e-01,  1.4223e-03,  4.3801e-02],\n",
      "          [ 6.5623e-02, -1.4990e-01,  1.2141e-01, -1.3783e-02,  8.0581e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1322e-01, -1.9726e-01,  7.9353e-03, -4.4787e-02,  1.6848e-01],\n",
      "          [ 7.8345e-02, -4.2794e-02,  1.8022e-01,  1.5772e-01,  7.7809e-02],\n",
      "          [ 1.0495e-01, -1.7089e-01,  1.3323e-01,  2.5954e-02,  9.5799e-04],\n",
      "          [ 1.4828e-01,  1.6508e-01, -7.2082e-03,  1.0186e-01, -1.7378e-01],\n",
      "          [-1.1721e-01,  3.0324e-04, -2.0825e-02,  9.1728e-02,  7.0678e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9776e-02, -1.3168e-01,  2.4154e-02, -4.5304e-02,  6.8677e-02],\n",
      "          [-1.8232e-01,  9.1022e-02, -7.2123e-02, -9.7199e-03, -3.1094e-02],\n",
      "          [ 2.8557e-02,  3.9763e-02, -3.2785e-02,  1.2154e-01, -1.2906e-01],\n",
      "          [ 1.1970e-01, -2.9830e-02, -1.2073e-01,  1.4320e-01, -1.1444e-01],\n",
      "          [ 1.5797e-01, -1.8464e-02, -5.0214e-02, -4.5412e-02, -1.5845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2919e-01, -2.3971e-02,  1.6241e-01, -1.2552e-01,  1.0633e-01],\n",
      "          [-1.7193e-01, -8.4782e-02,  1.5894e-01,  3.8409e-02, -1.8693e-01],\n",
      "          [-1.0562e-01,  6.0506e-02,  6.0093e-02,  2.5464e-02, -1.2752e-01],\n",
      "          [-1.6392e-02, -5.1873e-02,  1.9090e-01,  1.1538e-01, -1.1494e-02],\n",
      "          [ 4.7702e-02,  9.9459e-04, -1.1322e-01,  1.0613e-01, -9.6574e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4468e-02, -1.9568e-01, -8.3747e-02,  2.1697e-02, -1.6775e-01],\n",
      "          [-9.4823e-03,  6.9211e-02, -1.5341e-01,  9.8999e-02,  1.9264e-01],\n",
      "          [-5.4513e-02, -4.0235e-02, -1.1080e-01,  3.4654e-02, -1.1992e-01],\n",
      "          [ 1.6636e-01,  8.5964e-02,  5.3202e-02,  1.4344e-01,  9.3552e-02],\n",
      "          [ 1.8168e-01,  9.4864e-02, -6.3565e-02,  1.6350e-01, -7.3253e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7767e-01,  9.4857e-02,  1.3126e-01,  1.3162e-01, -1.8681e-01],\n",
      "          [-1.5823e-01, -1.1111e-02,  1.1166e-01,  4.4050e-02,  1.4993e-01],\n",
      "          [ 9.4183e-02, -7.8399e-02,  6.6749e-02, -1.6290e-02,  1.2230e-01],\n",
      "          [ 1.7485e-01, -4.1142e-02,  1.3335e-01, -1.4768e-01, -7.8840e-02],\n",
      "          [-1.3098e-01,  1.0426e-01, -6.6484e-02,  6.0214e-02,  1.2992e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9978e-01,  6.4416e-02,  6.5184e-02,  1.5113e-01, -1.5479e-01],\n",
      "          [-1.7515e-01, -4.4054e-02,  1.1378e-01,  1.7940e-01, -1.7875e-01],\n",
      "          [ 8.9578e-02,  1.9231e-01,  1.4054e-01,  1.6426e-01,  2.6875e-02],\n",
      "          [-5.9233e-02,  1.1354e-01,  1.5061e-01,  5.0135e-02, -3.3059e-02],\n",
      "          [ 1.8981e-01, -9.1344e-02,  9.9926e-02,  1.9885e-01, -6.9535e-02]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0573,  0.0840, -0.1971, -0.0123,  0.0091,  0.1132,  0.1386, -0.1841,\n",
      "        -0.0115, -0.0262,  0.0195,  0.1285, -0.0273, -0.1999, -0.1102, -0.1538,\n",
      "         0.1940,  0.1120,  0.1132,  0.0043], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-1.3871e-02,  1.8138e-03,  2.7409e-02,  1.9202e-03,  3.5283e-02],\n",
      "          [ 2.6181e-02, -1.2598e-03, -7.3440e-03,  4.4750e-03,  4.2259e-02],\n",
      "          [ 1.3897e-02, -3.8882e-02,  2.5302e-02,  9.9060e-03, -1.5260e-02],\n",
      "          [ 3.9157e-02, -4.0127e-02, -4.2976e-02,  3.9782e-02, -1.5026e-02],\n",
      "          [-1.7793e-02, -1.1287e-02, -4.0245e-02, -2.5290e-02, -1.5126e-03]],\n",
      "\n",
      "         [[-1.8095e-02, -2.9858e-02,  1.8384e-02,  4.2637e-03, -1.4755e-02],\n",
      "          [-2.0695e-02,  1.8060e-02, -1.5756e-02,  2.3952e-02, -4.2352e-02],\n",
      "          [ 2.3106e-02,  6.3974e-03,  6.0189e-04,  1.3654e-02, -1.3639e-02],\n",
      "          [-3.7988e-03, -3.6270e-02,  2.3508e-02, -6.1616e-03, -2.5438e-02],\n",
      "          [-1.7730e-02,  2.2161e-02,  1.6720e-02, -3.2676e-02,  9.0513e-03]],\n",
      "\n",
      "         [[ 1.4793e-02,  1.6415e-02, -2.8927e-02,  8.1149e-03,  3.6316e-02],\n",
      "          [ 1.8483e-02, -1.4564e-02,  4.2133e-02,  2.2380e-02, -1.8128e-02],\n",
      "          [-1.4943e-02, -3.3563e-02, -1.0543e-02,  2.4182e-02,  3.5721e-02],\n",
      "          [ 1.2420e-02, -9.2878e-03, -4.2604e-02,  3.0411e-02,  8.3704e-03],\n",
      "          [-3.6704e-02, -1.4528e-02, -8.2998e-03, -1.6295e-02, -1.3609e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0465e-03,  1.7051e-02,  7.7259e-03, -3.8155e-03,  3.9476e-03],\n",
      "          [ 3.1129e-02, -4.3741e-02, -2.0728e-02, -8.6993e-03,  2.7008e-02],\n",
      "          [-9.1237e-03, -3.5947e-02, -2.1752e-03, -1.9814e-02,  2.8245e-02],\n",
      "          [ 3.9406e-03,  3.3105e-03, -1.5305e-03,  2.5063e-02, -4.6007e-03],\n",
      "          [ 3.7993e-02, -1.6980e-02, -2.2232e-02, -1.1428e-02,  2.9301e-02]],\n",
      "\n",
      "         [[-6.4159e-03,  2.1685e-02,  8.6689e-03,  8.6723e-03,  1.8453e-02],\n",
      "          [-3.0057e-02,  4.0051e-02,  4.1262e-02,  2.9822e-02,  2.1606e-02],\n",
      "          [-2.1487e-02, -3.8540e-02, -9.6918e-03,  3.5614e-02,  2.3266e-02],\n",
      "          [ 4.3648e-02, -1.2313e-02,  4.0020e-02, -9.2189e-03, -2.5507e-02],\n",
      "          [ 2.3909e-02,  2.4166e-02,  2.8090e-02,  4.0647e-02, -2.8616e-02]],\n",
      "\n",
      "         [[ 2.0415e-03,  2.2509e-03,  2.5001e-02,  3.0924e-02, -3.3789e-03],\n",
      "          [ 8.6982e-03,  3.3180e-02, -1.8352e-02, -4.1864e-02, -3.5893e-02],\n",
      "          [ 3.2103e-02,  1.0422e-02, -2.7926e-02, -3.0336e-02, -2.0639e-02],\n",
      "          [-3.0402e-02, -1.1929e-02,  2.1070e-02,  8.6693e-03, -3.4097e-02],\n",
      "          [-3.5102e-02,  1.8101e-02, -2.5006e-02, -2.2366e-02,  3.0084e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9222e-02, -2.4327e-02,  1.3645e-02,  2.3390e-02,  3.0595e-02],\n",
      "          [ 2.6715e-02, -3.6614e-03, -2.1772e-02,  2.7429e-03,  1.1749e-02],\n",
      "          [ 2.4263e-02,  1.7774e-02,  3.4740e-02, -1.4598e-02, -3.5157e-02],\n",
      "          [ 2.4948e-03,  1.8638e-02, -2.5367e-02, -1.5732e-02,  3.7917e-03],\n",
      "          [-3.5909e-03,  3.6041e-02, -3.8344e-02, -4.1491e-02,  1.9854e-02]],\n",
      "\n",
      "         [[-2.6491e-02,  4.0159e-02, -4.1427e-02, -7.6170e-03, -7.3140e-03],\n",
      "          [-3.9630e-02, -1.1807e-02,  2.3813e-02,  1.7934e-03, -2.2907e-02],\n",
      "          [-3.9195e-02, -3.7322e-03,  4.9031e-03,  4.1874e-02,  2.5364e-02],\n",
      "          [ 3.0963e-02,  1.8185e-02,  3.2395e-02, -3.2413e-02, -1.2818e-02],\n",
      "          [ 4.6185e-03, -1.5100e-02, -8.0613e-03,  6.8208e-03, -2.4075e-02]],\n",
      "\n",
      "         [[-2.1455e-02, -2.7057e-03, -7.7437e-03,  2.6733e-04, -2.0691e-02],\n",
      "          [ 1.2371e-02,  1.2946e-02, -5.9853e-03, -5.1840e-03,  4.3210e-02],\n",
      "          [ 4.7497e-03,  2.1726e-02,  3.7029e-03,  4.0085e-02, -2.3352e-02],\n",
      "          [ 2.9196e-02, -1.6861e-02, -3.5422e-02, -4.9593e-03,  2.1213e-02],\n",
      "          [-8.5790e-03, -1.9741e-02, -2.4979e-02,  8.3580e-03, -3.0003e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2219e-02, -3.6488e-02,  8.1911e-03,  4.0574e-02,  2.7663e-02],\n",
      "          [ 3.8541e-02,  1.7447e-02,  3.3555e-02,  3.9525e-02,  1.2404e-02],\n",
      "          [-2.7404e-02,  1.0433e-03, -4.2537e-02,  3.6915e-03, -4.2093e-02],\n",
      "          [-1.0742e-02, -3.7113e-02,  8.2909e-03, -3.8922e-02, -3.9269e-02],\n",
      "          [-3.8352e-02,  1.9914e-02, -2.2876e-02, -4.3953e-02,  3.2267e-02]],\n",
      "\n",
      "         [[ 2.7342e-02, -2.2636e-02,  3.7276e-02, -2.6170e-02,  3.8131e-02],\n",
      "          [-4.1702e-02,  3.6494e-02,  3.4553e-02,  8.2889e-03, -1.3203e-02],\n",
      "          [ 2.1594e-02, -1.0232e-03, -1.3677e-02,  3.9646e-02,  6.8112e-03],\n",
      "          [ 3.0746e-02,  2.3654e-02, -2.5046e-02, -4.6949e-03, -1.2915e-02],\n",
      "          [ 2.7509e-02, -7.8877e-03,  7.3765e-03, -4.2027e-03,  8.1646e-03]],\n",
      "\n",
      "         [[ 3.4163e-02, -2.6366e-02,  4.4121e-02,  3.1600e-02, -1.1947e-02],\n",
      "          [-3.8639e-02,  3.0027e-02, -1.1069e-03,  3.3161e-02, -3.9655e-02],\n",
      "          [ 1.7341e-02,  3.0755e-02, -1.2879e-02,  5.1505e-05, -2.0856e-02],\n",
      "          [-1.0053e-02, -8.5097e-03, -2.5528e-02,  4.2424e-02, -1.7655e-02],\n",
      "          [-1.9958e-03,  4.2383e-02, -2.0389e-02, -2.1955e-02, -2.9821e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9111e-02, -9.8587e-03,  2.2674e-02,  4.1752e-02, -3.0308e-02],\n",
      "          [ 1.4281e-03,  1.4835e-02, -1.1873e-02, -4.3554e-02, -1.6282e-02],\n",
      "          [ 1.7979e-02,  3.7161e-03,  1.1927e-02, -3.1373e-02, -3.8399e-03],\n",
      "          [-1.7560e-02, -2.3035e-02, -1.8226e-03,  3.1850e-02,  2.0427e-02],\n",
      "          [ 3.7227e-02, -4.2418e-03, -4.5080e-03,  2.4929e-02,  7.2678e-04]],\n",
      "\n",
      "         [[ 1.8624e-02,  2.1771e-03,  2.9543e-03,  1.5655e-03, -1.9216e-02],\n",
      "          [-3.0592e-02,  4.6970e-03, -5.1550e-03, -3.1509e-02, -2.5539e-02],\n",
      "          [ 5.2691e-03,  1.1452e-02,  3.5991e-03, -5.6211e-03,  1.7269e-02],\n",
      "          [ 1.1463e-02, -1.9230e-02,  1.3327e-02, -2.2483e-02, -2.9959e-02],\n",
      "          [ 1.6108e-03, -4.0144e-02,  2.3154e-02,  2.1032e-02,  3.6967e-02]],\n",
      "\n",
      "         [[-1.7662e-02,  1.2009e-02,  6.9824e-03,  5.0339e-03, -2.3007e-02],\n",
      "          [-2.9563e-02, -2.0134e-02,  2.3330e-02, -1.2088e-02,  1.4290e-02],\n",
      "          [ 3.1472e-02,  1.1480e-02,  1.6631e-03,  7.0405e-03, -1.3417e-02],\n",
      "          [ 3.3113e-02,  8.7944e-03,  2.0377e-02,  3.7911e-02,  3.1440e-02],\n",
      "          [-1.7023e-03, -5.8193e-03, -1.3485e-02, -2.9056e-02, -1.9129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8464e-02,  4.3393e-03,  1.4314e-02,  1.9514e-02,  2.2890e-02],\n",
      "          [ 1.6913e-02,  3.6645e-03, -1.6260e-02, -3.3765e-02, -1.4770e-02],\n",
      "          [ 3.5910e-02, -7.2799e-03,  3.3204e-02, -2.5386e-02,  3.6073e-02],\n",
      "          [-3.1312e-02, -6.2849e-03,  4.0375e-02, -2.1666e-02, -1.0114e-02],\n",
      "          [-9.8907e-03,  3.4569e-02,  4.0549e-02, -1.1892e-02, -2.4159e-02]],\n",
      "\n",
      "         [[ 6.6576e-03, -3.2157e-02,  3.6202e-02,  2.8732e-02, -2.2077e-03],\n",
      "          [ 3.8741e-03,  4.4562e-03, -1.1733e-02, -1.8566e-02, -2.0058e-02],\n",
      "          [-2.6554e-02, -4.1024e-02, -1.7292e-02, -1.0175e-02,  9.5437e-03],\n",
      "          [-1.4051e-02,  4.0718e-02,  3.4673e-02,  2.5243e-02, -1.0394e-02],\n",
      "          [ 4.9209e-03,  3.1385e-02, -2.1820e-02, -1.2295e-02, -3.2178e-02]],\n",
      "\n",
      "         [[ 4.0259e-02, -1.1299e-02, -1.4106e-02,  3.2192e-02, -1.2603e-02],\n",
      "          [ 1.1950e-02,  4.2668e-02,  2.2611e-02, -4.0604e-02, -3.7600e-02],\n",
      "          [-1.7960e-02,  2.4670e-02, -3.2335e-02, -4.2435e-02,  8.7845e-03],\n",
      "          [-1.5702e-02,  1.0560e-02,  4.0255e-02,  1.9973e-02, -2.9173e-02],\n",
      "          [-2.9245e-02,  4.3673e-02, -2.9623e-02, -2.6126e-02,  3.6229e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3782e-02, -3.2018e-02, -4.1422e-02,  4.2965e-02,  4.1290e-02],\n",
      "          [ 2.6014e-02,  3.5790e-02, -3.1674e-02,  2.1011e-02, -3.2987e-02],\n",
      "          [-3.8864e-02, -3.4980e-02, -3.9175e-02,  2.2159e-02,  2.7862e-02],\n",
      "          [-1.5315e-02, -3.0641e-02,  2.4972e-02, -2.6885e-02, -1.8860e-02],\n",
      "          [-3.7953e-02, -2.5055e-03,  1.6515e-02, -3.8565e-03, -3.4413e-02]],\n",
      "\n",
      "         [[ 5.2746e-03, -5.7524e-03,  8.7690e-04,  2.1129e-02, -3.3714e-02],\n",
      "          [-2.5097e-02, -9.1407e-03, -1.2493e-02, -2.8287e-02,  8.1022e-03],\n",
      "          [-3.4974e-02, -8.4004e-03,  6.5616e-03, -3.1915e-02, -1.8039e-03],\n",
      "          [ 4.3422e-02,  2.5244e-02, -3.7508e-02, -1.5715e-04,  2.8635e-03],\n",
      "          [ 4.0159e-02, -1.0451e-02,  3.3808e-02,  2.2487e-03,  2.3882e-02]],\n",
      "\n",
      "         [[ 8.0380e-03,  3.9348e-02,  3.6196e-02, -1.2740e-02,  8.8485e-03],\n",
      "          [-2.9744e-02,  3.9094e-02,  2.5479e-02,  3.2697e-02,  3.4737e-02],\n",
      "          [-3.5794e-02, -4.2454e-02, -2.3609e-02,  1.8149e-02,  4.2802e-02],\n",
      "          [ 1.9548e-03,  3.2146e-02,  1.7434e-02, -2.2222e-02, -4.3828e-02],\n",
      "          [ 4.4119e-04,  2.0332e-02, -1.5830e-02,  3.0345e-02,  2.7871e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4941e-03,  2.4571e-02, -4.0033e-03, -2.4643e-02,  2.4928e-02],\n",
      "          [-2.4729e-02, -3.4175e-02,  1.5217e-02, -6.8067e-03, -1.5605e-02],\n",
      "          [-1.5520e-02,  1.3591e-02, -1.6952e-02,  2.3149e-02, -3.5015e-02],\n",
      "          [-3.8227e-02,  2.4797e-03, -1.7207e-02,  1.7616e-02,  3.8088e-02],\n",
      "          [ 3.7997e-02, -3.6835e-02, -2.2072e-02,  3.5769e-02,  1.6814e-02]],\n",
      "\n",
      "         [[-2.5929e-02, -1.4625e-02, -2.8879e-02, -3.1932e-03,  2.6450e-02],\n",
      "          [ 2.6795e-03,  3.4002e-02, -7.2258e-03,  2.3569e-02, -1.0126e-02],\n",
      "          [-1.3826e-02, -1.5366e-02, -2.0826e-02, -4.2160e-02,  2.9605e-02],\n",
      "          [-2.9491e-02, -5.9204e-04,  3.0640e-02, -3.2850e-02,  4.6293e-03],\n",
      "          [ 8.2218e-03,  3.3545e-02,  2.2686e-02,  3.7325e-02,  4.3212e-02]],\n",
      "\n",
      "         [[ 2.2121e-02, -1.0479e-02,  3.5456e-02,  1.9301e-02, -1.2956e-03],\n",
      "          [ 1.5912e-03,  2.9417e-03,  2.9833e-02,  4.1424e-02, -2.1308e-02],\n",
      "          [ 3.1825e-02,  2.2558e-02, -8.4701e-03,  3.9350e-02,  2.2740e-02],\n",
      "          [ 1.8655e-02,  9.8191e-03,  1.6428e-02, -4.1089e-02, -2.5863e-02],\n",
      "          [ 1.6437e-02,  4.3713e-02, -7.8577e-03,  4.3015e-02, -2.6737e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7608e-03, -4.1001e-02, -2.9989e-02,  5.7242e-03,  1.6483e-02],\n",
      "          [-2.1141e-02, -3.8201e-02,  2.6190e-03,  2.5314e-02,  6.5599e-03],\n",
      "          [ 7.4922e-03,  3.1143e-03,  3.9642e-02,  2.0673e-03, -1.5567e-02],\n",
      "          [-2.0046e-04,  2.7596e-02,  9.6397e-03,  1.6137e-02,  8.5051e-03],\n",
      "          [-2.9986e-02,  1.8297e-02, -3.6378e-03,  2.2362e-03, -1.7651e-02]],\n",
      "\n",
      "         [[-1.2912e-02, -2.2029e-02, -2.4961e-02, -1.9687e-02, -2.0274e-02],\n",
      "          [-1.8502e-02, -1.8732e-02, -1.6331e-02,  1.4594e-02,  2.7315e-02],\n",
      "          [ 2.7607e-02,  3.3074e-02, -2.5466e-02, -1.5396e-02,  4.2149e-03],\n",
      "          [ 4.2130e-02, -1.2793e-02,  1.5324e-02, -4.1559e-02, -2.1596e-02],\n",
      "          [-3.1985e-02,  4.2327e-02,  3.0103e-02, -1.8856e-02, -4.3335e-02]],\n",
      "\n",
      "         [[-8.8148e-03, -1.9361e-02, -2.7197e-02, -1.4601e-02,  2.9393e-02],\n",
      "          [-4.1036e-02, -4.0184e-02,  3.2189e-02, -2.5799e-02, -2.6795e-02],\n",
      "          [ 7.8577e-04, -1.6912e-02,  2.6480e-02,  6.3703e-03,  1.0465e-02],\n",
      "          [ 3.6253e-03, -2.3415e-02, -2.0984e-02, -1.4698e-02,  2.4545e-02],\n",
      "          [-2.6590e-02,  1.5386e-02, -4.5269e-03,  8.9440e-03,  2.8833e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9688e-02,  3.1305e-02,  1.0911e-02, -3.1096e-03, -6.1476e-03],\n",
      "          [ 4.4522e-02, -4.1974e-02,  1.4086e-03,  1.3176e-02, -3.5228e-02],\n",
      "          [ 4.3846e-02, -1.2587e-03, -3.4890e-02, -6.4030e-03,  3.9697e-03],\n",
      "          [-4.0698e-02,  1.3210e-02,  1.1198e-02, -1.1474e-02,  3.7271e-02],\n",
      "          [-1.7921e-02,  1.9403e-02, -1.1318e-02, -3.4611e-02,  4.0208e-02]],\n",
      "\n",
      "         [[-4.5511e-04, -3.8761e-02,  3.1732e-02,  2.4404e-03,  4.3232e-02],\n",
      "          [ 1.8153e-02, -2.1967e-02, -3.2062e-02, -2.4471e-02,  4.0476e-02],\n",
      "          [-2.7757e-02,  3.4205e-02,  3.3019e-02,  1.4792e-02,  9.9620e-04],\n",
      "          [ 9.9321e-03, -3.5928e-02,  1.7252e-02,  1.6250e-02,  4.9671e-03],\n",
      "          [ 4.3295e-04, -3.8847e-02, -4.0153e-02,  3.0456e-02,  5.4879e-03]],\n",
      "\n",
      "         [[-3.8609e-03,  3.3571e-02, -3.1285e-02, -2.3129e-02,  1.5465e-02],\n",
      "          [ 3.8651e-02,  3.4275e-02,  3.1002e-02,  2.8591e-04,  1.5209e-02],\n",
      "          [-8.5173e-03, -4.0278e-02,  8.8405e-03, -4.1458e-02, -2.9139e-02],\n",
      "          [-1.0918e-02,  1.5830e-02,  1.1770e-02, -2.9171e-02,  3.7284e-02],\n",
      "          [-3.1970e-03,  1.7156e-02, -4.3869e-02, -2.8430e-03, -4.6179e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5426e-03, -3.3489e-02,  4.3182e-02,  4.4257e-02,  2.2910e-02],\n",
      "          [ 1.0588e-02, -3.6287e-03, -1.2841e-02,  4.2236e-02,  2.1910e-02],\n",
      "          [ 2.5113e-02,  1.7791e-02, -2.8582e-02, -8.2183e-03,  4.2715e-02],\n",
      "          [-4.4355e-02, -8.3076e-03, -3.8030e-02,  1.8744e-02, -2.5378e-02],\n",
      "          [-3.6300e-02,  3.6503e-02,  4.3366e-02, -2.6602e-02,  4.5671e-04]],\n",
      "\n",
      "         [[-8.0117e-03,  1.2479e-02, -1.1636e-02, -2.2237e-02,  6.4645e-03],\n",
      "          [ 3.3277e-02, -2.6507e-02,  1.4027e-02, -3.5600e-02, -9.1320e-03],\n",
      "          [-2.6892e-02,  1.8206e-02, -1.3648e-02,  1.4801e-02, -1.0142e-02],\n",
      "          [ 3.2587e-02,  1.5215e-02,  1.8212e-02,  2.0784e-02, -2.4829e-02],\n",
      "          [-2.7623e-02, -2.1331e-02,  1.8614e-02,  8.3137e-03, -2.5571e-02]],\n",
      "\n",
      "         [[ 3.3985e-02,  2.0536e-02, -3.6736e-02, -3.4242e-02, -3.5011e-02],\n",
      "          [-1.2837e-02, -1.6274e-02, -3.8104e-02,  1.5304e-02,  3.1169e-02],\n",
      "          [ 3.7217e-02, -1.7904e-02,  1.4214e-03,  4.3906e-02,  4.3218e-02],\n",
      "          [ 4.9224e-03,  4.0308e-02,  3.9056e-02, -8.4914e-03, -7.2897e-03],\n",
      "          [ 3.2487e-02, -6.0824e-03,  3.4568e-02, -1.0007e-02, -2.7042e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8313e-02,  3.8931e-02,  4.1518e-02, -1.0579e-02, -3.9042e-02],\n",
      "          [ 2.4156e-02,  2.3572e-02,  3.4003e-02, -3.2104e-03,  4.0552e-02],\n",
      "          [ 1.9444e-02,  4.9861e-04, -1.0498e-02, -3.3191e-02,  3.1968e-02],\n",
      "          [-4.3698e-02, -4.1204e-02,  2.2203e-02, -3.6378e-02, -4.1366e-02],\n",
      "          [ 3.2657e-02, -1.2996e-02, -1.8007e-02, -2.5327e-02,  3.8129e-02]],\n",
      "\n",
      "         [[ 4.3869e-02, -1.5969e-02, -2.7958e-02, -4.0428e-02,  4.4211e-02],\n",
      "          [-1.4945e-02,  1.7142e-03,  2.9844e-03, -4.1683e-02, -1.0541e-02],\n",
      "          [-3.0339e-03, -3.9557e-02,  1.9041e-02,  1.3259e-02,  2.7224e-02],\n",
      "          [-5.7078e-03,  2.4114e-02,  2.3944e-02, -2.3861e-03, -3.2904e-02],\n",
      "          [ 2.6463e-02,  3.4529e-02,  6.5505e-03,  5.5897e-03, -3.4591e-02]],\n",
      "\n",
      "         [[-8.8023e-03, -1.4111e-02,  3.6047e-02, -2.7741e-02,  1.5809e-03],\n",
      "          [ 3.5177e-02,  1.1588e-02, -1.2560e-03,  4.1529e-02,  1.7147e-02],\n",
      "          [-3.4687e-02,  5.2443e-03,  2.3536e-02, -2.4470e-02, -7.5177e-03],\n",
      "          [ 1.8502e-02, -3.6382e-03,  3.0699e-02,  4.1438e-02, -6.3115e-04],\n",
      "          [-3.1555e-02, -4.1446e-02,  2.6937e-02,  2.7350e-02,  6.8305e-03]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0208, -0.0087,  0.0362, -0.0220, -0.0256,  0.0095,  0.0186, -0.0136,\n",
      "         0.0177, -0.0041,  0.0170, -0.0027, -0.0196,  0.0234, -0.0405, -0.0135,\n",
      "        -0.0309, -0.0404, -0.0075,  0.0444,  0.0423, -0.0372, -0.0131, -0.0381,\n",
      "         0.0133, -0.0289, -0.0221,  0.0352, -0.0110, -0.0044, -0.0370, -0.0284,\n",
      "         0.0397,  0.0232,  0.0216,  0.0064,  0.0168,  0.0110, -0.0194,  0.0445,\n",
      "         0.0036, -0.0137,  0.0069, -0.0088, -0.0233,  0.0234, -0.0068,  0.0105,\n",
      "        -0.0371, -0.0273, -0.0152, -0.0081,  0.0421,  0.0137, -0.0174, -0.0296,\n",
      "        -0.0234,  0.0100,  0.0340, -0.0171,  0.0026,  0.0309,  0.0317,  0.0267],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# `parameters()`\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10c66076-e8b5-4fda-b813-5910c4ce4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: conv_layers.0.weight\n",
      "Parameter containing:\n",
      "tensor([[[[ 1.3241e-01,  1.5604e-01, -1.0033e-01,  1.9216e-01, -6.9605e-02],\n",
      "          [ 1.7387e-01, -8.7238e-02, -8.7400e-02, -6.6454e-03, -1.3710e-02],\n",
      "          [ 4.7818e-02, -1.3161e-01, -1.2073e-01, -8.0846e-02, -1.4806e-01],\n",
      "          [ 1.5466e-01,  1.7643e-01,  6.8757e-02, -1.3546e-01,  8.1396e-02],\n",
      "          [ 1.4838e-01, -1.3129e-01, -3.4942e-02,  1.3256e-01,  1.8711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7838e-01,  9.0442e-02,  9.4969e-02,  1.9040e-01, -5.6426e-02],\n",
      "          [ 1.4222e-01,  1.0127e-01, -9.1116e-03, -2.4985e-02, -1.6505e-01],\n",
      "          [ 1.7914e-01, -7.6648e-02, -1.7809e-01,  1.2110e-01, -5.1342e-02],\n",
      "          [ 2.2690e-02,  1.5465e-01, -8.5308e-02, -4.7745e-02,  3.1571e-02],\n",
      "          [ 2.8867e-02, -3.0587e-02, -3.1570e-02, -1.9829e-01, -4.0238e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3186e-01, -1.4602e-01,  9.5862e-02, -8.8489e-02, -9.6553e-02],\n",
      "          [-1.3332e-01,  1.1675e-02,  1.6270e-01,  1.4342e-01,  1.4186e-02],\n",
      "          [ 6.7934e-02,  1.0176e-02,  5.6962e-02,  1.9649e-01,  1.5693e-01],\n",
      "          [-1.7073e-01, -2.1391e-02,  2.3361e-02,  3.1500e-02, -6.6577e-02],\n",
      "          [ 7.7104e-02,  1.4623e-01, -7.9448e-03,  3.1214e-02, -7.6848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7350e-02, -1.1280e-01, -1.1613e-01,  3.4520e-02, -9.1342e-03],\n",
      "          [-1.3996e-01, -1.8361e-01,  1.1601e-01, -5.5225e-02, -5.4041e-02],\n",
      "          [ 1.9208e-01, -9.1202e-02,  1.3636e-01,  7.3855e-02, -6.5894e-02],\n",
      "          [ 1.3723e-02,  1.5521e-01,  7.8226e-02, -1.1209e-01, -1.5964e-01],\n",
      "          [-6.5851e-02, -1.5129e-01, -5.2712e-02,  8.9967e-02, -1.8500e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2484e-01, -1.8534e-01,  3.6886e-02,  8.3262e-02,  6.8633e-02],\n",
      "          [ 1.4270e-02,  1.6860e-01,  4.8610e-02, -1.8697e-01, -1.5962e-01],\n",
      "          [-6.1016e-02, -1.6345e-02, -1.1608e-01, -1.8487e-01, -1.6567e-01],\n",
      "          [-4.0601e-02,  8.8121e-02, -1.8425e-02, -3.8099e-02, -1.9318e-01],\n",
      "          [-9.6685e-02,  4.7574e-02,  7.1982e-02,  1.3283e-01, -1.3550e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2990e-01, -1.8027e-02, -1.9720e-01, -1.0266e-01,  1.9599e-01],\n",
      "          [ 2.3637e-03,  8.8786e-02, -3.4413e-02, -1.1878e-01,  1.4574e-01],\n",
      "          [-1.1365e-01, -1.6888e-01,  5.0974e-05, -9.2363e-02, -4.1784e-02],\n",
      "          [ 1.6196e-01,  1.4280e-01, -8.2476e-02,  1.4793e-01,  9.5471e-02],\n",
      "          [ 9.4619e-02, -5.1215e-02,  7.4179e-02, -9.6469e-02, -8.7771e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1201e-01,  1.9360e-01, -1.8400e-01, -3.8823e-02,  1.8009e-01],\n",
      "          [ 1.5503e-01, -1.8852e-01,  2.5678e-02,  1.9906e-01, -1.4539e-01],\n",
      "          [-1.4287e-01, -1.7903e-01,  2.2451e-02,  1.4313e-01,  1.8826e-01],\n",
      "          [ 1.1788e-01,  1.4232e-01, -2.2371e-02, -4.0267e-02,  1.7885e-01],\n",
      "          [-9.0347e-02, -2.7690e-03, -5.3224e-02, -5.5934e-02, -1.3836e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8000e-02, -6.3736e-02, -1.5082e-01,  3.6312e-02, -1.9862e-01],\n",
      "          [ 4.8823e-02, -8.4725e-02,  6.8034e-02,  1.8329e-01,  4.5708e-02],\n",
      "          [ 1.9683e-01, -5.6322e-02,  6.3535e-02,  3.6922e-02,  1.7151e-01],\n",
      "          [ 1.4225e-01, -1.6482e-01,  6.7343e-02,  1.3643e-01,  1.4066e-01],\n",
      "          [ 2.8197e-02, -1.7635e-01, -1.5050e-01,  3.3212e-03,  6.0210e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8715e-02, -1.2924e-01,  1.1012e-01,  8.7607e-03, -1.6257e-01],\n",
      "          [ 7.7766e-02, -1.5367e-01,  1.5281e-01, -5.8361e-02,  1.0171e-01],\n",
      "          [ 1.7840e-01, -1.7470e-01, -1.5965e-01,  5.9101e-02,  1.6743e-01],\n",
      "          [-1.0642e-01, -7.9235e-03, -1.2118e-01, -1.6437e-01, -1.5323e-01],\n",
      "          [ 1.4803e-01,  1.1819e-01, -2.5592e-02,  6.2606e-02,  4.4999e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6631e-01, -1.3663e-01, -1.0860e-01,  1.8708e-01, -1.7883e-01],\n",
      "          [ 1.1482e-02, -1.2443e-01, -1.0491e-01, -9.3156e-02,  6.7180e-02],\n",
      "          [ 8.2907e-02,  1.0562e-01, -3.0791e-02, -8.7147e-02, -2.5293e-02],\n",
      "          [ 6.1346e-03,  1.6903e-01,  3.4932e-02, -1.4125e-01,  1.1192e-02],\n",
      "          [ 1.1734e-01,  1.3849e-01,  1.8247e-01, -6.6997e-02,  1.4443e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5675e-02,  1.7151e-02,  1.8107e-01, -6.6976e-02, -1.6386e-01],\n",
      "          [ 1.8581e-01,  1.1274e-01,  7.9142e-02,  1.4690e-01, -1.3505e-01],\n",
      "          [ 1.1049e-01,  1.0505e-01, -1.2216e-02, -1.7340e-01,  1.1556e-01],\n",
      "          [-5.8734e-02, -7.1824e-02, -3.7298e-02,  1.0030e-01, -6.1381e-02],\n",
      "          [ 1.6798e-01,  2.4707e-02, -8.9779e-02, -3.4683e-02,  6.7887e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0472e-02, -1.6816e-01,  1.6501e-01, -1.4424e-01,  1.4948e-01],\n",
      "          [ 1.3995e-01, -6.1184e-02, -1.7629e-02, -7.1295e-02, -1.3393e-01],\n",
      "          [ 2.0582e-02,  1.8349e-01, -1.7890e-01,  1.5396e-01, -5.8100e-02],\n",
      "          [ 1.8454e-01, -1.3551e-02,  2.1506e-02, -1.6931e-01, -1.8765e-01],\n",
      "          [ 1.0588e-01, -9.1665e-02, -1.6879e-01, -1.2527e-01, -1.0091e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9449e-02,  1.2685e-01,  7.2299e-02,  4.6595e-02,  1.9679e-01],\n",
      "          [ 2.2285e-02,  2.2567e-02,  1.0742e-01, -6.6561e-02,  1.8148e-01],\n",
      "          [ 5.5963e-02,  1.6754e-01,  7.0529e-02,  4.2915e-02, -6.9040e-02],\n",
      "          [ 4.6791e-02,  1.9311e-01, -5.7044e-02, -7.8055e-02, -1.4386e-01],\n",
      "          [-1.7197e-01, -1.6560e-01,  8.5198e-02, -1.8517e-01, -2.0688e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3139e-01,  1.4070e-01,  2.7097e-02, -1.5805e-01,  1.2808e-01],\n",
      "          [-1.7832e-01,  6.4503e-02,  2.9197e-02,  1.6657e-01, -4.3565e-02],\n",
      "          [ 5.4102e-02, -3.9023e-02,  3.9094e-02,  1.2332e-01,  1.4203e-01],\n",
      "          [ 5.1546e-02, -5.7866e-02,  1.5820e-01,  1.4223e-03,  4.3801e-02],\n",
      "          [ 6.5623e-02, -1.4990e-01,  1.2141e-01, -1.3783e-02,  8.0581e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1322e-01, -1.9726e-01,  7.9353e-03, -4.4787e-02,  1.6848e-01],\n",
      "          [ 7.8345e-02, -4.2794e-02,  1.8022e-01,  1.5772e-01,  7.7809e-02],\n",
      "          [ 1.0495e-01, -1.7089e-01,  1.3323e-01,  2.5954e-02,  9.5799e-04],\n",
      "          [ 1.4828e-01,  1.6508e-01, -7.2082e-03,  1.0186e-01, -1.7378e-01],\n",
      "          [-1.1721e-01,  3.0324e-04, -2.0825e-02,  9.1728e-02,  7.0678e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9776e-02, -1.3168e-01,  2.4154e-02, -4.5304e-02,  6.8677e-02],\n",
      "          [-1.8232e-01,  9.1022e-02, -7.2123e-02, -9.7199e-03, -3.1094e-02],\n",
      "          [ 2.8557e-02,  3.9763e-02, -3.2785e-02,  1.2154e-01, -1.2906e-01],\n",
      "          [ 1.1970e-01, -2.9830e-02, -1.2073e-01,  1.4320e-01, -1.1444e-01],\n",
      "          [ 1.5797e-01, -1.8464e-02, -5.0214e-02, -4.5412e-02, -1.5845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2919e-01, -2.3971e-02,  1.6241e-01, -1.2552e-01,  1.0633e-01],\n",
      "          [-1.7193e-01, -8.4782e-02,  1.5894e-01,  3.8409e-02, -1.8693e-01],\n",
      "          [-1.0562e-01,  6.0506e-02,  6.0093e-02,  2.5464e-02, -1.2752e-01],\n",
      "          [-1.6392e-02, -5.1873e-02,  1.9090e-01,  1.1538e-01, -1.1494e-02],\n",
      "          [ 4.7702e-02,  9.9459e-04, -1.1322e-01,  1.0613e-01, -9.6574e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4468e-02, -1.9568e-01, -8.3747e-02,  2.1697e-02, -1.6775e-01],\n",
      "          [-9.4823e-03,  6.9211e-02, -1.5341e-01,  9.8999e-02,  1.9264e-01],\n",
      "          [-5.4513e-02, -4.0235e-02, -1.1080e-01,  3.4654e-02, -1.1992e-01],\n",
      "          [ 1.6636e-01,  8.5964e-02,  5.3202e-02,  1.4344e-01,  9.3552e-02],\n",
      "          [ 1.8168e-01,  9.4864e-02, -6.3565e-02,  1.6350e-01, -7.3253e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7767e-01,  9.4857e-02,  1.3126e-01,  1.3162e-01, -1.8681e-01],\n",
      "          [-1.5823e-01, -1.1111e-02,  1.1166e-01,  4.4050e-02,  1.4993e-01],\n",
      "          [ 9.4183e-02, -7.8399e-02,  6.6749e-02, -1.6290e-02,  1.2230e-01],\n",
      "          [ 1.7485e-01, -4.1142e-02,  1.3335e-01, -1.4768e-01, -7.8840e-02],\n",
      "          [-1.3098e-01,  1.0426e-01, -6.6484e-02,  6.0214e-02,  1.2992e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9978e-01,  6.4416e-02,  6.5184e-02,  1.5113e-01, -1.5479e-01],\n",
      "          [-1.7515e-01, -4.4054e-02,  1.1378e-01,  1.7940e-01, -1.7875e-01],\n",
      "          [ 8.9578e-02,  1.9231e-01,  1.4054e-01,  1.6426e-01,  2.6875e-02],\n",
      "          [-5.9233e-02,  1.1354e-01,  1.5061e-01,  5.0135e-02, -3.3059e-02],\n",
      "          [ 1.8981e-01, -9.1344e-02,  9.9926e-02,  1.9885e-01, -6.9535e-02]]]],\n",
      "       requires_grad=True)\n",
      "Name: conv_layers.0.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0573,  0.0840, -0.1971, -0.0123,  0.0091,  0.1132,  0.1386, -0.1841,\n",
      "        -0.0115, -0.0262,  0.0195,  0.1285, -0.0273, -0.1999, -0.1102, -0.1538,\n",
      "         0.1940,  0.1120,  0.1132,  0.0043], requires_grad=True)\n",
      "Name: conv_layers.2.weight\n",
      "Parameter containing:\n",
      "tensor([[[[-1.3871e-02,  1.8138e-03,  2.7409e-02,  1.9202e-03,  3.5283e-02],\n",
      "          [ 2.6181e-02, -1.2598e-03, -7.3440e-03,  4.4750e-03,  4.2259e-02],\n",
      "          [ 1.3897e-02, -3.8882e-02,  2.5302e-02,  9.9060e-03, -1.5260e-02],\n",
      "          [ 3.9157e-02, -4.0127e-02, -4.2976e-02,  3.9782e-02, -1.5026e-02],\n",
      "          [-1.7793e-02, -1.1287e-02, -4.0245e-02, -2.5290e-02, -1.5126e-03]],\n",
      "\n",
      "         [[-1.8095e-02, -2.9858e-02,  1.8384e-02,  4.2637e-03, -1.4755e-02],\n",
      "          [-2.0695e-02,  1.8060e-02, -1.5756e-02,  2.3952e-02, -4.2352e-02],\n",
      "          [ 2.3106e-02,  6.3974e-03,  6.0189e-04,  1.3654e-02, -1.3639e-02],\n",
      "          [-3.7988e-03, -3.6270e-02,  2.3508e-02, -6.1616e-03, -2.5438e-02],\n",
      "          [-1.7730e-02,  2.2161e-02,  1.6720e-02, -3.2676e-02,  9.0513e-03]],\n",
      "\n",
      "         [[ 1.4793e-02,  1.6415e-02, -2.8927e-02,  8.1149e-03,  3.6316e-02],\n",
      "          [ 1.8483e-02, -1.4564e-02,  4.2133e-02,  2.2380e-02, -1.8128e-02],\n",
      "          [-1.4943e-02, -3.3563e-02, -1.0543e-02,  2.4182e-02,  3.5721e-02],\n",
      "          [ 1.2420e-02, -9.2878e-03, -4.2604e-02,  3.0411e-02,  8.3704e-03],\n",
      "          [-3.6704e-02, -1.4528e-02, -8.2998e-03, -1.6295e-02, -1.3609e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0465e-03,  1.7051e-02,  7.7259e-03, -3.8155e-03,  3.9476e-03],\n",
      "          [ 3.1129e-02, -4.3741e-02, -2.0728e-02, -8.6993e-03,  2.7008e-02],\n",
      "          [-9.1237e-03, -3.5947e-02, -2.1752e-03, -1.9814e-02,  2.8245e-02],\n",
      "          [ 3.9406e-03,  3.3105e-03, -1.5305e-03,  2.5063e-02, -4.6007e-03],\n",
      "          [ 3.7993e-02, -1.6980e-02, -2.2232e-02, -1.1428e-02,  2.9301e-02]],\n",
      "\n",
      "         [[-6.4159e-03,  2.1685e-02,  8.6689e-03,  8.6723e-03,  1.8453e-02],\n",
      "          [-3.0057e-02,  4.0051e-02,  4.1262e-02,  2.9822e-02,  2.1606e-02],\n",
      "          [-2.1487e-02, -3.8540e-02, -9.6918e-03,  3.5614e-02,  2.3266e-02],\n",
      "          [ 4.3648e-02, -1.2313e-02,  4.0020e-02, -9.2189e-03, -2.5507e-02],\n",
      "          [ 2.3909e-02,  2.4166e-02,  2.8090e-02,  4.0647e-02, -2.8616e-02]],\n",
      "\n",
      "         [[ 2.0415e-03,  2.2509e-03,  2.5001e-02,  3.0924e-02, -3.3789e-03],\n",
      "          [ 8.6982e-03,  3.3180e-02, -1.8352e-02, -4.1864e-02, -3.5893e-02],\n",
      "          [ 3.2103e-02,  1.0422e-02, -2.7926e-02, -3.0336e-02, -2.0639e-02],\n",
      "          [-3.0402e-02, -1.1929e-02,  2.1070e-02,  8.6693e-03, -3.4097e-02],\n",
      "          [-3.5102e-02,  1.8101e-02, -2.5006e-02, -2.2366e-02,  3.0084e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9222e-02, -2.4327e-02,  1.3645e-02,  2.3390e-02,  3.0595e-02],\n",
      "          [ 2.6715e-02, -3.6614e-03, -2.1772e-02,  2.7429e-03,  1.1749e-02],\n",
      "          [ 2.4263e-02,  1.7774e-02,  3.4740e-02, -1.4598e-02, -3.5157e-02],\n",
      "          [ 2.4948e-03,  1.8638e-02, -2.5367e-02, -1.5732e-02,  3.7917e-03],\n",
      "          [-3.5909e-03,  3.6041e-02, -3.8344e-02, -4.1491e-02,  1.9854e-02]],\n",
      "\n",
      "         [[-2.6491e-02,  4.0159e-02, -4.1427e-02, -7.6170e-03, -7.3140e-03],\n",
      "          [-3.9630e-02, -1.1807e-02,  2.3813e-02,  1.7934e-03, -2.2907e-02],\n",
      "          [-3.9195e-02, -3.7322e-03,  4.9031e-03,  4.1874e-02,  2.5364e-02],\n",
      "          [ 3.0963e-02,  1.8185e-02,  3.2395e-02, -3.2413e-02, -1.2818e-02],\n",
      "          [ 4.6185e-03, -1.5100e-02, -8.0613e-03,  6.8208e-03, -2.4075e-02]],\n",
      "\n",
      "         [[-2.1455e-02, -2.7057e-03, -7.7437e-03,  2.6733e-04, -2.0691e-02],\n",
      "          [ 1.2371e-02,  1.2946e-02, -5.9853e-03, -5.1840e-03,  4.3210e-02],\n",
      "          [ 4.7497e-03,  2.1726e-02,  3.7029e-03,  4.0085e-02, -2.3352e-02],\n",
      "          [ 2.9196e-02, -1.6861e-02, -3.5422e-02, -4.9593e-03,  2.1213e-02],\n",
      "          [-8.5790e-03, -1.9741e-02, -2.4979e-02,  8.3580e-03, -3.0003e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2219e-02, -3.6488e-02,  8.1911e-03,  4.0574e-02,  2.7663e-02],\n",
      "          [ 3.8541e-02,  1.7447e-02,  3.3555e-02,  3.9525e-02,  1.2404e-02],\n",
      "          [-2.7404e-02,  1.0433e-03, -4.2537e-02,  3.6915e-03, -4.2093e-02],\n",
      "          [-1.0742e-02, -3.7113e-02,  8.2909e-03, -3.8922e-02, -3.9269e-02],\n",
      "          [-3.8352e-02,  1.9914e-02, -2.2876e-02, -4.3953e-02,  3.2267e-02]],\n",
      "\n",
      "         [[ 2.7342e-02, -2.2636e-02,  3.7276e-02, -2.6170e-02,  3.8131e-02],\n",
      "          [-4.1702e-02,  3.6494e-02,  3.4553e-02,  8.2889e-03, -1.3203e-02],\n",
      "          [ 2.1594e-02, -1.0232e-03, -1.3677e-02,  3.9646e-02,  6.8112e-03],\n",
      "          [ 3.0746e-02,  2.3654e-02, -2.5046e-02, -4.6949e-03, -1.2915e-02],\n",
      "          [ 2.7509e-02, -7.8877e-03,  7.3765e-03, -4.2027e-03,  8.1646e-03]],\n",
      "\n",
      "         [[ 3.4163e-02, -2.6366e-02,  4.4121e-02,  3.1600e-02, -1.1947e-02],\n",
      "          [-3.8639e-02,  3.0027e-02, -1.1069e-03,  3.3161e-02, -3.9655e-02],\n",
      "          [ 1.7341e-02,  3.0755e-02, -1.2879e-02,  5.1505e-05, -2.0856e-02],\n",
      "          [-1.0053e-02, -8.5097e-03, -2.5528e-02,  4.2424e-02, -1.7655e-02],\n",
      "          [-1.9958e-03,  4.2383e-02, -2.0389e-02, -2.1955e-02, -2.9821e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9111e-02, -9.8587e-03,  2.2674e-02,  4.1752e-02, -3.0308e-02],\n",
      "          [ 1.4281e-03,  1.4835e-02, -1.1873e-02, -4.3554e-02, -1.6282e-02],\n",
      "          [ 1.7979e-02,  3.7161e-03,  1.1927e-02, -3.1373e-02, -3.8399e-03],\n",
      "          [-1.7560e-02, -2.3035e-02, -1.8226e-03,  3.1850e-02,  2.0427e-02],\n",
      "          [ 3.7227e-02, -4.2418e-03, -4.5080e-03,  2.4929e-02,  7.2678e-04]],\n",
      "\n",
      "         [[ 1.8624e-02,  2.1771e-03,  2.9543e-03,  1.5655e-03, -1.9216e-02],\n",
      "          [-3.0592e-02,  4.6970e-03, -5.1550e-03, -3.1509e-02, -2.5539e-02],\n",
      "          [ 5.2691e-03,  1.1452e-02,  3.5991e-03, -5.6211e-03,  1.7269e-02],\n",
      "          [ 1.1463e-02, -1.9230e-02,  1.3327e-02, -2.2483e-02, -2.9959e-02],\n",
      "          [ 1.6108e-03, -4.0144e-02,  2.3154e-02,  2.1032e-02,  3.6967e-02]],\n",
      "\n",
      "         [[-1.7662e-02,  1.2009e-02,  6.9824e-03,  5.0339e-03, -2.3007e-02],\n",
      "          [-2.9563e-02, -2.0134e-02,  2.3330e-02, -1.2088e-02,  1.4290e-02],\n",
      "          [ 3.1472e-02,  1.1480e-02,  1.6631e-03,  7.0405e-03, -1.3417e-02],\n",
      "          [ 3.3113e-02,  8.7944e-03,  2.0377e-02,  3.7911e-02,  3.1440e-02],\n",
      "          [-1.7023e-03, -5.8193e-03, -1.3485e-02, -2.9056e-02, -1.9129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8464e-02,  4.3393e-03,  1.4314e-02,  1.9514e-02,  2.2890e-02],\n",
      "          [ 1.6913e-02,  3.6645e-03, -1.6260e-02, -3.3765e-02, -1.4770e-02],\n",
      "          [ 3.5910e-02, -7.2799e-03,  3.3204e-02, -2.5386e-02,  3.6073e-02],\n",
      "          [-3.1312e-02, -6.2849e-03,  4.0375e-02, -2.1666e-02, -1.0114e-02],\n",
      "          [-9.8907e-03,  3.4569e-02,  4.0549e-02, -1.1892e-02, -2.4159e-02]],\n",
      "\n",
      "         [[ 6.6576e-03, -3.2157e-02,  3.6202e-02,  2.8732e-02, -2.2077e-03],\n",
      "          [ 3.8741e-03,  4.4562e-03, -1.1733e-02, -1.8566e-02, -2.0058e-02],\n",
      "          [-2.6554e-02, -4.1024e-02, -1.7292e-02, -1.0175e-02,  9.5437e-03],\n",
      "          [-1.4051e-02,  4.0718e-02,  3.4673e-02,  2.5243e-02, -1.0394e-02],\n",
      "          [ 4.9209e-03,  3.1385e-02, -2.1820e-02, -1.2295e-02, -3.2178e-02]],\n",
      "\n",
      "         [[ 4.0259e-02, -1.1299e-02, -1.4106e-02,  3.2192e-02, -1.2603e-02],\n",
      "          [ 1.1950e-02,  4.2668e-02,  2.2611e-02, -4.0604e-02, -3.7600e-02],\n",
      "          [-1.7960e-02,  2.4670e-02, -3.2335e-02, -4.2435e-02,  8.7845e-03],\n",
      "          [-1.5702e-02,  1.0560e-02,  4.0255e-02,  1.9973e-02, -2.9173e-02],\n",
      "          [-2.9245e-02,  4.3673e-02, -2.9623e-02, -2.6126e-02,  3.6229e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3782e-02, -3.2018e-02, -4.1422e-02,  4.2965e-02,  4.1290e-02],\n",
      "          [ 2.6014e-02,  3.5790e-02, -3.1674e-02,  2.1011e-02, -3.2987e-02],\n",
      "          [-3.8864e-02, -3.4980e-02, -3.9175e-02,  2.2159e-02,  2.7862e-02],\n",
      "          [-1.5315e-02, -3.0641e-02,  2.4972e-02, -2.6885e-02, -1.8860e-02],\n",
      "          [-3.7953e-02, -2.5055e-03,  1.6515e-02, -3.8565e-03, -3.4413e-02]],\n",
      "\n",
      "         [[ 5.2746e-03, -5.7524e-03,  8.7690e-04,  2.1129e-02, -3.3714e-02],\n",
      "          [-2.5097e-02, -9.1407e-03, -1.2493e-02, -2.8287e-02,  8.1022e-03],\n",
      "          [-3.4974e-02, -8.4004e-03,  6.5616e-03, -3.1915e-02, -1.8039e-03],\n",
      "          [ 4.3422e-02,  2.5244e-02, -3.7508e-02, -1.5715e-04,  2.8635e-03],\n",
      "          [ 4.0159e-02, -1.0451e-02,  3.3808e-02,  2.2487e-03,  2.3882e-02]],\n",
      "\n",
      "         [[ 8.0380e-03,  3.9348e-02,  3.6196e-02, -1.2740e-02,  8.8485e-03],\n",
      "          [-2.9744e-02,  3.9094e-02,  2.5479e-02,  3.2697e-02,  3.4737e-02],\n",
      "          [-3.5794e-02, -4.2454e-02, -2.3609e-02,  1.8149e-02,  4.2802e-02],\n",
      "          [ 1.9548e-03,  3.2146e-02,  1.7434e-02, -2.2222e-02, -4.3828e-02],\n",
      "          [ 4.4119e-04,  2.0332e-02, -1.5830e-02,  3.0345e-02,  2.7871e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4941e-03,  2.4571e-02, -4.0033e-03, -2.4643e-02,  2.4928e-02],\n",
      "          [-2.4729e-02, -3.4175e-02,  1.5217e-02, -6.8067e-03, -1.5605e-02],\n",
      "          [-1.5520e-02,  1.3591e-02, -1.6952e-02,  2.3149e-02, -3.5015e-02],\n",
      "          [-3.8227e-02,  2.4797e-03, -1.7207e-02,  1.7616e-02,  3.8088e-02],\n",
      "          [ 3.7997e-02, -3.6835e-02, -2.2072e-02,  3.5769e-02,  1.6814e-02]],\n",
      "\n",
      "         [[-2.5929e-02, -1.4625e-02, -2.8879e-02, -3.1932e-03,  2.6450e-02],\n",
      "          [ 2.6795e-03,  3.4002e-02, -7.2258e-03,  2.3569e-02, -1.0126e-02],\n",
      "          [-1.3826e-02, -1.5366e-02, -2.0826e-02, -4.2160e-02,  2.9605e-02],\n",
      "          [-2.9491e-02, -5.9204e-04,  3.0640e-02, -3.2850e-02,  4.6293e-03],\n",
      "          [ 8.2218e-03,  3.3545e-02,  2.2686e-02,  3.7325e-02,  4.3212e-02]],\n",
      "\n",
      "         [[ 2.2121e-02, -1.0479e-02,  3.5456e-02,  1.9301e-02, -1.2956e-03],\n",
      "          [ 1.5912e-03,  2.9417e-03,  2.9833e-02,  4.1424e-02, -2.1308e-02],\n",
      "          [ 3.1825e-02,  2.2558e-02, -8.4701e-03,  3.9350e-02,  2.2740e-02],\n",
      "          [ 1.8655e-02,  9.8191e-03,  1.6428e-02, -4.1089e-02, -2.5863e-02],\n",
      "          [ 1.6437e-02,  4.3713e-02, -7.8577e-03,  4.3015e-02, -2.6737e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7608e-03, -4.1001e-02, -2.9989e-02,  5.7242e-03,  1.6483e-02],\n",
      "          [-2.1141e-02, -3.8201e-02,  2.6190e-03,  2.5314e-02,  6.5599e-03],\n",
      "          [ 7.4922e-03,  3.1143e-03,  3.9642e-02,  2.0673e-03, -1.5567e-02],\n",
      "          [-2.0046e-04,  2.7596e-02,  9.6397e-03,  1.6137e-02,  8.5051e-03],\n",
      "          [-2.9986e-02,  1.8297e-02, -3.6378e-03,  2.2362e-03, -1.7651e-02]],\n",
      "\n",
      "         [[-1.2912e-02, -2.2029e-02, -2.4961e-02, -1.9687e-02, -2.0274e-02],\n",
      "          [-1.8502e-02, -1.8732e-02, -1.6331e-02,  1.4594e-02,  2.7315e-02],\n",
      "          [ 2.7607e-02,  3.3074e-02, -2.5466e-02, -1.5396e-02,  4.2149e-03],\n",
      "          [ 4.2130e-02, -1.2793e-02,  1.5324e-02, -4.1559e-02, -2.1596e-02],\n",
      "          [-3.1985e-02,  4.2327e-02,  3.0103e-02, -1.8856e-02, -4.3335e-02]],\n",
      "\n",
      "         [[-8.8148e-03, -1.9361e-02, -2.7197e-02, -1.4601e-02,  2.9393e-02],\n",
      "          [-4.1036e-02, -4.0184e-02,  3.2189e-02, -2.5799e-02, -2.6795e-02],\n",
      "          [ 7.8577e-04, -1.6912e-02,  2.6480e-02,  6.3703e-03,  1.0465e-02],\n",
      "          [ 3.6253e-03, -2.3415e-02, -2.0984e-02, -1.4698e-02,  2.4545e-02],\n",
      "          [-2.6590e-02,  1.5386e-02, -4.5269e-03,  8.9440e-03,  2.8833e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9688e-02,  3.1305e-02,  1.0911e-02, -3.1096e-03, -6.1476e-03],\n",
      "          [ 4.4522e-02, -4.1974e-02,  1.4086e-03,  1.3176e-02, -3.5228e-02],\n",
      "          [ 4.3846e-02, -1.2587e-03, -3.4890e-02, -6.4030e-03,  3.9697e-03],\n",
      "          [-4.0698e-02,  1.3210e-02,  1.1198e-02, -1.1474e-02,  3.7271e-02],\n",
      "          [-1.7921e-02,  1.9403e-02, -1.1318e-02, -3.4611e-02,  4.0208e-02]],\n",
      "\n",
      "         [[-4.5511e-04, -3.8761e-02,  3.1732e-02,  2.4404e-03,  4.3232e-02],\n",
      "          [ 1.8153e-02, -2.1967e-02, -3.2062e-02, -2.4471e-02,  4.0476e-02],\n",
      "          [-2.7757e-02,  3.4205e-02,  3.3019e-02,  1.4792e-02,  9.9620e-04],\n",
      "          [ 9.9321e-03, -3.5928e-02,  1.7252e-02,  1.6250e-02,  4.9671e-03],\n",
      "          [ 4.3295e-04, -3.8847e-02, -4.0153e-02,  3.0456e-02,  5.4879e-03]],\n",
      "\n",
      "         [[-3.8609e-03,  3.3571e-02, -3.1285e-02, -2.3129e-02,  1.5465e-02],\n",
      "          [ 3.8651e-02,  3.4275e-02,  3.1002e-02,  2.8591e-04,  1.5209e-02],\n",
      "          [-8.5173e-03, -4.0278e-02,  8.8405e-03, -4.1458e-02, -2.9139e-02],\n",
      "          [-1.0918e-02,  1.5830e-02,  1.1770e-02, -2.9171e-02,  3.7284e-02],\n",
      "          [-3.1970e-03,  1.7156e-02, -4.3869e-02, -2.8430e-03, -4.6179e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5426e-03, -3.3489e-02,  4.3182e-02,  4.4257e-02,  2.2910e-02],\n",
      "          [ 1.0588e-02, -3.6287e-03, -1.2841e-02,  4.2236e-02,  2.1910e-02],\n",
      "          [ 2.5113e-02,  1.7791e-02, -2.8582e-02, -8.2183e-03,  4.2715e-02],\n",
      "          [-4.4355e-02, -8.3076e-03, -3.8030e-02,  1.8744e-02, -2.5378e-02],\n",
      "          [-3.6300e-02,  3.6503e-02,  4.3366e-02, -2.6602e-02,  4.5671e-04]],\n",
      "\n",
      "         [[-8.0117e-03,  1.2479e-02, -1.1636e-02, -2.2237e-02,  6.4645e-03],\n",
      "          [ 3.3277e-02, -2.6507e-02,  1.4027e-02, -3.5600e-02, -9.1320e-03],\n",
      "          [-2.6892e-02,  1.8206e-02, -1.3648e-02,  1.4801e-02, -1.0142e-02],\n",
      "          [ 3.2587e-02,  1.5215e-02,  1.8212e-02,  2.0784e-02, -2.4829e-02],\n",
      "          [-2.7623e-02, -2.1331e-02,  1.8614e-02,  8.3137e-03, -2.5571e-02]],\n",
      "\n",
      "         [[ 3.3985e-02,  2.0536e-02, -3.6736e-02, -3.4242e-02, -3.5011e-02],\n",
      "          [-1.2837e-02, -1.6274e-02, -3.8104e-02,  1.5304e-02,  3.1169e-02],\n",
      "          [ 3.7217e-02, -1.7904e-02,  1.4214e-03,  4.3906e-02,  4.3218e-02],\n",
      "          [ 4.9224e-03,  4.0308e-02,  3.9056e-02, -8.4914e-03, -7.2897e-03],\n",
      "          [ 3.2487e-02, -6.0824e-03,  3.4568e-02, -1.0007e-02, -2.7042e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8313e-02,  3.8931e-02,  4.1518e-02, -1.0579e-02, -3.9042e-02],\n",
      "          [ 2.4156e-02,  2.3572e-02,  3.4003e-02, -3.2104e-03,  4.0552e-02],\n",
      "          [ 1.9444e-02,  4.9861e-04, -1.0498e-02, -3.3191e-02,  3.1968e-02],\n",
      "          [-4.3698e-02, -4.1204e-02,  2.2203e-02, -3.6378e-02, -4.1366e-02],\n",
      "          [ 3.2657e-02, -1.2996e-02, -1.8007e-02, -2.5327e-02,  3.8129e-02]],\n",
      "\n",
      "         [[ 4.3869e-02, -1.5969e-02, -2.7958e-02, -4.0428e-02,  4.4211e-02],\n",
      "          [-1.4945e-02,  1.7142e-03,  2.9844e-03, -4.1683e-02, -1.0541e-02],\n",
      "          [-3.0339e-03, -3.9557e-02,  1.9041e-02,  1.3259e-02,  2.7224e-02],\n",
      "          [-5.7078e-03,  2.4114e-02,  2.3944e-02, -2.3861e-03, -3.2904e-02],\n",
      "          [ 2.6463e-02,  3.4529e-02,  6.5505e-03,  5.5897e-03, -3.4591e-02]],\n",
      "\n",
      "         [[-8.8023e-03, -1.4111e-02,  3.6047e-02, -2.7741e-02,  1.5809e-03],\n",
      "          [ 3.5177e-02,  1.1588e-02, -1.2560e-03,  4.1529e-02,  1.7147e-02],\n",
      "          [-3.4687e-02,  5.2443e-03,  2.3536e-02, -2.4470e-02, -7.5177e-03],\n",
      "          [ 1.8502e-02, -3.6382e-03,  3.0699e-02,  4.1438e-02, -6.3115e-04],\n",
      "          [-3.1555e-02, -4.1446e-02,  2.6937e-02,  2.7350e-02,  6.8305e-03]]]],\n",
      "       requires_grad=True)\n",
      "Name: conv_layers.2.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0208, -0.0087,  0.0362, -0.0220, -0.0256,  0.0095,  0.0186, -0.0136,\n",
      "         0.0177, -0.0041,  0.0170, -0.0027, -0.0196,  0.0234, -0.0405, -0.0135,\n",
      "        -0.0309, -0.0404, -0.0075,  0.0444,  0.0423, -0.0372, -0.0131, -0.0381,\n",
      "         0.0133, -0.0289, -0.0221,  0.0352, -0.0110, -0.0044, -0.0370, -0.0284,\n",
      "         0.0397,  0.0232,  0.0216,  0.0064,  0.0168,  0.0110, -0.0194,  0.0445,\n",
      "         0.0036, -0.0137,  0.0069, -0.0088, -0.0233,  0.0234, -0.0068,  0.0105,\n",
      "        -0.0371, -0.0273, -0.0152, -0.0081,  0.0421,  0.0137, -0.0174, -0.0296,\n",
      "        -0.0234,  0.0100,  0.0340, -0.0171,  0.0026,  0.0309,  0.0317,  0.0267],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# `named_parameters()`\n",
    "for name, param in model.named_parameters():\n",
    "    print(\"Name:\", name)\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "500f1454-6912-43c7-8dfc-fb8d9df49380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: conv_layers.0.weight\n",
      "Parameters: tensor([[[[ 1.3241e-01,  1.5604e-01, -1.0033e-01,  1.9216e-01, -6.9605e-02],\n",
      "          [ 1.7387e-01, -8.7238e-02, -8.7400e-02, -6.6454e-03, -1.3710e-02],\n",
      "          [ 4.7818e-02, -1.3161e-01, -1.2073e-01, -8.0846e-02, -1.4806e-01],\n",
      "          [ 1.5466e-01,  1.7643e-01,  6.8757e-02, -1.3546e-01,  8.1396e-02],\n",
      "          [ 1.4838e-01, -1.3129e-01, -3.4942e-02,  1.3256e-01,  1.8711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7838e-01,  9.0442e-02,  9.4969e-02,  1.9040e-01, -5.6426e-02],\n",
      "          [ 1.4222e-01,  1.0127e-01, -9.1116e-03, -2.4985e-02, -1.6505e-01],\n",
      "          [ 1.7914e-01, -7.6648e-02, -1.7809e-01,  1.2110e-01, -5.1342e-02],\n",
      "          [ 2.2690e-02,  1.5465e-01, -8.5308e-02, -4.7745e-02,  3.1571e-02],\n",
      "          [ 2.8867e-02, -3.0587e-02, -3.1570e-02, -1.9829e-01, -4.0238e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3186e-01, -1.4602e-01,  9.5862e-02, -8.8489e-02, -9.6553e-02],\n",
      "          [-1.3332e-01,  1.1675e-02,  1.6270e-01,  1.4342e-01,  1.4186e-02],\n",
      "          [ 6.7934e-02,  1.0176e-02,  5.6962e-02,  1.9649e-01,  1.5693e-01],\n",
      "          [-1.7073e-01, -2.1391e-02,  2.3361e-02,  3.1500e-02, -6.6577e-02],\n",
      "          [ 7.7104e-02,  1.4623e-01, -7.9448e-03,  3.1214e-02, -7.6848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7350e-02, -1.1280e-01, -1.1613e-01,  3.4520e-02, -9.1342e-03],\n",
      "          [-1.3996e-01, -1.8361e-01,  1.1601e-01, -5.5225e-02, -5.4041e-02],\n",
      "          [ 1.9208e-01, -9.1202e-02,  1.3636e-01,  7.3855e-02, -6.5894e-02],\n",
      "          [ 1.3723e-02,  1.5521e-01,  7.8226e-02, -1.1209e-01, -1.5964e-01],\n",
      "          [-6.5851e-02, -1.5129e-01, -5.2712e-02,  8.9967e-02, -1.8500e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2484e-01, -1.8534e-01,  3.6886e-02,  8.3262e-02,  6.8633e-02],\n",
      "          [ 1.4270e-02,  1.6860e-01,  4.8610e-02, -1.8697e-01, -1.5962e-01],\n",
      "          [-6.1016e-02, -1.6345e-02, -1.1608e-01, -1.8487e-01, -1.6567e-01],\n",
      "          [-4.0601e-02,  8.8121e-02, -1.8425e-02, -3.8099e-02, -1.9318e-01],\n",
      "          [-9.6685e-02,  4.7574e-02,  7.1982e-02,  1.3283e-01, -1.3550e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2990e-01, -1.8027e-02, -1.9720e-01, -1.0266e-01,  1.9599e-01],\n",
      "          [ 2.3637e-03,  8.8786e-02, -3.4413e-02, -1.1878e-01,  1.4574e-01],\n",
      "          [-1.1365e-01, -1.6888e-01,  5.0974e-05, -9.2363e-02, -4.1784e-02],\n",
      "          [ 1.6196e-01,  1.4280e-01, -8.2476e-02,  1.4793e-01,  9.5471e-02],\n",
      "          [ 9.4619e-02, -5.1215e-02,  7.4179e-02, -9.6469e-02, -8.7771e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1201e-01,  1.9360e-01, -1.8400e-01, -3.8823e-02,  1.8009e-01],\n",
      "          [ 1.5503e-01, -1.8852e-01,  2.5678e-02,  1.9906e-01, -1.4539e-01],\n",
      "          [-1.4287e-01, -1.7903e-01,  2.2451e-02,  1.4313e-01,  1.8826e-01],\n",
      "          [ 1.1788e-01,  1.4232e-01, -2.2371e-02, -4.0267e-02,  1.7885e-01],\n",
      "          [-9.0347e-02, -2.7690e-03, -5.3224e-02, -5.5934e-02, -1.3836e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8000e-02, -6.3736e-02, -1.5082e-01,  3.6312e-02, -1.9862e-01],\n",
      "          [ 4.8823e-02, -8.4725e-02,  6.8034e-02,  1.8329e-01,  4.5708e-02],\n",
      "          [ 1.9683e-01, -5.6322e-02,  6.3535e-02,  3.6922e-02,  1.7151e-01],\n",
      "          [ 1.4225e-01, -1.6482e-01,  6.7343e-02,  1.3643e-01,  1.4066e-01],\n",
      "          [ 2.8197e-02, -1.7635e-01, -1.5050e-01,  3.3212e-03,  6.0210e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8715e-02, -1.2924e-01,  1.1012e-01,  8.7607e-03, -1.6257e-01],\n",
      "          [ 7.7766e-02, -1.5367e-01,  1.5281e-01, -5.8361e-02,  1.0171e-01],\n",
      "          [ 1.7840e-01, -1.7470e-01, -1.5965e-01,  5.9101e-02,  1.6743e-01],\n",
      "          [-1.0642e-01, -7.9235e-03, -1.2118e-01, -1.6437e-01, -1.5323e-01],\n",
      "          [ 1.4803e-01,  1.1819e-01, -2.5592e-02,  6.2606e-02,  4.4999e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6631e-01, -1.3663e-01, -1.0860e-01,  1.8708e-01, -1.7883e-01],\n",
      "          [ 1.1482e-02, -1.2443e-01, -1.0491e-01, -9.3156e-02,  6.7180e-02],\n",
      "          [ 8.2907e-02,  1.0562e-01, -3.0791e-02, -8.7147e-02, -2.5293e-02],\n",
      "          [ 6.1346e-03,  1.6903e-01,  3.4932e-02, -1.4125e-01,  1.1192e-02],\n",
      "          [ 1.1734e-01,  1.3849e-01,  1.8247e-01, -6.6997e-02,  1.4443e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5675e-02,  1.7151e-02,  1.8107e-01, -6.6976e-02, -1.6386e-01],\n",
      "          [ 1.8581e-01,  1.1274e-01,  7.9142e-02,  1.4690e-01, -1.3505e-01],\n",
      "          [ 1.1049e-01,  1.0505e-01, -1.2216e-02, -1.7340e-01,  1.1556e-01],\n",
      "          [-5.8734e-02, -7.1824e-02, -3.7298e-02,  1.0030e-01, -6.1381e-02],\n",
      "          [ 1.6798e-01,  2.4707e-02, -8.9779e-02, -3.4683e-02,  6.7887e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0472e-02, -1.6816e-01,  1.6501e-01, -1.4424e-01,  1.4948e-01],\n",
      "          [ 1.3995e-01, -6.1184e-02, -1.7629e-02, -7.1295e-02, -1.3393e-01],\n",
      "          [ 2.0582e-02,  1.8349e-01, -1.7890e-01,  1.5396e-01, -5.8100e-02],\n",
      "          [ 1.8454e-01, -1.3551e-02,  2.1506e-02, -1.6931e-01, -1.8765e-01],\n",
      "          [ 1.0588e-01, -9.1665e-02, -1.6879e-01, -1.2527e-01, -1.0091e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9449e-02,  1.2685e-01,  7.2299e-02,  4.6595e-02,  1.9679e-01],\n",
      "          [ 2.2285e-02,  2.2567e-02,  1.0742e-01, -6.6561e-02,  1.8148e-01],\n",
      "          [ 5.5963e-02,  1.6754e-01,  7.0529e-02,  4.2915e-02, -6.9040e-02],\n",
      "          [ 4.6791e-02,  1.9311e-01, -5.7044e-02, -7.8055e-02, -1.4386e-01],\n",
      "          [-1.7197e-01, -1.6560e-01,  8.5198e-02, -1.8517e-01, -2.0688e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3139e-01,  1.4070e-01,  2.7097e-02, -1.5805e-01,  1.2808e-01],\n",
      "          [-1.7832e-01,  6.4503e-02,  2.9197e-02,  1.6657e-01, -4.3565e-02],\n",
      "          [ 5.4102e-02, -3.9023e-02,  3.9094e-02,  1.2332e-01,  1.4203e-01],\n",
      "          [ 5.1546e-02, -5.7866e-02,  1.5820e-01,  1.4223e-03,  4.3801e-02],\n",
      "          [ 6.5623e-02, -1.4990e-01,  1.2141e-01, -1.3783e-02,  8.0581e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1322e-01, -1.9726e-01,  7.9353e-03, -4.4787e-02,  1.6848e-01],\n",
      "          [ 7.8345e-02, -4.2794e-02,  1.8022e-01,  1.5772e-01,  7.7809e-02],\n",
      "          [ 1.0495e-01, -1.7089e-01,  1.3323e-01,  2.5954e-02,  9.5799e-04],\n",
      "          [ 1.4828e-01,  1.6508e-01, -7.2082e-03,  1.0186e-01, -1.7378e-01],\n",
      "          [-1.1721e-01,  3.0324e-04, -2.0825e-02,  9.1728e-02,  7.0678e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9776e-02, -1.3168e-01,  2.4154e-02, -4.5304e-02,  6.8677e-02],\n",
      "          [-1.8232e-01,  9.1022e-02, -7.2123e-02, -9.7199e-03, -3.1094e-02],\n",
      "          [ 2.8557e-02,  3.9763e-02, -3.2785e-02,  1.2154e-01, -1.2906e-01],\n",
      "          [ 1.1970e-01, -2.9830e-02, -1.2073e-01,  1.4320e-01, -1.1444e-01],\n",
      "          [ 1.5797e-01, -1.8464e-02, -5.0214e-02, -4.5412e-02, -1.5845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2919e-01, -2.3971e-02,  1.6241e-01, -1.2552e-01,  1.0633e-01],\n",
      "          [-1.7193e-01, -8.4782e-02,  1.5894e-01,  3.8409e-02, -1.8693e-01],\n",
      "          [-1.0562e-01,  6.0506e-02,  6.0093e-02,  2.5464e-02, -1.2752e-01],\n",
      "          [-1.6392e-02, -5.1873e-02,  1.9090e-01,  1.1538e-01, -1.1494e-02],\n",
      "          [ 4.7702e-02,  9.9459e-04, -1.1322e-01,  1.0613e-01, -9.6574e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4468e-02, -1.9568e-01, -8.3747e-02,  2.1697e-02, -1.6775e-01],\n",
      "          [-9.4823e-03,  6.9211e-02, -1.5341e-01,  9.8999e-02,  1.9264e-01],\n",
      "          [-5.4513e-02, -4.0235e-02, -1.1080e-01,  3.4654e-02, -1.1992e-01],\n",
      "          [ 1.6636e-01,  8.5964e-02,  5.3202e-02,  1.4344e-01,  9.3552e-02],\n",
      "          [ 1.8168e-01,  9.4864e-02, -6.3565e-02,  1.6350e-01, -7.3253e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7767e-01,  9.4857e-02,  1.3126e-01,  1.3162e-01, -1.8681e-01],\n",
      "          [-1.5823e-01, -1.1111e-02,  1.1166e-01,  4.4050e-02,  1.4993e-01],\n",
      "          [ 9.4183e-02, -7.8399e-02,  6.6749e-02, -1.6290e-02,  1.2230e-01],\n",
      "          [ 1.7485e-01, -4.1142e-02,  1.3335e-01, -1.4768e-01, -7.8840e-02],\n",
      "          [-1.3098e-01,  1.0426e-01, -6.6484e-02,  6.0214e-02,  1.2992e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9978e-01,  6.4416e-02,  6.5184e-02,  1.5113e-01, -1.5479e-01],\n",
      "          [-1.7515e-01, -4.4054e-02,  1.1378e-01,  1.7940e-01, -1.7875e-01],\n",
      "          [ 8.9578e-02,  1.9231e-01,  1.4054e-01,  1.6426e-01,  2.6875e-02],\n",
      "          [-5.9233e-02,  1.1354e-01,  1.5061e-01,  5.0135e-02, -3.3059e-02],\n",
      "          [ 1.8981e-01, -9.1344e-02,  9.9926e-02,  1.9885e-01, -6.9535e-02]]]])\n",
      "Name: conv_layers.0.bias\n",
      "Parameters: tensor([-0.0573,  0.0840, -0.1971, -0.0123,  0.0091,  0.1132,  0.1386, -0.1841,\n",
      "        -0.0115, -0.0262,  0.0195,  0.1285, -0.0273, -0.1999, -0.1102, -0.1538,\n",
      "         0.1940,  0.1120,  0.1132,  0.0043])\n",
      "Name: conv_layers.2.weight\n",
      "Parameters: tensor([[[[-1.3871e-02,  1.8138e-03,  2.7409e-02,  1.9202e-03,  3.5283e-02],\n",
      "          [ 2.6181e-02, -1.2598e-03, -7.3440e-03,  4.4750e-03,  4.2259e-02],\n",
      "          [ 1.3897e-02, -3.8882e-02,  2.5302e-02,  9.9060e-03, -1.5260e-02],\n",
      "          [ 3.9157e-02, -4.0127e-02, -4.2976e-02,  3.9782e-02, -1.5026e-02],\n",
      "          [-1.7793e-02, -1.1287e-02, -4.0245e-02, -2.5290e-02, -1.5126e-03]],\n",
      "\n",
      "         [[-1.8095e-02, -2.9858e-02,  1.8384e-02,  4.2637e-03, -1.4755e-02],\n",
      "          [-2.0695e-02,  1.8060e-02, -1.5756e-02,  2.3952e-02, -4.2352e-02],\n",
      "          [ 2.3106e-02,  6.3974e-03,  6.0189e-04,  1.3654e-02, -1.3639e-02],\n",
      "          [-3.7988e-03, -3.6270e-02,  2.3508e-02, -6.1616e-03, -2.5438e-02],\n",
      "          [-1.7730e-02,  2.2161e-02,  1.6720e-02, -3.2676e-02,  9.0513e-03]],\n",
      "\n",
      "         [[ 1.4793e-02,  1.6415e-02, -2.8927e-02,  8.1149e-03,  3.6316e-02],\n",
      "          [ 1.8483e-02, -1.4564e-02,  4.2133e-02,  2.2380e-02, -1.8128e-02],\n",
      "          [-1.4943e-02, -3.3563e-02, -1.0543e-02,  2.4182e-02,  3.5721e-02],\n",
      "          [ 1.2420e-02, -9.2878e-03, -4.2604e-02,  3.0411e-02,  8.3704e-03],\n",
      "          [-3.6704e-02, -1.4528e-02, -8.2998e-03, -1.6295e-02, -1.3609e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0465e-03,  1.7051e-02,  7.7259e-03, -3.8155e-03,  3.9476e-03],\n",
      "          [ 3.1129e-02, -4.3741e-02, -2.0728e-02, -8.6993e-03,  2.7008e-02],\n",
      "          [-9.1237e-03, -3.5947e-02, -2.1752e-03, -1.9814e-02,  2.8245e-02],\n",
      "          [ 3.9406e-03,  3.3105e-03, -1.5305e-03,  2.5063e-02, -4.6007e-03],\n",
      "          [ 3.7993e-02, -1.6980e-02, -2.2232e-02, -1.1428e-02,  2.9301e-02]],\n",
      "\n",
      "         [[-6.4159e-03,  2.1685e-02,  8.6689e-03,  8.6723e-03,  1.8453e-02],\n",
      "          [-3.0057e-02,  4.0051e-02,  4.1262e-02,  2.9822e-02,  2.1606e-02],\n",
      "          [-2.1487e-02, -3.8540e-02, -9.6918e-03,  3.5614e-02,  2.3266e-02],\n",
      "          [ 4.3648e-02, -1.2313e-02,  4.0020e-02, -9.2189e-03, -2.5507e-02],\n",
      "          [ 2.3909e-02,  2.4166e-02,  2.8090e-02,  4.0647e-02, -2.8616e-02]],\n",
      "\n",
      "         [[ 2.0415e-03,  2.2509e-03,  2.5001e-02,  3.0924e-02, -3.3789e-03],\n",
      "          [ 8.6982e-03,  3.3180e-02, -1.8352e-02, -4.1864e-02, -3.5893e-02],\n",
      "          [ 3.2103e-02,  1.0422e-02, -2.7926e-02, -3.0336e-02, -2.0639e-02],\n",
      "          [-3.0402e-02, -1.1929e-02,  2.1070e-02,  8.6693e-03, -3.4097e-02],\n",
      "          [-3.5102e-02,  1.8101e-02, -2.5006e-02, -2.2366e-02,  3.0084e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9222e-02, -2.4327e-02,  1.3645e-02,  2.3390e-02,  3.0595e-02],\n",
      "          [ 2.6715e-02, -3.6614e-03, -2.1772e-02,  2.7429e-03,  1.1749e-02],\n",
      "          [ 2.4263e-02,  1.7774e-02,  3.4740e-02, -1.4598e-02, -3.5157e-02],\n",
      "          [ 2.4948e-03,  1.8638e-02, -2.5367e-02, -1.5732e-02,  3.7917e-03],\n",
      "          [-3.5909e-03,  3.6041e-02, -3.8344e-02, -4.1491e-02,  1.9854e-02]],\n",
      "\n",
      "         [[-2.6491e-02,  4.0159e-02, -4.1427e-02, -7.6170e-03, -7.3140e-03],\n",
      "          [-3.9630e-02, -1.1807e-02,  2.3813e-02,  1.7934e-03, -2.2907e-02],\n",
      "          [-3.9195e-02, -3.7322e-03,  4.9031e-03,  4.1874e-02,  2.5364e-02],\n",
      "          [ 3.0963e-02,  1.8185e-02,  3.2395e-02, -3.2413e-02, -1.2818e-02],\n",
      "          [ 4.6185e-03, -1.5100e-02, -8.0613e-03,  6.8208e-03, -2.4075e-02]],\n",
      "\n",
      "         [[-2.1455e-02, -2.7057e-03, -7.7437e-03,  2.6733e-04, -2.0691e-02],\n",
      "          [ 1.2371e-02,  1.2946e-02, -5.9853e-03, -5.1840e-03,  4.3210e-02],\n",
      "          [ 4.7497e-03,  2.1726e-02,  3.7029e-03,  4.0085e-02, -2.3352e-02],\n",
      "          [ 2.9196e-02, -1.6861e-02, -3.5422e-02, -4.9593e-03,  2.1213e-02],\n",
      "          [-8.5790e-03, -1.9741e-02, -2.4979e-02,  8.3580e-03, -3.0003e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2219e-02, -3.6488e-02,  8.1911e-03,  4.0574e-02,  2.7663e-02],\n",
      "          [ 3.8541e-02,  1.7447e-02,  3.3555e-02,  3.9525e-02,  1.2404e-02],\n",
      "          [-2.7404e-02,  1.0433e-03, -4.2537e-02,  3.6915e-03, -4.2093e-02],\n",
      "          [-1.0742e-02, -3.7113e-02,  8.2909e-03, -3.8922e-02, -3.9269e-02],\n",
      "          [-3.8352e-02,  1.9914e-02, -2.2876e-02, -4.3953e-02,  3.2267e-02]],\n",
      "\n",
      "         [[ 2.7342e-02, -2.2636e-02,  3.7276e-02, -2.6170e-02,  3.8131e-02],\n",
      "          [-4.1702e-02,  3.6494e-02,  3.4553e-02,  8.2889e-03, -1.3203e-02],\n",
      "          [ 2.1594e-02, -1.0232e-03, -1.3677e-02,  3.9646e-02,  6.8112e-03],\n",
      "          [ 3.0746e-02,  2.3654e-02, -2.5046e-02, -4.6949e-03, -1.2915e-02],\n",
      "          [ 2.7509e-02, -7.8877e-03,  7.3765e-03, -4.2027e-03,  8.1646e-03]],\n",
      "\n",
      "         [[ 3.4163e-02, -2.6366e-02,  4.4121e-02,  3.1600e-02, -1.1947e-02],\n",
      "          [-3.8639e-02,  3.0027e-02, -1.1069e-03,  3.3161e-02, -3.9655e-02],\n",
      "          [ 1.7341e-02,  3.0755e-02, -1.2879e-02,  5.1505e-05, -2.0856e-02],\n",
      "          [-1.0053e-02, -8.5097e-03, -2.5528e-02,  4.2424e-02, -1.7655e-02],\n",
      "          [-1.9958e-03,  4.2383e-02, -2.0389e-02, -2.1955e-02, -2.9821e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9111e-02, -9.8587e-03,  2.2674e-02,  4.1752e-02, -3.0308e-02],\n",
      "          [ 1.4281e-03,  1.4835e-02, -1.1873e-02, -4.3554e-02, -1.6282e-02],\n",
      "          [ 1.7979e-02,  3.7161e-03,  1.1927e-02, -3.1373e-02, -3.8399e-03],\n",
      "          [-1.7560e-02, -2.3035e-02, -1.8226e-03,  3.1850e-02,  2.0427e-02],\n",
      "          [ 3.7227e-02, -4.2418e-03, -4.5080e-03,  2.4929e-02,  7.2678e-04]],\n",
      "\n",
      "         [[ 1.8624e-02,  2.1771e-03,  2.9543e-03,  1.5655e-03, -1.9216e-02],\n",
      "          [-3.0592e-02,  4.6970e-03, -5.1550e-03, -3.1509e-02, -2.5539e-02],\n",
      "          [ 5.2691e-03,  1.1452e-02,  3.5991e-03, -5.6211e-03,  1.7269e-02],\n",
      "          [ 1.1463e-02, -1.9230e-02,  1.3327e-02, -2.2483e-02, -2.9959e-02],\n",
      "          [ 1.6108e-03, -4.0144e-02,  2.3154e-02,  2.1032e-02,  3.6967e-02]],\n",
      "\n",
      "         [[-1.7662e-02,  1.2009e-02,  6.9824e-03,  5.0339e-03, -2.3007e-02],\n",
      "          [-2.9563e-02, -2.0134e-02,  2.3330e-02, -1.2088e-02,  1.4290e-02],\n",
      "          [ 3.1472e-02,  1.1480e-02,  1.6631e-03,  7.0405e-03, -1.3417e-02],\n",
      "          [ 3.3113e-02,  8.7944e-03,  2.0377e-02,  3.7911e-02,  3.1440e-02],\n",
      "          [-1.7023e-03, -5.8193e-03, -1.3485e-02, -2.9056e-02, -1.9129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8464e-02,  4.3393e-03,  1.4314e-02,  1.9514e-02,  2.2890e-02],\n",
      "          [ 1.6913e-02,  3.6645e-03, -1.6260e-02, -3.3765e-02, -1.4770e-02],\n",
      "          [ 3.5910e-02, -7.2799e-03,  3.3204e-02, -2.5386e-02,  3.6073e-02],\n",
      "          [-3.1312e-02, -6.2849e-03,  4.0375e-02, -2.1666e-02, -1.0114e-02],\n",
      "          [-9.8907e-03,  3.4569e-02,  4.0549e-02, -1.1892e-02, -2.4159e-02]],\n",
      "\n",
      "         [[ 6.6576e-03, -3.2157e-02,  3.6202e-02,  2.8732e-02, -2.2077e-03],\n",
      "          [ 3.8741e-03,  4.4562e-03, -1.1733e-02, -1.8566e-02, -2.0058e-02],\n",
      "          [-2.6554e-02, -4.1024e-02, -1.7292e-02, -1.0175e-02,  9.5437e-03],\n",
      "          [-1.4051e-02,  4.0718e-02,  3.4673e-02,  2.5243e-02, -1.0394e-02],\n",
      "          [ 4.9209e-03,  3.1385e-02, -2.1820e-02, -1.2295e-02, -3.2178e-02]],\n",
      "\n",
      "         [[ 4.0259e-02, -1.1299e-02, -1.4106e-02,  3.2192e-02, -1.2603e-02],\n",
      "          [ 1.1950e-02,  4.2668e-02,  2.2611e-02, -4.0604e-02, -3.7600e-02],\n",
      "          [-1.7960e-02,  2.4670e-02, -3.2335e-02, -4.2435e-02,  8.7845e-03],\n",
      "          [-1.5702e-02,  1.0560e-02,  4.0255e-02,  1.9973e-02, -2.9173e-02],\n",
      "          [-2.9245e-02,  4.3673e-02, -2.9623e-02, -2.6126e-02,  3.6229e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3782e-02, -3.2018e-02, -4.1422e-02,  4.2965e-02,  4.1290e-02],\n",
      "          [ 2.6014e-02,  3.5790e-02, -3.1674e-02,  2.1011e-02, -3.2987e-02],\n",
      "          [-3.8864e-02, -3.4980e-02, -3.9175e-02,  2.2159e-02,  2.7862e-02],\n",
      "          [-1.5315e-02, -3.0641e-02,  2.4972e-02, -2.6885e-02, -1.8860e-02],\n",
      "          [-3.7953e-02, -2.5055e-03,  1.6515e-02, -3.8565e-03, -3.4413e-02]],\n",
      "\n",
      "         [[ 5.2746e-03, -5.7524e-03,  8.7690e-04,  2.1129e-02, -3.3714e-02],\n",
      "          [-2.5097e-02, -9.1407e-03, -1.2493e-02, -2.8287e-02,  8.1022e-03],\n",
      "          [-3.4974e-02, -8.4004e-03,  6.5616e-03, -3.1915e-02, -1.8039e-03],\n",
      "          [ 4.3422e-02,  2.5244e-02, -3.7508e-02, -1.5715e-04,  2.8635e-03],\n",
      "          [ 4.0159e-02, -1.0451e-02,  3.3808e-02,  2.2487e-03,  2.3882e-02]],\n",
      "\n",
      "         [[ 8.0380e-03,  3.9348e-02,  3.6196e-02, -1.2740e-02,  8.8485e-03],\n",
      "          [-2.9744e-02,  3.9094e-02,  2.5479e-02,  3.2697e-02,  3.4737e-02],\n",
      "          [-3.5794e-02, -4.2454e-02, -2.3609e-02,  1.8149e-02,  4.2802e-02],\n",
      "          [ 1.9548e-03,  3.2146e-02,  1.7434e-02, -2.2222e-02, -4.3828e-02],\n",
      "          [ 4.4119e-04,  2.0332e-02, -1.5830e-02,  3.0345e-02,  2.7871e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4941e-03,  2.4571e-02, -4.0033e-03, -2.4643e-02,  2.4928e-02],\n",
      "          [-2.4729e-02, -3.4175e-02,  1.5217e-02, -6.8067e-03, -1.5605e-02],\n",
      "          [-1.5520e-02,  1.3591e-02, -1.6952e-02,  2.3149e-02, -3.5015e-02],\n",
      "          [-3.8227e-02,  2.4797e-03, -1.7207e-02,  1.7616e-02,  3.8088e-02],\n",
      "          [ 3.7997e-02, -3.6835e-02, -2.2072e-02,  3.5769e-02,  1.6814e-02]],\n",
      "\n",
      "         [[-2.5929e-02, -1.4625e-02, -2.8879e-02, -3.1932e-03,  2.6450e-02],\n",
      "          [ 2.6795e-03,  3.4002e-02, -7.2258e-03,  2.3569e-02, -1.0126e-02],\n",
      "          [-1.3826e-02, -1.5366e-02, -2.0826e-02, -4.2160e-02,  2.9605e-02],\n",
      "          [-2.9491e-02, -5.9204e-04,  3.0640e-02, -3.2850e-02,  4.6293e-03],\n",
      "          [ 8.2218e-03,  3.3545e-02,  2.2686e-02,  3.7325e-02,  4.3212e-02]],\n",
      "\n",
      "         [[ 2.2121e-02, -1.0479e-02,  3.5456e-02,  1.9301e-02, -1.2956e-03],\n",
      "          [ 1.5912e-03,  2.9417e-03,  2.9833e-02,  4.1424e-02, -2.1308e-02],\n",
      "          [ 3.1825e-02,  2.2558e-02, -8.4701e-03,  3.9350e-02,  2.2740e-02],\n",
      "          [ 1.8655e-02,  9.8191e-03,  1.6428e-02, -4.1089e-02, -2.5863e-02],\n",
      "          [ 1.6437e-02,  4.3713e-02, -7.8577e-03,  4.3015e-02, -2.6737e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7608e-03, -4.1001e-02, -2.9989e-02,  5.7242e-03,  1.6483e-02],\n",
      "          [-2.1141e-02, -3.8201e-02,  2.6190e-03,  2.5314e-02,  6.5599e-03],\n",
      "          [ 7.4922e-03,  3.1143e-03,  3.9642e-02,  2.0673e-03, -1.5567e-02],\n",
      "          [-2.0046e-04,  2.7596e-02,  9.6397e-03,  1.6137e-02,  8.5051e-03],\n",
      "          [-2.9986e-02,  1.8297e-02, -3.6378e-03,  2.2362e-03, -1.7651e-02]],\n",
      "\n",
      "         [[-1.2912e-02, -2.2029e-02, -2.4961e-02, -1.9687e-02, -2.0274e-02],\n",
      "          [-1.8502e-02, -1.8732e-02, -1.6331e-02,  1.4594e-02,  2.7315e-02],\n",
      "          [ 2.7607e-02,  3.3074e-02, -2.5466e-02, -1.5396e-02,  4.2149e-03],\n",
      "          [ 4.2130e-02, -1.2793e-02,  1.5324e-02, -4.1559e-02, -2.1596e-02],\n",
      "          [-3.1985e-02,  4.2327e-02,  3.0103e-02, -1.8856e-02, -4.3335e-02]],\n",
      "\n",
      "         [[-8.8148e-03, -1.9361e-02, -2.7197e-02, -1.4601e-02,  2.9393e-02],\n",
      "          [-4.1036e-02, -4.0184e-02,  3.2189e-02, -2.5799e-02, -2.6795e-02],\n",
      "          [ 7.8577e-04, -1.6912e-02,  2.6480e-02,  6.3703e-03,  1.0465e-02],\n",
      "          [ 3.6253e-03, -2.3415e-02, -2.0984e-02, -1.4698e-02,  2.4545e-02],\n",
      "          [-2.6590e-02,  1.5386e-02, -4.5269e-03,  8.9440e-03,  2.8833e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9688e-02,  3.1305e-02,  1.0911e-02, -3.1096e-03, -6.1476e-03],\n",
      "          [ 4.4522e-02, -4.1974e-02,  1.4086e-03,  1.3176e-02, -3.5228e-02],\n",
      "          [ 4.3846e-02, -1.2587e-03, -3.4890e-02, -6.4030e-03,  3.9697e-03],\n",
      "          [-4.0698e-02,  1.3210e-02,  1.1198e-02, -1.1474e-02,  3.7271e-02],\n",
      "          [-1.7921e-02,  1.9403e-02, -1.1318e-02, -3.4611e-02,  4.0208e-02]],\n",
      "\n",
      "         [[-4.5511e-04, -3.8761e-02,  3.1732e-02,  2.4404e-03,  4.3232e-02],\n",
      "          [ 1.8153e-02, -2.1967e-02, -3.2062e-02, -2.4471e-02,  4.0476e-02],\n",
      "          [-2.7757e-02,  3.4205e-02,  3.3019e-02,  1.4792e-02,  9.9620e-04],\n",
      "          [ 9.9321e-03, -3.5928e-02,  1.7252e-02,  1.6250e-02,  4.9671e-03],\n",
      "          [ 4.3295e-04, -3.8847e-02, -4.0153e-02,  3.0456e-02,  5.4879e-03]],\n",
      "\n",
      "         [[-3.8609e-03,  3.3571e-02, -3.1285e-02, -2.3129e-02,  1.5465e-02],\n",
      "          [ 3.8651e-02,  3.4275e-02,  3.1002e-02,  2.8591e-04,  1.5209e-02],\n",
      "          [-8.5173e-03, -4.0278e-02,  8.8405e-03, -4.1458e-02, -2.9139e-02],\n",
      "          [-1.0918e-02,  1.5830e-02,  1.1770e-02, -2.9171e-02,  3.7284e-02],\n",
      "          [-3.1970e-03,  1.7156e-02, -4.3869e-02, -2.8430e-03, -4.6179e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5426e-03, -3.3489e-02,  4.3182e-02,  4.4257e-02,  2.2910e-02],\n",
      "          [ 1.0588e-02, -3.6287e-03, -1.2841e-02,  4.2236e-02,  2.1910e-02],\n",
      "          [ 2.5113e-02,  1.7791e-02, -2.8582e-02, -8.2183e-03,  4.2715e-02],\n",
      "          [-4.4355e-02, -8.3076e-03, -3.8030e-02,  1.8744e-02, -2.5378e-02],\n",
      "          [-3.6300e-02,  3.6503e-02,  4.3366e-02, -2.6602e-02,  4.5671e-04]],\n",
      "\n",
      "         [[-8.0117e-03,  1.2479e-02, -1.1636e-02, -2.2237e-02,  6.4645e-03],\n",
      "          [ 3.3277e-02, -2.6507e-02,  1.4027e-02, -3.5600e-02, -9.1320e-03],\n",
      "          [-2.6892e-02,  1.8206e-02, -1.3648e-02,  1.4801e-02, -1.0142e-02],\n",
      "          [ 3.2587e-02,  1.5215e-02,  1.8212e-02,  2.0784e-02, -2.4829e-02],\n",
      "          [-2.7623e-02, -2.1331e-02,  1.8614e-02,  8.3137e-03, -2.5571e-02]],\n",
      "\n",
      "         [[ 3.3985e-02,  2.0536e-02, -3.6736e-02, -3.4242e-02, -3.5011e-02],\n",
      "          [-1.2837e-02, -1.6274e-02, -3.8104e-02,  1.5304e-02,  3.1169e-02],\n",
      "          [ 3.7217e-02, -1.7904e-02,  1.4214e-03,  4.3906e-02,  4.3218e-02],\n",
      "          [ 4.9224e-03,  4.0308e-02,  3.9056e-02, -8.4914e-03, -7.2897e-03],\n",
      "          [ 3.2487e-02, -6.0824e-03,  3.4568e-02, -1.0007e-02, -2.7042e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8313e-02,  3.8931e-02,  4.1518e-02, -1.0579e-02, -3.9042e-02],\n",
      "          [ 2.4156e-02,  2.3572e-02,  3.4003e-02, -3.2104e-03,  4.0552e-02],\n",
      "          [ 1.9444e-02,  4.9861e-04, -1.0498e-02, -3.3191e-02,  3.1968e-02],\n",
      "          [-4.3698e-02, -4.1204e-02,  2.2203e-02, -3.6378e-02, -4.1366e-02],\n",
      "          [ 3.2657e-02, -1.2996e-02, -1.8007e-02, -2.5327e-02,  3.8129e-02]],\n",
      "\n",
      "         [[ 4.3869e-02, -1.5969e-02, -2.7958e-02, -4.0428e-02,  4.4211e-02],\n",
      "          [-1.4945e-02,  1.7142e-03,  2.9844e-03, -4.1683e-02, -1.0541e-02],\n",
      "          [-3.0339e-03, -3.9557e-02,  1.9041e-02,  1.3259e-02,  2.7224e-02],\n",
      "          [-5.7078e-03,  2.4114e-02,  2.3944e-02, -2.3861e-03, -3.2904e-02],\n",
      "          [ 2.6463e-02,  3.4529e-02,  6.5505e-03,  5.5897e-03, -3.4591e-02]],\n",
      "\n",
      "         [[-8.8023e-03, -1.4111e-02,  3.6047e-02, -2.7741e-02,  1.5809e-03],\n",
      "          [ 3.5177e-02,  1.1588e-02, -1.2560e-03,  4.1529e-02,  1.7147e-02],\n",
      "          [-3.4687e-02,  5.2443e-03,  2.3536e-02, -2.4470e-02, -7.5177e-03],\n",
      "          [ 1.8502e-02, -3.6382e-03,  3.0699e-02,  4.1438e-02, -6.3115e-04],\n",
      "          [-3.1555e-02, -4.1446e-02,  2.6937e-02,  2.7350e-02,  6.8305e-03]]]])\n",
      "Name: conv_layers.2.bias\n",
      "Parameters: tensor([ 0.0208, -0.0087,  0.0362, -0.0220, -0.0256,  0.0095,  0.0186, -0.0136,\n",
      "         0.0177, -0.0041,  0.0170, -0.0027, -0.0196,  0.0234, -0.0405, -0.0135,\n",
      "        -0.0309, -0.0404, -0.0075,  0.0444,  0.0423, -0.0372, -0.0131, -0.0381,\n",
      "         0.0133, -0.0289, -0.0221,  0.0352, -0.0110, -0.0044, -0.0370, -0.0284,\n",
      "         0.0397,  0.0232,  0.0216,  0.0064,  0.0168,  0.0110, -0.0194,  0.0445,\n",
      "         0.0036, -0.0137,  0.0069, -0.0088, -0.0233,  0.0234, -0.0068,  0.0105,\n",
      "        -0.0371, -0.0273, -0.0152, -0.0081,  0.0421,  0.0137, -0.0174, -0.0296,\n",
      "        -0.0234,  0.0100,  0.0340, -0.0171,  0.0026,  0.0309,  0.0317,  0.0267])\n"
     ]
    }
   ],
   "source": [
    "# `named_parameters()` & `data` attribute\n",
    "for name, param in model.named_parameters():\n",
    "    print(\"Name:\", name)\n",
    "    print(\"Parameters:\", param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a77c2157-f8b9-45d9-a3f8-ae182b742690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_layers.0.weight',\n",
       "              tensor([[[[ 1.3241e-01,  1.5604e-01, -1.0033e-01,  1.9216e-01, -6.9605e-02],\n",
       "                        [ 1.7387e-01, -8.7238e-02, -8.7400e-02, -6.6454e-03, -1.3710e-02],\n",
       "                        [ 4.7818e-02, -1.3161e-01, -1.2073e-01, -8.0846e-02, -1.4806e-01],\n",
       "                        [ 1.5466e-01,  1.7643e-01,  6.8757e-02, -1.3546e-01,  8.1396e-02],\n",
       "                        [ 1.4838e-01, -1.3129e-01, -3.4942e-02,  1.3256e-01,  1.8711e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7838e-01,  9.0442e-02,  9.4969e-02,  1.9040e-01, -5.6426e-02],\n",
       "                        [ 1.4222e-01,  1.0127e-01, -9.1116e-03, -2.4985e-02, -1.6505e-01],\n",
       "                        [ 1.7914e-01, -7.6648e-02, -1.7809e-01,  1.2110e-01, -5.1342e-02],\n",
       "                        [ 2.2690e-02,  1.5465e-01, -8.5308e-02, -4.7745e-02,  3.1571e-02],\n",
       "                        [ 2.8867e-02, -3.0587e-02, -3.1570e-02, -1.9829e-01, -4.0238e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3186e-01, -1.4602e-01,  9.5862e-02, -8.8489e-02, -9.6553e-02],\n",
       "                        [-1.3332e-01,  1.1675e-02,  1.6270e-01,  1.4342e-01,  1.4186e-02],\n",
       "                        [ 6.7934e-02,  1.0176e-02,  5.6962e-02,  1.9649e-01,  1.5693e-01],\n",
       "                        [-1.7073e-01, -2.1391e-02,  2.3361e-02,  3.1500e-02, -6.6577e-02],\n",
       "                        [ 7.7104e-02,  1.4623e-01, -7.9448e-03,  3.1214e-02, -7.6848e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7350e-02, -1.1280e-01, -1.1613e-01,  3.4520e-02, -9.1342e-03],\n",
       "                        [-1.3996e-01, -1.8361e-01,  1.1601e-01, -5.5225e-02, -5.4041e-02],\n",
       "                        [ 1.9208e-01, -9.1202e-02,  1.3636e-01,  7.3855e-02, -6.5894e-02],\n",
       "                        [ 1.3723e-02,  1.5521e-01,  7.8226e-02, -1.1209e-01, -1.5964e-01],\n",
       "                        [-6.5851e-02, -1.5129e-01, -5.2712e-02,  8.9967e-02, -1.8500e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2484e-01, -1.8534e-01,  3.6886e-02,  8.3262e-02,  6.8633e-02],\n",
       "                        [ 1.4270e-02,  1.6860e-01,  4.8610e-02, -1.8697e-01, -1.5962e-01],\n",
       "                        [-6.1016e-02, -1.6345e-02, -1.1608e-01, -1.8487e-01, -1.6567e-01],\n",
       "                        [-4.0601e-02,  8.8121e-02, -1.8425e-02, -3.8099e-02, -1.9318e-01],\n",
       "                        [-9.6685e-02,  4.7574e-02,  7.1982e-02,  1.3283e-01, -1.3550e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2990e-01, -1.8027e-02, -1.9720e-01, -1.0266e-01,  1.9599e-01],\n",
       "                        [ 2.3637e-03,  8.8786e-02, -3.4413e-02, -1.1878e-01,  1.4574e-01],\n",
       "                        [-1.1365e-01, -1.6888e-01,  5.0974e-05, -9.2363e-02, -4.1784e-02],\n",
       "                        [ 1.6196e-01,  1.4280e-01, -8.2476e-02,  1.4793e-01,  9.5471e-02],\n",
       "                        [ 9.4619e-02, -5.1215e-02,  7.4179e-02, -9.6469e-02, -8.7771e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1201e-01,  1.9360e-01, -1.8400e-01, -3.8823e-02,  1.8009e-01],\n",
       "                        [ 1.5503e-01, -1.8852e-01,  2.5678e-02,  1.9906e-01, -1.4539e-01],\n",
       "                        [-1.4287e-01, -1.7903e-01,  2.2451e-02,  1.4313e-01,  1.8826e-01],\n",
       "                        [ 1.1788e-01,  1.4232e-01, -2.2371e-02, -4.0267e-02,  1.7885e-01],\n",
       "                        [-9.0347e-02, -2.7690e-03, -5.3224e-02, -5.5934e-02, -1.3836e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.8000e-02, -6.3736e-02, -1.5082e-01,  3.6312e-02, -1.9862e-01],\n",
       "                        [ 4.8823e-02, -8.4725e-02,  6.8034e-02,  1.8329e-01,  4.5708e-02],\n",
       "                        [ 1.9683e-01, -5.6322e-02,  6.3535e-02,  3.6922e-02,  1.7151e-01],\n",
       "                        [ 1.4225e-01, -1.6482e-01,  6.7343e-02,  1.3643e-01,  1.4066e-01],\n",
       "                        [ 2.8197e-02, -1.7635e-01, -1.5050e-01,  3.3212e-03,  6.0210e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8715e-02, -1.2924e-01,  1.1012e-01,  8.7607e-03, -1.6257e-01],\n",
       "                        [ 7.7766e-02, -1.5367e-01,  1.5281e-01, -5.8361e-02,  1.0171e-01],\n",
       "                        [ 1.7840e-01, -1.7470e-01, -1.5965e-01,  5.9101e-02,  1.6743e-01],\n",
       "                        [-1.0642e-01, -7.9235e-03, -1.2118e-01, -1.6437e-01, -1.5323e-01],\n",
       "                        [ 1.4803e-01,  1.1819e-01, -2.5592e-02,  6.2606e-02,  4.4999e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6631e-01, -1.3663e-01, -1.0860e-01,  1.8708e-01, -1.7883e-01],\n",
       "                        [ 1.1482e-02, -1.2443e-01, -1.0491e-01, -9.3156e-02,  6.7180e-02],\n",
       "                        [ 8.2907e-02,  1.0562e-01, -3.0791e-02, -8.7147e-02, -2.5293e-02],\n",
       "                        [ 6.1346e-03,  1.6903e-01,  3.4932e-02, -1.4125e-01,  1.1192e-02],\n",
       "                        [ 1.1734e-01,  1.3849e-01,  1.8247e-01, -6.6997e-02,  1.4443e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5675e-02,  1.7151e-02,  1.8107e-01, -6.6976e-02, -1.6386e-01],\n",
       "                        [ 1.8581e-01,  1.1274e-01,  7.9142e-02,  1.4690e-01, -1.3505e-01],\n",
       "                        [ 1.1049e-01,  1.0505e-01, -1.2216e-02, -1.7340e-01,  1.1556e-01],\n",
       "                        [-5.8734e-02, -7.1824e-02, -3.7298e-02,  1.0030e-01, -6.1381e-02],\n",
       "                        [ 1.6798e-01,  2.4707e-02, -8.9779e-02, -3.4683e-02,  6.7887e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0472e-02, -1.6816e-01,  1.6501e-01, -1.4424e-01,  1.4948e-01],\n",
       "                        [ 1.3995e-01, -6.1184e-02, -1.7629e-02, -7.1295e-02, -1.3393e-01],\n",
       "                        [ 2.0582e-02,  1.8349e-01, -1.7890e-01,  1.5396e-01, -5.8100e-02],\n",
       "                        [ 1.8454e-01, -1.3551e-02,  2.1506e-02, -1.6931e-01, -1.8765e-01],\n",
       "                        [ 1.0588e-01, -9.1665e-02, -1.6879e-01, -1.2527e-01, -1.0091e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9449e-02,  1.2685e-01,  7.2299e-02,  4.6595e-02,  1.9679e-01],\n",
       "                        [ 2.2285e-02,  2.2567e-02,  1.0742e-01, -6.6561e-02,  1.8148e-01],\n",
       "                        [ 5.5963e-02,  1.6754e-01,  7.0529e-02,  4.2915e-02, -6.9040e-02],\n",
       "                        [ 4.6791e-02,  1.9311e-01, -5.7044e-02, -7.8055e-02, -1.4386e-01],\n",
       "                        [-1.7197e-01, -1.6560e-01,  8.5198e-02, -1.8517e-01, -2.0688e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3139e-01,  1.4070e-01,  2.7097e-02, -1.5805e-01,  1.2808e-01],\n",
       "                        [-1.7832e-01,  6.4503e-02,  2.9197e-02,  1.6657e-01, -4.3565e-02],\n",
       "                        [ 5.4102e-02, -3.9023e-02,  3.9094e-02,  1.2332e-01,  1.4203e-01],\n",
       "                        [ 5.1546e-02, -5.7866e-02,  1.5820e-01,  1.4223e-03,  4.3801e-02],\n",
       "                        [ 6.5623e-02, -1.4990e-01,  1.2141e-01, -1.3783e-02,  8.0581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1322e-01, -1.9726e-01,  7.9353e-03, -4.4787e-02,  1.6848e-01],\n",
       "                        [ 7.8345e-02, -4.2794e-02,  1.8022e-01,  1.5772e-01,  7.7809e-02],\n",
       "                        [ 1.0495e-01, -1.7089e-01,  1.3323e-01,  2.5954e-02,  9.5799e-04],\n",
       "                        [ 1.4828e-01,  1.6508e-01, -7.2082e-03,  1.0186e-01, -1.7378e-01],\n",
       "                        [-1.1721e-01,  3.0324e-04, -2.0825e-02,  9.1728e-02,  7.0678e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.9776e-02, -1.3168e-01,  2.4154e-02, -4.5304e-02,  6.8677e-02],\n",
       "                        [-1.8232e-01,  9.1022e-02, -7.2123e-02, -9.7199e-03, -3.1094e-02],\n",
       "                        [ 2.8557e-02,  3.9763e-02, -3.2785e-02,  1.2154e-01, -1.2906e-01],\n",
       "                        [ 1.1970e-01, -2.9830e-02, -1.2073e-01,  1.4320e-01, -1.1444e-01],\n",
       "                        [ 1.5797e-01, -1.8464e-02, -5.0214e-02, -4.5412e-02, -1.5845e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2919e-01, -2.3971e-02,  1.6241e-01, -1.2552e-01,  1.0633e-01],\n",
       "                        [-1.7193e-01, -8.4782e-02,  1.5894e-01,  3.8409e-02, -1.8693e-01],\n",
       "                        [-1.0562e-01,  6.0506e-02,  6.0093e-02,  2.5464e-02, -1.2752e-01],\n",
       "                        [-1.6392e-02, -5.1873e-02,  1.9090e-01,  1.1538e-01, -1.1494e-02],\n",
       "                        [ 4.7702e-02,  9.9459e-04, -1.1322e-01,  1.0613e-01, -9.6574e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4468e-02, -1.9568e-01, -8.3747e-02,  2.1697e-02, -1.6775e-01],\n",
       "                        [-9.4823e-03,  6.9211e-02, -1.5341e-01,  9.8999e-02,  1.9264e-01],\n",
       "                        [-5.4513e-02, -4.0235e-02, -1.1080e-01,  3.4654e-02, -1.1992e-01],\n",
       "                        [ 1.6636e-01,  8.5964e-02,  5.3202e-02,  1.4344e-01,  9.3552e-02],\n",
       "                        [ 1.8168e-01,  9.4864e-02, -6.3565e-02,  1.6350e-01, -7.3253e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7767e-01,  9.4857e-02,  1.3126e-01,  1.3162e-01, -1.8681e-01],\n",
       "                        [-1.5823e-01, -1.1111e-02,  1.1166e-01,  4.4050e-02,  1.4993e-01],\n",
       "                        [ 9.4183e-02, -7.8399e-02,  6.6749e-02, -1.6290e-02,  1.2230e-01],\n",
       "                        [ 1.7485e-01, -4.1142e-02,  1.3335e-01, -1.4768e-01, -7.8840e-02],\n",
       "                        [-1.3098e-01,  1.0426e-01, -6.6484e-02,  6.0214e-02,  1.2992e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9978e-01,  6.4416e-02,  6.5184e-02,  1.5113e-01, -1.5479e-01],\n",
       "                        [-1.7515e-01, -4.4054e-02,  1.1378e-01,  1.7940e-01, -1.7875e-01],\n",
       "                        [ 8.9578e-02,  1.9231e-01,  1.4054e-01,  1.6426e-01,  2.6875e-02],\n",
       "                        [-5.9233e-02,  1.1354e-01,  1.5061e-01,  5.0135e-02, -3.3059e-02],\n",
       "                        [ 1.8981e-01, -9.1344e-02,  9.9926e-02,  1.9885e-01, -6.9535e-02]]]])),\n",
       "             ('conv_layers.0.bias',\n",
       "              tensor([-0.0573,  0.0840, -0.1971, -0.0123,  0.0091,  0.1132,  0.1386, -0.1841,\n",
       "                      -0.0115, -0.0262,  0.0195,  0.1285, -0.0273, -0.1999, -0.1102, -0.1538,\n",
       "                       0.1940,  0.1120,  0.1132,  0.0043])),\n",
       "             ('conv_layers.2.weight',\n",
       "              tensor([[[[-1.3871e-02,  1.8138e-03,  2.7409e-02,  1.9202e-03,  3.5283e-02],\n",
       "                        [ 2.6181e-02, -1.2598e-03, -7.3440e-03,  4.4750e-03,  4.2259e-02],\n",
       "                        [ 1.3897e-02, -3.8882e-02,  2.5302e-02,  9.9060e-03, -1.5260e-02],\n",
       "                        [ 3.9157e-02, -4.0127e-02, -4.2976e-02,  3.9782e-02, -1.5026e-02],\n",
       "                        [-1.7793e-02, -1.1287e-02, -4.0245e-02, -2.5290e-02, -1.5126e-03]],\n",
       "              \n",
       "                       [[-1.8095e-02, -2.9858e-02,  1.8384e-02,  4.2637e-03, -1.4755e-02],\n",
       "                        [-2.0695e-02,  1.8060e-02, -1.5756e-02,  2.3952e-02, -4.2352e-02],\n",
       "                        [ 2.3106e-02,  6.3974e-03,  6.0189e-04,  1.3654e-02, -1.3639e-02],\n",
       "                        [-3.7988e-03, -3.6270e-02,  2.3508e-02, -6.1616e-03, -2.5438e-02],\n",
       "                        [-1.7730e-02,  2.2161e-02,  1.6720e-02, -3.2676e-02,  9.0513e-03]],\n",
       "              \n",
       "                       [[ 1.4793e-02,  1.6415e-02, -2.8927e-02,  8.1149e-03,  3.6316e-02],\n",
       "                        [ 1.8483e-02, -1.4564e-02,  4.2133e-02,  2.2380e-02, -1.8128e-02],\n",
       "                        [-1.4943e-02, -3.3563e-02, -1.0543e-02,  2.4182e-02,  3.5721e-02],\n",
       "                        [ 1.2420e-02, -9.2878e-03, -4.2604e-02,  3.0411e-02,  8.3704e-03],\n",
       "                        [-3.6704e-02, -1.4528e-02, -8.2998e-03, -1.6295e-02, -1.3609e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.0465e-03,  1.7051e-02,  7.7259e-03, -3.8155e-03,  3.9476e-03],\n",
       "                        [ 3.1129e-02, -4.3741e-02, -2.0728e-02, -8.6993e-03,  2.7008e-02],\n",
       "                        [-9.1237e-03, -3.5947e-02, -2.1752e-03, -1.9814e-02,  2.8245e-02],\n",
       "                        [ 3.9406e-03,  3.3105e-03, -1.5305e-03,  2.5063e-02, -4.6007e-03],\n",
       "                        [ 3.7993e-02, -1.6980e-02, -2.2232e-02, -1.1428e-02,  2.9301e-02]],\n",
       "              \n",
       "                       [[-6.4159e-03,  2.1685e-02,  8.6689e-03,  8.6723e-03,  1.8453e-02],\n",
       "                        [-3.0057e-02,  4.0051e-02,  4.1262e-02,  2.9822e-02,  2.1606e-02],\n",
       "                        [-2.1487e-02, -3.8540e-02, -9.6918e-03,  3.5614e-02,  2.3266e-02],\n",
       "                        [ 4.3648e-02, -1.2313e-02,  4.0020e-02, -9.2189e-03, -2.5507e-02],\n",
       "                        [ 2.3909e-02,  2.4166e-02,  2.8090e-02,  4.0647e-02, -2.8616e-02]],\n",
       "              \n",
       "                       [[ 2.0415e-03,  2.2509e-03,  2.5001e-02,  3.0924e-02, -3.3789e-03],\n",
       "                        [ 8.6982e-03,  3.3180e-02, -1.8352e-02, -4.1864e-02, -3.5893e-02],\n",
       "                        [ 3.2103e-02,  1.0422e-02, -2.7926e-02, -3.0336e-02, -2.0639e-02],\n",
       "                        [-3.0402e-02, -1.1929e-02,  2.1070e-02,  8.6693e-03, -3.4097e-02],\n",
       "                        [-3.5102e-02,  1.8101e-02, -2.5006e-02, -2.2366e-02,  3.0084e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9222e-02, -2.4327e-02,  1.3645e-02,  2.3390e-02,  3.0595e-02],\n",
       "                        [ 2.6715e-02, -3.6614e-03, -2.1772e-02,  2.7429e-03,  1.1749e-02],\n",
       "                        [ 2.4263e-02,  1.7774e-02,  3.4740e-02, -1.4598e-02, -3.5157e-02],\n",
       "                        [ 2.4948e-03,  1.8638e-02, -2.5367e-02, -1.5732e-02,  3.7917e-03],\n",
       "                        [-3.5909e-03,  3.6041e-02, -3.8344e-02, -4.1491e-02,  1.9854e-02]],\n",
       "              \n",
       "                       [[-2.6491e-02,  4.0159e-02, -4.1427e-02, -7.6170e-03, -7.3140e-03],\n",
       "                        [-3.9630e-02, -1.1807e-02,  2.3813e-02,  1.7934e-03, -2.2907e-02],\n",
       "                        [-3.9195e-02, -3.7322e-03,  4.9031e-03,  4.1874e-02,  2.5364e-02],\n",
       "                        [ 3.0963e-02,  1.8185e-02,  3.2395e-02, -3.2413e-02, -1.2818e-02],\n",
       "                        [ 4.6185e-03, -1.5100e-02, -8.0613e-03,  6.8208e-03, -2.4075e-02]],\n",
       "              \n",
       "                       [[-2.1455e-02, -2.7057e-03, -7.7437e-03,  2.6733e-04, -2.0691e-02],\n",
       "                        [ 1.2371e-02,  1.2946e-02, -5.9853e-03, -5.1840e-03,  4.3210e-02],\n",
       "                        [ 4.7497e-03,  2.1726e-02,  3.7029e-03,  4.0085e-02, -2.3352e-02],\n",
       "                        [ 2.9196e-02, -1.6861e-02, -3.5422e-02, -4.9593e-03,  2.1213e-02],\n",
       "                        [-8.5790e-03, -1.9741e-02, -2.4979e-02,  8.3580e-03, -3.0003e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2219e-02, -3.6488e-02,  8.1911e-03,  4.0574e-02,  2.7663e-02],\n",
       "                        [ 3.8541e-02,  1.7447e-02,  3.3555e-02,  3.9525e-02,  1.2404e-02],\n",
       "                        [-2.7404e-02,  1.0433e-03, -4.2537e-02,  3.6915e-03, -4.2093e-02],\n",
       "                        [-1.0742e-02, -3.7113e-02,  8.2909e-03, -3.8922e-02, -3.9269e-02],\n",
       "                        [-3.8352e-02,  1.9914e-02, -2.2876e-02, -4.3953e-02,  3.2267e-02]],\n",
       "              \n",
       "                       [[ 2.7342e-02, -2.2636e-02,  3.7276e-02, -2.6170e-02,  3.8131e-02],\n",
       "                        [-4.1702e-02,  3.6494e-02,  3.4553e-02,  8.2889e-03, -1.3203e-02],\n",
       "                        [ 2.1594e-02, -1.0232e-03, -1.3677e-02,  3.9646e-02,  6.8112e-03],\n",
       "                        [ 3.0746e-02,  2.3654e-02, -2.5046e-02, -4.6949e-03, -1.2915e-02],\n",
       "                        [ 2.7509e-02, -7.8877e-03,  7.3765e-03, -4.2027e-03,  8.1646e-03]],\n",
       "              \n",
       "                       [[ 3.4163e-02, -2.6366e-02,  4.4121e-02,  3.1600e-02, -1.1947e-02],\n",
       "                        [-3.8639e-02,  3.0027e-02, -1.1069e-03,  3.3161e-02, -3.9655e-02],\n",
       "                        [ 1.7341e-02,  3.0755e-02, -1.2879e-02,  5.1505e-05, -2.0856e-02],\n",
       "                        [-1.0053e-02, -8.5097e-03, -2.5528e-02,  4.2424e-02, -1.7655e-02],\n",
       "                        [-1.9958e-03,  4.2383e-02, -2.0389e-02, -2.1955e-02, -2.9821e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9111e-02, -9.8587e-03,  2.2674e-02,  4.1752e-02, -3.0308e-02],\n",
       "                        [ 1.4281e-03,  1.4835e-02, -1.1873e-02, -4.3554e-02, -1.6282e-02],\n",
       "                        [ 1.7979e-02,  3.7161e-03,  1.1927e-02, -3.1373e-02, -3.8399e-03],\n",
       "                        [-1.7560e-02, -2.3035e-02, -1.8226e-03,  3.1850e-02,  2.0427e-02],\n",
       "                        [ 3.7227e-02, -4.2418e-03, -4.5080e-03,  2.4929e-02,  7.2678e-04]],\n",
       "              \n",
       "                       [[ 1.8624e-02,  2.1771e-03,  2.9543e-03,  1.5655e-03, -1.9216e-02],\n",
       "                        [-3.0592e-02,  4.6970e-03, -5.1550e-03, -3.1509e-02, -2.5539e-02],\n",
       "                        [ 5.2691e-03,  1.1452e-02,  3.5991e-03, -5.6211e-03,  1.7269e-02],\n",
       "                        [ 1.1463e-02, -1.9230e-02,  1.3327e-02, -2.2483e-02, -2.9959e-02],\n",
       "                        [ 1.6108e-03, -4.0144e-02,  2.3154e-02,  2.1032e-02,  3.6967e-02]],\n",
       "              \n",
       "                       [[-1.7662e-02,  1.2009e-02,  6.9824e-03,  5.0339e-03, -2.3007e-02],\n",
       "                        [-2.9563e-02, -2.0134e-02,  2.3330e-02, -1.2088e-02,  1.4290e-02],\n",
       "                        [ 3.1472e-02,  1.1480e-02,  1.6631e-03,  7.0405e-03, -1.3417e-02],\n",
       "                        [ 3.3113e-02,  8.7944e-03,  2.0377e-02,  3.7911e-02,  3.1440e-02],\n",
       "                        [-1.7023e-03, -5.8193e-03, -1.3485e-02, -2.9056e-02, -1.9129e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8464e-02,  4.3393e-03,  1.4314e-02,  1.9514e-02,  2.2890e-02],\n",
       "                        [ 1.6913e-02,  3.6645e-03, -1.6260e-02, -3.3765e-02, -1.4770e-02],\n",
       "                        [ 3.5910e-02, -7.2799e-03,  3.3204e-02, -2.5386e-02,  3.6073e-02],\n",
       "                        [-3.1312e-02, -6.2849e-03,  4.0375e-02, -2.1666e-02, -1.0114e-02],\n",
       "                        [-9.8907e-03,  3.4569e-02,  4.0549e-02, -1.1892e-02, -2.4159e-02]],\n",
       "              \n",
       "                       [[ 6.6576e-03, -3.2157e-02,  3.6202e-02,  2.8732e-02, -2.2077e-03],\n",
       "                        [ 3.8741e-03,  4.4562e-03, -1.1733e-02, -1.8566e-02, -2.0058e-02],\n",
       "                        [-2.6554e-02, -4.1024e-02, -1.7292e-02, -1.0175e-02,  9.5437e-03],\n",
       "                        [-1.4051e-02,  4.0718e-02,  3.4673e-02,  2.5243e-02, -1.0394e-02],\n",
       "                        [ 4.9209e-03,  3.1385e-02, -2.1820e-02, -1.2295e-02, -3.2178e-02]],\n",
       "              \n",
       "                       [[ 4.0259e-02, -1.1299e-02, -1.4106e-02,  3.2192e-02, -1.2603e-02],\n",
       "                        [ 1.1950e-02,  4.2668e-02,  2.2611e-02, -4.0604e-02, -3.7600e-02],\n",
       "                        [-1.7960e-02,  2.4670e-02, -3.2335e-02, -4.2435e-02,  8.7845e-03],\n",
       "                        [-1.5702e-02,  1.0560e-02,  4.0255e-02,  1.9973e-02, -2.9173e-02],\n",
       "                        [-2.9245e-02,  4.3673e-02, -2.9623e-02, -2.6126e-02,  3.6229e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.3782e-02, -3.2018e-02, -4.1422e-02,  4.2965e-02,  4.1290e-02],\n",
       "                        [ 2.6014e-02,  3.5790e-02, -3.1674e-02,  2.1011e-02, -3.2987e-02],\n",
       "                        [-3.8864e-02, -3.4980e-02, -3.9175e-02,  2.2159e-02,  2.7862e-02],\n",
       "                        [-1.5315e-02, -3.0641e-02,  2.4972e-02, -2.6885e-02, -1.8860e-02],\n",
       "                        [-3.7953e-02, -2.5055e-03,  1.6515e-02, -3.8565e-03, -3.4413e-02]],\n",
       "              \n",
       "                       [[ 5.2746e-03, -5.7524e-03,  8.7690e-04,  2.1129e-02, -3.3714e-02],\n",
       "                        [-2.5097e-02, -9.1407e-03, -1.2493e-02, -2.8287e-02,  8.1022e-03],\n",
       "                        [-3.4974e-02, -8.4004e-03,  6.5616e-03, -3.1915e-02, -1.8039e-03],\n",
       "                        [ 4.3422e-02,  2.5244e-02, -3.7508e-02, -1.5715e-04,  2.8635e-03],\n",
       "                        [ 4.0159e-02, -1.0451e-02,  3.3808e-02,  2.2487e-03,  2.3882e-02]],\n",
       "              \n",
       "                       [[ 8.0380e-03,  3.9348e-02,  3.6196e-02, -1.2740e-02,  8.8485e-03],\n",
       "                        [-2.9744e-02,  3.9094e-02,  2.5479e-02,  3.2697e-02,  3.4737e-02],\n",
       "                        [-3.5794e-02, -4.2454e-02, -2.3609e-02,  1.8149e-02,  4.2802e-02],\n",
       "                        [ 1.9548e-03,  3.2146e-02,  1.7434e-02, -2.2222e-02, -4.3828e-02],\n",
       "                        [ 4.4119e-04,  2.0332e-02, -1.5830e-02,  3.0345e-02,  2.7871e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.4941e-03,  2.4571e-02, -4.0033e-03, -2.4643e-02,  2.4928e-02],\n",
       "                        [-2.4729e-02, -3.4175e-02,  1.5217e-02, -6.8067e-03, -1.5605e-02],\n",
       "                        [-1.5520e-02,  1.3591e-02, -1.6952e-02,  2.3149e-02, -3.5015e-02],\n",
       "                        [-3.8227e-02,  2.4797e-03, -1.7207e-02,  1.7616e-02,  3.8088e-02],\n",
       "                        [ 3.7997e-02, -3.6835e-02, -2.2072e-02,  3.5769e-02,  1.6814e-02]],\n",
       "              \n",
       "                       [[-2.5929e-02, -1.4625e-02, -2.8879e-02, -3.1932e-03,  2.6450e-02],\n",
       "                        [ 2.6795e-03,  3.4002e-02, -7.2258e-03,  2.3569e-02, -1.0126e-02],\n",
       "                        [-1.3826e-02, -1.5366e-02, -2.0826e-02, -4.2160e-02,  2.9605e-02],\n",
       "                        [-2.9491e-02, -5.9204e-04,  3.0640e-02, -3.2850e-02,  4.6293e-03],\n",
       "                        [ 8.2218e-03,  3.3545e-02,  2.2686e-02,  3.7325e-02,  4.3212e-02]],\n",
       "              \n",
       "                       [[ 2.2121e-02, -1.0479e-02,  3.5456e-02,  1.9301e-02, -1.2956e-03],\n",
       "                        [ 1.5912e-03,  2.9417e-03,  2.9833e-02,  4.1424e-02, -2.1308e-02],\n",
       "                        [ 3.1825e-02,  2.2558e-02, -8.4701e-03,  3.9350e-02,  2.2740e-02],\n",
       "                        [ 1.8655e-02,  9.8191e-03,  1.6428e-02, -4.1089e-02, -2.5863e-02],\n",
       "                        [ 1.6437e-02,  4.3713e-02, -7.8577e-03,  4.3015e-02, -2.6737e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7608e-03, -4.1001e-02, -2.9989e-02,  5.7242e-03,  1.6483e-02],\n",
       "                        [-2.1141e-02, -3.8201e-02,  2.6190e-03,  2.5314e-02,  6.5599e-03],\n",
       "                        [ 7.4922e-03,  3.1143e-03,  3.9642e-02,  2.0673e-03, -1.5567e-02],\n",
       "                        [-2.0046e-04,  2.7596e-02,  9.6397e-03,  1.6137e-02,  8.5051e-03],\n",
       "                        [-2.9986e-02,  1.8297e-02, -3.6378e-03,  2.2362e-03, -1.7651e-02]],\n",
       "              \n",
       "                       [[-1.2912e-02, -2.2029e-02, -2.4961e-02, -1.9687e-02, -2.0274e-02],\n",
       "                        [-1.8502e-02, -1.8732e-02, -1.6331e-02,  1.4594e-02,  2.7315e-02],\n",
       "                        [ 2.7607e-02,  3.3074e-02, -2.5466e-02, -1.5396e-02,  4.2149e-03],\n",
       "                        [ 4.2130e-02, -1.2793e-02,  1.5324e-02, -4.1559e-02, -2.1596e-02],\n",
       "                        [-3.1985e-02,  4.2327e-02,  3.0103e-02, -1.8856e-02, -4.3335e-02]],\n",
       "              \n",
       "                       [[-8.8148e-03, -1.9361e-02, -2.7197e-02, -1.4601e-02,  2.9393e-02],\n",
       "                        [-4.1036e-02, -4.0184e-02,  3.2189e-02, -2.5799e-02, -2.6795e-02],\n",
       "                        [ 7.8577e-04, -1.6912e-02,  2.6480e-02,  6.3703e-03,  1.0465e-02],\n",
       "                        [ 3.6253e-03, -2.3415e-02, -2.0984e-02, -1.4698e-02,  2.4545e-02],\n",
       "                        [-2.6590e-02,  1.5386e-02, -4.5269e-03,  8.9440e-03,  2.8833e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.9688e-02,  3.1305e-02,  1.0911e-02, -3.1096e-03, -6.1476e-03],\n",
       "                        [ 4.4522e-02, -4.1974e-02,  1.4086e-03,  1.3176e-02, -3.5228e-02],\n",
       "                        [ 4.3846e-02, -1.2587e-03, -3.4890e-02, -6.4030e-03,  3.9697e-03],\n",
       "                        [-4.0698e-02,  1.3210e-02,  1.1198e-02, -1.1474e-02,  3.7271e-02],\n",
       "                        [-1.7921e-02,  1.9403e-02, -1.1318e-02, -3.4611e-02,  4.0208e-02]],\n",
       "              \n",
       "                       [[-4.5511e-04, -3.8761e-02,  3.1732e-02,  2.4404e-03,  4.3232e-02],\n",
       "                        [ 1.8153e-02, -2.1967e-02, -3.2062e-02, -2.4471e-02,  4.0476e-02],\n",
       "                        [-2.7757e-02,  3.4205e-02,  3.3019e-02,  1.4792e-02,  9.9620e-04],\n",
       "                        [ 9.9321e-03, -3.5928e-02,  1.7252e-02,  1.6250e-02,  4.9671e-03],\n",
       "                        [ 4.3295e-04, -3.8847e-02, -4.0153e-02,  3.0456e-02,  5.4879e-03]],\n",
       "              \n",
       "                       [[-3.8609e-03,  3.3571e-02, -3.1285e-02, -2.3129e-02,  1.5465e-02],\n",
       "                        [ 3.8651e-02,  3.4275e-02,  3.1002e-02,  2.8591e-04,  1.5209e-02],\n",
       "                        [-8.5173e-03, -4.0278e-02,  8.8405e-03, -4.1458e-02, -2.9139e-02],\n",
       "                        [-1.0918e-02,  1.5830e-02,  1.1770e-02, -2.9171e-02,  3.7284e-02],\n",
       "                        [-3.1970e-03,  1.7156e-02, -4.3869e-02, -2.8430e-03, -4.6179e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5426e-03, -3.3489e-02,  4.3182e-02,  4.4257e-02,  2.2910e-02],\n",
       "                        [ 1.0588e-02, -3.6287e-03, -1.2841e-02,  4.2236e-02,  2.1910e-02],\n",
       "                        [ 2.5113e-02,  1.7791e-02, -2.8582e-02, -8.2183e-03,  4.2715e-02],\n",
       "                        [-4.4355e-02, -8.3076e-03, -3.8030e-02,  1.8744e-02, -2.5378e-02],\n",
       "                        [-3.6300e-02,  3.6503e-02,  4.3366e-02, -2.6602e-02,  4.5671e-04]],\n",
       "              \n",
       "                       [[-8.0117e-03,  1.2479e-02, -1.1636e-02, -2.2237e-02,  6.4645e-03],\n",
       "                        [ 3.3277e-02, -2.6507e-02,  1.4027e-02, -3.5600e-02, -9.1320e-03],\n",
       "                        [-2.6892e-02,  1.8206e-02, -1.3648e-02,  1.4801e-02, -1.0142e-02],\n",
       "                        [ 3.2587e-02,  1.5215e-02,  1.8212e-02,  2.0784e-02, -2.4829e-02],\n",
       "                        [-2.7623e-02, -2.1331e-02,  1.8614e-02,  8.3137e-03, -2.5571e-02]],\n",
       "              \n",
       "                       [[ 3.3985e-02,  2.0536e-02, -3.6736e-02, -3.4242e-02, -3.5011e-02],\n",
       "                        [-1.2837e-02, -1.6274e-02, -3.8104e-02,  1.5304e-02,  3.1169e-02],\n",
       "                        [ 3.7217e-02, -1.7904e-02,  1.4214e-03,  4.3906e-02,  4.3218e-02],\n",
       "                        [ 4.9224e-03,  4.0308e-02,  3.9056e-02, -8.4914e-03, -7.2897e-03],\n",
       "                        [ 3.2487e-02, -6.0824e-03,  3.4568e-02, -1.0007e-02, -2.7042e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.8313e-02,  3.8931e-02,  4.1518e-02, -1.0579e-02, -3.9042e-02],\n",
       "                        [ 2.4156e-02,  2.3572e-02,  3.4003e-02, -3.2104e-03,  4.0552e-02],\n",
       "                        [ 1.9444e-02,  4.9861e-04, -1.0498e-02, -3.3191e-02,  3.1968e-02],\n",
       "                        [-4.3698e-02, -4.1204e-02,  2.2203e-02, -3.6378e-02, -4.1366e-02],\n",
       "                        [ 3.2657e-02, -1.2996e-02, -1.8007e-02, -2.5327e-02,  3.8129e-02]],\n",
       "              \n",
       "                       [[ 4.3869e-02, -1.5969e-02, -2.7958e-02, -4.0428e-02,  4.4211e-02],\n",
       "                        [-1.4945e-02,  1.7142e-03,  2.9844e-03, -4.1683e-02, -1.0541e-02],\n",
       "                        [-3.0339e-03, -3.9557e-02,  1.9041e-02,  1.3259e-02,  2.7224e-02],\n",
       "                        [-5.7078e-03,  2.4114e-02,  2.3944e-02, -2.3861e-03, -3.2904e-02],\n",
       "                        [ 2.6463e-02,  3.4529e-02,  6.5505e-03,  5.5897e-03, -3.4591e-02]],\n",
       "              \n",
       "                       [[-8.8023e-03, -1.4111e-02,  3.6047e-02, -2.7741e-02,  1.5809e-03],\n",
       "                        [ 3.5177e-02,  1.1588e-02, -1.2560e-03,  4.1529e-02,  1.7147e-02],\n",
       "                        [-3.4687e-02,  5.2443e-03,  2.3536e-02, -2.4470e-02, -7.5177e-03],\n",
       "                        [ 1.8502e-02, -3.6382e-03,  3.0699e-02,  4.1438e-02, -6.3115e-04],\n",
       "                        [-3.1555e-02, -4.1446e-02,  2.6937e-02,  2.7350e-02,  6.8305e-03]]]])),\n",
       "             ('conv_layers.2.bias',\n",
       "              tensor([ 0.0208, -0.0087,  0.0362, -0.0220, -0.0256,  0.0095,  0.0186, -0.0136,\n",
       "                       0.0177, -0.0041,  0.0170, -0.0027, -0.0196,  0.0234, -0.0405, -0.0135,\n",
       "                      -0.0309, -0.0404, -0.0075,  0.0444,  0.0423, -0.0372, -0.0131, -0.0381,\n",
       "                       0.0133, -0.0289, -0.0221,  0.0352, -0.0110, -0.0044, -0.0370, -0.0284,\n",
       "                       0.0397,  0.0232,  0.0216,  0.0064,  0.0168,  0.0110, -0.0194,  0.0445,\n",
       "                       0.0036, -0.0137,  0.0069, -0.0088, -0.0233,  0.0234, -0.0068,  0.0105,\n",
       "                      -0.0371, -0.0273, -0.0152, -0.0081,  0.0421,  0.0137, -0.0174, -0.0296,\n",
       "                      -0.0234,  0.0100,  0.0340, -0.0171,  0.0026,  0.0309,  0.0317,  0.0267]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `state_dict()`\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67e60a-08b4-429d-b947-347280bd0973",
   "metadata": {},
   "source": [
    "## 2-3. Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a7b4c-1e47-4d90-b93f-1ccc9e8a4680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3009f9af-8f0c-411b-81d9-ce297e91a347",
   "metadata": {},
   "source": [
    "## 2-4. Summary\n",
    "- [torchinfo](https://github.com/TylerYep/torchinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f167aa44-e272-41ff-acf5-2b3c88895ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CNNModel                                 --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       520\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Conv2d: 2-3                       32,064\n",
       "│    └─ReLU: 2-4                         --\n",
       "=================================================================\n",
       "Total params: 32,584\n",
       "Trainable params: 32,584\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e41b8f83-96fc-49e0-97d9-d13462a16940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNModel                                 [32, 64, 20, 20]          --\n",
       "├─Sequential: 1-1                        [32, 64, 20, 20]          --\n",
       "│    └─Conv2d: 2-1                       [32, 20, 24, 24]          520\n",
       "│    └─ReLU: 2-2                         [32, 20, 24, 24]          --\n",
       "│    └─Conv2d: 2-3                       [32, 64, 20, 20]          32,064\n",
       "│    └─ReLU: 2-4                         [32, 64, 20, 20]          --\n",
       "==========================================================================================\n",
       "Total params: 32,584\n",
       "Trainable params: 32,584\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 420.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 9.50\n",
       "Params size (MB): 0.13\n",
       "Estimated Total Size (MB): 9.73\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(32, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed72acc-c3a7-4214-81da-99802b2d2f0b",
   "metadata": {},
   "source": [
    "# 3. Training\n",
    "## 3-1. Loss Functions\n",
    "1. Each PyTorch Loss function creates a criterion that measures the loss between `output` from a model and `target`, returning a `torch.Tensor`.\n",
    "   - [Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "   - Metrics supporting backpropagation (`is_differentiable == True`) in **TorchMetrics** can be used. More details in [Metrics & Differentiability](https://lightning.ai/docs/torchmetrics/stable/pages/overview.html#metrics-and-differentiability).\n",
    "3. `torch.Tensor.backward(gradient=None, retain_graph=None, create_graph=False, inputs=None)`: Computes the gradient of current tensor with reference to graph leaves. The graph is differentiated using the chain rule. This function accumulates gradients in the leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72365525-def0-4046-886a-4cbc7fc15bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6368,  0.6902, -1.1642,  1.7340,  0.3089],\n",
      "        [-0.5741, -2.2496,  0.1549,  0.2255, -0.5959],\n",
      "        [ 0.6467,  0.2575,  1.8013,  0.4424, -0.4409]], requires_grad=True)\n",
      "tensor([[-0.7584,  0.2138, -0.3933,  0.1054,  0.2149],\n",
      "        [ 0.2793,  0.7960, -0.1902,  2.1231, -0.5180],\n",
      "        [ 1.6648, -0.5898,  2.1185,  0.5762,  1.2281]])\n",
      "tensor(1.4591, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 0.0162,  0.0635, -0.1028,  0.2171,  0.0125],\n",
      "        [-0.1138, -0.4061,  0.0460, -0.2530, -0.0104],\n",
      "        [-0.1358,  0.1130, -0.0423, -0.0178, -0.2225]])\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "# Model output\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.randn(3, 5)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1d009-513f-4c3a-b10e-447c9e85eefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8186341c-4204-451a-8c54-89cbf35d5fec",
   "metadata": {},
   "source": [
    "## 3-2. Optimizer\n",
    "1. `torch.optim` implements various [Optimization Algorithms](https://pytorch.org/docs/stable/optim.html#algorithms).\n",
    "2. `torch.optim.Optimizer.step(closure=None)`: Performs a single optimization step (parameter update).\n",
    "    - For example, [torch.optim.SGD.step(closure=None)](https://github.com/pytorch/pytorch/blob/cd9b27231b51633e76e28b6a34002ab83b0660fc/torch/optim/sgd.py#L63).\n",
    "3. `torch.optim.Optimizer.zero_grad(set_to_none=True)`: Resets the gradients of all optimized `torch.Tensor`s.\n",
    "4. `torch.optim.Optimizer.load_state_dict(state_dict)`: Loads the optimizer state. Uses this function when loading a general checkpoint for inference or resuming training.\n",
    "5. `torch.optim.Optimizer.state_dict`: Contains information about the optimizer's state (parameters to be optimized), as well as the hyperparameters used.\n",
    "6. `torch.optim.Optimizer.add_param_group(param_group)`: Adds a param group to the `Optimizer`'s `param_groups`. Uses this function when fine tuning a pre-trained network as frozen layers can be made trainable and added to the `Optimizer` as training progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ee11b-4aaf-49d5-806d-16b910234ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a077774c-eebd-439b-aa55-77d37ea16794",
   "metadata": {},
   "source": [
    "## 3-3. Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbc941-9048-4ab3-ba4b-d3b300c7645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "# import dataset\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53517c3-4a3d-4d07-82aa-485cf0131b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "iris.plot(marker='o',linestyle='none',figsize=(12,6))\n",
    "plt.xlabel('Sample number')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f12a3-6c65-441f-826e-531b071edd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize the data\n",
    "\n",
    "# convert from pandas dataframe to tensor\n",
    "data = torch.tensor( iris[iris.columns[0:4]].values ).float()\n",
    "\n",
    "# transform species to number\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "# labels[iris.species=='setosa']   = 0 # don't need!\n",
    "labels[iris.species=='versicolor'] = 1\n",
    "labels[iris.species=='virginica']  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90856652-1012-4478-a2a9-d944f098fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(data, labels, test_size=.2)\n",
    "\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "batchsize    = 16\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0]) # how big should these batches be??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955c1c2-43cd-4ba8-8d87-302df28d610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes of data batches\n",
    "for X,y in train_loader:\n",
    "  print(X.shape,y.shape)\n",
    "\n",
    "# go back and set drop_last=True in training DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be21595-d10e-4dc9-a73d-40965b4cf21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates the ANN model\n",
    "\n",
    "def createANewModel():\n",
    "\n",
    "  # model architecture\n",
    "  ANNiris = nn.Sequential(\n",
    "      nn.Linear(4,64),   # input layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,64),  # hidden layer\n",
    "      nn.ReLU(),         # activation unit\n",
    "      nn.Linear(64,3),   # output units\n",
    "        )\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.0005)\n",
    "\n",
    "  return ANNiris,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc8a3d6-af1b-492a-a92b-875fec8bfedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 2500\n",
    "\n",
    "def trainTheModel():\n",
    "\n",
    "  # initialize accuracies as empties\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "  losses   = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = ANNiris(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # compute training accuracy just for this batch\n",
    "      batchAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "      batchLoss.append( loss.item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "    losses.append( np.mean(batchLoss) )\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    predlabels = torch.argmax( ANNiris(X),axis=1 )\n",
    "    testAcc.append( 100*torch.mean((predlabels == y).float()).item() )\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844352f-be17-415b-9919-d1ce43b0274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "ANNiris,lossfun,optimizer = createANewModel()\n",
    "\n",
    "# train the model\n",
    "trainAcc,testAcc,losses = trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab9130-b9a9-4b4e-9622-695725d38d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "\n",
    "ax[0].plot(losses,'k^-')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_title('Losses with minibatch size=' + str(batchsize))\n",
    "\n",
    "ax[1].plot(trainAcc,'ro-')\n",
    "ax[1].plot(testAcc,'bs-')\n",
    "ax[1].set_title('Accuracy with minibatch size=' + str(batchsize))\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].legend(['Train','Test'])\n",
    "ax[1].set_ylim([27,103])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4d614-d8c9-4023-be2f-b4ccbb225f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "# create data\n",
    "\n",
    "nPerClust = 200\n",
    "\n",
    "th = np.linspace(0,4*np.pi,nPerClust)\n",
    "r1 = 10\n",
    "r2 = 15\n",
    "\n",
    "# generate data\n",
    "a = [ r1*np.cos(th) + np.random.randn(nPerClust)*3 ,\n",
    "      r1*np.sin(th) + np.random.randn(nPerClust) ]\n",
    "b = [ r2*np.cos(th) + np.random.randn(nPerClust) ,\n",
    "      r2*np.sin(th) + np.random.randn(nPerClust)*3 ]\n",
    "\n",
    "# true labels\n",
    "labels_np = np.vstack((np.zeros((nPerClust,1)),np.ones((nPerClust,1))))\n",
    "\n",
    "# concatanate into a matrix\n",
    "data_np = np.hstack((a,b)).T\n",
    "\n",
    "# convert to a pytorch tensor\n",
    "data = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).float()\n",
    "\n",
    "# show the data\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'bs')\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'ko')\n",
    "plt.title(\"The qwerties' doughnuts!\")\n",
    "plt.xlabel('qwerty dimension 1')\n",
    "plt.ylabel('qwerty dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5f3ab-1924-4ec0-944e-73d450ccc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(data, labels, test_size=.1)\n",
    "\n",
    "\n",
    "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "train_batchsize = 16\n",
    "test_batchsize  = test_data.tensors[0].shape[0]-2\n",
    "train_loader = DataLoader(train_data,batch_size=train_batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539de07-8938-4224-ad9e-4a8ff75a5583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes of data batches\n",
    "for X,y in test_loader:\n",
    "  print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc3167-6b3a-4522-b894-e2657c3c285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class theModelClass(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    ### layers\n",
    "    self.input  = nn.Linear(  2,128)\n",
    "    self.hidden = nn.Linear(128,128)\n",
    "    self.output = nn.Linear(128, 1)\n",
    "\n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    x = F.relu( self.input(x) )\n",
    "    x = F.relu( self.hidden(x) )\n",
    "    x = self.output(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5a97a-5f5d-4763-9682-d4126ea535a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates the ANN model\n",
    "\n",
    "def createANewModel():\n",
    "\n",
    "  # grab an instance of the model class\n",
    "  ANNQC = theModelClass()\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(ANNQC.parameters(),lr=.01)\n",
    "\n",
    "  return ANNQC,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38951141-ac42-49fc-80c0-d82d2eb4ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "# global parameter\n",
    "numepochs = 500\n",
    "\n",
    "# NOTE: this time, the model, lossfun, and optimizer are inputs into the function!\n",
    "def trainTheModel(ANNQC,lossfun,optimizer):\n",
    "\n",
    "  # initialize accuracies as empties (not storing losses here)\n",
    "  trainAcc = []\n",
    "  testAcc  = []\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = ANNQC(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "      \n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # compute training accuracy just for this batch\n",
    "      batchAcc.append( 100*torch.mean(((yHat>0)==y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # test accuracy (NOTE: testing in batches!)\n",
    "    tstacc = []\n",
    "    for X,y in test_loader:\n",
    "      yHat = ANNQC(X)\n",
    "      tstacc.append( 100*torch.mean(((yHat>0) == y).float()).item() )\n",
    "    # now get the average accuracy over test-batches\n",
    "    testAcc.append(np.mean(tstacc))\n",
    "  \n",
    "  # function output\n",
    "  return trainAcc,testAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0356e-2672-4bef-bc4e-56294da62ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "ANNQC,lossfun,optimizer = createANewModel()\n",
    "\n",
    "# train the model (note the inputs!)\n",
    "trainAcc,testAcc = trainTheModel(ANNQC,lossfun,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346ae98-cd51-4204-a1c9-b450a63e7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(trainAcc,'bs')\n",
    "plt.plot(testAcc,'ro')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Train','Test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7430ef-1497-4966-81eb-88b16bec52a4",
   "metadata": {},
   "source": [
    "## 3-4. Gradient Accumulation\n",
    "\n",
    "**Gradient Accumulation** refers to the situation, where multiple backwards passes are performed before updating the parameters. The goal is to have the same model parameters for multiple inputs (batches) and then update the model's parameters based on all these batches, instead of performing an update after every single batch. This technique is used to overcome GPU memory limitations when training neural networks. \n",
    "\n",
    "Gradient accumulation adds gradients over an effective batch of size, `batch_per_iter * iters_to_accumulate` (`* num_procs` if distributed). Steps including:\n",
    "- Specify the `iters_to_accumulate` parameter, indicating how many batches we would like to update the network weights.\n",
    "- Condition the weight update on the index of the running batch. This requires using `enumerate(DataLoader)` to store the batch index when looping through the data.\n",
    "- Divide the running loss by `iters_to_accumulate`. This normalizes the loss to reduce the contribution of each mini-batch we are actually processing. Depending on the way you compute the loss, you might not need this step. If you average loss within each batch, the division is already correct and there is no need for extra normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba2b20-8111-41b1-950c-3eec57c7fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ...\n",
    "\n",
    "for epoch in range(...):\n",
    "    # loop through batches\n",
    "    for inputs, labels in data_loader:\n",
    "        # extract inputs and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # passes and weights update\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # forward pass\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, labels)\n",
    "    \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "    \n",
    "            # weights update\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6a7bc-304b-4054-9fa4-95d639415f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch accumulation parameter\n",
    "iters_to_accumulate = 4\n",
    "optimizer = ...\n",
    "\n",
    "for epoch in range(...):\n",
    "    # loop through enumaretad batches\n",
    "    for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "        # extract inputs and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # passes and weights update\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # forward pass\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, labels)\n",
    "    \n",
    "            # normalize loss to account for batch accumulation\n",
    "            loss = loss / iters_to_accumulate\n",
    "    \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "    \n",
    "            # weights update\n",
    "            if ((batch_idx + 1) % iters_to_accumulate == 0) or (batch_idx + 1 == len(data_loader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d967f5ac-c9f9-422c-a4b2-642bfdd2bb13",
   "metadata": {},
   "source": [
    "## 3-5. Automatic Mixed Precision\n",
    "\n",
    "NVIDIA researchers created a methodology that combines single precision with the half precision floating point numbers for training deep learning models, that achieves the same level of accuracy as `float32`. Main advantages include less training time, enabling larger batch sizes, larger models & inputs, lower memory requirements. \n",
    "\n",
    "In PyTorch, **Automatic Mixed Precision Training** means training with `torch.autocast` & `torch.amp.GradScaler` together.\n",
    "- Instances of `torch.autocast` enable autocasting for chosen regions. Autocasting automatically chooses the precision for GPU operations to improve performance while maintaining accuracy.\n",
    "- Instances of `torch.amp.GradScaler` help perform the steps of gradient scaling conveniently. Gradient scaling improves convergence for networks with `float16` gradients by minimizing gradient underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792f4fa-7ad2-4ae2-9ae6-c55b5b6a0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for input, target in data:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target)\n",
    "\t\t\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52513cc0-1ad8-4c10-84aa-0979e02ef442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler()\n",
    "batch_size = 4\n",
    "iters_to_accumulate = 16\n",
    "# this means training will be done for affective batch size of 4 * 16 = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (input, target) in enumerate(data):\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss = loss / iters_to_accumulate\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (batch_idx + 1) % iters_to_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dcf049-2281-4799-b40f-3889f32d7cc8",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791b620-38d4-4b95-b463-42dbfe2030f9",
   "metadata": {},
   "source": [
    "# 5. Save & Reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348e51b-28cc-43a9-95ac-86de4a72d700",
   "metadata": {},
   "source": [
    "# 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff3e5a-041b-4426-940f-a49700691f72",
   "metadata": {},
   "source": [
    "## 7. Optimization\n",
    "PyTorch introduces the inference speedups.\n",
    "\n",
    "1. `torch.compile(model=None, *, fullgraph=False, dynamic=None, backend='inductor', mode=None, options=None, disable=False)`: Optimizes given model/function using TorchDynamo & specified backend.\n",
    "   - Running TorchInductor on GPU requires [Triton](https://github.com/triton-lang/triton). Check the installation instructions. Update NVIDIA drivers & PyTorch to the latest versions.\n",
    "   - An arbitrary Python function can be optimized by passing the callable to `torch.compile` or decorating the function with `@torch.compile`.\n",
    "   - Nested function calls & submodules will also be compiled. Or you can disable compilation using `@torch.compiler.disable(recursive=False)`.\n",
    "   - [TorchDynamo APIs for Fine-Grained Tracing](https://pytorch.org/docs/stable/torch.compiler_fine_grain_apis.html#torchdynamo-apis-for-fine-grained-tracing)\n",
    "\n",
    "Best practices:\n",
    "- **Top-Level Compilation:** One approach is to compile at the highest level possible (i.e., when the top-level module is initialized/called) and selectively disable compilation when encountering excessive graph breaks or errors. If there are still many compile issues, compile individual subcomponents instead.\n",
    "- **Modular Testing:** Test individual functions and modules with `torch.compile` before integrating them into larger models to isolate potential issues.\n",
    "- **Disable Compilation Selectively:** If certain functions or sub-modules cannot be handled by `torch.compile`, use the `torch.compiler.disable` context managers to recursively exclude them from compilation.\n",
    "- **Compile Leaf Functions First:** In complex models with multiple nested functions and modules, start by compiling the leaf functions or modules first. For more information see TorchDynamo APIs for fine-grained tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e65132d-685d-4728-a2eb-8e787d0a3b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> quantize_per_tensor\n",
      "refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> quantize_per_tensor\n",
      "refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> dequantize_per_tensor\n",
      "refreshing <module 'torch.ops.quantized_decomposed' from 'torch.ops'> dequantize_per_tensor\n",
      "tensor([[ 8.6933e-01,  7.5847e-04,  3.9209e-01,  8.7964e-01,  9.0168e-02,\n",
      "          1.8997e+00,  6.3927e-02,  1.9821e+00,  1.0241e+00,  2.5646e-01],\n",
      "        [ 5.8212e-02,  1.1917e+00, -3.9244e-01,  4.9394e-01,  1.0135e+00,\n",
      "         -5.8056e-02,  4.3636e-01,  3.7796e-02, -8.9714e-01,  7.5028e-01],\n",
      "        [ 8.4038e-01,  5.7328e-01, -9.5642e-02,  4.7605e-02,  2.5690e-01,\n",
      "         -1.4153e-01,  6.5757e-01,  4.1083e-01,  1.5635e+00,  9.8605e-01],\n",
      "        [ 3.4656e-01,  2.0036e-01,  8.9890e-02,  1.6248e+00,  6.8143e-01,\n",
      "          1.7246e+00,  3.4969e-01, -1.1370e+00,  1.7010e+00, -6.9169e-02],\n",
      "        [-1.8587e-01,  1.9307e+00,  1.6062e+00,  5.6829e-01, -2.2361e-01,\n",
      "          6.7700e-02, -2.3033e-01,  1.6427e+00,  6.9321e-01,  1.9857e+00],\n",
      "        [ 2.4839e-01,  2.2238e-01, -3.3283e-01,  1.4502e+00,  5.6896e-02,\n",
      "          7.6480e-01,  1.5154e+00,  9.8800e-02,  1.1502e+00,  1.9455e+00],\n",
      "        [ 8.0042e-01,  1.2376e+00, -4.9435e-03,  1.6363e+00,  1.1950e+00,\n",
      "          8.6264e-01,  5.7797e-01,  2.1018e-01,  2.4096e-02,  7.4641e-02],\n",
      "        [ 4.0109e-01,  5.3398e-01,  3.5497e-02,  1.1745e-01,  3.7927e-01,\n",
      "         -4.4563e-01,  9.5947e-02,  1.4713e+00, -8.6062e-01,  2.0885e-01],\n",
      "        [ 5.9912e-01,  1.3075e-02, -1.1133e+00, -1.1433e-01,  7.7315e-01,\n",
      "         -3.3709e-01, -2.5222e-01,  8.2125e-01, -4.7753e-02, -2.4673e-01],\n",
      "        [ 1.9559e-01,  5.3607e-01,  9.6211e-01, -1.4481e-03, -4.5880e-01,\n",
      "          9.4744e-03,  1.6845e+00,  1.6216e+00,  1.5713e+00,  3.5508e-01]])\n"
     ]
    }
   ],
   "source": [
    "# `torch.compile()`\n",
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "opt_foo1 = torch.compile(foo)\n",
    "print(opt_foo1(torch.randn(10, 10), torch.randn(10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "666748ec-a026-47c5-b948-3878ce8a35d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.5126e-01,  8.7730e-02, -1.5393e-03,  6.8282e-01,  1.5495e+00,\n",
      "         -1.1766e-01,  4.8922e-01,  5.2666e-01,  2.9069e-01, -3.9022e-02],\n",
      "        [ 1.4289e+00,  6.8740e-02,  6.8203e-01,  1.4575e+00,  1.6099e+00,\n",
      "          1.9043e+00,  9.8577e-01, -1.5439e-01,  1.4233e+00, -2.6519e-01],\n",
      "        [ 4.2308e-01,  1.8493e+00,  3.9818e-01,  4.7927e-01, -9.0105e-02,\n",
      "          6.0482e-01,  1.2752e+00, -2.6861e-01, -3.1696e-01,  7.3602e-01],\n",
      "        [ 8.0196e-01,  3.5524e-01,  1.8555e+00,  9.0838e-01, -3.1011e-01,\n",
      "         -7.7550e-01,  9.3343e-01,  7.4526e-01, -3.8135e-02,  6.0181e-01],\n",
      "        [ 1.6538e+00,  1.3102e+00,  3.3101e-01,  1.7505e+00,  4.6171e-01,\n",
      "          8.5225e-01,  9.6259e-01,  5.2586e-01,  1.6967e+00, -2.6893e-01],\n",
      "        [ 7.6992e-01,  1.0677e+00,  1.1792e-01,  1.1183e-01,  1.2136e+00,\n",
      "          9.9022e-01,  1.0098e+00,  4.9332e-01, -8.8015e-01,  1.0438e+00],\n",
      "        [ 1.6655e+00,  1.8387e+00,  5.5634e-01,  1.4005e-01, -6.5086e-01,\n",
      "          8.6880e-01,  1.5779e+00,  3.1937e-01,  1.5763e+00,  9.4115e-01],\n",
      "        [ 1.5085e-01,  6.5551e-01,  3.2504e-01,  1.7724e-01,  2.7040e-01,\n",
      "          1.1358e+00,  9.6705e-01,  7.2777e-01,  1.6561e+00, -3.8364e-02],\n",
      "        [ 1.5939e+00,  1.5664e+00, -2.7975e-01, -2.1025e-01,  1.3504e+00,\n",
      "         -7.7260e-02,  6.1707e-01,  6.0979e-01,  2.2117e-01, -1.5377e+00],\n",
      "        [ 4.4446e-01,  1.2673e+00,  1.9353e+00,  1.6581e+00,  9.2520e-01,\n",
      "          1.6581e+00,  5.6697e-01, -1.5729e-01,  8.6051e-01, -3.9237e-01]])\n"
     ]
    }
   ],
   "source": [
    "# `@torch.compile`\n",
    "t1 = torch.randn(10, 10)\n",
    "t2 = torch.randn(10, 10)\n",
    "\n",
    "@torch.compile\n",
    "def opt_foo2(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "print(opt_foo2(t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24aceefe-8e56-4693-a38e-da8da1e8a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.5126e-01,  8.7730e-02, -1.5393e-03,  6.8282e-01,  1.5495e+00,\n",
      "         -1.1766e-01,  4.8922e-01,  5.2666e-01,  2.9069e-01, -3.9022e-02],\n",
      "        [ 1.4289e+00,  6.8740e-02,  6.8203e-01,  1.4575e+00,  1.6099e+00,\n",
      "          1.9043e+00,  9.8577e-01, -1.5439e-01,  1.4233e+00, -2.6519e-01],\n",
      "        [ 4.2308e-01,  1.8493e+00,  3.9818e-01,  4.7927e-01, -9.0105e-02,\n",
      "          6.0482e-01,  1.2752e+00, -2.6861e-01, -3.1696e-01,  7.3602e-01],\n",
      "        [ 8.0196e-01,  3.5524e-01,  1.8555e+00,  9.0838e-01, -3.1011e-01,\n",
      "         -7.7550e-01,  9.3343e-01,  7.4526e-01, -3.8135e-02,  6.0181e-01],\n",
      "        [ 1.6538e+00,  1.3102e+00,  3.3101e-01,  1.7505e+00,  4.6171e-01,\n",
      "          8.5225e-01,  9.6259e-01,  5.2586e-01,  1.6967e+00, -2.6893e-01],\n",
      "        [ 7.6992e-01,  1.0677e+00,  1.1792e-01,  1.1183e-01,  1.2136e+00,\n",
      "          9.9022e-01,  1.0098e+00,  4.9332e-01, -8.8015e-01,  1.0438e+00],\n",
      "        [ 1.6655e+00,  1.8387e+00,  5.5634e-01,  1.4005e-01, -6.5086e-01,\n",
      "          8.6880e-01,  1.5779e+00,  3.1937e-01,  1.5763e+00,  9.4115e-01],\n",
      "        [ 1.5085e-01,  6.5551e-01,  3.2504e-01,  1.7724e-01,  2.7040e-01,\n",
      "          1.1358e+00,  9.6705e-01,  7.2777e-01,  1.6561e+00, -3.8364e-02],\n",
      "        [ 1.5939e+00,  1.5664e+00, -2.7975e-01, -2.1025e-01,  1.3504e+00,\n",
      "         -7.7260e-02,  6.1707e-01,  6.0979e-01,  2.2117e-01, -1.5377e+00],\n",
      "        [ 4.4446e-01,  1.2673e+00,  1.9353e+00,  1.6581e+00,  9.2520e-01,\n",
      "          1.6581e+00,  5.6697e-01, -1.5729e-01,  8.6051e-01, -3.9237e-01]])\n"
     ]
    }
   ],
   "source": [
    "# `@torch.compile` with nested functions\n",
    "def nested_function(x):\n",
    "    return torch.sin(x)\n",
    "\n",
    "@torch.compile\n",
    "def outer_function(x, y):\n",
    "    a = nested_function(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "print(outer_function(t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92e43b1a-549a-4483-8de6-4c29ec8318fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5393, 0.2917, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000, 0.4562, 0.3549,\n",
      "         0.5634],\n",
      "        [0.2787, 0.0000, 0.0000, 0.1695, 0.4874, 0.0000, 0.0000, 0.0000, 0.9075,\n",
      "         0.3468],\n",
      "        [0.1160, 0.0000, 0.0000, 0.7212, 0.6043, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.4435],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6279, 0.1041, 0.0000, 0.0000, 0.0000, 0.4334,\n",
      "         0.0000],\n",
      "        [0.0119, 0.0000, 1.0767, 0.7205, 0.3798, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2850, 0.6219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0924, 0.6958,\n",
      "         0.3071],\n",
      "        [0.0000, 0.3307, 0.1828, 0.0000, 0.0000, 0.0000, 0.8457, 0.0000, 0.0000,\n",
      "         0.2721],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1516, 0.0000, 0.2325, 0.3455,\n",
      "         0.0000],\n",
      "        [0.0000, 1.0032, 0.0000, 0.0000, 0.0000, 0.0000, 0.7204, 0.0000, 0.0000,\n",
      "         0.4558],\n",
      "        [0.0000, 0.0000, 0.0000, 1.2350, 0.6283, 0.6489, 0.0000, 0.6369, 0.1068,\n",
      "         0.0835]], grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# `torch.compile()` with `torch.nn.Module` instances\n",
    "t = torch.randn(10, 100)\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.lin(x))\n",
    "\n",
    "mod = MyModule()\n",
    "opt_mod = torch.compile(mod)\n",
    "print(opt_mod(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "528e44b8-b838-4c42-bd29-8a03de4ca1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0747],\n",
      "        [0.0000, 0.1943],\n",
      "        [0.0000, 0.2722],\n",
      "        [0.0000, 0.2669],\n",
      "        [0.0000, 0.4329],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0878],\n",
      "        [0.0000, 0.2325],\n",
      "        [0.0000, 0.2807],\n",
      "        [0.0000, 0.6843]], grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# `torch.compile()` with submodules\n",
    "class OuterModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inner_module = MyModule()\n",
    "        self.outer_lin = torch.nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inner_module(x)\n",
    "        return torch.nn.functional.relu(self.outer_lin(x))\n",
    "\n",
    "outer_mod = OuterModule()\n",
    "opt_outer_mod = torch.compile(outer_mod)\n",
    "print(opt_outer_mod(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178a9aac-2dda-476e-97ed-24444cfc1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Speedups\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "# Generates random input and targets data for the model, where `b` is batch size.\n",
    "def generate_data(b):\n",
    "    return (\n",
    "        torch.randn(b, 3, 128, 128).to(torch.float32).cuda(),\n",
    "        torch.randint(1000, (b,)).cuda(),\n",
    "    )\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "def init_model():\n",
    "    return densenet121().to(torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c7b0d4-6989-4cd4-b591-f521029d2367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager train time 0: 0.02529996871948242\n",
      "eager train time 1: 0.021381824493408204\n",
      "eager train time 2: 0.023163679122924805\n",
      "eager train time 3: 0.022937599182128905\n",
      "eager train time 4: 0.022953983306884765\n",
      "eager train time 5: 0.022991840362548827\n",
      "eager train time 6: 0.023912256240844726\n",
      "eager train time 7: 0.023015552520751954\n",
      "eager train time 8: 0.022227968215942383\n",
      "eager train time 9: 0.019496864318847656\n",
      "~~~~~~~~~~\n",
      "compile train time 0: 51.86091796875\n",
      "compile train time 1: 5.8743623046875\n",
      "compile train time 2: 0.018679807662963867\n",
      "compile train time 3: 0.01844121551513672\n",
      "compile train time 4: 0.017512447357177736\n",
      "compile train time 5: 0.0174704647064209\n",
      "compile train time 6: 0.017583103179931642\n",
      "compile train time 7: 0.017505151748657227\n",
      "compile train time 8: 0.017543167114257813\n",
      "compile train time 9: 0.0174653434753418\n",
      "~~~~~~~~~~\n",
      "(train) eager median: 0.022972911834716794, compile median: 0.017563135147094726, speedup: 1.308018849841678x\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# [1] Eager\n",
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def train(mod, data):\n",
    "    opt.zero_grad(True)\n",
    "    pred = mod(data[0])\n",
    "    loss = torch.nn.CrossEntropyLoss()(pred, data[1])\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "eager_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)\n",
    "    _, eager_time = timed(lambda: train(model, inp))\n",
    "    eager_times.append(eager_time)\n",
    "    print(f\"eager train time {i}: {eager_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "# [2] `torch.compile()`\n",
    "model = init_model()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_opt = torch.compile(train, mode=\"reduce-overhead\")\n",
    "\n",
    "compile_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)\n",
    "    _, compile_time = timed(lambda: train_opt(model, inp))\n",
    "    compile_times.append(compile_time)\n",
    "    print(f\"compile train time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "eager_med = np.median(eager_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = eager_med / compile_med\n",
    "assert(speedup > 1)\n",
    "print(f\"(train) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\")\n",
    "print(\"~\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310841d-839d-44e2-b616-7a5f5e743ecf",
   "metadata": {},
   "source": [
    "## 8. PyTorch Lightning Trainer\n",
    "1. `pytorch_lightning.Trainer(*, accelerator='auto', strategy='auto', devices='auto', num_nodes=1, precision=None, logger=None, callbacks=None, fast_dev_run=False, max_epochs=None, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, overfit_batches=0.0, val_check_interval=None, check_val_every_n_epoch=1, num_sanity_val_steps=None, log_every_n_steps=None, enable_checkpointing=None, enable_progress_bar=None, enable_model_summary=None, accumulate_grad_batches=1, gradient_clip_val=None, gradient_clip_algorithm=None, deterministic=None, benchmark=None, inference_mode=True, use_distributed_sampler=True, profiler=None, detect_anomaly=False, barebones=False, plugins=None, sync_batchnorm=False, reload_dataloaders_every_n_epochs=0, default_root_dir=None)`\n",
    "   - [Trainer Class API](https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api)\n",
    "3. `Trainer.fit()`\n",
    "4. `Trainer.validate()`\n",
    "5. `Trainer.test()`\n",
    "6. `Trainer.predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1652f-41a6-4382-88a4-a0e54eb2e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLightningModule()\n",
    "\n",
    "trainer = Trainer()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ac98c-289e-41db-9633-119d5b9b1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model=model, dataloaders=val_dataloaders)\n",
    "trainer.test(dataloaders=test_dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc95c5-9d7e-40bd-9527-aeff46b9e5a6",
   "metadata": {},
   "source": [
    "## 9. Accelerate Accelerator\n",
    "**Accelerate** is a library, developed by Hugging Face, that makes training & inference at scale simple, efficient & adaptable. 3 main features of Accelerate:\n",
    "- **Unified Launch Interface:** A unified command line launching interface for distributed training scripts.\n",
    "- **Adapt Training Code:** Enables the same PyTorch code to be run across different distributed configurations.\n",
    "- **Big Model Inference:** Loads large models for inference that typically don't fit into memory.\n",
    "1. `accelerate.Accelerator(gradient_accumulation_steps)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e2ca4-00a2-4ee7-b1c5-203ed0f2cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd11ffa-9208-42de-825b-5f414e4483a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1b5f6-6de6-49a4-9e9a-5164b5c52f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = accelerator.device\n",
    "\n",
    "model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7698e8a-2029-49ae-9a6d-94b221eb7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in dataloader:\n",
    "    # inputs = inputs.to(device)\n",
    "    # targets = targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    # loss.backward()\n",
    "    #\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07711fd-2b43-47e2-ad5f-a382d031ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "import evaluate\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "train_dataloader, eval_dataloader, model, optimizer, scheduler = (\n",
    "    accelerator.prepare(\n",
    "        train_dataloader, eval_dataloader, \n",
    "        model, optimizer, scheduler\n",
    "    )\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "for inputs, targets in train_dataloader:\n",
    "    # inputs = inputs.to(device)\n",
    "    # targets = targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "model.eval()\n",
    "for inputs, targets in eval_dataloader:\n",
    "    # inputs = inputs.to(device)\n",
    "    # targets = targets.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    predictions = outputs.argmax(dim=-1)\n",
    "    # \n",
    "    predictions, references = accelerator.gather_for_metrics(\n",
    "        (predictions, references)\n",
    "    )\n",
    "    metric.add_batch(\n",
    "        predictions = predictions,\n",
    "        references = references\n",
    "    )\n",
    "print(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc2e49-609d-4f78-a8d8-0648a04465b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient accumulation\n",
    "from accelerate import Accelerator\n",
    "\n",
    "#\n",
    "accelerator = Accelerator(gradient_accumulation_steps=2)\n",
    "dataloader, model, optimizer, scheduler = accelerator.prepare(dataloader, model, optimizer, scheduler)\n",
    "\n",
    "for batch in dataloader:\n",
    "    #\n",
    "    with accelerator.accumulate(model):\n",
    "        inputs, targets = batch\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d66920-398a-4890-9005-0a336d467952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "dataloader, model, optimizer, scheduler = accelerator.prepare(\n",
    "    dataloader, model, optimizer, scheduler\n",
    ")\n",
    "  \n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "#\n",
    "accelerator.save_state(\"checkpoint_dir\")\n",
    "#\n",
    "accelerator.load_state(\"checkpoint_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9660cfab-bec4-4af8-ae07-f1598444ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Tracking\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator(log_with=\"wandb\")\n",
    "train_dataloader, model, optimizer, scheduler = accelerator.prepare(\n",
    "    dataloader, model, optimizer, scheduler\n",
    ")\n",
    "#\n",
    "accelerator.init_trackers()\n",
    "model.train()\n",
    "for batch in train_dataloader:\n",
    "    inputs, targets = batch\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    #\n",
    "    accelerator.log({\"loss\":loss})\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "#\n",
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086b7d4-9b0a-4b1f-8849-4e984057e434",
   "metadata": {},
   "source": [
    "## 10. Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512193-998a-41f1-8a16-5de2368a3cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
