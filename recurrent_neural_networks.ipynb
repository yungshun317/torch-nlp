{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f855ed-f0fc-438c-aa63-ff38f4ad76c2",
   "metadata": {},
   "source": [
    "# 1. Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7fa873-6734-437d-af98-7a2141a241a5",
   "metadata": {},
   "source": [
    "# 1-1. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bda735-2fdb-4799-aa03-a78446f75164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set layer parameters\n",
    "input_size  =  9 # number of features to extract (e.g., number of data channels)\n",
    "hidden_size = 16 # number of units in the hidden state\n",
    "num_layers  =  1 # number of vertical stacks of hidden layers (note: only the final layer gives an output)\n",
    "actfun      = 'tanh'\n",
    "bias        = True\n",
    "\n",
    "# create an RNN instance\n",
    "rnn = nn.RNN(input_size,hidden_size,num_layers,nonlinearity=actfun,bias=bias)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67746fc-1c1a-48fc-8cb5-4c7818a791e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the source code for more detailed info about this class\n",
    "??nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97015c-74e7-4e8f-a15b-8e0666270c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data parameters\n",
    "seqlength = 5\n",
    "batchsize = 2\n",
    "\n",
    "# create some data\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "\n",
    "# create a hidden layer (typically initialized as zeros)\n",
    "hidden = torch.zeros(num_layers,batchsize,hidden_size)\n",
    "\n",
    "\n",
    "# run some data through the model and show the output sizes\n",
    "y,h = rnn(X,hidden)\n",
    "print(f' Input shape: {list(X.shape)}')\n",
    "print(f'Hidden shape: {list(h.shape)}')\n",
    "print(f'Output shape: {list(y.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d44942-a294-41e5-a7d8-8fe9196e860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Default hidden state is all zeros if nothing specified:\n",
    "y,h1 = rnn(X,hidden)\n",
    "print(h1), print('\\n\\n')\n",
    "\n",
    "y,h2 = rnn(X)\n",
    "print(h2), print('\\n\\n')\n",
    "\n",
    "# they're the same! (meaning default=zeros)\n",
    "print(h1-h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d3e40-757f-4254-aa9d-78943353e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the learned parameters and their sizes\n",
    "for p in rnn.named_parameters():\n",
    "  if 'weight' in p[0]:\n",
    "    print(f'{p[0]} has size {list(p[1].shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4c394-a21b-40ac-8945-20cba7f4fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNnet(nn.Module):\n",
    "  def __init__(self,input_size,num_hidden,num_layers):\n",
    "    super().__init__()\n",
    "\n",
    "    # store parameters\n",
    "    self.input_size = input_size\n",
    "    self.num_hidden = num_hidden\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # RNN Layer\n",
    "    self.rnn = nn.RNN(input_size,num_hidden,num_layers)\n",
    "    \n",
    "    # linear layer for output\n",
    "    self.out = nn.Linear(num_hidden,1)\n",
    "  \n",
    "  def forward(self,x):\n",
    "    \n",
    "    print(f'Input: {list(x.shape)}')\n",
    "    \n",
    "    # initialize hidden state for first input\n",
    "    hidden = torch.zeros(self.num_layers,batchsize,self.num_hidden)\n",
    "    print(f'Hidden: {list(hidden.shape)}')\n",
    "\n",
    "    # run through the RNN layer\n",
    "    y,hidden = self.rnn(x,hidden)\n",
    "    print(f'RNN-out: {list(y.shape)}')\n",
    "    print(f'RNN-hidden: {list(hidden.shape)}')\n",
    "    \n",
    "    # pass the RNN output through the linear output layer\n",
    "    o = self.out(y)\n",
    "    print(f'Output: {list(o.shape)}')\n",
    "\n",
    "    return o,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a56d4-ecd2-45dd-8336-8b1894b7561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the model and inspect\n",
    "net = RNNnet(input_size,hidden_size,num_layers)\n",
    "print(net), print(' ')\n",
    "\n",
    "# and check out all learnable parameters\n",
    "for p in net.named_parameters():\n",
    "  print(f'{p[0]} has size {list(p[1].shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aed8a8-4fb8-48da-8c64-407c58b9f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with some data\n",
    "# create some data\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "y = torch.rand(seqlength,batchsize,1)\n",
    "yHat,h = net(X)\n",
    "\n",
    "# try a loss function\n",
    "lossfun = nn.MSELoss()\n",
    "lossfun(yHat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceadb69-d0de-48e5-a1e8-82123af58b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "# import the data\n",
    "N = 50\n",
    "\n",
    "data = torch.zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "  data[i] = torch.rand(1) * (-1)**i\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot([-1,N+1],[0,0],'--',color=[.8,.8,.8])\n",
    "plt.plot(data,'ks-',markerfacecolor='w')\n",
    "plt.xlim([-1,N+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624d852-4f82-492b-9568-b27c144bb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnnnet(nn.Module):\n",
    "  def __init__(self,input_size,num_hidden,num_layers):\n",
    "    super().__init__()\n",
    "\n",
    "    # RNN Layer\n",
    "    self.rnn = nn.RNN(input_size,num_hidden,num_layers)\n",
    "    \n",
    "    # linear layer for output\n",
    "    self.out = nn.Linear(num_hidden,1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    \n",
    "    # run through the RNN layer\n",
    "    y,hidden = self.rnn(x) # no explicit hidden state initialization\n",
    "    \n",
    "    # and the output (linear) layer\n",
    "    y = self.out(y)\n",
    "    \n",
    "    return y,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d7f5b-b273-4020-900b-2e1be7763236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_size =  1 # \"channels\" of data\n",
    "num_hidden =  5 # breadth of model (number of units in hidden layers)\n",
    "num_layers =  1 # depth of model (number of \"stacks\" of hidden layers)\n",
    "seqlength  =  9 # number of datapoints used for learning in each segment\n",
    "batchsize  =  1 # Note: the training code is actually hard-coded to organize data into batchsize=1\n",
    "\n",
    "# create an instance of the model and inspect\n",
    "net = rnnnet(input_size,num_hidden,num_layers)\n",
    "\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "y,h = net(X)\n",
    "print(X.shape)\n",
    "print(y.shape) # note: one output per sequence element; generally, we take the final output to force a \"many-to-one\" design.\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45228901-c09c-47d4-bd57-764781b62e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with some data\n",
    "somedata = data[:seqlength].view(seqlength,1,1)\n",
    "y = net(somedata)\n",
    "\n",
    "# grab the final predicted value from the output (first element of tuple output of net)\n",
    "finalValue = y[0][-1]\n",
    "\n",
    "lossfun = nn.MSELoss()\n",
    "lossfun(finalValue,data[seqlength].view(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da796d3a-0a61-4135-9ef5-e397ad375a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training epochs\n",
    "numepochs = 30\n",
    "\n",
    "# create a new instance of the model (and optimizer!)\n",
    "net = rnnnet(input_size,num_hidden,num_layers)\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=.001)\n",
    "\n",
    "\n",
    "\n",
    "# initialize losses\n",
    "losses = np.zeros(numepochs)\n",
    "signaccuracy = np.zeros(numepochs)\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # loop over data segments\n",
    "  seglosses = []\n",
    "  segacc    = []\n",
    "  hidden_state = torch.zeros(num_layers,batchsize,num_hidden) # reset the hidden state on each epoch\n",
    "\n",
    "  for timei in range(N-seqlength):\n",
    "\n",
    "    # grab a snippet of data\n",
    "    X = data[timei:timei+seqlength].view(seqlength,1,1)\n",
    "    y = data[timei+seqlength].view(1,1)\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat,hidden_state = net(X)\n",
    "    finalValue = yHat[-1]\n",
    "    loss = lossfun(finalValue,y) # compare final value of output\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss from this segment\n",
    "    seglosses.append(loss.item())\n",
    "\n",
    "    # also get sign accuracy\n",
    "    truesign = np.sign(torch.squeeze(y).numpy())\n",
    "    predsign = np.sign(torch.squeeze(finalValue).detach().numpy())\n",
    "    accuracy = 100*(truesign==predsign)\n",
    "    segacc.append(accuracy)\n",
    "  \n",
    "  # average losses from this epoch\n",
    "  losses[epochi] = np.mean(seglosses)\n",
    "  signaccuracy[epochi] = np.mean(segacc)\n",
    "  \n",
    "  msg = f'Finished epoch {epochi+1}/{numepochs}'\n",
    "  sys.stdout.write('\\r' + msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0db0c-5de6-4fc9-b9ea-695f5a352a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "truesign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423c21f-abbe-4006-b846-1ed35861d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's see how the model did!\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses,'s-')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(signaccuracy,'m^-',markerfacecolor='g',markersize=15)\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_title('Sign accuracy (final accuracy: %.2f%%)'%signaccuracy[-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82167c81-fe44-416c-9caa-1f96f344baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hidden state\n",
    "h = np.zeros((N,num_hidden))\n",
    "\n",
    "# initialize predicted values\n",
    "yHat = np.zeros(N)\n",
    "yHat[:] = np.nan\n",
    "\n",
    "\n",
    "# loop over time segments\n",
    "for timei in range(N-seqlength):\n",
    "\n",
    "  # grab a snippet of data\n",
    "  X = data[timei:timei+seqlength].view(seqlength,1,1)\n",
    "\n",
    "  # forward pass and loss\n",
    "  yy,hh = net(X)\n",
    "  yHat[timei+seqlength] = yy[-1]\n",
    "  h[timei+seqlength,:] = hh.detach()\n",
    "\n",
    "\n",
    "## compute sign-accuracy\n",
    "truesign = np.sign(data.numpy())\n",
    "predsign = np.sign(yHat)\n",
    "signaccuracy = 100*np.mean(truesign[seqlength:]==predsign[seqlength:])\n",
    "\n",
    "\n",
    "## plot!\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "ax[0].plot(data,'bs-',label='Actual data')\n",
    "ax[0].plot(yHat,'ro-',label='Predicted')\n",
    "ax[0].set_ylim([-1.1,1.1])\n",
    "ax[0].set_title('Sign accuracy = %.2f%%' %signaccuracy)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(data-yHat,'k^')\n",
    "ax[1].set_ylim([-1.1,1.1])\n",
    "\n",
    "ax[2].plot(data[seqlength:],yHat[seqlength:],'mo')\n",
    "ax[2].set_xlabel('Real data')\n",
    "ax[2].set_ylabel('Predicted data')\n",
    "r = np.corrcoef(data[seqlength:],yHat[seqlength:])\n",
    "ax[2].set_title(f\"r={r[0,1]:.2f} (but Simpson's paradox!)\")\n",
    "\n",
    "plt.suptitle('Performance on training data',fontweight='bold',fontsize=20,y=1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f9df3-6e18-4bf6-a5ef-c1dbbc50f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the hidden \"states\" (units activations)\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.plot(h,'s-')\n",
    "plt.xlabel('Sequence index')\n",
    "plt.ylabel('State value (a.u.)')\n",
    "plt.title('Each line is a different hidden unit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e0c8f-0df7-47a7-a37f-0adce22acbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data WITH FLIPPED SIGNS!\n",
    "newdata = torch.zeros(N)\n",
    "for i in range(N):\n",
    "  newdata[i] = torch.rand(1) * (-1)**(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26203fb3-2afe-43d7-95e3-8a8a338d37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now test the network!\n",
    "# note: no learning here!\n",
    "\n",
    "h = np.zeros((N,num_hidden))\n",
    "\n",
    "yHat = np.zeros(N)\n",
    "for timei in range(N-seqlength):\n",
    "\n",
    "  # grab a snippet of data\n",
    "  X = newdata[timei:timei+seqlength].view(seqlength,1,1)\n",
    "\n",
    "  # forward pass and loss\n",
    "  yy,hh = net(X)\n",
    "  yHat[timei+seqlength] = yy[-1]\n",
    "  h[timei+seqlength,:] = hh.detach()\n",
    "\n",
    "\n",
    "# compute sign-accuracy\n",
    "truesign = np.sign(newdata.numpy())\n",
    "predsign = np.sign(yHat)\n",
    "signaccuracy = 100*np.mean(truesign[seqlength:]==predsign[seqlength:])\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(18,4))\n",
    "ax[0].plot(newdata,'bs-',label='Actual data')\n",
    "ax[0].plot(yHat,'ro-',label='Predicted')\n",
    "ax[0].set_ylim([-1.1,1.1])\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(newdata-yHat,'k^')\n",
    "ax[1].set_ylim([-1.1,1.1])\n",
    "ax[1].set_title('Sign accuracy = %.2f%%' %signaccuracy)\n",
    "\n",
    "plt.suptitle('Performance on unseen test data',fontweight='bold',fontsize=20,y=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94245f45-8819-45ea-9f4f-ffdeb4e2781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the weights for the input->hidden layers\n",
    "plt.bar(range(num_hidden),net.rnn.weight_ih_l0.detach())\n",
    "plt.ylabel('Weight value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85baab2-6b32-4db1-8766-070499758bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [] GRU & LSTM\n",
    "# set layer parameters\n",
    "input_size  =  9 # number of features to extract (e.g., number of data channels)\n",
    "hidden_size = 16 # number of units in the hidden state\n",
    "num_layers  =  2 # number of vertical stacks of hidden layers (note: only the final layer gives an output)\n",
    "\n",
    "# create an LSTM instance\n",
    "lstm = nn.LSTM(input_size,hidden_size,num_layers)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15daff9-603b-4d98-89f3-509bbdf50578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the source code for more detailed info about this class\n",
    "??nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6f22e-c6a1-49b4-ba92-bf1868ff7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data parameters\n",
    "seqlength = 5\n",
    "batchsize = 2\n",
    "\n",
    "# create some data\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "\n",
    "# create initial hidden states (typically initialized as zeros)\n",
    "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
    "C = torch.zeros(num_layers,batchsize,hidden_size)\n",
    "\n",
    "# the input is actually a tuple of (hidden,cell)\n",
    "hiddeninputs = (H,C)\n",
    "\n",
    "# run some data through the model and show the output sizes\n",
    "y,h = lstm(X,hiddeninputs)\n",
    "print(f' Input shape: {list(X.shape)}')\n",
    "print(f'Hidden shape: {list(h[0].shape)}')\n",
    "print(f'  Cell shape: {list(h[1].shape)}')\n",
    "print(f'Output shape: {list(y.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4169a2-1c76-41db-b170-206b7ebe74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the learned parameters and their sizes\n",
    "for p in lstm.named_parameters():\n",
    "  if 'weight' in p[0]:\n",
    "    print(f'{p[0]} has size {list(p[1].shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03fa52-159a-4455-8c6d-d315294aebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMnet(nn.Module):\n",
    "  def __init__(self,input_size,num_hidden,num_layers):\n",
    "    super().__init__()\n",
    "\n",
    "    # store parameters\n",
    "    self.input_size = input_size\n",
    "    self.num_hidden = num_hidden\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # RNN Layer (notation: LSTM \\in RNN)\n",
    "    self.lstm = nn.LSTM(input_size,num_hidden,num_layers)\n",
    "    \n",
    "    # linear layer for output\n",
    "    self.out = nn.Linear(num_hidden,1)\n",
    "  \n",
    "  def forward(self,x):\n",
    "    \n",
    "    print(f'Input: {list(x.shape)}')\n",
    "\n",
    "    # run through the RNN layer\n",
    "    y,hidden = self.lstm(x)\n",
    "    print(f'RNN-out: {list(y.shape)}')\n",
    "    print(f'RNN-hidden: {list(hidden[0].shape)}')\n",
    "    print(f'RNN-cell: {list(hidden[1].shape)}')\n",
    "    \n",
    "    # pass the RNN output through the linear output layer\n",
    "    o = self.out(y)\n",
    "    print(f'Output: {list(o.shape)}')\n",
    "\n",
    "    return o,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa44c3-8e93-48ae-aa3c-931cfddc96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the model and inspect\n",
    "net = LSTMnet(input_size,hidden_size,num_layers)\n",
    "print(net), print(' ')\n",
    "\n",
    "# and check out all learnable parameters\n",
    "for p in net.named_parameters():\n",
    "  print(f'{p[0]:>20} has size {list(p[1].shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126257a-adc0-43fc-9d0b-a789a4cbfd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with some data\n",
    "# create some data\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "y = torch.rand(seqlength,batchsize,1)\n",
    "yHat,h = net(X)\n",
    "\n",
    "\n",
    "lossfun = nn.MSELoss()\n",
    "lossfun(yHat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543f02b-dd5f-4896-ba71-adf109390ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "# create a GRU instance\n",
    "gru = nn.GRU(input_size,hidden_size,num_layers)\n",
    "gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c621f1-db8d-45c3-a6ec-6358aa73d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "??nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843e5b2-4dca-47c0-80b9-45165d227839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some data and a hidden state\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
    "\n",
    "# run some data through the model and show the output sizes\n",
    "y,h = gru(X,H) # No cell states in GRU!\n",
    "print(f' Input shape: {list(X.shape)}')\n",
    "print(f'Hidden shape: {list(h.shape)}')\n",
    "print(f'Output shape: {list(y.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49ca90-5759-4e96-925f-bfbb472837e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the learned parameters and their sizes\n",
    "for p in gru.named_parameters():\n",
    "  print(f'{p[0]:>15} has size {list(p[1].shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be505636-197d-42a7-aa97-6c6d4931857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [] Lorem Ipsum\n",
    "text = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent molestie sapien auctor eleifend egestas. Fusce at purus sodales, viverra nunc quis, consequat augue. Vestibulum eget tempus lorem, et blandit dui. Suspendisse ac gravida odio. Maecenas consequat tristique mi, vitae rutrum lacus pulvinar vitae. Nunc ullamcorper nulla eu velit vehicula, vitae facilisis erat dignissim. Proin consectetur nec lacus ac pellentesque. Nulla purus ligula, commodo id tellus id, efficitur varius massa. Phasellus et volutpat felis, gravida imperdiet justo. Cras metus velit, aliquet et tristique sit amet, elementum ultrices dui. Nullam condimentum quis orci quis pretium. Mauris tincidunt ante nec ex tristique, a commodo quam eleifend. Nam convallis ultrices magna fringilla porta. Phasellus non lobortis nisi. Donec nec lectus ligula. Maecenas id purus at lectus auctor finibus sit amet et enim. Vivamus nibh urna, dapibus sed porta in, sodales vitae elit. Fusce sed facilisis elit, ut porta massa. Vivamus blandit congue erat eget rutrum. Nullam mollis, eros et laoreet euismod, nunc mi condimentum eros, mollis pretium mi orci in nibh. Pellentesque rhoncus justo et pretium tempor. Ut gravida egestas quam, sit amet sagittis tortor scelerisque in. Vestibulum sed odio urna. Donec semper quis erat quis laoreet. Ut malesuada volutpat sem ac luctus. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Praesent sed bibendum sapien, id imperdiet elit. Vestibulum erat lorem, finibus eu enim non, posuere tempus velit. Vestibulum a massa id orci interdum malesuada eu vel tellus. Proin tempus viverra scelerisque. Nullam suscipit laoreet nisl, id consequat sem porttitor et. Integer congue urna lacus, ac feugiat arcu tincidunt eget. Aliquam erat volutpat. Vivamus accumsan semper gravida. Mauris porta magna vitae semper hendrerit. Vestibulum urna nunc, faucibus sit amet auctor sed, scelerisque nec est. Nulla ut sagittis urna. Proin fermentum turpis non iaculis tincidunt. Maecenas scelerisque rutrum hendrerit. Sed fermentum vehicula molestie. Sed nec rutrum nisi. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Cras malesuada, magna in ornare pretium, leo tellus sodales tortor, sit amet fermentum nunc odio eu enim. Quisque placerat eros ornare nulla vulputate, at efficitur sem convallis. Sed libero risus, viverra a turpis a, sollicitudin feugiat neque. Fusce vitae erat commodo, consectetur lacus vel, sollicitudin lorem. Nunc sed risus arcu. Pellentesque nec eleifend risus, a fringilla odio. Sed auctor augue a rutrum maximus. Maecenas suscipit tellus sem, vitae suscipit nisl euismod a. Phasellus elementum sodales urna, ac fringilla mi malesuada id. Suspendisse sollicitudin rhoncus dolor ut consequat. Duis tincidunt quis neque nec tincidunt. Fusce vitae sagittis nulla. Suspendisse ac varius mauris. Maecenas dapibus posuere velit, nec pellentesque quam sagittis a. Nunc aliquet justo vitae justo pharetra consectetur. Nam porttitor at nisl sit amet ullamcorper. Sed rutrum, nulla ac porttitor pulvinar, nisi leo hendrerit magna, non luctus nibh risus eget est. Quisque pulvinar rutrum vehicula. Ut tempor placerat sollicitudin. Etiam pharetra sit amet nulla at fringilla. Pellentesque feugiat odio ligula, ac ullamcorper leo vulputate a. Vestibulum placerat interdum arcu, sit amet ullamcorper ipsum finibus sed. Aliquam erat volutpat. Nam tincidunt, augue eu eleifend dictum, tellus sem blandit sem, et pulvinar ex purus sed leo. Nullam ultricies tincidunt sem, imperdiet condimentum ex porttitor at. Nunc id lacus sit amet nibh elementum dignissim. Nam facilisis tincidunt tincidunt. Suspendisse in mauris vel dui imperdiet facilisis. Aenean eu neque tortor. Cras sit amet mi nibh. Mauris sit amet feugiat nulla. Nam ac leo ipsum. Vestibulum id enim sit amet est pharetra consectetur. Vestibulum et lacus sed ipsum placerat blandit vitae quis nisl. Curabitur lacus est, euismod non accumsan sed, accumsan nec lectus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Maecenas ultrices eros in erat molestie interdum. Nunc et tellus orci. Maecenas et magna ornare mauris sodales malesuada. Duis iaculis ipsum non laoreet porta. Aenean vitae purus tempor, porttitor arcu id, bibendum enim. Aliquam faucibus congue eros, eget feugiat risus venenatis a. Duis malesuada, sem eu mattis placerat, velit lectus varius tellus, eget placerat nibh quam non turpis. Donec auctor pellentesque odio, nec pulvinar nisi fermentum eget. Mauris eget eleifend metus. Mauris venenatis arcu semper erat facilisis, malesuada viverra tortor imperdiet. Nunc ut quam sit amet ex varius euismod. Mauris eleifend lectus venenatis risus mattis consequat. Nulla a eros non erat egestas consequat nec volutpat neque. In diam nulla, mollis ut semper nec, vulputate luctus odio. Morbi ac elementum quam, ut vestibulum sem. Ut tincidunt sapien ac fermentum ullamcorper. Cras convallis tortor quis malesuada dignissim. Suspendisse rutrum cursus diam, in consequat nisi vulputate sit amet. Nunc euismod consectetur libero eu pulvinar. Ut finibus scelerisque lectus vel auctor. Vivamus congue non sem et tincidunt. Vestibulum vehicula erat sed nisi mattis aliquet. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Etiam pulvinar tortor enim, vel blandit mauris sodales quis. Ut bibendum dui non posuere pellentesque. Phasellus metus diam, blandit accumsan porta a, pharetra nec nulla. Nam pulvinar, lacus et ornare luctus, magna orci tincidunt lorem, porttitor tincidunt enim mi a ligula. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Etiam quis mi porta, mattis velit vel, rhoncus nisi. Etiam lobortis placerat lacus.'.lower()\n",
    "# generated at https://www.lipsum.com/\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62b529-cbb3-4621-b2d6-ee19704bb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the unique characters\n",
    "uniquecharacters = set(text)\n",
    "uniquecharacters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a739c-b488-4c3d-a43e-615e373de0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look-up tables to convert characters to indices and vice-versa\n",
    "number2letter = dict(enumerate(uniquecharacters))\n",
    "letter2number = { l:i for i,l in number2letter.items() }\n",
    "\n",
    "letter2number#['e']\n",
    "number2letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c6a4f-f630-4619-bd02-f615850b326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the text from characters into numbers\n",
    "\n",
    "# note the inputs to zeros()\n",
    "data = torch.zeros( (len(text),1), dtype=torch.int64, device=device)\n",
    "for i,ch in enumerate(text):\n",
    "  data[i] = letter2number[ch]\n",
    "\n",
    "\n",
    "# let's see the data!\n",
    "print(data)\n",
    "plt.plot(data.cpu().numpy(),'k.')\n",
    "plt.xlabel('Character index')\n",
    "plt.ylabel('Character label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e4a23-efb1-4d23-b393-863cc311be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstmnet(nn.Module):\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
    "    super().__init__()\n",
    "\n",
    "    # embedding layer\n",
    "    self.embedding = nn.Embedding(input_size,input_size)\n",
    "\n",
    "    # LSTM layer\n",
    "    self.lstm = nn.LSTM(input_size,hidden_size,num_layers)\n",
    "\n",
    "    # linear output layer\n",
    "    self.out = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "\n",
    "  def forward(self,x,h):\n",
    "\n",
    "    # embedding layer\n",
    "    embedding = self.embedding(x)\n",
    "\n",
    "    # run through the RNN layer\n",
    "    y,h = self.lstm(embedding,h)\n",
    "\n",
    "    # and the output (linear) layer\n",
    "    y = self.out(y)\n",
    "\n",
    "    return y,(h[0].detach(),h[1].detach()) # just the numerical values for h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1bdb9-303d-4176-9a5b-600c061fc4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-parameters\n",
    "hidden_size = 512   # size of hidden state\n",
    "seqlength   = 80    # length of sequence\n",
    "num_layers  = 3     # number of stacked hidden layers\n",
    "epochs      = 10    # training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cec2c8-6686-4805-b5c2-a81c33944419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model instance\n",
    "lstm = lstmnet(len(uniquecharacters),len(uniquecharacters), hidden_size, num_layers).to(device)\n",
    "\n",
    "# loss function and optimizer\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fff7d-24f6-436e-8294-93effb3de509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the randomly initialized embeddings matrix\n",
    "I = next(lstm.embedding.named_parameters())\n",
    "plt.imshow(I[1].cpu().detach());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c4b54-975b-489b-a231-395840e7574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.zeros(epochs)\n",
    "\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(epochs):\n",
    "\n",
    "  # initialize loss for this epoch, and hidden state\n",
    "  txtloss = 0\n",
    "  hidden_state = None\n",
    "\n",
    "  # loop through the entire text character-wise\n",
    "  for txtloc in range(0,len(text)-seqlength):\n",
    "\n",
    "    # get input and target (shifted version of input)\n",
    "    x = data[txtloc   : txtloc+seqlength  ]\n",
    "    y = data[txtloc+1 : txtloc+seqlength+1]\n",
    "\n",
    "    # forward pass\n",
    "    output, hidden_state = lstm(x,None)\n",
    "\n",
    "    # compute loss\n",
    "    loss = lossfun(torch.squeeze(output), torch.squeeze(y))\n",
    "    txtloss += loss.item()\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  # average losses for this epoch (run through the entire text)\n",
    "  losses[epochi] = txtloss/txtloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134f8c6-d2df-4507-b381-66c1ea573e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the losses\n",
    "plt.plot(losses,'s-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a87b2b-65f6-4057-bac6-27ed2bbd22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructing a character sequence from number sequence\n",
    "t = ''\n",
    "for l in x:\n",
    "  t += number2letter[l.item()]\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d80c68-0b41-4e68-8045-ba47e66b3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many characters to generate?\n",
    "lorem_length = 200\n",
    "\n",
    "# random character from data to begin\n",
    "x = torch.tensor(letter2number['x']).view(1,1).to(device)\n",
    "lorem = number2letter[x.item()]\n",
    "\n",
    "# initialize the hidden state\n",
    "hidden_state = None\n",
    "\n",
    "\n",
    "# generate the text!\n",
    "for i in range(lorem_length):\n",
    "\n",
    "  # push a letter though the LSTM\n",
    "  output, hidden_state = lstm(x,hidden_state)\n",
    "\n",
    "  # get the maximum output and replace input data\n",
    "  index = torch.argmax(output).item()\n",
    "  x[0][0] = index\n",
    "\n",
    "  # append that output to the text\n",
    "  lorem += number2letter[index]\n",
    "\n",
    "\n",
    "## what's it say?!?!?!\n",
    "lorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6840d8-810e-4553-9cc9-22418cfe0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hidden states\n",
    "for i in range(num_layers):\n",
    "  plt.plot(hidden_state[0][i,0,:].cpu().numpy(),'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360cddd-80ae-4fce-a1c6-5b181873f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the learned embeddings matrix\n",
    "I = next(lstm.embedding.named_parameters())\n",
    "I = I[1].cpu().detach().numpy()\n",
    "plt.imshow(I);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d31c0e-21cd-46f6-a617-8950eb6f875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI, lots can be done with this matrix, e.g., PCA...\n",
    "d,V = np.linalg.eig(I@I.T)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(8,5))\n",
    "axs[0].imshow(np.corrcoef(I),vmin=-.5,vmax=.5)\n",
    "axs[0].set_title('Correlation of embeddings')\n",
    "axs[0].set_xticks(range(len(letter2number.keys())))\n",
    "axs[0].set_xticklabels(letter2number.keys())\n",
    "axs[0].set_yticks(range(len(letter2number.keys())))\n",
    "axs[0].set_yticklabels(letter2number.keys())\n",
    "\n",
    "axs[1].plot(d,'s-')\n",
    "axs[1].set_xlabel('Component')\n",
    "axs[1].set_ylabel('Eigenvalue')\n",
    "axs[1].set_title('Eigenspectrum of embeddings')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856653b-c455-46e9-9ef3-d0a5e6bdf94c",
   "metadata": {},
   "source": [
    "## 1-2. RNN\n",
    "\n",
    "[Large Movie Review Dataset](https://ai.stanford.edu/%7Eamaas/data/sentiment/) for binary sentiment classification from Stanford.\n",
    "- [imdb_reviews](https://www.tensorflow.org/datasets/catalog/imdb_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae1db46-c8cd-4e21-91d1-0df2e466d599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't understand why the other comments focu...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The information contained in this movie is som...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The premise of this anime series is about brea...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I watched the first series avidly, but wondere...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"GOOD TIMES,\" in my opinion, is a must-see CBS...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>First of all, I was expecting \"Caged Heat\" to ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>THIS IS NOT A CHILDREN'S MOVIE!!!&lt;br /&gt;&lt;br /&gt;T...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Perhaps because I was so young, innocent and B...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>By all the fawning people have been doing over...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Ulli Lommel's 1980 film 'The Boogey Man' is no...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "0      I don't understand why the other comments focu...   pos\n",
       "1      The information contained in this movie is som...   pos\n",
       "2      The premise of this anime series is about brea...   pos\n",
       "3      I watched the first series avidly, but wondere...   pos\n",
       "4      \"GOOD TIMES,\" in my opinion, is a must-see CBS...   pos\n",
       "...                                                  ...   ...\n",
       "24995  First of all, I was expecting \"Caged Heat\" to ...   neg\n",
       "24996  THIS IS NOT A CHILDREN'S MOVIE!!!<br /><br />T...   neg\n",
       "24997  Perhaps because I was so young, innocent and B...   neg\n",
       "24998  By all the fawning people have been doing over...   neg\n",
       "24999  Ulli Lommel's 1980 film 'The Boogey Man' is no...   neg\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get the class names from the target directory\n",
    "class_names_found = ['pos', 'neg']\n",
    "\n",
    "# Construct a pandas DataFrame using `read()`\n",
    "dict_train = []\n",
    "\n",
    "for class_name in class_names_found:\n",
    "    doc_lst = glob.glob(f\"./datasets/aclImdb_v1/aclImdb/train/{class_name}/*.txt\", recursive=True)\n",
    "    for filename in doc_lst:\n",
    "        with open(filename, 'r', errors='replace') as f:\n",
    "            # Use `read()` instead of `readlines()`\n",
    "            doc = f.read()\n",
    "            dict_train.append({\"text\": doc, \"label\": class_name})\n",
    "\n",
    "df_train = pd.DataFrame(dict_train)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068d9ce8-e327-4dcf-b50e-130db9f6c3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like both this version of DORIAN GRAY and th...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the face of it, any teen comedy runs the ri...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Icky Flix\" is an excellent starting point for...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just saw this at SIFF, and I absolutely love...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The creative team of Jim Abrahams, David Zucke...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I am sitting here writing this review and the ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I can't believe some of the scores this film i...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I have just watched this \"latest\" version of M...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Woa, talk about awful. Do not waste your time....</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>This appears to be one of Noel Coward's lesser...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "0      I like both this version of DORIAN GRAY and th...   pos\n",
       "1      On the face of it, any teen comedy runs the ri...   pos\n",
       "2      \"Icky Flix\" is an excellent starting point for...   pos\n",
       "3      I just saw this at SIFF, and I absolutely love...   pos\n",
       "4      The creative team of Jim Abrahams, David Zucke...   pos\n",
       "...                                                  ...   ...\n",
       "24995  I am sitting here writing this review and the ...   neg\n",
       "24996  I can't believe some of the scores this film i...   neg\n",
       "24997  I have just watched this \"latest\" version of M...   neg\n",
       "24998  Woa, talk about awful. Do not waste your time....   neg\n",
       "24999  This appears to be one of Noel Coward's lesser...   neg\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a pandas DataFrame using `read()`\n",
    "dict_test = []\n",
    "\n",
    "for class_name in class_names_found:\n",
    "    doc_lst = glob.glob(f\"./datasets/aclImdb_v1/aclImdb/test/{class_name}/*.txt\", recursive=True)\n",
    "    for filename in doc_lst:\n",
    "        with open(filename, 'r', errors='replace') as f:\n",
    "            # Use `read()` instead of `readlines()`\n",
    "            doc = f.read()\n",
    "            dict_test.append({\"text\": doc, \"label\": class_name})\n",
    "\n",
    "df_test = pd.DataFrame(dict_test)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c66dd22-0b9c-4297-98a8-6250dce0a14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't understand why the other comments focu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The information contained in this movie is som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The premise of this anime series is about brea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I watched the first series avidly, but wondere...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"GOOD TIMES,\" in my opinion, is a must-see CBS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>First of all, I was expecting \"Caged Heat\" to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>THIS IS NOT A CHILDREN'S MOVIE!!!&lt;br /&gt;&lt;br /&gt;T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Perhaps because I was so young, innocent and B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>By all the fawning people have been doing over...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Ulli Lommel's 1980 film 'The Boogey Man' is no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I don't understand why the other comments focu...      1\n",
       "1      The information contained in this movie is som...      1\n",
       "2      The premise of this anime series is about brea...      1\n",
       "3      I watched the first series avidly, but wondere...      1\n",
       "4      \"GOOD TIMES,\" in my opinion, is a must-see CBS...      1\n",
       "...                                                  ...    ...\n",
       "24995  First of all, I was expecting \"Caged Heat\" to ...      0\n",
       "24996  THIS IS NOT A CHILDREN'S MOVIE!!!<br /><br />T...      0\n",
       "24997  Perhaps because I was so young, innocent and B...      0\n",
       "24998  By all the fawning people have been doing over...      0\n",
       "24999  Ulli Lommel's 1980 film 'The Boogey Man' is no...      0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'] = df_train['label'].map({'neg': 0, 'pos': 1})\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9d9750-bbc7-4045-b888-85b22f2e8074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like both this version of DORIAN GRAY and th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the face of it, any teen comedy runs the ri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Icky Flix\" is an excellent starting point for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just saw this at SIFF, and I absolutely love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The creative team of Jim Abrahams, David Zucke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I am sitting here writing this review and the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I can't believe some of the scores this film i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I have just watched this \"latest\" version of M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Woa, talk about awful. Do not waste your time....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>This appears to be one of Noel Coward's lesser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I like both this version of DORIAN GRAY and th...      1\n",
       "1      On the face of it, any teen comedy runs the ri...      1\n",
       "2      \"Icky Flix\" is an excellent starting point for...      1\n",
       "3      I just saw this at SIFF, and I absolutely love...      1\n",
       "4      The creative team of Jim Abrahams, David Zucke...      1\n",
       "...                                                  ...    ...\n",
       "24995  I am sitting here writing this review and the ...      0\n",
       "24996  I can't believe some of the scores this film i...      0\n",
       "24997  I have just watched this \"latest\" version of M...      0\n",
       "24998  Woa, talk about awful. Do not waste your time....      0\n",
       "24999  This appears to be one of Noel Coward's lesser...      0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'] = df_test['label'].map({'neg': 0, 'pos': 1})\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b34f9-e19a-4294-933e-75973d30548d",
   "metadata": {},
   "source": [
    "## 7-1. Masking & Padding\n",
    "\n",
    "**Masking** is a way to tell sequence-processing layers that certain timesteps in an input are missing, and thus should be skipped when processing the data. **Padding** is a special form of masking where the masked steps are at the start or the end of a sequence. Padding comes from the need to encode sequence data into contiguous batches. In order to make all sequences in a batch fit a given standard length, it is necessary to pad or truncate some sequences. The steps are as follows:\n",
    "\n",
    "- Truncate and pad samples to a uniform length, for Individual samples of sequence data usually have different lengths.\n",
    "- Mask some parts of the input data which are actually paddings and should be ignored before sent to the model.\n",
    "- Re-pad the model outputs for the final output layer to get scores over the vocabulary space.\n",
    "\n",
    "There are several approaches in PyTorch:\n",
    "- Just pad the sequences and train the model without masking. It is computationally inefficient, but it does not lead to inaccurate representations. Need more logic to extract correct representations for sequences.\n",
    "    - For RNN modules with only forward direction, pick up the hidden vector from `L`th step, instead of the last step, as a representation.\n",
    "    - For bidirectional RNN modules, have to work with pre padding & post padding at once, and finally extract and concatenate the hidden vectors as above.\n",
    "- Or perform **Sequence Packing**, creating a consistent-sized data structure, `PackedSequence`, composed of variable length sequences, with PyTorch utility functions.\n",
    "    - Create a custom `Dataset` class because `TensorDataset` does not allow variable sequence lengths.\n",
    "    - Pad sequences in custom `collate_fn` of `DataLoader` and also return original sequence lengths for used later in `pack_padded_sequence`.\n",
    "\n",
    "PyTorch:\n",
    "\n",
    "1. `torch.nn.utils.rnn.pad_sequence(sequences, batch_first=False, padding_value=0.0)`: Stacks a list of `Tensor`s along a new dimension and pads them to equal length. For example, if the input is a list of sequences with size `(L, *)` and `batch_first` is False, the output is of size `(B, T, *)`. `B` is batch size. It is equal to the number of elements in sequences. `T` is length of the longest sequence. `L` is length of the sequence. `*` is any number of trailing dimensions, including `None`. Only supports post padding.\n",
    "   - Because of **Gradient Vanishing**, pre padding is recommended.\n",
    "   - [Effects of Padding on LSTMs & CNNs](https://arxiv.org/abs/1903.07288)\n",
    "2. `torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)`: Packs a `Tensor` containing padded sequences of variable length. All RNN modules in PyTorch accept packed sequences as inputs. If `enforce_sorted` is `True`, the input is expected to contain sequences sorted by length in a decreasing order. If `False`, the input will get sorted unconditionally.\n",
    "3. `torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None)`: Pads a packed batch of variable length sequences.\n",
    "4. `torch.nn.utils.rnn.pack_sequence(sequences, enforce_sorted=True)`: Consecutive call of `pad_sequence` & `pack_padded_sequence`.\n",
    "\n",
    "Keras:\n",
    "\n",
    "5. `tf.keras.utils.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)`: Supports truncating and pre padding.\n",
    "   - [Masking](https://www.tensorflow.org/guide/keras/understanding_masking_and_padding#masking) in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3311edbe-1cb3-4a4d-8773-a64dabfc1579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 01:59:05.569021: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-22 01:59:05.576823: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-22 01:59:05.586475: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-22 01:59:05.586489: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-22 01:59:05.592718: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-22 01:59:05.938585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "sequences_train = tokenizer.texts_to_sequences(df_train.text)\n",
    "# filtered_sequence_train = list(filter(lambda x: (x != []), sequence_train))\n",
    "sequences_test = tokenizer.texts_to_sequences(df_test.text)\n",
    "\n",
    "# Get sequence lengths\n",
    "train_lengths = [len(x) for x in sequences_train]\n",
    "test_lengths = [len(x) for x in sequences_test]\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "V = len(word2idx)\n",
    "print(\"Found %s unique tokens.\" % V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d50f326c-d417-413e-95ef-6edb03a5e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Set Tensor: (25000, 2493)\n",
      "Sample: [  0   0   0 ...  73 326 218]\n"
     ]
    }
   ],
   "source": [
    "# `pad_sequences()` from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Pad sequences so that we get a N x T matrix\n",
    "data_train = pad_sequences(sequences_train)\n",
    "print(\"Shape of Training Set Tensor:\", data_train.shape)\n",
    "print(\"Sample:\", data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f6b6e234-6c50-4f79-9a4c-c76b3312bac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Set Tensor: torch.Size([25000, 2493])\n",
      "Sample: tensor([ 10,  89, 388,  ...,   0,   0,   0])\n"
     ]
    }
   ],
   "source": [
    "# `pad_sequence()`\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Convert list of lists to list of tensors\n",
    "sequences_train_tensor = list(map(lambda x: torch.as_tensor(x), sequences_train))\n",
    "data_train = pad_sequence(sequences=sequences_train_tensor, batch_first=True)\n",
    "print(\"Shape of Training Set Tensor:\", data_train.shape)\n",
    "print(\"Sample:\", data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "fb64d877-a8f7-405d-8929-dfb98f94497a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1012, 2737,  688,  ...,    3,    7,    7]), batch_sizes=tensor([25000, 25000, 25000,  ...,     1,     1,     1]), sorted_indices=tensor([ 5079,   329,  7842,  ..., 22795, 24523, 13597]), unsorted_indices=tensor([16274,  9240, 19451,  ..., 15842,  6124,  2493]))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `pack_padded_sequence()`\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "train_lengths_tensor = torch.as_tensor(train_lengths)\n",
    "packed_data_train = pack_padded_sequence(input=data_train, lengths=train_lengths_tensor, batch_first=True, enforce_sorted=False)\n",
    "packed_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d5d38763-dc15-458e-9945-54d3d4f7d8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Set Tensor: torch.Size([25000, 2493])\n",
      "Sample: tensor([ 10,  89, 388,  ...,   0,   0,   0])\n"
     ]
    }
   ],
   "source": [
    "# `pad_packed_sequence()`\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "unpacked_data_train, unpacked_train_lengths = pad_packed_sequence(sequence=packed_data_train, batch_first=True)\n",
    "print(\"Shape of Training Set Tensor:\", unpacked_data_train.shape)\n",
    "print(\"Sample:\", unpacked_data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "52538557-ccff-4445-97b2-61df9b83c28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1012, 2737,  688,  ...,    3,    7,    7]), batch_sizes=tensor([25000, 25000, 25000,  ...,     1,     1,     1]), sorted_indices=tensor([ 5079,   329,  7842,  ..., 22795, 24523, 13597]), unsorted_indices=tensor([16274,  9240, 19451,  ..., 15842,  6124,  2493]))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `pack_sequence()`\n",
    "sequences_train_tensor = list(map(lambda x: torch.as_tensor(x), sequences_train))\n",
    "packed_data_train = pack_sequence(sequences=sequences_train_tensor, enforce_sorted=False)\n",
    "packed_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5ef911f0-4c3d-4b32-8b96-1dd4986372e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom pre padding for PyTorch\n",
    "from torch import Tensor\n",
    "from typing import Union, List\n",
    "\n",
    "def pad_sequence_with_pos(\n",
    "    sequences: Union[Tensor, List[Tensor]],\n",
    "    batch_first: bool = False,\n",
    "    padding_value: float = 0.0,\n",
    "    pos: str = 'post',\n",
    ") -> Tensor:\n",
    "\n",
    "    if pos == 'post':\n",
    "        padded_sequence = torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n",
    "    elif pos == 'pre':\n",
    "        sequences = tuple(map(lambda s: s.flip(0), sequences))\n",
    "        padded_sequence = torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n",
    "        _seq_dim = padded_sequence.dim()\n",
    "        padded_sequence = padded_sequence.flip(-_seq_dim+batch_first)\n",
    "    else:\n",
    "        raise ValueError(\"pos should be either 'post' or 'pre', but got {}\".format(pos))\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5315f710-274d-4e56-a5c1-3a9584b18cdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Set Tensor: torch.Size([25000, 2493])\n"
     ]
    }
   ],
   "source": [
    "sequences_train_tensor = list(map(lambda x: torch.as_tensor(x), sequences_train))\n",
    "data_train = pad_sequence_with_pos(sequences_train_tensor, batch_first=True, pos='pre')\n",
    "print(\"Shape of Training Set Tensor:\", data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4a268-aa2a-4cc4-8a1b-f91d49a0d851",
   "metadata": {},
   "source": [
    "Handle sequence padding & packing with `Dataset` and `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a55d517-dc93-4f04-9517-2ed205739246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Pad test set & turn label series to tensors\n",
    "y_train = torch.tensor(df_train['label'].values)\n",
    "y_test = torch.tensor(df_test['label'].values)\n",
    "\n",
    "sequences_train_tensor = list(map(lambda x: torch.as_tensor(x), sequences_train))\n",
    "data_train = pad_sequence(sequences_train_tensor, batch_first=True)\n",
    "# sequences_train_tensor = torch.cat(sequences_train_tensor)\n",
    "sequences_test_tensor = list(map(lambda x: torch.as_tensor(x), sequences_test))\n",
    "data_test = pad_sequence(sequences_test_tensor, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e51a102-e417-48c8-a4dd-4666b1481b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_lengths_train = torch.tensor([len(seq) for seq in sequences_train])\n",
    "# sequence_lengths_test = torch.tensor([len(seq) for seq in sequences_test])\n",
    "# print(sequence_lengths_train)\n",
    "# print(sequence_lengths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e4eeee-75cb-4af8-9c44-bd9b1332b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `TensorDataset()`\n",
    "# train_dataset = torch.utils.data.TensorDataset(data_train, y_train)\n",
    "# test_dataset = torch.utils.data.TensorDataset(data_test, y_test)\n",
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25752839-616f-4b26-bea3-ba99aafe551d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   10,    89,   388,   135,     1,    82,   792,  1148,    20, 14896,\n",
       "            26,    44,   112,    74,     3,    52,   218,    19,   281,     7,\n",
       "             7,     1,   115,   170,     4,    11,    17,     6,     1,   484,\n",
       "             2,     1,  2205,  4939, 13886,     2,  2326, 40830,    94,    32,\n",
       "          1727,   695,  3866,   404,    21,  2043,  2103,   258,    28,   188,\n",
       "           132,    65,   102,    23,    70,  1383,    12,   149,    94,    95,\n",
       "            98,   326,   160,     7,     7,     1,   307,    10,   216,    13,\n",
       "            20, 40831,     2,    66,  2567,    15,     1,  1866,   804,    35,\n",
       "            12,    13,   431,    21,     3,   436,     1,   358,     4,  1866,\n",
       "           405,     9,    50,  6259,     7,     7,     3,    52,  2178,    17,\n",
       "          4201,    31,     1,  6985,   361,   600,   894,  1063,    25,   345,\n",
       "             9,    10,   194,     9,    13,   250,     2,   218,     2,   287,\n",
       "             3,   690,    30,   219,     3,   173,     4,  4588,    99,    16,\n",
       "          1927,  4589,     2,   228,   191,   275,    30,     1,   950,  1048,\n",
       "            23,    73,   326,   218]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, y):\n",
    "        self.data = data\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[idx], self.y[idx])\n",
    "\n",
    "train_dataset = CustomDataset(sequences_train_tensor, y_train)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef0821f-c289-491e-8243-5269d66edf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(data_train, y_train)\n",
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049b8c17-27d0-4e4a-86a8-d018836dd558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   10,    37,   196,    11,   307,     4, 31688,  3833,     2,     1,\n",
       "          2727,   307,   196,   758,     3,   114,   247,   399,     8,     1,\n",
       "            62,    34,  3414,    53,     5,    25,    32,  8951,    16, 31688,\n",
       "            11,     6,    21,     8,     1,   201,   271,     2,    12,     6,\n",
       "            58,    61,  3290,    10,   259,    37,  4934,  9042,    14, 10303,\n",
       "         37673,     2,   739,  7073,    14,  1331,     8,     1,  2727,   307,\n",
       "            18, 11839, 59093,    14, 31688,     8,     1,   245,   307,     6,\n",
       "            73,   125,   264,    10,   101,     2,   227,    50,  4269,    71,\n",
       "         68102, 68103,     8,     1,  2727,   307,    10,   101, 59093,     6,\n",
       "            50,   280,     5,     1, 14727, 31688,     8,     1,   127,    11,\n",
       "             6,     3,    52,    49,  1251,     4,     1,   664,     9,    57,\n",
       "          4190,    30,    16,   346,    14,   124,    60,    97,    21,    27,\n",
       "           221,     8,     1,  2727,   307]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = CustomDataset(sequences_test_tensor, y_test)\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35face30-e726-412b-a99d-bee11482bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    # print(xx, yy)\n",
    "\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = 1\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    yy_pad = torch.Tensor(yy)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, collate_fn=pad_collate)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876487d8-6daf-4eb6-8a17-b27bb8acde96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 906])\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "Feature batch shape: torch.Size([32])\n",
      "Text: tensor([   11,   120,   263,    53,    16,   218,  1981,    14,   699,    14,\n",
      "            1,  2107,  1305,     9,     6,  5163,    14,   632,    18,     8,\n",
      "        10134,     9,     6,  1047,  2479,    55,  1844,  1421,    42,   494,\n",
      "            5,   358,  4199,  9141,    14,     3, 12761,     5,   718,    81,\n",
      "           80,     3,  4974,  4957,    92,  4738,     5,  4363,   794,    20,\n",
      "            1,  6927,  1844,  1421,   402,     7,     7,     9,    79,  8653,\n",
      "           36,    32,   399,  6260,   497,   120, 10818,  1558,     1,  5421,\n",
      "           31, 12468,  1183,    15,    91,  6927,     5,   350,  3071,    92,\n",
      "            9, 12893,     1,  2279,   275,    45,    33,    67,  6779,     9,\n",
      "           53,    16,     3,   114,  4333,   197,     1,   102,    57,   125,\n",
      "          134,     1,   497,  2711,     6,     8,   547,  1265,  3994,  1558,\n",
      "            1,  5421,     1,   144,  8612,     4,    11,   198,     6,     5,\n",
      "         1087,   632,     7,     7,    11,   120,    44,   789,     4,   447,\n",
      "         2103,     4,  1109,   498,  5874,   632,   698,   981,    18,    45,\n",
      "          126,  3285,    20,     1,  6927,  8467,    39,  4957,    11,     6,\n",
      "          126,  3634,     4,  3378,    45,   126,    21,    11,   433,   198,\n",
      "            6,    14,    10,   132,  3571,  9361,    16, 24264,     9,     6,\n",
      "          157,   120,  3204,   493,     1,   632,  6077,    60,     6,     1,\n",
      "         5352,     9,   644,     8,  3078,     7,     7,     9,     6,  4588,\n",
      "           70,  1052,    35,     9,   235,   233,     3,   134,   243,   100,\n",
      "           29,    35,    78,   793,  1126,     4, 10665,  1107,  1415, 21219,\n",
      "            1,  5387, 12939,     1,  4170,   760,    11,    40,   149,  9743,\n",
      "         1619,   153,     1,  1658,   648,     6,    41,     1,   169,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "y: 0.0\n",
      "Length: 229\n",
      "y Length: 1\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dataloader to display text and label\n",
    "train_features, train_y, train_length, train_y_length = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(train_y)\n",
    "print(f\"Feature batch shape: {train_y.size()}\")\n",
    "#print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "text = train_features[0].squeeze()\n",
    "y = train_y[0].squeeze()\n",
    "length = train_length[0]\n",
    "y_len = train_y_length\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"Length: {length}\")\n",
    "print(f\"y Length: {y_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d0678-f69a-43ae-8f1a-0ba675aeb695",
   "metadata": {},
   "source": [
    "## 7-2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1158be5d-232b-43ed-b317-1c684609a4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c22e08d4-8e21-4b23-b3bc-aa4d088530da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs):\n",
    "        super(RNN, self).__init__()\n",
    "        self.V = n_vocab\n",
    "        self.D = embed_dim\n",
    "        self.M = n_hidden\n",
    "        self.K = n_outputs\n",
    "        self.L = n_rnnlayers\n",
    "        \n",
    "        self.embed = nn.Embedding(self.V, self.D)\n",
    "        # self.embed = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.D,\n",
    "            hidden_size=self.M,\n",
    "            num_layers=self.L,\n",
    "            # dropout=0.5,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # self.dense = nn.Linear(self.M, 256)\n",
    "        self.fc = nn.Linear(self.M, self.K)\n",
    "\n",
    "    def forward(self, X, X_lengths):\n",
    "        h_0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        c_0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        \n",
    "        out = self.embed(X)\n",
    "        out = self.dropout(out)\n",
    "        # print(out.shape)\n",
    "        # (32, 999, 128)torch.Size([32, 698, 128])\n",
    "        out = torch.nn.utils.rnn.pack_padded_sequence(out, X_lengths, batch_first=True, enforce_sorted=False)\n",
    "        out, _ = self.rnn(out, (h_0, c_0))\n",
    "        out, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        #print(out.shape)\n",
    "        #torch.Size([698, 32, 256])\n",
    "        # out = self.dense(out)\n",
    "        # out = nn.functional.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out, _ = torch.max(out, 1)\n",
    "        #print(out.shape)\n",
    "        #torch.Size([698, 256])\n",
    "        out = self.fc(out)\n",
    "        #print(out.shape)\n",
    "        #torch.Size([698, 1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c902e0d-97f6-41e8-b5bd-f1de90efdf77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embed): Embedding(88583, 128)\n",
       "  (rnn): LSTM(128, 32, batch_first=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(V+1, 128, 32, 1, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce65437f-651d-4d72-b45f-dead49685e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6777, Test Loss: 0.6514, Duration: 0:00:17.182787\n",
      "Epoch 2/10, Train Loss: 0.5681, Test Loss: 0.5043, Duration: 0:00:16.965491\n",
      "Epoch 3/10, Train Loss: 0.4337, Test Loss: 0.4188, Duration: 0:00:16.535316\n",
      "Epoch 4/10, Train Loss: 0.3648, Test Loss: 0.3906, Duration: 0:00:16.793443\n",
      "Epoch 5/10, Train Loss: 0.3233, Test Loss: 0.3696, Duration: 0:00:16.790974\n",
      "Epoch 6/10, Train Loss: 0.2886, Test Loss: 0.3645, Duration: 0:00:16.974890\n",
      "Epoch 7/10, Train Loss: 0.2699, Test Loss: 0.3594, Duration: 0:00:16.828900\n",
      "Epoch 8/10, Train Loss: 0.2464, Test Loss: 0.3501, Duration: 0:00:16.804966\n",
      "Epoch 9/10, Train Loss: 0.2295, Test Loss: 0.3548, Duration: 0:00:16.981852\n",
      "Epoch 10/10, Train Loss: 0.2108, Test Loss: 0.3545, Duration: 0:00:16.733287\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "    for it in range(epochs):\n",
    "        t_0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets, x_lens, y_lens in train_loader:\n",
    "            # print(\"inputs.shape:\", inputs.shape, \"targets.shape\", targets.shape)\n",
    "            targets = targets.view(-1, 1).float()\n",
    "            # Move data to GPU\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs, x_lens)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward & optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        # Get train loss & test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        test_loss = []\n",
    "        for inputs, targets, x_lens, y_lens in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.view(-1, 1).float()\n",
    "            outputs = model(inputs, x_lens)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "\n",
    "        dt = datetime.now() - t_0\n",
    "        print(f\"Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Duration: {dt}\")\n",
    "    return train_losses, test_losses\n",
    "\n",
    "train_losses, test_losses = batch_gd(model, criterion, optimizer, train_dataloader, test_dataloader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25e1d906-4b5f-4605-824c-28918f11d843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(train_losses, label=\"train loss\")\n",
    "plt.plot(test_losses, label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bc91aba-dd70-4905-90b1-5335fd37c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9232, Test acc: 0.8516\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "for inputs, targets, x_lens, y_lens in train_dataloader:\n",
    "  targets = targets.view(-1, 1).float()\n",
    "  inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "  # Forward pass\n",
    "  outputs = model(inputs, x_lens)\n",
    "\n",
    "  # Get prediction\n",
    "  predictions = (outputs > 0)\n",
    "  \n",
    "  # update counts\n",
    "  n_correct += (predictions == targets).sum().item()\n",
    "  n_total += targets.shape[0]\n",
    "\n",
    "train_acc = n_correct / n_total\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "for inputs, targets, x_lens, y_lens in test_dataloader:\n",
    "  targets = targets.view(-1, 1).float()\n",
    "  inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "  # Forward pass\n",
    "  outputs = model(inputs, x_lens)\n",
    "\n",
    "  # Get prediction\n",
    "  predictions = (outputs > 0)\n",
    "  \n",
    "  # update counts\n",
    "  n_correct += (predictions == targets).sum().item()\n",
    "  n_total += targets.shape[0]\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d689cec-fd1e-426e-9090-96b739153f9d",
   "metadata": {},
   "source": [
    "# 2. GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c17838-fc1f-4a3e-b02b-76280369d6a8",
   "metadata": {},
   "source": [
    "# 3. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512193-998a-41f1-8a16-5de2368a3cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
