{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880ff17a-cf78-46b0-aca5-43cd45f9bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab94ae-4641-4f7e-b2dc-f13c5f256607",
   "metadata": {},
   "source": [
    "# 1. Seq2seq\n",
    "\n",
    "**Seq2seq (Sequence to Sequence)** is an RNN encoder-decoder framework for **Neural Machine Translation**, or more generally **Sequence Transduction**, specifically by encoding a variable-length source sentence into a fixed-shape vector. The latter would then be decoded into a variable-length target sentence. \n",
    "- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n",
    "- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) by Ilya Sutskever & Quoc Le at Google Brain\n",
    "\n",
    "Conventionally, in an RNN all relevant information about a source sequence is translated into some internal fixed-dimensional state representation by the encoder. It is this very state that is used by the decoder as the complete and exclusive source of information for generating the translated sequence. In other words, the sequence-to-sequence mechanism treats the intermediate state as a sufficient statistic of whatever string might have served as input.\n",
    "\n",
    "# 2. Attention Mechanisms\n",
    "## 2-1. Neural Machine Translation with Bahdanau Attention\n",
    "1. `torch.utils.data.RandomSampler(data_source, replacement=False, num_samples=None, generator=None)`: Samples elements randomly. If without replacement, then sample from a shuffled dataset.\n",
    "\n",
    "The dataset is derived from the open translation website, [Tatoeba Project](https://tatoeba.org/en), and [Tab-Delimited Bilingual Sentence Pairs](https://www.manythings.org/anki/) splitting languages into individual text files. We will trim the dataset to only relatively short & simple sentences by setting the maximum length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5832d943-180f-4cc0-bc6b-5a32a2d58512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata, re\n",
    "\n",
    "# Turn a Unicode string to plain ASCII\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(string):\n",
    "    string = unicode_to_ascii(string.lower().strip())\n",
    "    string = re.sub(r\"([.!?])\", r\" \\1\", string)\n",
    "    string = re.sub(r\"[^a-zA-Z!?]+\", r\" \", string)\n",
    "    return string.strip()\n",
    "\n",
    "max_length = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filter_pair(pair):\n",
    "    return len(pair[0].split(' ')) < max_length and len(pair[1].split(' ')) < max_length and pair[1].startswith(eng_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "425a0b49-7e60-4f93-964e-e21eb4f91fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = 0\n",
    "eos_token = 1\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2idx = {}\n",
    "        self.word_count = {}\n",
    "        self.idx2word = {0: \"<SOS>\", 1: \"<EOS>\"}\n",
    "        # Count `<SOS>` & `<EOS>`\n",
    "        self.num_words = 2\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.num_words\n",
    "            self.word_count[word] = 1\n",
    "            self.idx2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word_count[word] += 1\n",
    "\n",
    "def read_languages(language_1, language_2, reverse=False):\n",
    "    print(\"Reading Lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('datasets/name_languages/%s-%s.txt' % (language_1, language_2), encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make `Language` instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_language = Language(language_2)\n",
    "        output_language = Language(language_1)\n",
    "    else:\n",
    "        input_language = Language(language_1)\n",
    "        output_language = Language(language_2)\n",
    "\n",
    "    return input_language, output_language, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc2b92fa-c4ab-42e3-8f83-2c765ddeaf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Lines...\n",
      "Read 135842 sentence pairs.\n",
      "Trimmed to 11445 sentence pairs.\n",
      "Counting Words...\n",
      "Counted Words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "['nous sommes du meme cote', 'we re on the same side']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "def prepare_data(language_1, language_2, reverse=False):\n",
    "    input_language, output_language, pairs = read_languages(language_1, language_2, reverse)\n",
    "    print(\"Read %s sentence pairs.\" % len(pairs))\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs.\" % len(pairs))\n",
    "    print(\"Counting Words...\")\n",
    "    for pair in pairs:\n",
    "        input_language.add_sentence(pair[0])\n",
    "        output_language.add_sentence(pair[1])\n",
    "    print(\"Counted Words:\")\n",
    "    print(input_language.name, input_language.num_words)\n",
    "    print(output_language.name, output_language.num_words)\n",
    "    return input_language, output_language, pairs\n",
    "\n",
    "input_language, output_language, pairs = prepare_data('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c4d15e4-9ed2-4063-ae65-bfac591e4bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Lines...\n",
      "Read 135842 sentence pairs.\n",
      "Trimmed to 11445 sentence pairs.\n",
      "Counting Words...\n",
      "Counted Words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "Input Shape: (11445, 10)\n",
      "Target Shape: (11445, 10)\n",
      "Dataset Size: 11445\n",
      "Dataset Sample:\n",
      "(tensor([2, 3, 4, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'), tensor([2, 3, 4, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "Feature Batch Shape: torch.Size([32, 10])\n",
      "Labels Batch Shape: torch.Size([32, 10])\n",
      "Feature Batch Sample:\n",
      "tensor([[ 121,  124,  568,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 209,  210,  305,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 209,  210, 1510,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 209,  210,  201,  980,   99,  629, 2392,    1,    0,    0],\n",
      "        [ 209,  210, 1289,  144,  113,  601, 3008, 4070,    1,    0],\n",
      "        [   2,    7,  669,   99, 2127, 4081,    1,    0,    0,    0],\n",
      "        [ 121,  124,  193,  194,  196,    1,    0,    0,    0,    0],\n",
      "        [ 244, 1581, 1362,   64,  884,   23, 3897,    1,    0,    0],\n",
      "        [  20,   21,  278,  113,  425,  223,  359,  689,    1,    0],\n",
      "        [ 216,  210,   64, 2021, 3412,    1,    0,    0,    0,    0],\n",
      "        [ 347,  348, 1460,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 121,  122,   99,  247, 1722,    1,    0,    0,    0,    0],\n",
      "        [ 121,  124,  193,  194,    1,    0,    0,    0,    0,    0],\n",
      "        [ 116,  213, 1051,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 116,  213,  320,  690,    1,    0,    0,    0,    0,    0],\n",
      "        [   2, 2646, 2107,  452,  137,  452, 4173, 2703,    1,    0],\n",
      "        [ 121,  124,  706,  643,    1,    0,    0,    0,    0,    0],\n",
      "        [   2,    7,  442,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [  20,  296, 2665,  245,  232,   64,   20,    1,    0,    0],\n",
      "        [  20,  244,   21,  245,  201,  729, 1888,    1,    0,    0],\n",
      "        [  29,   30, 1411,   32,    1,    0,    0,    0,    0,    0],\n",
      "        [ 347,  348,  349,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [  20,  113,  656,   99, 1388,    1,    0,    0,    0,    0],\n",
      "        [ 121,   10,  122, 1120,   32,    1,    0,    0,    0,    0],\n",
      "        [ 121,  124,  772,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [   2,    7, 1175, 1451,   99,  700,    1,    0,    0,    0],\n",
      "        [ 116,  213,   60,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 350,  760,  996,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [  29, 2315,  201,   47,    1,    0,    0,    0,    0,    0],\n",
      "        [ 209,  241,  452,  167,   99,  247, 1544,    1,    0,    0],\n",
      "        [   2,    7,  110,  232, 1887,  688,    1,    0,    0,    0],\n",
      "        [ 121,  559,   64, 1395, 2263,    1,    0,    0,    0,    0]],\n",
      "       device='cuda:0')\n",
      "Labels Batch Sample:\n",
      "tensor([[  76,   77,  113,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 128,   77,  190,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 128,   77, 1271,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 128,   77,  293,  884,  517,  144, 2168,    1,    0,    0],\n",
      "        [ 128,   77,  293,  516, 1740, 2785,  694, 2556,    1,    0],\n",
      "        [   2,    3,  882,  676, 1480, 2564,    1,    0,    0,    0],\n",
      "        [  76,  123,   18,  124,    1,    0,    0,    0,    0,    0],\n",
      "        [   2,    3,    4,  676,  500,  387,  516,  468,    1,    0],\n",
      "        [  13,   39,  168,  531,  144, 1644,  663,    1,    0,    0],\n",
      "        [ 128,   77,   41, 2098,   43, 2016,    1,    0,    0,    0],\n",
      "        [ 220,  123,  804,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [  76,   77,  947,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [  76,  123,  124,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 128,   77,  332,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 128,   77,  200,  380,    1,    0,    0,    0,    0,    0],\n",
      "        [   2,    3,  295,  517, 1055,   84, 1591, 2634,    1,    0],\n",
      "        [  76,  123,  588,  677,    1,    0,    0,    0,    0,    0],\n",
      "        [   2,   15,  252,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [  13,   39,   51,  101,  516, 1561,    1,    0,    0,    0],\n",
      "        [  13,  536,  537,   45,   39,   13, 1050,    1,    0,    0],\n",
      "        [   2,    3,  762,   21,    1,    0,    0,    0,    0,    0],\n",
      "        [ 220,   77,  129,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [  13,   39,  359,  517,  746,    1,    0,    0,    0,    0],\n",
      "        [  76,   77, 1101,  259,    1,    0,    0,    0,    0,    0],\n",
      "        [  76,   77,  161,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [   2,    3,  449,  795,  517,  694,    1,    0,    0,    0],\n",
      "        [ 128,  123,   43,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [ 220,   77,  154,   63,    1,    0,    0,    0,    0,    0],\n",
      "        [   2,    3, 1341, 1342,    1,    0,    0,    0,    0,    0],\n",
      "        [ 128,   77,  394,    1,    0,    0,    0,    0,    0,    0],\n",
      "        [   2,   15,   71,  517,  388,  531,  377,    1,    0,    0],\n",
      "        [  76,   77, 1268, 1299,  754,    1,    0,    0,    0,    0]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "def indexes_from_sentence(language, sentence):\n",
    "    return [language.word2idx[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensor_from_sentence(language, sentence):\n",
    "    indexes = indexes_from_sentence(language, sentence)\n",
    "    indexes.append(eos_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensors_from_pair(pair):\n",
    "    input_tensor = tensor_from_sentence(input_language, pair[0])\n",
    "    target_tensor = tensor_from_sentence(output_language, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_language, output_language, pairs = prepare_data('eng', 'fra', True)\n",
    "\n",
    "    num_pairs = len(pairs)\n",
    "    input_ids = np.zeros((num_pairs, max_length), dtype=np.int32)\n",
    "    target_ids = np.zeros((num_pairs, max_length), dtype=np.int32)\n",
    "\n",
    "    for idx, (input_sentence, target_sentence) in enumerate(pairs):\n",
    "        input_sentence_ids = indexes_from_sentence(input_language, input_sentence)\n",
    "        target_sentence_ids = indexes_from_sentence(output_language, target_sentence)\n",
    "        input_sentence_ids.append(eos_token)\n",
    "        target_sentence_ids.append(eos_token)\n",
    "        input_ids[idx, :len(input_sentence_ids)] = input_sentence_ids\n",
    "        target_ids[idx, :len(target_sentence_ids)] = target_sentence_ids\n",
    "\n",
    "    print(\"Input Shape:\", input_ids.shape)\n",
    "    print(\"Target Shape:\", target_ids.shape)\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device), torch.LongTensor(target_ids).to(device))\n",
    "    print(\"Dataset Size:\", train_data.__len__())\n",
    "    print(\"Dataset Sample:\")\n",
    "    print(train_data.__getitem__(0))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # Iterate through the `DataLoader` & print shapes\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    print(f\"Feature Batch Shape: {train_features.size()}\")\n",
    "    print(f\"Labels Batch Shape: {train_labels.size()}\")\n",
    "    print(\"Feature Batch Sample:\")\n",
    "    print(train_features)\n",
    "    print(\"Labels Batch Sample:\")\n",
    "    print(train_labels)\n",
    "\n",
    "    return input_language, output_language, train_dataloader\n",
    "\n",
    "batch_size = 32\n",
    "input_language, output_language, train_dataloader = get_dataloader(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e77b02-8ad9-4a27-8e0b-95e48ca0e656",
   "metadata": {},
   "source": [
    "### 2-1-1. Encoder with Gated Recurrent Units (GRUs)\n",
    "The encoder of a seq2seq network is a recurrent neural network (RNN) that outputs some value for every word from the input sequence. For every input word the encoder outputs a vector & a hidden state, and uses the hidden state for the next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da276cc-287b-41fd-9c28-c540bacbe396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class EncoderGRUNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_prob=0.1):\n",
    "        super(EncoderGRUNeuralNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc2aa3-e157-4eaa-b942-6c519d12c9ce",
   "metadata": {},
   "source": [
    "### 2-1-2. Decoder with Gated Recurrent Units (GRUs)\n",
    "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string, `<SOS>`, token. In the simplest seq2seq decoder we use only last output of the encoder, which is called **Context Vector** as it encodes context from the entire sequence, for the initial hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac695398-68d2-456b-aec9-f930a7b10831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRUNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderGRUNeuralNetwork, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.output = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(sos_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(max_length):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # With teacher forcing feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) \n",
    "            else:\n",
    "                # Without teacher forcing use its own predictions as the next input\n",
    "                _, top_idx = decoder_output.topk(1)\n",
    "                # Detach from history as input\n",
    "                decoder_input = top_idx.squeeze(-1).detach()  \n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = torch.nn.functional.log_softmax(decoder_outputs, dim=-1)\n",
    "        # Return `None` for consistency in the training loop\n",
    "        return decoder_outputs, decoder_hidden, None \n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.output(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe88105-d66c-4eec-a1cf-0a83769b104c",
   "metadata": {},
   "source": [
    "### 2-1-3. Bahdanau Attention\n",
    "**Bahdanau Attention**, or **Addition Attention**, is a commonly used attention mechanism in seq2seq models, particularly in neural machine translation tasks. The encoding of a variable-length input into a fixed-length vector squashes the information of the source sentence, irrespective of its length, causing the performance of a basic encoder-decoder model to deteriorate rapidly with an increasing length of the input sentence.\n",
    "\n",
    "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "\n",
    "In the original research, it employs a bidirectional RNN as an encoder, which generates an annotation for each word in an input sequence, and an RNN decoder, which combines each annotation and the previous hidden decoder state using an addition attention. A learned alignment model, parameterized as a feed-forward neural network & jointly trained with the remaining system components, is used to compute attention scores between the encoder and decoder hidden states.\n",
    "\n",
    "1. `torch.bmm(input, mat2, *, out=None)`: Performs a batch matrix-matrix product of matrices stored in `input` and `mat2`, which both of them must be three-dimensional tensors each containing the same number of matrices. If `input` is a $(b, n, m)$ tensor, `mat2` is a $(b, m, p)$ tensor, then `out` will be a $(b, n, p)$ tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368847fe-7080-4da8-8bf5-a9333ad60d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(torch.nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        # Calculate attention scores\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class BahdanauAttentionDecoderGRUNeuralNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_prob=0.1):\n",
    "        super(BahdanauAttentionDecoderGRUNeuralNetwork, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = torch.nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.output = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(sos_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(max_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # With teacher forcing feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                # Without teacher forcing use its own predictions as the next input\n",
    "                _, top_idx = decoder_output.topk(1)\n",
    "                # Detach from history as input\n",
    "                decoder_input = top_idx.squeeze(-1).detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = torch.nn.functional.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.output(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f7e5d0e-073b-4119-9286-1bb5064542fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))\n",
    "\n",
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # This locator puts ticks at regular intervals\n",
    "    locator = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(locator)\n",
    "    plt.plot(points)\n",
    "\n",
    "def train(train_dataloader, encoder, decoder, num_epochs, learning_rate=0.001, print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    # Reset every `print_every`\n",
    "    print_loss_total = 0\n",
    "    # Reset every `plot_every`\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (time_since(start, epoch / num_epochs), epoch, epoch / num_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec056612-caaf-44b0-891c-4d21bb5045cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_language, output_language):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensor_from_sentence(input_language, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, top_idx = decoder_outputs.topk(1)\n",
    "        decoded_ids = top_idx.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == eos_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_language.idx2word[idx.item()])\n",
    "    return decoded_words, decoder_attn\n",
    "\n",
    "def evaluate_randomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_language, output_language)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        # Print empty lines betweem samples if not the last one\n",
    "        if i != n - 1:\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e7d29ad-7f82-4642-8244-5605fd2a5cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 11s (- 2m 49s) (5 6%) 1.5440\n",
      "0m 21s (- 2m 32s) (10 12%) 0.6843\n",
      "0m 32s (- 2m 20s) (15 18%) 0.3545\n",
      "0m 42s (- 2m 8s) (20 25%) 0.1979\n",
      "0m 53s (- 1m 57s) (25 31%) 0.1234\n",
      "1m 4s (- 1m 47s) (30 37%) 0.0862\n",
      "1m 15s (- 1m 37s) (35 43%) 0.0648\n",
      "1m 26s (- 1m 26s) (40 50%) 0.0541\n",
      "1m 37s (- 1m 15s) (45 56%) 0.0456\n",
      "1m 48s (- 1m 4s) (50 62%) 0.0412\n",
      "1m 58s (- 0m 54s) (55 68%) 0.0373\n",
      "2m 9s (- 0m 43s) (60 75%) 0.0350\n",
      "2m 20s (- 0m 32s) (65 81%) 0.0336\n",
      "2m 31s (- 0m 21s) (70 87%) 0.0314\n",
      "2m 42s (- 0m 10s) (75 93%) 0.0302\n",
      "2m 53s (- 0m 0s) (80 100%) 0.0292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "\n",
    "encoder = EncoderGRUNeuralNetwork(input_language.num_words, hidden_size).to(device)\n",
    "decoder = BahdanauAttentionDecoderGRUNeuralNetwork(hidden_size, output_language.num_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, num_epochs=80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9ffe81b-340a-4cd9-a9d5-51697fe0936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> il est le plus grand des deux\n",
      "= he is the taller of the two\n",
      "< he is the taller of the two <EOS>\n",
      "\n",
      "> il est fort courageux\n",
      "= he is very brave\n",
      "< he is very brave <EOS>\n",
      "\n",
      "> vous n etes pas encore mort\n",
      "= you re not dead yet\n",
      "< you re not dead yet <EOS>\n",
      "\n",
      "> il est un peu ivre\n",
      "= he s a bit drunk\n",
      "< he s a bit drunk <EOS>\n",
      "\n",
      "> nous n en avons pas termine\n",
      "= we re not done\n",
      "< we re not done <EOS>\n",
      "\n",
      "> je vais avoir besoin de plus de temps\n",
      "= i m going to need some more time\n",
      "< i m going to need some more time <EOS>\n",
      "\n",
      "> vous etes tres astucieuses\n",
      "= you re very astute\n",
      "< you re very astute <EOS>\n",
      "\n",
      "> je requiers ton aide\n",
      "= i m asking you for your help\n",
      "< i m asking you for your help <EOS>\n",
      "\n",
      "> je ne suis pas si presse\n",
      "= i m not in that much of a hurry\n",
      "< i m not in that much of a hurry <EOS>\n",
      "\n",
      "> je suis plutot content\n",
      "= i m fairly happy\n",
      "< i m fairly happy <EOS>\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluate_randomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d1a9954-e85c-4f35-9062-b83a25380830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Attention:\n",
      "tensor([[[3.8052e-02, 3.3325e-01, 1.5430e-01, 1.3771e-01, 2.5129e-01,\n",
      "          2.6021e-02, 2.2861e-02, 1.5383e-02, 1.8317e-02, 2.8240e-03],\n",
      "         [2.2669e-04, 1.2873e-03, 5.8983e-04, 9.3445e-02, 2.4531e-01,\n",
      "          1.7962e-01, 1.7801e-01, 1.2158e-01, 1.4049e-01, 3.9445e-02],\n",
      "         [2.3186e-03, 8.1286e-02, 4.6676e-02, 3.7880e-01, 3.7287e-01,\n",
      "          4.2105e-02, 4.4898e-02, 1.1891e-02, 1.4720e-02, 4.4345e-03],\n",
      "         [1.0716e-04, 3.5082e-04, 4.8032e-05, 2.1164e-02, 6.7391e-01,\n",
      "          9.1989e-02, 6.3175e-02, 7.5774e-02, 5.5719e-02, 1.7765e-02],\n",
      "         [1.0064e-06, 8.6094e-07, 2.8683e-06, 3.8114e-05, 2.1602e-02,\n",
      "          2.3130e-01, 2.0626e-01, 2.3559e-01, 2.6166e-01, 4.3544e-02],\n",
      "         [9.2085e-08, 1.2156e-07, 7.8310e-07, 1.4651e-05, 5.1336e-03,\n",
      "          3.4612e-02, 2.3286e-01, 3.9058e-01, 2.4398e-01, 9.2816e-02],\n",
      "         [2.9240e-09, 2.9445e-08, 2.9455e-08, 2.1786e-05, 2.6234e-03,\n",
      "          5.0081e-03, 3.9052e-03, 3.5720e-01, 4.0450e-01, 2.2675e-01],\n",
      "         [2.2021e-09, 8.1641e-09, 2.4347e-08, 3.6414e-06, 1.8195e-04,\n",
      "          1.5381e-03, 4.1047e-03, 1.5778e-01, 5.3550e-01, 3.0090e-01],\n",
      "         [5.8407e-10, 1.9398e-09, 1.6121e-08, 9.1258e-06, 5.0909e-05,\n",
      "          1.4362e-03, 5.9054e-04, 2.9090e-02, 1.2259e-01, 8.4623e-01],\n",
      "         [1.0193e-09, 6.4704e-09, 1.1689e-08, 7.3423e-06, 5.4390e-05,\n",
      "          1.0909e-03, 1.4972e-03, 1.1701e-01, 2.7733e-01, 6.0302e-01]]],\n",
      "       device='cuda:0')\n",
      "Attention Shape: torch.Size([1, 10, 10])\n",
      "Input Sentence: il n est pas aussi grand que son pere\n",
      "output Words: he is not as tall as his father <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_567401/1572440452.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
      "/tmp/ipykernel_567401/1572440452.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Attention:\n",
      "tensor([[[4.3554e-01, 3.4978e-02, 1.5061e-01, 1.7389e-01, 5.7214e-02,\n",
      "          1.3638e-01, 1.1388e-02],\n",
      "         [4.4103e-04, 2.4309e-04, 1.4897e-01, 6.2378e-01, 1.0226e-02,\n",
      "          1.9708e-01, 1.9256e-02],\n",
      "         [3.6976e-04, 3.9402e-04, 9.2100e-01, 6.6431e-02, 1.0558e-02,\n",
      "          1.0195e-03, 2.2268e-04],\n",
      "         [3.8476e-04, 1.7453e-04, 1.7084e-02, 8.4998e-01, 7.6120e-02,\n",
      "          5.0987e-02, 5.2681e-03],\n",
      "         [3.2406e-06, 1.5784e-06, 2.5433e-04, 5.8591e-02, 2.5236e-01,\n",
      "          5.9901e-01, 8.9776e-02],\n",
      "         [5.8227e-08, 5.4780e-08, 3.7763e-05, 6.4751e-02, 2.6292e-02,\n",
      "          7.2828e-01, 1.8064e-01],\n",
      "         [6.9161e-08, 2.1063e-08, 1.2070e-05, 1.4800e-03, 6.7318e-04,\n",
      "          4.7436e-01, 5.2347e-01],\n",
      "         [1.7623e-08, 1.3590e-08, 1.7409e-05, 1.5054e-03, 5.5899e-04,\n",
      "          6.9992e-01, 2.9800e-01],\n",
      "         [1.2136e-08, 5.7767e-08, 1.3048e-04, 2.9330e-02, 1.1816e-03,\n",
      "          7.1837e-01, 2.5099e-01],\n",
      "         [4.2042e-08, 3.8790e-07, 6.2532e-04, 6.6575e-02, 2.9051e-03,\n",
      "          3.8768e-01, 5.4222e-01]]], device='cuda:0')\n",
      "Attention Shape: torch.Size([1, 10, 7])\n",
      "Input Sentence: je suis trop fatigue pour conduire\n",
      "output Words: i am too tired to drive <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_567401/1572440452.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
      "/tmp/ipykernel_567401/1572440452.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Attention:\n",
      "tensor([[[4.4646e-01, 7.5509e-02, 2.2904e-01, 1.1369e-01, 4.6290e-02,\n",
      "          2.7662e-02, 1.3278e-02, 2.6403e-02, 1.7943e-02, 3.7250e-03],\n",
      "         [6.1199e-05, 3.4543e-05, 9.7702e-02, 5.1603e-01, 5.8891e-02,\n",
      "          9.1750e-02, 3.6629e-02, 8.4077e-02, 9.5820e-02, 1.9010e-02],\n",
      "         [1.3093e-04, 2.9958e-04, 6.7707e-01, 3.0907e-01, 3.4263e-03,\n",
      "          3.0145e-03, 1.4361e-03, 4.4527e-03, 9.1890e-04, 1.8519e-04],\n",
      "         [4.4561e-06, 2.5824e-06, 4.7770e-03, 5.9482e-01, 1.4016e-01,\n",
      "          6.7075e-02, 2.9370e-02, 7.5699e-02, 6.9208e-02, 1.8879e-02],\n",
      "         [1.3148e-04, 3.4638e-05, 4.2033e-03, 8.8291e-02, 3.3482e-01,\n",
      "          1.4520e-01, 5.8968e-02, 1.6163e-01, 1.6022e-01, 4.6500e-02],\n",
      "         [2.6767e-07, 4.8416e-08, 3.7955e-04, 1.7293e-02, 7.1557e-02,\n",
      "          4.5458e-02, 9.6183e-02, 2.5829e-01, 3.8983e-01, 1.2101e-01],\n",
      "         [3.5214e-06, 3.8356e-07, 8.2853e-04, 2.2998e-02, 1.9928e-02,\n",
      "          3.8960e-02, 8.5175e-02, 5.1169e-01, 2.4155e-01, 7.8864e-02],\n",
      "         [6.1313e-08, 1.7469e-08, 6.6936e-05, 1.5136e-03, 1.9376e-02,\n",
      "          1.6601e-02, 6.7429e-02, 1.0482e-01, 5.1291e-01, 2.7728e-01],\n",
      "         [1.8778e-07, 2.1214e-07, 1.0265e-04, 1.0338e-03, 7.0380e-03,\n",
      "          3.9868e-02, 4.0576e-02, 2.6749e-02, 6.5007e-01, 2.3457e-01],\n",
      "         [2.1761e-09, 6.7686e-09, 6.2390e-06, 4.5991e-05, 8.4413e-04,\n",
      "          1.2609e-02, 1.0667e-01, 4.6228e-02, 3.2331e-01, 5.1029e-01]]],\n",
      "       device='cuda:0')\n",
      "Attention Shape: torch.Size([1, 10, 10])\n",
      "Input Sentence: je suis desole si c est une question idiote\n",
      "output Words: i m sorry if this is a stupid question <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_567401/1572440452.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
      "/tmp/ipykernel_567401/1572440452.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Attention:\n",
      "tensor([[[5.6678e-01, 5.4391e-02, 1.0181e-01, 1.4862e-01, 5.3501e-02,\n",
      "          6.4664e-02, 1.0240e-02],\n",
      "         [4.5626e-04, 1.6115e-04, 7.7397e-02, 5.6768e-01, 6.9028e-02,\n",
      "          2.1635e-01, 6.8927e-02],\n",
      "         [1.1521e-04, 2.5682e-04, 6.4028e-01, 3.0824e-01, 3.9454e-02,\n",
      "          1.1238e-02, 4.1504e-04],\n",
      "         [5.4609e-05, 5.1073e-06, 1.5508e-02, 7.5872e-01, 1.7726e-01,\n",
      "          4.1564e-02, 6.8876e-03],\n",
      "         [3.3952e-04, 3.5322e-05, 3.8563e-03, 1.0088e-01, 2.8000e-01,\n",
      "          5.0211e-01, 1.1277e-01],\n",
      "         [1.6078e-07, 9.2564e-08, 1.5715e-04, 6.1031e-03, 1.3506e-01,\n",
      "          5.9768e-01, 2.6100e-01],\n",
      "         [1.2991e-07, 6.2935e-08, 1.8821e-04, 2.6679e-03, 5.4962e-02,\n",
      "          3.8195e-01, 5.6023e-01],\n",
      "         [1.7365e-08, 3.1211e-09, 6.7585e-05, 4.0400e-04, 6.4256e-04,\n",
      "          2.6367e-02, 9.7252e-01],\n",
      "         [9.6447e-09, 1.3819e-08, 1.7543e-05, 5.5388e-04, 8.4358e-03,\n",
      "          1.1766e-01, 8.7333e-01],\n",
      "         [8.5280e-09, 1.7578e-08, 4.2613e-05, 4.5597e-04, 2.6188e-03,\n",
      "          8.6916e-02, 9.0997e-01]]], device='cuda:0')\n",
      "Attention Shape: torch.Size([1, 10, 7])\n",
      "Input Sentence: je suis reellement fiere de vous\n",
      "output Words: i m really proud of you <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_567401/1572440452.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
      "/tmp/ipykernel_567401/1572440452.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Setup axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_language, output_language)\n",
    "    print(\"Sample Attention:\")\n",
    "    print(attentions)\n",
    "    print(\"Attention Shape:\", attentions.shape)\n",
    "    print('Input Sentence:', input_sentence)\n",
    "    print('output Words:', ' '.join(output_words))\n",
    "    show_attention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "evaluate_and_show_attention('il n est pas aussi grand que son pere')\n",
    "evaluate_and_show_attention('je suis trop fatigue pour conduire')\n",
    "evaluate_and_show_attention('je suis desole si c est une question idiote')\n",
    "evaluate_and_show_attention('je suis reellement fiere de vous')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a38757e-bf69-47a7-8182-a2006c970080",
   "metadata": {},
   "source": [
    "# 2. Transformers\n",
    "- [Attention is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar\n",
    "## 2-1. Multi-Head Self-Attention\n",
    "As the model processes each word, **Self-Attention** allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word. It is the method the Transformer uses to bake the understanding of other relevant words into the one we are currently processing. The steps are as follows:\n",
    "- Creates three vectors (a **Query Vector**, a **Key Vector** & **a Value Vector**) from each of the encoder's input vectors (the embedding of each word). These vectors are created by multiplying the embedding by three matrices that we trained during the training process. They are usually smaller in dimension than the embedding vector.\n",
    "- Calculates scores by taking the dot product of the query vector with the key vector of the respective word we are scoring.\n",
    "- Divides the scores by the square root of the dimension of the key vectors. This leads to having more stable gradients.\n",
    "- Passes the result through a softmax operation for normalization so that they are all positive & add up to $1$. This softmax score determines how much each word will be expressed at this position.\n",
    "- Multiplies each value vector by the softmax score. Keeps intact the values of the words we want to focus on & drown-out irrelevant words.\n",
    "- Sums up the weighted value vectors. Produces the output of the self-attention layer at this position for the first word.\n",
    "\n",
    "**Multi-Head Attention** is a module for attention mechanisms which runs through an attention mechanism several times in parallel. The independent attention outputs are then concatenated and linearly transformed into the expected dimension. Multiple attention heads allows for attending to parts of the sequence differently, such as longer-term dependencies versus shorter-term dependencies.\n",
    "\n",
    "1. `torch.Tensor.masked_fill(mask, value)`: Fills elements of `self` tensor with `value` where `mask` is `True`. The shape of `mask` must be broadcastable with the shape of the underlying tensor.\n",
    "\n",
    "- [Masked Attention](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)#Masked_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02dfde8c-dd1b-417d-b616-3be3f234cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, dim_k, dim_model, num_heads, maximum_length, causal=False):\n",
    "        super().__init__()\n",
    "    \n",
    "        # Assume `dim_v = dim_k`\n",
    "        self.dim_k = dim_k\n",
    "        self.num_heads = num_heads\n",
    "    \n",
    "        self.key = torch.nn.Linear(dim_model, dim_k * num_heads)\n",
    "        self.query = torch.nn.Linear(dim_model, dim_k * num_heads)\n",
    "        self.value = torch.nn.Linear(dim_model, dim_k * num_heads)\n",
    "    \n",
    "        # Final linear layer\n",
    "        self.linear = torch.nn.Linear(dim_k * num_heads, dim_model)\n",
    "    \n",
    "        # Causal mask \n",
    "        # Make it so that diagonal is `0` too\n",
    "        # This way we don't have to shift the inputs to make targets\n",
    "        self.causal = causal\n",
    "        if causal:\n",
    "            causal_mask = torch.tril(torch.ones(maximum_length, maximum_length))\n",
    "            self.register_buffer(\"causal_mask\", causal_mask.view(1, 1, maximum_length, maximum_length))\n",
    "\n",
    "    def forward(self, q, k, v, pad_mask=None):\n",
    "        # `N` is batch size; `T` means \n",
    "        # `(N, T, h * dim_k)`\n",
    "        q = self.query(q)\n",
    "        # `(N, T, h * dim_k)`\n",
    "        k = self.key(k)\n",
    "        # `(N, T, h * dim_v)`\n",
    "        v = self.value(v)\n",
    "    \n",
    "        N = q.shape[0]\n",
    "        T_output = q.shape[1]\n",
    "        T_input = k.shape[1]\n",
    "    \n",
    "        # Change the shape from `(N, T, h, dim_k)` to `(N, h, T, dim_k)` in order for matrix multiplication to work properly\n",
    "        q = q.view(N, T_output, self.num_heads, self.dim_k).transpose(1, 2)\n",
    "        k = k.view(N, T_input, self.num_heads, self.dim_k).transpose(1, 2)\n",
    "        v = v.view(N, T_input, self.num_heads, self.dim_k).transpose(1, 2)\n",
    "    \n",
    "        # Compute attention weights\n",
    "        # `(N, h, T, d_k)` x `(N, h, d_k, T)` to `(N, h, T, T)`\n",
    "        attn_scores = q @ k.transpose(-2, -1) / math.sqrt(self.dim_k)\n",
    "        if pad_mask is not None:\n",
    "            # `(N, T)` to `(N, 1, 1, T)`; Use `float('-inf')` because the result it takes softmax is `0`\n",
    "            attn_scores = attn_scores.masked_fill(pad_mask[:, None, None, :] == 0, float('-inf'))\n",
    "        if self.causal:\n",
    "            attn_scores = attn_scores.masked_fill(self.causal_mask[:, :, :T_output, :T_input] == 0, float('-inf'))\n",
    "        attn_weights = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Compute attention-weighted values: `(N, h, T, T)` x `(N, h, T, dim_k)` to `(N, h, T, dim_k)`\n",
    "        A = attn_weights @ v\n",
    "    \n",
    "        # Reshape it back before final linear layer\n",
    "        # `(N, T, h, dim_k)`\n",
    "        A = A.transpose(1, 2)\n",
    "        # `(N, T, h * dim_k)`\n",
    "        A = A.contiguous().view(N, T_output, self.dim_k * self.num_heads) \n",
    "    \n",
    "        # Projection\n",
    "        return self.linear(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bd4579-97be-49a5-bccf-b94f773ea7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dim_k, dim_model, num_heads, maximum_length, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(dim_model)\n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(dim_model)\n",
    "        self.multi_head_attn = MultiHeadAttention(dim_k, dim_model, num_heads, maximum_length, causal=False)\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim_model, dim_model * 4),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(dim_model * 4, dim_model),\n",
    "            torch.nn.Dropout(dropout_prob),\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_prob)\n",
    "  \n",
    "    def forward(self, X, pad_mask=None):\n",
    "        X = self.layer_norm_1(X + self.multi_head_attn(X, X, X, pad_mask))\n",
    "        X = self.layer_norm_2(X + self.linear(X))\n",
    "        X = self.dropout(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc53b97-2677-4d24-a575-6dcc192d620f",
   "metadata": {},
   "source": [
    "## 2-2. Sinusoidal Positional Encoding\n",
    "**Positional Encoding** describes the location or position of an entity in a sequence so that each position is assigned a unique representation. The following criteria should be satisfied:\n",
    "- It should output a unique encoding for each time step (word’s position in a sentence).\n",
    "- Distance between any two time steps should be consistent across sentences with different lengths.\n",
    "- Our model should generalize to longer sentences without any efforts. Its values should be bounded.\n",
    "- It must be deterministic.\n",
    "\n",
    "**Sinusoidal Positional Encoding (SPE)** is the first proposed method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb268c55-2eb9-44d0-9d0a-f3c28c6b600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, dim_model, maximum_length=2048, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_prob)\n",
    "    \n",
    "        position = torch.arange(maximum_length).unsqueeze(1)\n",
    "        power_term = torch.arange(0, dim_model, 2)\n",
    "        # We take advantage of the property `exp(-ylog(x)) = 1 / (x^y)`  \n",
    "        denominator_term = torch.exp(power_term * (-math.log(10000.0) / dim_model))\n",
    "        positional_encoding = torch.zeros(1, maximum_length, dim_model)\n",
    "        positional_encoding[0, :, 0::2] = torch.sin(position * denominator_term)\n",
    "        positional_encoding[0, :, 1::2] = torch.cos(position * denominator_term)\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # `(N, T, D)`\n",
    "        X = X + self.positional_encoding[:, :X.size(1), :]\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd96e63-5aaf-48a2-ae9c-8f7b9ed38aa8",
   "metadata": {},
   "source": [
    "## 2-3. Text Classification with Transformer Encoders\n",
    "Use GLUE SST-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297ed3fc-8879-439b-836d-1cac5f81154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, maximum_length, dim_k, dim_model, num_heads, num_layers, num_classes, dropout_prob):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.embedding = torch.nn.Embedding(vocab_size, dim_model)\n",
    "        self.positional_encoding = PositionalEncoding(dim_model, maximum_length, dropout_prob)\n",
    "        transformer_blocks = [EncoderBlock(dim_k, dim_model, num_heads, maximum_length, dropout_prob) for _ in range(num_layers)]\n",
    "        self.transformer_blocks = torch.nn.Sequential(*transformer_blocks)\n",
    "        self.layer_norm = torch.nn.LayerNorm(dim_model)\n",
    "        self.linear = torch.nn.Linear(dim_model, num_classes)\n",
    "  \n",
    "    def forward(self, X, pad_mask=None):\n",
    "        X = self.embedding(X)\n",
    "        X = self.positional_encoding(X)\n",
    "        for block in self.transformer_blocks:\n",
    "            # print(block)\n",
    "            X = block(X, pad_mask)\n",
    "    \n",
    "        # Many-to-one (X has the shape N x T x D)\n",
    "        X = X[:, 0, :]\n",
    "    \n",
    "        X = self.layer_norm(X)\n",
    "        X = self.linear(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8d7885-cfb6-4576-8d66-14943504b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding): Embedding(20000, 64)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): EncoderBlock(\n",
       "      (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "encoder = Encoder(vocab_size=20_000, maximum_length=1024, dim_k=16, dim_model=64, num_heads=4, num_layers=2, num_classes=5, dropout_prob=0.1)\n",
    "\n",
    "# Device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a795b5f-8962-4d86-8057-a685ea532c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 20_000, size=(8, 512))\n",
    "X = torch.tensor(X).to(device)\n",
    "\n",
    "mask = np.ones((8, 512))\n",
    "mask[:, 256:] = 0\n",
    "mask = torch.tensor(mask).to(device)\n",
    "\n",
    "y = encoder(X, mask)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71338386-18b2-438e-9378-0dad0d081ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 10:07:10.123882: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-27 10:07:10.131370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-27 10:07:10.139767: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-27 10:07:10.142248: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-27 10:07:10.149278: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 10:07:10.616102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/yungshun317/envs/yungshun-py3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "\n",
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_dataset = load_dataset(\"glue\", \"sst2\")\n",
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "319d04f1-3e85-4fef-9abd-e500edfa9951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'], truncation=True)\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(tokenize, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5dc5de9-a2a7-4260-82bf-f639f3edb69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3515bdd-ef6d-40cb-91e5-52bcba8e531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns([\"sentence\", \"idx\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5feb63-4069-4669-9d34-6db9e3f23262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: labels v.shape: torch.Size([32])\n",
      "k: input_ids v.shape: torch.Size([32, 43])\n",
      "k: attention_mask v.shape: torch.Size([32, 43])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    tokenized_dataset[\"validation\"],\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# Check how it works\n",
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(\"k:\", k, \"v.shape:\", v.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d49f73-b2f5-4299-8ab8-f0fb3611922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in the Tokenized Dataset: {0, 1}\n",
      "Vocabulary Size: 28996\n",
      "Model Maximum Length: 512\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels in the Tokenized Dataset:\", set(tokenized_dataset['train']['labels']))\n",
    "print(\"Vocabulary Size:\", tokenizer.vocab_size)\n",
    "print(\"Model Maximum Length:\", tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342ca43a-10e3-430f-b15a-ceac344160d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding): Embedding(28996, 64)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): EncoderBlock(\n",
       "      (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size=tokenizer.vocab_size, maximum_length=tokenizer.model_max_length, dim_k=16, dim_model=64, num_heads=4, num_layers=2, num_classes=2, dropout_prob=0.1)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672a64f6-a994-46ed-8d33-ef509f94ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 4, Train Loss: 0.5335, Test Loss: 0.4901, Duration: 0:00:05.956681\n",
      "Epoch 2 / 4, Train Loss: 0.3705, Test Loss: 0.4639, Duration: 0:00:05.120563\n",
      "Epoch 3 / 4, Train Loss: 0.3001, Test Loss: 0.4533, Duration: 0:00:06.071800\n",
      "Epoch 4 / 4, Train Loss: 0.2599, Test Loss: 0.4942, Duration: 0:00:05.040054\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(encoder.parameters())\n",
    "\n",
    "# A function to encapsulate the training loop\n",
    "def train(model, criterion, optimizer, train_loader, valid_loader, num_epochs):\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    test_losses = np.zeros(num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        t_0 = datetime.now()\n",
    "        train_loss = 0\n",
    "        num_train = 0\n",
    "        for batch in train_loader:\n",
    "            # Move data to GPU\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "            loss = criterion(outputs, batch['labels'])\n",
    "                \n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_loss += loss.item() * batch['input_ids'].size(0)\n",
    "            num_train += batch['input_ids'].size(0)\n",
    "    \n",
    "        # Get average train loss\n",
    "        train_loss = train_loss / num_train\n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        num_test = 0\n",
    "        for batch in valid_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "            loss = criterion(outputs, batch['labels'])\n",
    "            test_loss += loss.item() * batch['input_ids'].size(0)\n",
    "            num_test += batch['input_ids'].size(0)\n",
    "        test_loss = test_loss / num_test\n",
    "    \n",
    "        # Save losses\n",
    "        train_losses[epoch] = train_loss\n",
    "        test_losses[epoch] = test_loss\n",
    "        \n",
    "        d_t = datetime.now() - t_0\n",
    "        print(f'Epoch {epoch + 1} / {num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Duration: {d_t}')\n",
    "  \n",
    "    return train_losses, test_losses\n",
    "\n",
    "train_losses, test_losses = train(encoder, criterion, optimizer, train_loader, valid_loader, num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc7d32a-1bd3-4836-9e6c-94adad2d06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9298, Test acc: 0.7856\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "encoder.eval()\n",
    "num_correct = 0.\n",
    "num_total = 0.\n",
    "for batch in train_loader:\n",
    "    # Move to GPU\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = encoder(batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "  \n",
    "    # update counts\n",
    "    num_correct += (predictions == batch['labels']).sum().item()\n",
    "    num_total += batch['labels'].shape[0]\n",
    "\n",
    "train_acc = num_correct / num_total\n",
    "\n",
    "num_correct = 0.\n",
    "num_total = 0.\n",
    "for batch in valid_loader:\n",
    "    # Move to GPU\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "  \n",
    "    # Forward pass\n",
    "    outputs = encoder(batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "  \n",
    "    # update counts\n",
    "    num_correct += (predictions == batch['labels']).sum().item()\n",
    "    num_total += batch['labels'].shape[0]\n",
    "\n",
    "test_acc = num_correct / num_total\n",
    "print(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134c532-7fde-45ef-a2bc-90852bbba140",
   "metadata": {},
   "source": [
    "## 2-4. Text Classification with Transformer Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74cf2d22-a4fd-4c0b-af9e-78138469d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, dim_k, dim_model, num_heads, maximum_length, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(dim_model)\n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(dim_model)\n",
    "        self.layer_norm_3 = torch.nn.LayerNorm(dim_model)\n",
    "        self.multi_head_attn_1 = MultiHeadAttention(dim_k, dim_model, num_heads, maximum_length, causal=True)\n",
    "        self.multi_head_attn_2 = MultiHeadAttention(dim_k, dim_model, num_heads, maximum_length, causal=False)\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim_model, dim_model * 4),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(dim_model * 4, dim_model),\n",
    "            torch.nn.Dropout(p=dropout_prob),\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_prob)\n",
    "  \n",
    "    def forward(self, encoder_output, decoder_input, encoder_mask=None, decoder_mask=None):\n",
    "        # Self-attention on decoder input\n",
    "        X = self.layer_norm_1(decoder_input + self.multi_head_attn_1(decoder_input, decoder_input, decoder_input, decoder_mask))\n",
    "    \n",
    "        # Multi-head attention including encoder output\n",
    "        X = self.layer_norm_2(X + self.multi_head_attn_2(X, encoder_output, encoder_output, encoder_mask))\n",
    "    \n",
    "        X = self.layer_norm_3(X + self.linear(X))\n",
    "        X = self.dropout(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c039a219-45d7-40c3-a81f-650fddffad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, maximum_length, dim_k, dim_model, num_heads, num_layers, dropout_prob):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.embedding = torch.nn.Embedding(vocab_size, dim_model)\n",
    "        self.positional_encoding = PositionalEncoding(dim_model, maximum_length, dropout_prob)\n",
    "        transformer_blocks = [DecoderBlock(dim_k, dim_model, num_heads, maximum_length, dropout_prob) for _ in range(num_layers)]\n",
    "        self.transformer_blocks = torch.nn.Sequential(*transformer_blocks)\n",
    "        self.layer_norm = torch.nn.LayerNorm(dim_model)\n",
    "        self.linear = torch.nn.Linear(dim_model, vocab_size)\n",
    "  \n",
    "    def forward(self, encoder_output, decoder_input, encoder_mask=None, decoder_mask=None):\n",
    "        X = self.embedding(decoder_input)\n",
    "        X = self.positional_encoding(X)\n",
    "        for block in self.transformer_blocks:\n",
    "            X = block(encoder_output, X, encoder_mask, decoder_mask)\n",
    "        X = self.layer_norm(X)\n",
    "        # Many-to-many\n",
    "        X = self.linear(X) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c76aad6-a393-490b-8dc4-dbc568fad6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/yungshun-py3/lib/python3.12/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/yungshun-py3/lib/python3.12/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/yungshun-py3/lib/python3.12/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/yungshun-py3/lib/python3.12/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "decoder = Decoder(vocab_size=20_000, maximum_length=1024, dim_k=16, dim_model=64, num_heads=4, num_layers=2, dropout_prob=0.1)\n",
    "\n",
    "# Device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8ab57-a0c0-4073-9433-7faa01e1d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 20_000, size=(8, 512))\n",
    "X = torch.tensor(X).to(device)\n",
    "\n",
    "mask = np.ones((8, 512))\n",
    "mask[:, 256:] = 0\n",
    "mask = torch.tensor(mask).to(device)\n",
    "\n",
    "y = decoder(X, mask)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4631018-87d2-426b-9e52-72851f92fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "\n",
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# Use the same dataset but ignore the labels\n",
    "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b760665-1292-4931-ad92-ca6658381a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "   return tokenizer(batch['sentence'], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492071d-c6bb-4ee6-80e0-d07ca0369028",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\", \"label\"])\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a381e-caa8-49dd-ae29-5c81e1b88f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=32, collate_fn=data_collator)\n",
    "\n",
    "# check how it works\n",
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(\"k:\", k, \"v.shape:\", v.shape)\n",
    "    break\n",
    "\n",
    "print(tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88827485-8060-4fe2-a7b7-dea78adeb0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size=tokenizer.vocab_size, maximum_length=tokenizer.model_max_length, dim_k=16, dim_model=64, num_heads=4, num_layers=2, dropout_prob=0.1)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75decdd6-d233-4ee1-bee9-59f993ad852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "# A function to encapsulate the training loop\n",
    "def train(model, criterion, optimizer, train_loader, num_epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "\n",
    "    for it in range(epochs):\n",
    "        model.train()\n",
    "        t_0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for batch in train_loader:\n",
    "            # move data to GPU\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # shift targets backwards\n",
    "            targets = batch['input_ids'].clone().detach()\n",
    "            targets = torch.roll(targets, shifts=-1, dims=1)\n",
    "            targets[:, -1] = tokenizer.pad_token_id\n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "            # outputs are (N, T, V)\n",
    "            # but PyTorch expects (N, V, T)\n",
    "            # print(\"outputs:\", outputs)\n",
    "            # print(\"targets:\", targets)\n",
    "            loss = criterion(outputs.transpose(2, 1), targets)\n",
    "            # N, T, V = outputs.shape\n",
    "            # loss = criterion(outputs.view(N * T, V), targets.view(N * T))\n",
    "            \n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "    \n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        \n",
    "        d_t = datetime.now() - t_0\n",
    "        print(f'Epoch {it + 1} / {num_epochs}, Train Loss: {train_loss:.4f}, Duration: {dt}')\n",
    "        \n",
    "  return train_losses\n",
    "\n",
    "train_losses = train(decoder, criterion, optimizer, train_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089c0e3-d398-4313-a921-0a968762c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(tokenized_datasets[\"validation\"], batch_size=1, collate_fn=data_collator)\n",
    "\n",
    "decoder.eval()\n",
    "for batch in valid_loader:\n",
    "    # move data to GPU\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    outputs = decoder(batch['input_ids'], batch['attention_mask'])\n",
    "    break\n",
    "\n",
    "print(outputs.shape)\n",
    "print(torch.argmax(outputs, axis=-1))\n",
    "\n",
    "prediction_ids = torch.argmax(outputs, axis=-1)\n",
    "print(tokenizer.decode(prediction_ids[0]))\n",
    "\n",
    "print(tokenizer.decode(batch['input_ids'][0]))\n",
    "print(tokenizer.decode(torch.concat((batch['input_ids'][0, :5], prediction_ids[:, 4]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72691b8d-2e19-449b-9459-87dd60379cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate something\n",
    "prompt = \"it's\"\n",
    "\n",
    "tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n",
    "print(tokenized_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad86fe-b325-42bf-bf2d-c7038d8e433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(tokenized_prompt['input_ids'][:, :-1].to(device), tokenized_prompt['attention_mask'][:, :-1].to(device))\n",
    "print(outputs.shape)\n",
    "\n",
    "prediction_ids = torch.argmax(outputs[:, -1, :], axis=-1)\n",
    "print(tokenizer.decode(prediction_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b89b5-3dec-4d8a-91e7-9d9e9742dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate something\n",
    "prompt = \"it's a\"\n",
    "\n",
    "tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "# Prepare inputs & get rid of `<SEP>` token at the end\n",
    "input_ids = tokenized_prompt['input_ids'][:, :-1].to(device)\n",
    "mask = tokenized_prompt['attention_mask'][:, :-1].to(device)\n",
    "\n",
    "for _ in range(20):\n",
    "    outputs = decoder(input_ids, mask)\n",
    "    prediction_id = torch.argmax(outputs[:, -1, :], axis=-1)\n",
    "\n",
    "    input_ids = torch.hstack((input_ids, prediction_id.view(1, 1)))\n",
    "    mask = torch.ones_like(input_ids)\n",
    "\n",
    "    if prediction_id == tokenizer.sep_token_id:\n",
    "        break\n",
    "\n",
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7dcf65-5b19-4435-b5f5-b038731ecdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "840ddcb1-389c-4fac-a5d4-b505e62918af",
   "metadata": {},
   "source": [
    "## 2-5. Text Classification with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d42abc-e76d-499e-93f5-2335565b1be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "  def __init__(self, encoder, decoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "  \n",
    "  def forward(self, enc_input, dec_input, enc_mask, dec_mask):\n",
    "    enc_output = self.encoder(enc_input, enc_mask)\n",
    "    dec_output = self.decoder(enc_output, dec_input, enc_mask, dec_mask)\n",
    "    return dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d94af-5082-47cb-98fa-b542f9820349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "encoder = Encoder(vocab_size=20_000,\n",
    "                  max_len=512,\n",
    "                  d_k=16,\n",
    "                  d_model=64,\n",
    "                  n_heads=4,\n",
    "                  n_layers=2,\n",
    "                  dropout_prob=0.1)\n",
    "decoder = Decoder(vocab_size=10_000,\n",
    "                  max_len=512,\n",
    "                  d_k=16,\n",
    "                  d_model=64,\n",
    "                  n_heads=4,\n",
    "                  n_layers=2,\n",
    "                  dropout_prob=0.1)\n",
    "transformer = Transformer(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1761e9c-2006-4631-90b6-dc3850c1b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f47c3-f4eb-42ba-9561-dd9d7d0286cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, maximum_length, dim_k, dim_model, num_heads, num_layers, dropout_prob):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.embedding = torch.nn.Embedding(vocab_size, dim_model)\n",
    "        self.position_encoding = PositionalEncoding(dim_model, maximum_length, dropout_prob)\n",
    "        transformer_blocks = [EncoderBlock(dim_k, dim_model, num_heads, maximum_length, dropout_prob) for _ in range(n_layers)]\n",
    "        self.transformer_blocks = torch.nn.Sequential(*transformer_blocks)\n",
    "        self.layer_norm = torch.nn.LayerNorm(dim_model)\n",
    "        # self.linear = nn.Linear(dim_model, num_classes)\n",
    "  \n",
    "    def forward(self, x, pad_mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        for block in self.transformer_blocks:\n",
    "          x = block(x, pad_mask)\n",
    "    \n",
    "        # many-to-one (x has the shape N x T x D)\n",
    "        # x = x[:, 0, :]\n",
    "    \n",
    "        x = self.ln(x)\n",
    "        # x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decc91c-8903-4365-a0fa-43b79fb45553",
   "metadata": {},
   "source": [
    "# 4. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9f03c-639e-4b23-9622-c724939830d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] Freeze weights\n",
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1117be-5ddf-403a-b48f-7c9913292402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e60f3-7a01-4c75-9b6d-a5de22b9b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer (using SGD to slow down learning!)\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527c916-6716-4d19-847c-142bcbeafd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the \"learning toggle\" of a layer\n",
    "N = createTheMNISTNet()[0]\n",
    "N.fc1.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c627e-959c-4647-97a0-c83061970e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = createTheMNISTNet()[0]\n",
    "\n",
    "# switch off all layers except input\n",
    "for p in N.named_parameters():\n",
    "  if 'input' not in p[0]:\n",
    "    p[1].requires_grad = False\n",
    "  \n",
    "\n",
    "# check what we've done\n",
    "for p in N.named_parameters():\n",
    "  print('Requires_grad status in layer %s: %s' %(p[0],p[1].requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b0ffd-88fc-4449-a43e-ff20225fff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel(net,lossfun,optimizer):\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 100\n",
    "  \n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # NEW: switch off learning in all-but-output layers during first 1/2 of training\n",
    "    if epochi<(numepochs/2):\n",
    "      for p in net.named_parameters():\n",
    "        if 'output' not in p[0]:\n",
    "          p[1].requires_grad = False\n",
    "    else:\n",
    "      for p in net.named_parameters():\n",
    "        p[1].requires_grad = True\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # loop over training data batches\n",
    "    net.train()\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d9537-37fe-4478-980c-aaff5eaf3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network\n",
    "net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "# train the model\n",
    "trainAcc,testAcc,losses,net = function2trainTheModel(net,lossfun,optimizer)\n",
    "\n",
    "plt.plot(trainAcc,label='Train')\n",
    "plt.plot(testAcc,label='Test')\n",
    "plt.plot([len(trainAcc)/2, len(trainAcc)/2],[10,80],'k--',label='Learning switched on')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c079bdfb-1844-4f8d-b170-a3a2f996afcb",
   "metadata": {},
   "source": [
    "## 4-2. Transformers\n",
    "\n",
    "- [Supported Models & Frameworks](https://huggingface.co/docs/transformers/index#supported-models-and-frameworks)\n",
    "### 4-2-1. Pipelines\n",
    "- [Complete List of Supported Tasks](https://huggingface.co/docs/transformers/v4.44.0/en/main_classes/pipelines#transformers.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f7b534-dcce-49bb-a9e4-e77cd229bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tf-keras \n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cce711-675c-4f08-92dc-94a6174d6a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f4a1dbf2b14680a392b903fe58172c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f5694e3f69404fa5ab98663f6efc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb85ba1a9034aa5bdbe00a54d6211aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text_classification.TextClassificationPipeline"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90fce79-03b0-4566-a71e-0501beb0d585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998759031295776}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output is a dictionary\n",
    "classifier(\"This is such a great movie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ce99b-4718-4fa5-be2b-cee251d7e158",
   "metadata": {},
   "source": [
    "### 4-2-2. Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1f8b4f-369d-4ca7-af24-5cbf68708be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292480eb-6d72-41d1-ba77-c2cc5a7b4377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13e40586bb44aba9bf4a3fa67469a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84bf07de1774c06b385611cd277728d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9309390dac454bcc953ec69d3d171ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7530e8bcb57f41359357d6cd0f96977a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f7b3a3bba64b9e8b8a88a206b563b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28d6f2199864ffe90be76f8c262b14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f358d052bfdf46408bdd70b0b8e1306f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5486156e-fe89-4804-87db-d8da07f370bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label', 'idx'],\n",
       "    num_rows: 67349\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a25f1878-bee8-4048-953c-d59f84291b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryMappedTable\n",
       "sentence: string\n",
       "label: int64\n",
       "idx: int32\n",
       "----\n",
       "sentence: [[\"hide new secretions from the parental units \",\"contains no wit , only labored gags \",\"that loves its characters and communicates something rather beautiful about human nature \",\"remains utterly satisfied to remain the same throughout \",\"on the worst revenge-of-the-nerds clichés the filmmakers could dredge up \",...,\"you wish you were at home watching that movie instead of in the theater watching this one \",\"'s no point in extracting the bare bones of byatt 's plot for purposes of bland hollywood romance \",\"underdeveloped \",\"the jokes are flat \",\"a heartening tale of small victories \"],[\"suspense , intriguing characters and bizarre bank robberies , \",\"a gritty police thriller with all the dysfunctional family dynamics one could wish for \",\"with a wonderful ensemble cast of characters that bring the routine day to day struggles of the working class to life \",\"nonetheless appreciates the art and reveals a music scene that transcends culture and race . \",\"do we really need the tiger beat version ? \",...,\"when there 's nothing else happening \",\"on cable \",\"it with ring , \",\"far from a groundbreaking endeavor \",\"that these women are spectacular \"],...,[\"it does turn out to be a bit of a cheat in the end \",\"may be convinced that he has something significant to say \",\"to be both hugely entertaining and uplifting . \",\", boredom never takes hold . \",\"left to work with , sort of like michael jackson 's nose \",...,\"from a severe case of hollywood-itis \",\"the very best of them \",\"thrills , \",\"'s attracting audiences to unfaithful \",\"impressively delicate range \"],[\"starts off promisingly but then proceeds to flop \",\"distinguished actor \",\"on their parents ' anguish \",\"pays off and is effective if you stick with it \",\"is n't particularly funny \",...,\"a delightful comedy \",\"anguish , anger and frustration \",\"at achieving the modest , crowd-pleasing goals it sets for itself \",\"a patient viewer \",\"this new jangle of noise , mayhem and stupidity must be a serious contender for the title . \"]]\n",
       "label: [[0,0,1,0,0,...,0,0,0,0,1],[1,1,1,1,0,...,0,0,1,0,1],...,[0,0,1,1,0,...,0,1,1,1,1],[0,1,0,1,0,...,1,0,1,1,0]]\n",
       "idx: [[0,1,2,3,4,...,995,996,997,998,999],[1000,1001,1002,1003,1004,...,1995,1996,1997,1998,1999],...,[66000,66001,66002,66003,66004,...,66995,66996,66997,66998,66999],[67000,67001,67002,67003,67004,...,67344,67345,67346,67347,67348]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4558f922-6ad9-465f-bd7c-2e305584f503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'positive'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8cf0a4-39bf-4ab7-9840-bfc085c68808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915d9bc28cf64d9b9b16e4a089079423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f22131436804f63b052dec0264053b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16dbce17f844673a53dc12abd43ec6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c999c9cd39bb4411934371883556a53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " 'input_ids': [[101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102],\n",
      "               [101,\n",
      "                3397,\n",
      "                2053,\n",
      "                15966,\n",
      "                1010,\n",
      "                2069,\n",
      "                4450,\n",
      "                2098,\n",
      "                18201,\n",
      "                2015,\n",
      "                102],\n",
      "               [101,\n",
      "                2008,\n",
      "                7459,\n",
      "                2049,\n",
      "                3494,\n",
      "                1998,\n",
      "                10639,\n",
      "                2015,\n",
      "                2242,\n",
      "                2738,\n",
      "                3376,\n",
      "                2055,\n",
      "                2529,\n",
      "                3267,\n",
      "                102]]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from pprint import pprint\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "tokenized_sentences = tokenizer(raw_datasets['train'][0:3]['sentence'])\n",
    "pprint(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d515f6b-3769-43e6-916f-fca294f7a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bde47a18bc4a91b372330e7c17925b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f414a499ef40440f8c58716f4b50b467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0ea13c27744a31a5ede242980c28f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_fn(batch):\n",
    "  return tokenizer(batch['sentence'], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
    "type(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b95f2797-056f-43bc-9514-8248d4ff314c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=my_trainer/runs/Aug12_22-42-33_yungshun317-Titan-18-HX-A14VIG,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=1,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=my_trainer,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=my_trainer,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.EPOCH,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  'my_trainer',\n",
    "  eval_strategy='epoch',\n",
    "  save_strategy='epoch',\n",
    "  num_train_epochs=1,\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e6cae1-8ecd-4efa-8e18-233b580ef77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54dd42b8b634e5e84eb7c42ebad2d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=2)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb643e8-9dc2-4091-9495-7e4d86a67b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f728925-aff4-4841-bfe0-b92b30e8901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "DistilBertForSequenceClassification                     --\n",
       "├─DistilBertModel: 1-1                                  --\n",
       "│    └─Embeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                              23,440,896\n",
       "│    │    └─Embedding: 3-2                              393,216\n",
       "│    │    └─LayerNorm: 3-3                              1,536\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    └─Transformer: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-5                             42,527,232\n",
       "├─Linear: 1-2                                           590,592\n",
       "├─Linear: 1-3                                           1,538\n",
       "├─Dropout: 1-4                                          --\n",
       "================================================================================\n",
       "Total params: 66,955,010\n",
       "Trainable params: 66,955,010\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffde041c-e5f6-4183-91bd-37e47ecc0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install evaluate\n",
    "import evaluate\n",
    "\n",
    "# Metric for validation error\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"glue\", \"sst2\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c222023-bf0d-48b1-a846-349f0cfae16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8419' max='8419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8419/8419 03:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.509155</td>\n",
       "      <td>0.883028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8419, training_loss=0.07386701579104694, metrics={'train_runtime': 194.6434, 'train_samples_per_second': 346.012, 'train_steps_per_second': 43.253, 'total_flos': 517212489917652.0, 'train_loss': 0.07386701579104694, 'epoch': 1.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "063f5e9a-9529-4dbc-b21e-9baa13ff53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('models/finetuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38cb7889-f9f1-4ee3-96c3-ffb08eda8aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9997863173484802}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model = pipeline(\"sentiment-analysis\", model='models/finetuned_model', device=0)\n",
    "finetuned_model('This is such a great movie!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "292f822a-1fed-46a4-8fd4-de1ad309779c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9997292160987854}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model('This is such a bad movie!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d55f06db-45cf-4029-afe3-c7408fd4c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.43.4\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cat models/finetuned_model/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddde7e38-f876-4bc6-8af4-37dedb9b5c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.988}\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"glue\", \"sst2\")\n",
    "\n",
    "n_samples = 500\n",
    "\n",
    "# The labels in test set of `glue/sst2` are `-1`\n",
    "X = raw_datasets['train'].data[\"sentence\"].to_pylist()[:n_samples]\n",
    "y = raw_datasets['train'].data[\"label\"].to_pylist()[:n_samples]\n",
    "\n",
    "results = finetuned_model(X)\n",
    "predictions = [0 if res[\"label\"] == \"LABEL_0\" else 1 for res in results]\n",
    "print(metric.compute(predictions=predictions, references=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847dd8c-5032-4218-a459-5701f60145c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
