{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/yungshun317/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Quantization\n",
    "\n",
    "- **Post-Training Quantization (PTQ):** Quantizes a pre-trained model using moderate resources, such as a calibration dataset & a few hours of computation.\n",
    "- **Quantization-Aware Training (QAT):** Quantization is performed before training or further fine-tunning.\n",
    " \n",
    "## 1-1. GPTQ ()\n",
    "GPTQ () is a  quantization method\n",
    "\n",
    "[C4](https://www.tensorflow.org/datasets/catalog/c4) is a colossal, cleaned version of Common Crawl's web crawl corpus released by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1, 29871,    13,  ...,    13,    13,    13]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datasets, transformers, random, torch\n",
    "\n",
    "train_data = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1', split=\"train\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_fast=False)\n",
    "\n",
    "train_enclosed = tokenizer(\"\\n\\n\".join(train_data[\"text\"]), return_tensors=\"pt\")\n",
    "print(train_enclosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' = Valkyria Chronicles III = \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n = Valkyria Chronicles III = \\n\\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\\n\".join(train_data[\"text\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enclosed = tokenizer(\"\\n\\n\".join(train_data[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2874559])\n"
     ]
    }
   ],
   "source": [
    "print(train_enclosed.input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': tensor([[ 869,  512,  278,  ...,  491, 1060,  331]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29947, 10387,   785,  ...,  4818,   322,  9999]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1339, 15387,   393,  ...,  1857,  2106,  1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29871, 29900, 29900,  ...,   869,   365,  5271]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[15874,  2649,   310,  ..., 29953,   869,   450]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[26504,   373, 18032,  ...,  8805, 29879,   310]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1919,   372,  5714,  ..., 12206,   278,   838]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  372,   525, 29879,  ...,   433,   446,   869]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29946,  1919, 13138,  ..., 16156,   269,  6576]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 327,  262,  293,  ..., 5960, 2925,  393]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  273, 18935,   869,  ...,   322,  3371,   929]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29889,  6182,   525,  ...,   716, 19341,   583]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29992,   975,   732,  ...,  8794,   491,   263]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[10340,  9701,   892,  ...,   278,   707, 29884]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 278, 6410,  310,  ...,  485, 4600, 1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  322, 23273,  4358,  ...,   278,  4842,  9795]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1619,  4634,   376,  ...,   654,  1919, 20976]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  297,  9475, 14354,  ...,  3352, 29879,  1476]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 3926, 12692, 10697,  ...,   424,   410,   344]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  328,   869, 29871,  ...,   278, 14378,  1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[11021,  1608,   869,  ...,   310,  2148,   290]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  323,   732, 29899,  ...,   723,   367,  9213]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1723,   869,  6265,  ...,  2648, 29871, 29896]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29871,    13,    13,  ...,   278,  6221,   732]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[4235, 1919, 3265,  ..., 9435, 1919,  322]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  314,  1004,   375,  ..., 16197,  1384,  1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  310,  4517,   525,  ...,   322,  1963, 19982]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[27719, 27688,   869,  ...,  4925,  2362,  8819]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[22094,   376,   750,  ..., 29871, 29896, 29900]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1724,   338,  2998,  ...,  5846, 29871, 29906]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 2877,   732, 29899,  ..., 23181,   297, 29871]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  322,   437, 29920,  ...,  1919, 29871, 29941]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 2211,  6166,   363,  ..., 29900, 29900, 29945]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 2267,   815,   681,  ..., 29896, 29929, 29955]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  306,  1073,  3721,  ..., 16528,  1494,   967]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  869,   315,  1377,  ...,   869, 29871,    13]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1932,   445,   338,  ...,   975, 11143,  7362]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29879, 18873,  1265,  ...,   297, 29871, 29906]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29899, 29992,  7234,  ..., 22405,  1048,   902]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[   13,    13,   353,  ...,   869,   940, 19952]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 521,  272, 6394,  ...,  363, 2834,  363]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 2178,  3628, 17142,  ..., 10443,  1580,   326]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 869,  376, 2598,  ...,  519,  471, 5492]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  869,   450, 14321,  ...,   322,  3023,   732]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  869, 29871,    13,  ...,  8010,  1394,   291]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  376,   851,   329,  ...,   260, 24729,   313]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29871, 29896, 29947,  ...,   407,  1723,   313]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[7560, 1348,  414,  ...,  475, 6567, 1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 310,  478, 2235,  ...,  841, 1058,  750]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 4452,   869, 29871,  ...,  7618,   311,   322]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  451,   560,  1682,  ..., 17900,   304,  2367]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  777, 21420,   310,  ...,  1728, 10757,   393]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[10819,   322, 19595,  ..., 12919,  1304,   408]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  13,   13,  450,  ...,  411, 1009, 2175]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  869, 29871,    13,  ...,   319, 29889,   298]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1919,   297,  6124,  ..., 22309,   322, 22237]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1049,   310,  4623,  ...,   732, 29899, 29992]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  267,  5528, 16719,  ...,   278,  2706,   471]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 385, 2441, 2931,  ...,   13,  319, 1595]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  670,  3252,   262,  ...,   322, 17102, 18588]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[   13,    13,    13,  ..., 29946, 29955,  1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  491, 11254,   316,  ..., 29955, 29906,  1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  869,   450, 25657,  ...,   475,   471,  1497]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 408, 8378, 2650,  ..., 2184, 1919,  322]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 869,  910,  471,  ..., 9132,  304, 2088]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1028, 21321,   892,  ...,  3796,   714,  1546]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[   13,    13,    13,  ..., 29900,   286,  3448]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[16126,   322,  1018,  ...,   445,  1776,  2056]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[13807, 12949,   310,  ...,  3464,   310,  1090]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29871, 29906, 29900,  ...,   353,   353, 29871]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29947, 29953, 29896,  ...,   512,  4688, 29871]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[10040,   402,  7781,  ...,  5546,  1723,  3965]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29992, 26259, 17325,  ...,  1723,  8967,   263]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  322,  7679, 10901,  ...,   304,  1716,  4223]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[   13,    13,    13,  ..., 29871, 29896, 29947]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[27489,   287,   266,  ..., 25166,  4306,  1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[   13,    13,    13,  ..., 29896, 29947,   386]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[1580,  326,  575,  ..., 4452, 1919, 1316]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[1951,  967, 8718,  ..., 1098, 5818, 8866]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  313, 29871, 29906,  ...,  5791,  4125, 23941]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 3725, 29907,  5282,  ..., 12243,   557,   310]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29900, 29924,  1060,  ...,  7968,   322,   901]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 4959,   297,   278,  ..., 11335,  1919,  5007]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1497,   393, 15020,  ...,   670,  5192,  2645]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 307,  861,  869,  ..., 2379,  523,  853]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1024,  4702,  3554,  ..., 17763,  1847,  7415]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 5866, 13958,   515,  ...,  5193,   963,   964]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29872,   552,   376,  ..., 17692,  9014,   414]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[22580,   372,   376,  ...,  1094,   379, 12392]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[4967,  287,  304,  ...,  263, 9416, 1616]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  561,   313, 29871,  ...,    13,  8512, 13840]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29879,   298,   668,  ...,   278,  1708,  2696]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 360, 2904,  273,  ..., 4863, 3748, 4696]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 292, 9862,  472,  ...,  278, 7062, 3088]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 869, 3834,  310,  ...,  422, 3283,  353]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  310,   278,  3767,  ...,  1919, 13843,   869]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[14893,  1076,   297,  ..., 28645, 24094,  1287]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29871,    13,    13,  ...,   515,  2462,   304]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 2446, 29871, 29906,  ...,  2719,   297,   445]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 881,  367, 5700,  ...,  278, 6641,  869]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  869,   450,  6520,  ...,  2360, 20653,   670]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  287,   491,   278,  ..., 29992,  1298,  2507]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 2538,  3615,  1270,  ...,  1357,   732, 29899]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  988,  1183,  5456,  ...,  4822, 13370, 29880]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 1919,  1122, 29888,  ...,   313,  9656,   517]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[1913, 6729, 1919,  ...,  391, 3686,  388]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 5468, 29871, 29906,  ..., 29965,  2750, 18168]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 8027,  8508, 29871,  ...,  5456,   393,   390]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[10296,   310,  1716,  ..., 29896, 29929, 29929]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[11021,   391,   322,  ..., 29879,   304,   777]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 8481,  1110,   525,  ...,   297, 29871, 29896]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[2621,  412, 1919,  ...,  310,  592,  471]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  278,  1667, 20332,  ..., 29891,   322,   297]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 6811,   278, 21726,  ...,   333,   330, 29458]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  375,  1919,   988,  ..., 10800,   338, 11736]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  434,   278, 12944,  ...,  1919,  5007,   393]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[11069,   319,  3164,  ...,   379, 29889,   652]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 451,  304, 4066,  ...,  297, 1432, 4223]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[5360, 1919, 4892,  ...,  450, 4818, 1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 3036,  1061,  1974,  ...,   713, 21110,   391]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29946, 10309, 29871,  ..., 29900, 29879,  1919]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29945, 29946,   847,  ...,   975,   607,   263]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  303,   322, 29871,  ...,    13,    13,   353]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[ 5034,   304,  2407,  ...,   278,  7333, 15196]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[12462, 12420,   297,  ...,   385,  2812,  1357]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  316,  2590, 16317,  ...,   353,   353,   353]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[  525, 29879,  5516,  ...,   314,  3631, 12453]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[29903, 29889, 11559,  ...,   399, 29889,   512]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datasets, transformers, random, torch\n",
    "\n",
    "def get_wikitext2(num_samples, seed, sequence_length, model):\n",
    "    train_data = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1', split=\"train\")\n",
    "    test_data = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1', split=\"test\")\n",
    "\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model, use_fast=False)\n",
    "\n",
    "    # Enclose each `text` row with `\\n\\n`\n",
    "    train_enclosed = tokenizer(\"\\n\\n\".join(train_data[\"text\"]), return_tensors=\"pt\")\n",
    "    # \"\\n\\n\".join(train_data[\"text\"][:5])\n",
    "    # '\\n\\n = Valkyria Chronicles III = \\n\\n\\n\\n\\n Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n\\n\\n The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game \\'s opening theme was sung by May \\'n . \\n'   \n",
    "    # print(train_enclosed)\n",
    "    # {'input_ids': tensor([[    1, 29871,    13,  ...,    13,    13,    13]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
    "    test_enclosed = tokenizer(\"\\n\\n\".join(test_data[\"text\"]), return_tensors=\"pt\")\n",
    "\n",
    "    # Set random seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "\n",
    "    train_dataset = []\n",
    "    # Grab `num_samples` samples\n",
    "    for _ in range(num_samples):\n",
    "        # Pick a random number as the starting id but not from the last `sequence_length - 1` id to prevent index out of range error\n",
    "        start_id = random.randint(0, train_enclosed.input_ids.shape[1] - sequence_length - 1)\n",
    "        # print(train_enclosed.input_ids.shape)\n",
    "        # torch.Size([1, 2874559])\n",
    "        end_id = start_id + sequence_length\n",
    "        input_ids = train_enclosed.input_ids[:, start_id:end_id]\n",
    "        attention_mask = torch.ones_like(input_ids)\n",
    "        train_dataset.append({\"input_ids\": input_ids, \"attention_mask\": attention_mask})\n",
    "    return train_dataset, test_enclosed\n",
    "\n",
    "train_dataset, test_enclosed = get_wikitext2(num_samples=128, seed=0, sequence_length=2048, model=\"meta-llama/Llama-2-7b-hf\")\n",
    "print(\"Sample Data:\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 869,  512,  278,  ...,  491, 1060,  331]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yungshun317/workspace/py/torch-nlp/AutoGPTQ/auto_gptq/nn_modules/triton_utils/kernels.py:410: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/yungshun317/workspace/py/torch-nlp/AutoGPTQ/auto_gptq/nn_modules/triton_utils/kernels.py:418: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/home/yungshun317/workspace/py/torch-nlp/AutoGPTQ/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd(cast_inputs=torch.float16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4732e0a25c4240b4a45475065c7f9b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yungshun317/envs/yungshun-py3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae83fef001ee4d0c9e6936a1d4e72f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1ca4c490e74085b5241202a3565cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061d36670b8e44d1a9e05b9e721067df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfebd1a01d94bd290421d6ee5427b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151642a7e2944fb4be6bad66eebbe38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63f3f74801044efade3bc2332c9d987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m torch_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoGPTQForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m, quantize_config\u001b[38;5;241m=\u001b[39mquantize_config, low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39mquantize(\u001b[43mtrain_dataset\u001b[49m, use_triton\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "\n",
    "quantize_config = BaseQuantizeConfig(\n",
    "    bits=4,\n",
    "    group_size=128,\n",
    "    desc_act=False,\n",
    "    # damp_percent=damp\n",
    ")\n",
    "\n",
    "torch_dtype = torch.float16\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", quantize_config=quantize_config, low_cpu_mem_usage=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Start quantizing layer 1/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 1/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 1/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 1/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 1/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 1/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 1/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 1/32...\n",
      "INFO - Start quantizing layer 2/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 2/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 2/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 2/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 2/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 2/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 2/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 2/32...\n",
      "INFO - Start quantizing layer 3/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 3/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 3/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 3/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 3/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 3/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 3/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 3/32...\n",
      "INFO - Start quantizing layer 4/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 4/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 4/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 4/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 4/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 4/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 4/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 4/32...\n",
      "INFO - Start quantizing layer 5/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 5/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 5/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 5/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 5/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 5/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 5/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 5/32...\n",
      "INFO - Start quantizing layer 6/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 6/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 6/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 6/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 6/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 6/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 6/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 6/32...\n",
      "INFO - Start quantizing layer 7/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 7/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 7/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 7/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 7/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 7/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 7/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 7/32...\n",
      "INFO - Start quantizing layer 8/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 8/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 8/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 8/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 8/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 8/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 8/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 8/32...\n",
      "INFO - Start quantizing layer 9/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 9/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 9/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 9/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 9/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 9/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 9/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 9/32...\n",
      "INFO - Start quantizing layer 10/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 10/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 10/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 10/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 10/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 10/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 10/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 10/32...\n",
      "INFO - Start quantizing layer 11/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 11/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 11/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 11/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 11/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 11/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 11/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 11/32...\n",
      "INFO - Start quantizing layer 12/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 12/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 12/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 12/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 12/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 12/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 12/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 12/32...\n",
      "INFO - Start quantizing layer 13/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 13/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 13/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 13/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 13/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 13/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 13/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 13/32...\n",
      "INFO - Start quantizing layer 14/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 14/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 14/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 14/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 14/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 14/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 14/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 14/32...\n",
      "INFO - Start quantizing layer 15/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 15/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 15/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 15/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 15/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 15/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 15/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 15/32...\n",
      "INFO - Start quantizing layer 16/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 16/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 16/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 16/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 16/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 16/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 16/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 16/32...\n",
      "INFO - Start quantizing layer 17/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 17/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 17/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 17/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 17/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 17/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 17/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 17/32...\n",
      "INFO - Start quantizing layer 18/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 18/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 18/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 18/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 18/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 18/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 18/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 18/32...\n",
      "INFO - Start quantizing layer 19/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 19/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 19/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 19/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 19/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 19/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 19/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 19/32...\n",
      "INFO - Start quantizing layer 20/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 20/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 20/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 20/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 20/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 20/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 20/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 20/32...\n",
      "INFO - Start quantizing layer 21/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 21/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 21/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 21/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 21/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 21/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 21/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 21/32...\n",
      "INFO - Start quantizing layer 22/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 22/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 22/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 22/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 22/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 22/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 22/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 22/32...\n",
      "INFO - Start quantizing layer 23/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 23/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 23/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 23/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 23/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 23/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 23/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 23/32...\n",
      "INFO - Start quantizing layer 24/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 24/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 24/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 24/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 24/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 24/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 24/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 24/32...\n",
      "INFO - Start quantizing layer 25/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 25/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 25/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 25/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 25/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 25/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 25/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 25/32...\n",
      "INFO - Start quantizing layer 26/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 26/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 26/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 26/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 26/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 26/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 26/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 26/32...\n",
      "INFO - Start quantizing layer 27/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 27/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 27/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 27/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 27/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 27/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 27/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 27/32...\n",
      "INFO - Start quantizing layer 28/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 28/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 28/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 28/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 28/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 28/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 28/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 28/32...\n",
      "INFO - Start quantizing layer 29/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 29/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 29/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 29/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 29/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 29/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 29/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 29/32...\n",
      "INFO - Start quantizing layer 30/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 30/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 30/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 30/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 30/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 30/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 30/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 30/32...\n",
      "INFO - Start quantizing layer 31/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 31/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 31/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 31/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 31/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 31/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 31/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 31/32...\n",
      "INFO - Start quantizing layer 32/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 32/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 32/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 32/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 32/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 32/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 32/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 32/32...\n",
      "INFO - Packing model...\n",
      "Packing model.layers.31.mlp.down_proj...: 100%|█| 224/224 [01:55<00:00,  1.95it/\n",
      "INFO - Model packed.\n"
     ]
    }
   ],
   "source": [
    "model.quantize(train_dataset, use_triton=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_quantized(\"models/llama-2-7b-hf-gptq\", use_safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaGPTQForCausalLM(\n",
      "  (model): LlamaForCausalLM(\n",
      "    (model): LlamaModel(\n",
      "      (embed_tokens): Embedding(32000, 4096)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x LlamaDecoderLayer(\n",
      "          (self_attn): LlamaSdpaAttention(\n",
      "            (q_proj): QuantLinear()\n",
      "            (k_proj): QuantLinear()\n",
      "            (v_proj): QuantLinear()\n",
      "            (o_proj): QuantLinear()\n",
      "            (rotary_emb): LlamaRotaryEmbedding()\n",
      "          )\n",
      "          (mlp): LlamaMLP(\n",
      "            (gate_proj): QuantLinear()\n",
      "            (up_proj): QuantLinear()\n",
      "            (down_proj): QuantLinear()\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      (rotary_emb): LlamaRotaryEmbedding()\n",
      "    )\n",
      "    (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "LlamaGPTQForCausalLM                                         --\n",
       "├─LlamaForCausalLM: 1-1                                      --\n",
       "│    └─LlamaModel: 2-1                                       --\n",
       "│    │    └─Embedding: 3-1                                   131,072,000\n",
       "│    │    └─ModuleList: 3-2                                  262,144\n",
       "│    │    └─LlamaRMSNorm: 3-3                                4,096\n",
       "│    │    └─LlamaRotaryEmbedding: 3-4                        --\n",
       "│    └─Linear: 2-2                                           131,072,000\n",
       "=====================================================================================\n",
       "Total params: 262,410,240\n",
       "Trainable params: 262,410,240\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - You passed a model that is compatible with the Marlin int4*fp16 GPTQ kernel but use_marlin is False. We recommend using `use_marlin=True` to use the optimized Marlin kernels for inference. Example: `model = AutoGPTQForCausalLM.from_quantized(..., use_marlin=True)`.\n",
      "INFO - The layer lm_head is not quantized.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Write a tweet on future of AI [/INST]\n",
      "A few days ago, I was reading an article about the future of artificial intelligence. The author said that in 20 years time, we will have robots doing all our work for us and humans would be left with nothing to do but enjoy life. He also mentioned how this is already happening nowadays as more and more people are becoming unemployed due to automation taking over their jobs. This got me thinking: what if there were no such thing called \"work\" anymore? What kind of society would it look like then? Would everyone just sit around watching TV or playing video games all day long without any responsibilities at all? Or maybe they'd go out into nature instead - exploring new places every weekend perhaps! It sounds pretty nice doesn't it? But wait...what happens when these machines start getting smarter than humanity itself?? Will they take control away from us too??? Hmmm......\n",
      "The Future Of Artificial Intelligence Is Here And Now\n",
      "Artificial intelligence (AI) has been around since the early 1950s, but only recently has it become mainstream enough to make headlines. In fact, according to Forbes magazine’\n"
     ]
    }
   ],
   "source": [
    "# Load & inderence the quantized model\n",
    "quantized_model = AutoGPTQForCausalLM.from_quantized(\"models/llama-2-7b-hf-gptq\", device=\"cuda:0\", use_triton=False)\n",
    "\n",
    "prompt = \"<s>[INST] Write a tweet on future of AI [/INST]\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(0)\n",
    "output = quantized_model.generate(**inputs, max_new_tokens=250, temperature=0.6, repetition_penalty=1.2, top_p=0.95, top_k=40)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. AWQ (Activation-Aware Weight Quantization)\n",
    "**AWQ (Activation-Aware Weight Quantization)** assumes that not all weights are equally important for an LLM’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. bitsandbytes\n",
    "`bitsandbytes` enables accessible large language models via k-bit **Quantization** for PyTorch by providing the following features to reduce memory consumption for inference & training:\n",
    "\n",
    "### 1-3-1. 8-Bit Optimizers\n",
    "- 8-bit optimizers uses block-wise quantization to maintain 32-bit performance at a small fraction of the memory cost.\n",
    "    - [8-bit Optimizers via Block-wise Quantization](https://arxiv.org/abs/2110.02861)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "# adam = torch.optim.Adam()\n",
    "# Optimize parameters to 8-bit only if the minimum size is the value set by `min_8bit_size` \n",
    "adam = bnb.optim.Adam8bit(model.parameters(), min_8bit_size=16384)\n",
    "\n",
    "# Recommended for NLP models to improve stability\n",
    "# torch.nn.Embedding(.)\n",
    "bnb.nn.StableEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32-bit Adam optimizer with 5th percentile clipping\n",
    "adam = bnb.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.995), optim_bits=32, percentile_clipping=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [] Unstable parameters\n",
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "mng = bnb.optim.GlobalOptimManager.get_instance()\n",
    "\n",
    "model = MyModel()\n",
    "mng.register_parameters(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "# use 8-bit optimizer states for all parameters\n",
    "adam = bnb.optim.Adam(model.parameters(), lr=0.001, optim_bits=8)\n",
    "\n",
    "# override the parameter model.fc1.weight now uses 32-bit Adam\n",
    "mng.override_config(model.fc1.weight, \"optim_bits\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mng.override_config([model.special.weight, model.also_special.weight],\n",
    "                    key_value_dict ={'is_sparse': True, 'lr': 1e-5, 'betas'=(0.9, 0.98)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(d_in, d_out):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linear = torch.nn.Linear(d_in, d_out)\n",
    "        # optimization will happen in 32-bit and\n",
    "        # learning rate will be set to 0.0001 independent of the main learning rate\n",
    "        config = {'optim_bits': 32, 'lr' : 0.0001}\n",
    "        GlobalOptimManager.get_instance().register_module_override(self, 'weight', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3-2. LLM.int8()\n",
    "\n",
    "- **LLM.int8()**, or 8-bit Quantization, enables large language model inference with only half the required memory and without any performance degradation. This method is based on vector-wise quantization to quantize most features to 8-bits and separately treating outliers with 16-bit matrix multiplication.\n",
    "    - [LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale](https://arxiv.org/abs/2208.07339)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3-3. QLoRA \n",
    "- **QLoRA ()** or 4-bit quantization enables large language model training with several memory-saving techniques that don’t compromise performance. This method quantizes a model to 4-bits and inserts a small set of trainable low-rank adaptation (LoRA) weights to allow training.\n",
    "    - [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)\n",
    "\n",
    "**FSDP (Fully Sharded Data Parallel)** enables sharding model parameters, optimizer states, and gradients across GPUs. **FSDP-QLoRA** combines data parallelism, 4-bit quantization, and **QLoRA (Quantized Low-Rank Adaptation)** to train LLMs up to 70B parameters on a dual 24GB GPU system.\n",
    "\n",
    "**PEFT (Parameter-Efficient Fine-Tuning)** is a library for efficiently adapting large pretrained models to various downstream applications without fine-tuning all of a model’s parameters because it is prohibitively costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_storage=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-70b\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=\"all-linear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Llama (Large Language Model Meta AI)\n",
    "\n",
    "Access:\n",
    "- [meta-llama/llama-models](https://github.com/meta-llama/llama-models) in GitHub\n",
    "- [meta-llama/Meta-Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct) in Hugging Face\n",
    "\n",
    "Information:\n",
    "- [Comparison of Llama Models](https://en.wikipedia.org/wiki/Llama_(language_model)#Comparison_of_models)\n",
    "\n",
    "Leaderboard:\n",
    "- [Artificial Analysis](https://artificialanalysis.ai/)\n",
    "- [LMSYS Chatbot Arena Leaderboard](https://chat.lmsys.org/?leaderboard)\n",
    "- [Open LLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)\n",
    "\n",
    "## 2-1. Text Generation Web UI\n",
    "\n",
    "Launch [Oobabooga Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1722642331284,
     "user": {
      "displayName": "YungShun Chang",
      "userId": "16917011985937891008"
     },
     "user_tz": -480
    },
    "id": "mNFbEm4kaidU",
    "outputId": "b2667178-0391-457f-f1e6-1076bd6512de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/yungshun317/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdVzV_omannu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32;1m\n",
      " --> Installing the web UI. This will take a while, but after the initial setup, you can download and test as many models as you like.\u001b[0;37;0m\n",
      "\n",
      "Cloning into 'text-generation-webui'...\n",
      "remote: Enumerating objects: 18858, done.\u001b[K\n",
      "remote: Counting objects: 100% (492/492), done.\u001b[K\n",
      "remote: Compressing objects: 100% (217/217), done.\u001b[K\n",
      "remote: Total 18858 (delta 349), reused 384 (delta 275), pack-reused 18366\u001b[K\n",
      "Receiving objects: 100% (18858/18858), 27.83 MiB | 17.15 MiB/s, done.\n",
      "Resolving deltas: 100% (13355/13355), done.\n",
      "/content/text-generation-webui\n",
      "Downloading Miniconda from https://repo.anaconda.com/miniconda/Miniconda3-py310_23.3.1-0-Linux-x86_64.sh to /content/text-generation-webui/installer_files/miniconda_installer.sh\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 69.7M  100 69.7M    0     0   286M      0 --:--:-- --:--:-- --:--:--  288M\n",
      "PREFIX=/content/text-generation-webui/installer_files/conda\n",
      "Unpacking payload ...\n",
      "                                                                                             \n",
      "Installing base environment...\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
      "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
      "installation finished.\n",
      "Miniconda version:\n",
      "conda 23.3.1\n",
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
      "Solving environment: / \b\bdone\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.7.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.7.1\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /content/text-generation-webui/installer_files/env\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.11\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bzip2-1.0.8                |       h5eee18b_6         262 KB\n",
      "    ca-certificates-2024.7.2   |       h06a4308_0         127 KB\n",
      "    libffi-3.4.4               |       h6a678d5_1         141 KB\n",
      "    openssl-3.0.14             |       h5eee18b_0         5.2 MB\n",
      "    pip-24.0                   |  py311h06a4308_0         3.3 MB\n",
      "    python-3.11.9              |       h955ad1f_0        32.9 MB\n",
      "    setuptools-69.5.1          |  py311h06a4308_0         1.3 MB\n",
      "    sqlite-3.45.3              |       h5eee18b_0         1.2 MB\n",
      "    tk-8.6.14                  |       h39e8969_0         3.4 MB\n",
      "    tzdata-2024a               |       h04d1e81_0         116 KB\n",
      "    wheel-0.43.0               |  py311h06a4308_0         146 KB\n",
      "    xz-5.4.6                   |       h5eee18b_1         643 KB\n",
      "    zlib-1.2.13                |       h5eee18b_1         111 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        48.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.7.2-h06a4308_0 \n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 \n",
      "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
      "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
      "  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
      "  openssl            pkgs/main/linux-64::openssl-3.0.14-h5eee18b_0 \n",
      "  pip                pkgs/main/linux-64::pip-24.0-py311h06a4308_0 \n",
      "  python             pkgs/main/linux-64::python-3.11.9-h955ad1f_0 \n",
      "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
      "  setuptools         pkgs/main/linux-64::setuptools-69.5.1-py311h06a4308_0 \n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
      "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
      "  tzdata             pkgs/main/noarch::tzdata-2024a-h04d1e81_0 \n",
      "  wheel              pkgs/main/linux-64::wheel-0.43.0-py311h06a4308_0 \n",
      "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1 \n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "bzip2-1.0.8          | 262 KB    | :   0% 0/1 [00:00<?, ?it/s]\n",
      "libffi-3.4.4         | 141 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "tzdata-2024a         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "wheel-0.43.0         | 146 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "zlib-1.2.13          | 111 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.4.6             | 643 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 127 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.14            | 3.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.14       | 5.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-24.0             | 3.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.45.3        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-69.5.1    | 1.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.4.6             | 643 KB    | :  82% 0.8205165561104864/1 [00:00<00:00,  8.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.14            | 3.4 MB    | :   8% 0.08227598074334956/1 [00:00<00:01,  1.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-24.0             | 3.3 MB    | :   3% 0.032907386286197965/1 [00:00<00:02,  3.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.14       | 5.2 MB    | :   5% 0.04509513355690068/1 [00:00<00:02,  2.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.45.3        | 1.2 MB    | :   5% 0.050978125673338925/1 [00:00<00:01,  1.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :   0% 0.0004752826479857534/1 [00:00<05:04, 304.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.14            | 3.4 MB    | :  58% 0.5805027530225219/1 [00:00<00:00,  3.24it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-69.5.1    | 1.3 MB    | :   1% 0.011777839919429914/1 [00:00<00:16, 17.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-24.0             | 3.3 MB    | :  53% 0.5312192357629101/1 [00:00<00:00,  3.04it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:00<00:00,  4.52it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :   5% 0.0489541127425326/1 [00:00<00:03,  4.14s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-24.0             | 3.3 MB    | :  99% 0.987221588585939/1 [00:00<00:00,  3.72it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.14       | 5.2 MB    | :  62% 0.6223128430852294/1 [00:00<00:00,  2.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "zlib-1.2.13          | 111 KB    | : 100% 1.0/1 [00:00<00:00,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "zlib-1.2.13          | 111 KB    | : 100% 1.0/1 [00:00<00:00,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  11% 0.11359255286859506/1 [00:00<00:02,  2.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "wheel-0.43.0         | 146 KB    | : 100% 1.0/1 [00:00<00:00,  2.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "wheel-0.43.0         | 146 KB    | : 100% 1.0/1 [00:00<00:00,  2.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 127 KB    | : 100% 1.0/1 [00:00<00:00,  2.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 127 KB    | : 100% 1.0/1 [00:00<00:00,  2.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  21% 0.211976061001646/1 [00:00<00:01,  1.61s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  30% 0.3027550467669249/1 [00:00<00:00,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  1.73it/s]\u001b[A\n",
      "libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  1.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  39% 0.391157619292275/1 [00:00<00:00,  1.29s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.55it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  52% 0.5161569557125282/1 [00:00<00:00,  1.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  63% 0.6307000738770947/1 [00:00<00:00,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xz-5.4.6             | 643 KB    | : 100% 1.0/1 [00:00<00:00,  8.20it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  74% 0.7371633870259034/1 [00:00<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  84% 0.8393491563428405/1 [00:01<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-3.11.9        | 32.9 MB   | :  94% 0.9358315338839484/1 [00:01<00:00,  1.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "tzdata-2024a         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "tzdata-2024a         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.14            | 3.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.82s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tk-8.6.14            | 3.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-69.5.1    | 1.3 MB    | : 100% 1.0/1 [00:01<00:00,  1.53s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "setuptools-69.5.1    | 1.3 MB    | : 100% 1.0/1 [00:01<00:00,  1.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.14       | 5.2 MB    | : 100% 1.0/1 [00:01<00:00,  2.29s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.14       | 5.2 MB    | : 100% 1.0/1 [00:01<00:00,  2.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-24.0             | 3.3 MB    | : 100% 1.0/1 [00:02<00:00,  3.72it/s]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \n",
      "                                                                        \u001b[A\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: \\ \b\b| \b\b/ \b\bdone\n",
      "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
      "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /content/text-generation-webui/installer_files/env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\n",
      "\n",
      "*******************************************************************\n",
      "* Selected GPU choice \"A\" based on the GPU_CHOICE environment variable.\n",
      "*******************************************************************\n",
      "\n",
      "\n",
      "CUDA: 12.1\n",
      "\n",
      "\n",
      "*******************************************************************\n",
      "* Installing PyTorch.\n",
      "*******************************************************************\n",
      "\n",
      "\n",
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
      "Solving environment: - \b\b\\ \b\b| \b\bdone\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.7.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.7.1\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /content/text-generation-webui/installer_files/env\n",
      "\n",
      "  added / updated specs:\n",
      "    - git\n",
      "    - ninja\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    c-ares-1.19.1              |       h5eee18b_0         118 KB\n",
      "    curl-8.7.1                 |       hdbd6064_0          86 KB\n",
      "    expat-2.6.2                |       h6a678d5_0         177 KB\n",
      "    gdbm-1.18                  |       hd4cb3f1_4         194 KB\n",
      "    gettext-0.21.0             |       h39681ba_1         3.0 MB\n",
      "    git-2.45.2                 | pl5340h9abc3c3_0        10.2 MB\n",
      "    icu-73.1                   |       h6a678d5_0        25.9 MB\n",
      "    krb5-1.20.1                |       h143b758_1         1.3 MB\n",
      "    libcurl-8.7.1              |       h251f7ec_0         424 KB\n",
      "    libedit-3.1.20230828       |       h5eee18b_0         179 KB\n",
      "    libev-4.33                 |       h7f8727e_1         111 KB\n",
      "    libnghttp2-1.57.0          |       h2d74bed_0         674 KB\n",
      "    libssh2-1.11.0             |       h251f7ec_0         282 KB\n",
      "    libxml2-2.10.4             |       hfdd30dd_2         754 KB\n",
      "    ninja-1.10.2               |       h06a4308_5           8 KB\n",
      "    ninja-base-1.10.2          |       hd09550d_5         109 KB\n",
      "    pcre2-10.42                |       hebb0a14_1         1.3 MB\n",
      "    perl-5.34.0                |       h5eee18b_2        12.4 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        57.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  c-ares             pkgs/main/linux-64::c-ares-1.19.1-h5eee18b_0 \n",
      "  curl               pkgs/main/linux-64::curl-8.7.1-hdbd6064_0 \n",
      "  expat              pkgs/main/linux-64::expat-2.6.2-h6a678d5_0 \n",
      "  gdbm               pkgs/main/linux-64::gdbm-1.18-hd4cb3f1_4 \n",
      "  gettext            pkgs/main/linux-64::gettext-0.21.0-h39681ba_1 \n",
      "  git                pkgs/main/linux-64::git-2.45.2-pl5340h9abc3c3_0 \n",
      "  icu                pkgs/main/linux-64::icu-73.1-h6a678d5_0 \n",
      "  krb5               pkgs/main/linux-64::krb5-1.20.1-h143b758_1 \n",
      "  libcurl            pkgs/main/linux-64::libcurl-8.7.1-h251f7ec_0 \n",
      "  libedit            pkgs/main/linux-64::libedit-3.1.20230828-h5eee18b_0 \n",
      "  libev              pkgs/main/linux-64::libev-4.33-h7f8727e_1 \n",
      "  libnghttp2         pkgs/main/linux-64::libnghttp2-1.57.0-h2d74bed_0 \n",
      "  libssh2            pkgs/main/linux-64::libssh2-1.11.0-h251f7ec_0 \n",
      "  libxml2            pkgs/main/linux-64::libxml2-2.10.4-hfdd30dd_2 \n",
      "  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5 \n",
      "  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5 \n",
      "  pcre2              pkgs/main/linux-64::pcre2-10.42-hebb0a14_1 \n",
      "  perl               pkgs/main/linux-64::perl-5.34.0-h5eee18b_2 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ninja-1.10.2         | 8 KB      | :   0% 0/1 [00:00<?, ?it/s]\n",
      "libev-4.33           | 111 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "libnghttp2-1.57.0    | 674 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "c-ares-1.19.1        | 118 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "gdbm-1.18            | 194 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "krb5-1.20.1          | 1.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "perl-5.34.0          | 12.4 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "curl-8.7.1           | 86 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ninja-base-1.10.2    | 109 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "git-2.45.2           | 10.2 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcre2-10.42          | 1.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.6.2          | 177 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libedit-3.1.20230828 | 179 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 282 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcurl-8.7.1        | 424 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.10.4       | 754 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ninja-1.10.2         | 8 KB      | : 100% 1.0/1 [00:00<00:00,  9.66it/s]\n",
      "\n",
      "\n",
      "c-ares-1.19.1        | 118 KB    | :  14% 0.13577975568925796/1 [00:00<00:00,  1.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "gdbm-1.18            | 194 KB    | :   8% 0.08247671784545683/1 [00:00<00:01,  1.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "libev-4.33           | 111 KB    | :  14% 0.14370543193200655/1 [00:00<00:00,  1.27it/s]\u001b[A\n",
      "\n",
      "libnghttp2-1.57.0    | 674 KB    | :   2% 0.02373257971577107/1 [00:00<00:05,  5.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ninja-1.10.2         | 8 KB      | : 100% 1.0/1 [00:00<00:00,  9.66it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "perl-5.34.0          | 12.4 MB   | :   0% 0.001261326941501575/1 [00:00<01:44, 104.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "curl-8.7.1           | 86 KB     | :  19% 0.1862199086176718/1 [00:00<00:00,  1.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ninja-base-1.10.2    | 109 KB    | :  15% 0.14719384775714453/1 [00:00<00:00,  1.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "git-2.45.2           | 10.2 MB   | :   0% 0.001536149726593664/1 [00:00<01:46, 107.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :   0% 0.0006024446146419119/1 [00:00<05:05, 305.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "libev-4.33           | 111 KB    | : 100% 1.0/1 [00:00<00:00,  1.27it/s]                \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "perl-5.34.0          | 12.4 MB   | :  15% 0.15009790603868742/1 [00:00<00:01,  1.29s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcre2-10.42          | 1.3 MB    | :   1% 0.011879729341713339/1 [00:00<00:20, 20.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.6.2          | 177 KB    | :   9% 0.09041593315931504/1 [00:00<00:02,  2.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "curl-8.7.1           | 86 KB     | : 100% 1.0/1 [00:00<00:00,  4.36it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "curl-8.7.1           | 86 KB     | : 100% 1.0/1 [00:00<00:00,  4.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "git-2.45.2           | 10.2 MB   | :  19% 0.19048256609761433/1 [00:00<00:00,  1.14s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "gdbm-1.18            | 194 KB    | : 100% 1.0/1 [00:00<00:00,  4.03it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "gdbm-1.18            | 194 KB    | : 100% 1.0/1 [00:00<00:00,  4.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :   7% 0.06687135222525221/1 [00:00<00:03,  3.43s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libedit-3.1.20230828 | 179 KB    | :   9% 0.08928123807966869/1 [00:00<00:02,  3.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 282 KB    | :   6% 0.05670675780912001/1 [00:00<00:05,  5.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ninja-base-1.10.2    | 109 KB    | : 100% 1.0/1 [00:00<00:00,  3.41it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ninja-base-1.10.2    | 109 KB    | : 100% 1.0/1 [00:00<00:00,  3.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "perl-5.34.0          | 12.4 MB   | :  29% 0.2901051965453622/1 [00:00<00:00,  1.04it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcurl-8.7.1        | 424 KB    | :   4% 0.03770762322756449/1 [00:00<00:09,  9.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "git-2.45.2           | 10.2 MB   | :  34% 0.33948908957719975/1 [00:00<00:00,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  14% 0.13735737213835592/1 [00:00<00:01,  2.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gettext-0.21.0       | 3.0 MB    | :   1% 0.00512470672283075/1 [00:00<01:16, 76.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "c-ares-1.19.1        | 118 KB    | : 100% 1.0/1 [00:00<00:00,  2.52it/s]                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "c-ares-1.19.1        | 118 KB    | : 100% 1.0/1 [00:00<00:00,  2.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libnghttp2-1.57.0    | 674 KB    | : 100% 1.0/1 [00:00<00:00,  2.62it/s]                \u001b[A\u001b[A\n",
      "\n",
      "libnghttp2-1.57.0    | 674 KB    | : 100% 1.0/1 [00:00<00:00,  2.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "perl-5.34.0          | 12.4 MB   | :  42% 0.42380585234452917/1 [00:00<00:00,  1.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "git-2.45.2           | 10.2 MB   | :  52% 0.5207547573152521/1 [00:00<00:00,  1.36it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  21% 0.20904828128074343/1 [00:00<00:01,  1.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gettext-0.21.0       | 3.0 MB    | :  65% 0.6508377537995053/1 [00:00<00:00,  1.73it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "perl-5.34.0          | 12.4 MB   | :  57% 0.5650744697927056/1 [00:00<00:00,  1.24it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.6.2          | 177 KB    | : 100% 1.0/1 [00:00<00:00,  2.08it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "expat-2.6.2          | 177 KB    | : 100% 1.0/1 [00:00<00:00,  2.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libedit-3.1.20230828 | 179 KB    | : 100% 1.0/1 [00:00<00:00,  2.05it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libedit-3.1.20230828 | 179 KB    | : 100% 1.0/1 [00:00<00:00,  2.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "git-2.45.2           | 10.2 MB   | :  69% 0.6881950775139615/1 [00:00<00:00,  1.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  27% 0.2729074104327861/1 [00:00<00:01,  1.74s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.10.4       | 754 KB    | :   2% 0.02121172496740691/1 [00:00<00:27, 28.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "perl-5.34.0          | 12.4 MB   | :  70% 0.6987751255918725/1 [00:00<00:00,  1.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "git-2.45.2           | 10.2 MB   | :  88% 0.8756053441583884/1 [00:00<00:00,  1.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  34% 0.3445983195751736/1 [00:00<00:01,  1.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "perl-5.34.0          | 12.4 MB   | :  86% 0.8614863010455757/1 [00:00<00:00,  1.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  45% 0.44882123790822437/1 [00:00<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "krb5-1.20.1          | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.24it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "krb5-1.20.1          | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  55% 0.5506343777827074/1 [00:00<00:00,  1.20s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcurl-8.7.1        | 424 KB    | : 100% 1.0/1 [00:00<00:00,  1.25it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcurl-8.7.1        | 424 KB    | : 100% 1.0/1 [00:00<00:00,  1.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 282 KB    | : 100% 1.0/1 [00:00<00:00,  1.13it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 282 KB    | : 100% 1.0/1 [00:00<00:00,  1.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  65% 0.6530499622718324/1 [00:00<00:00,  1.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  76% 0.7572728806048832/1 [00:01<00:00,  1.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.10.4       | 754 KB    | : 100% 1.0/1 [00:01<00:00,  1.06it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.10.4       | 754 KB    | : 100% 1.0/1 [00:01<00:00,  1.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcre2-10.42          | 1.3 MB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcre2-10.42          | 1.3 MB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  87% 0.8693275789282788/1 [00:01<00:00,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | :  98% 0.9849969449395259/1 [00:01<00:00,  1.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gettext-0.21.0       | 3.0 MB    | : 100% 1.0/1 [00:01<00:00,  1.73it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "icu-73.1             | 25.9 MB   | : 100% 1.0/1 [00:02<00:00,  1.04it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "git-2.45.2           | 10.2 MB   | : 100% 1.0/1 [00:02<00:00,  1.60it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \n",
      "                                                                        \u001b[A\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: - \b\b\\ \b\bdone\n",
      "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
      "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.2.2\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp311-cp311-linux_x86_64.whl (757.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.3/757.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.17.2\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp311-cp311-linux_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.2.2\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting sympy (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jinja2 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m180.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy (from torchvision==0.17.2)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.17.2)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.2.2)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 pillow-10.2.0 sympy-1.12 torch-2.2.2+cu121 torchaudio-2.2.2+cu121 torchvision-0.17.2+cu121 triton-2.2.0 typing-extensions-4.9.0\n",
      "Collecting py-cpuinfo==9.0.0\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo\n",
      "Successfully installed py-cpuinfo-9.0.0\n",
      "\n",
      "\n",
      "*******************************************************************\n",
      "* Installing webui requirements from file: requirements.txt\n",
      "*******************************************************************\n",
      "\n",
      "\n",
      "TORCH: 2.2.2+cu121\n",
      "\n",
      "Collecting llama-cpp-python==0.2.85+cpuavx2 (from -r temp_requirements.txt (line 38))\n",
      "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.85+cpuavx2-cp311-cp311-linux_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hIgnoring llama-cpp-python: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\"' don't match your environment\n",
      "Ignoring llama-cpp-python: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
      "Ignoring llama-cpp-python: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
      "Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
      "Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
      "Collecting llama-cpp-python-cuda==0.2.85+cu121 (from -r temp_requirements.txt (line 46))\n",
      "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.85+cu121-cp311-cp311-linux_x86_64.whl (397.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.5/397.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hIgnoring llama-cpp-python-cuda: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\"' don't match your environment\n",
      "Ignoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
      "Ignoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
      "Collecting llama-cpp-python-cuda-tensorcores==0.2.85+cu121 (from -r temp_requirements.txt (line 52))\n",
      "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda_tensorcores-0.2.85+cu121-cp311-cp311-linux_x86_64.whl (434.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hIgnoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\"' don't match your environment\n",
      "Ignoring exllamav2: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
      "Ignoring exllamav2: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
      "Collecting exllamav2==0.1.8+cu121.torch2.2.2 (from -r temp_requirements.txt (line 58))\n",
      "  Downloading https://github.com/oobabooga/exllamav2/releases/download/v0.1.8/exllamav2-0.1.8+cu121.torch2.2.2-cp311-cp311-linux_x86_64.whl (135.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hIgnoring exllamav2: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\"' don't match your environment\n",
      "Ignoring exllamav2: markers 'platform_system == \"Linux\" and platform_machine != \"x86_64\"' don't match your environment\n",
      "Ignoring flash-attn: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
      "Ignoring flash-attn: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
      "Collecting flash-attn==2.6.1+cu123torch2.2cxx11abiFALSE (from -r temp_requirements.txt (line 63))\n",
      "  Downloading https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.1/flash_attn-2.6.1+cu123torch2.2cxx11abiFALSE-cp311-cp311-linux_x86_64.whl (198.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.4/198.4 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hIgnoring flash-attn: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\"' don't match your environment\n",
      "Ignoring autoawq: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
      "Ignoring autoawq: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
      "Collecting autoawq==0.2.6 (from -r temp_requirements.txt (line 67))\n",
      "  Downloading https://github.com/oobabooga/AutoAWQ/releases/download/0.2.6/autoawq-0.2.6-cp311-cp311-linux_x86_64.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hIgnoring autoawq: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\"' don't match your environment\n",
      "Ignoring autoawq-kernels: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
      "Ignoring autoawq-kernels: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
      "Collecting autoawq-kernels==0.0.7 (from -r temp_requirements.txt (line 71))\n",
      "  Downloading https://github.com/oobabooga/AutoAWQ_kernels/releases/download/0.0.7/autoawq_kernels-0.0.7-cp311-cp311-linux_x86_64.whl (33.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hIgnoring autoawq-kernels: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\"' don't match your environment\n",
      "Collecting accelerate==0.32.* (from -r temp_requirements.txt (line 1))\n",
      "  Using cached accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting aqlm==1.1.6 (from aqlm[cpu,gpu]==1.1.6->-r temp_requirements.txt (line 2))\n",
      "  Downloading aqlm-1.1.6-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting auto-gptq==0.7.1 (from -r temp_requirements.txt (line 3))\n",
      "  Downloading auto_gptq-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting bitsandbytes==0.43.* (from -r temp_requirements.txt (line 4))\n",
      "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting colorama (from -r temp_requirements.txt (line 5))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting datasets (from -r temp_requirements.txt (line 6))\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting einops (from -r temp_requirements.txt (line 7))\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting gradio==4.26.* (from -r temp_requirements.txt (line 8))\n",
      "  Downloading gradio-4.26.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting hqq==0.1.7.post3 (from -r temp_requirements.txt (line 9))\n",
      "  Downloading hqq-0.1.7.post3.tar.gz (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting jinja2==3.1.4 (from -r temp_requirements.txt (line 10))\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting lm_eval==0.3.0 (from -r temp_requirements.txt (line 11))\n",
      "  Downloading lm_eval-0.3.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting markdown (from -r temp_requirements.txt (line 12))\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting numba==0.59.* (from -r temp_requirements.txt (line 13))\n",
      "  Downloading numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy==1.26.* in ./installer_files/env/lib/python3.11/site-packages (from -r temp_requirements.txt (line 14)) (1.26.3)\n",
      "Collecting numpy==1.26.* (from -r temp_requirements.txt (line 14))\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optimum==1.17.* (from -r temp_requirements.txt (line 15))\n",
      "  Downloading optimum-1.17.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pandas (from -r temp_requirements.txt (line 16))\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting peft==0.8.* (from -r temp_requirements.txt (line 17))\n",
      "  Downloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: Pillow>=9.5.0 in ./installer_files/env/lib/python3.11/site-packages (from -r temp_requirements.txt (line 18)) (10.2.0)\n",
      "Collecting Pillow>=9.5.0 (from -r temp_requirements.txt (line 18))\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting psutil (from -r temp_requirements.txt (line 19))\n",
      "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting pyyaml (from -r temp_requirements.txt (line 20))\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from -r temp_requirements.txt (line 21))\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich (from -r temp_requirements.txt (line 22))\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting safetensors==0.4.* (from -r temp_requirements.txt (line 23))\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting scipy (from -r temp_requirements.txt (line 24))\n",
      "  Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from -r temp_requirements.txt (line 25))\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tensorboard (from -r temp_requirements.txt (line 26))\n",
      "  Using cached tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting transformers==4.43.* (from -r temp_requirements.txt (line 27))\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from -r temp_requirements.txt (line 28))\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting wandb (from -r temp_requirements.txt (line 29))\n",
      "  Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting SpeechRecognition==3.10.0 (from -r temp_requirements.txt (line 32))\n",
      "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Collecting flask_cloudflared==0.0.14 (from -r temp_requirements.txt (line 33))\n",
      "  Downloading flask_cloudflared-0.0.14-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sse-starlette==1.6.5 (from -r temp_requirements.txt (line 34))\n",
      "  Downloading sse_starlette-1.6.5-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting tiktoken (from -r temp_requirements.txt (line 35))\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting packaging>=20.0 (from accelerate==0.32.*->-r temp_requirements.txt (line 1))\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./installer_files/env/lib/python3.11/site-packages (from accelerate==0.32.*->-r temp_requirements.txt (line 1)) (2.2.2+cu121)\n",
      "Collecting huggingface-hub (from accelerate==0.32.*->-r temp_requirements.txt (line 1))\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting rouge (from auto-gptq==0.7.1->-r temp_requirements.txt (line 3))\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting gekko (from auto-gptq==0.7.1->-r temp_requirements.txt (line 3))\n",
      "  Downloading gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==0.15.1 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading gradio_client-0.15.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in ./installer_files/env/lib/python3.11/site-packages (from gradio==4.26.*->-r temp_requirements.txt (line 8)) (2.1.5)\n",
      "Collecting matplotlib~=3.0 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading matplotlib-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting orjson~=3.0 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m117.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic>=2.0 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting pydub (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading ruff-0.5.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.9 (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./installer_files/env/lib/python3.11/site-packages (from gradio==4.26.*->-r temp_requirements.txt (line 8)) (4.9.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting termcolor (from hqq==0.1.7.post3->-r temp_requirements.txt (line 9))\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting jsonlines (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting numexpr (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading numexpr-2.10.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting openai>=0.6.4 (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pybind11>=2.6.2 (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading pybind11-2.13.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pycountry (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pytablewriter (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting rouge-score>=0.0.4 (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting sacrebleu==1.5.0 (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading sacrebleu-1.5.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting scikit-learn>=0.24.1 (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting sqlitedict (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tqdm-multiprocess (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting zstandard (from lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba==0.59.*->-r temp_requirements.txt (line 13))\n",
      "  Downloading llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting coloredlogs (from optimum==1.17.*->-r temp_requirements.txt (line 15))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in ./installer_files/env/lib/python3.11/site-packages (from optimum==1.17.*->-r temp_requirements.txt (line 15)) (1.12)\n",
      "Requirement already satisfied: filelock in ./installer_files/env/lib/python3.11/site-packages (from transformers==4.43.*->-r temp_requirements.txt (line 27)) (3.13.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.43.*->-r temp_requirements.txt (line 27))\n",
      "  Downloading regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m51.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.20,>=0.19 (from transformers==4.43.*->-r temp_requirements.txt (line 27))\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting Flask>=0.8 (from flask_cloudflared==0.0.14->-r temp_requirements.txt (line 33))\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting starlette (from sse-starlette==1.6.5->-r temp_requirements.txt (line 34))\n",
      "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: triton>=2.1 in ./installer_files/env/lib/python3.11/site-packages (from aqlm[cpu,gpu]==1.1.6->-r temp_requirements.txt (line 2)) (2.2.0)\n",
      "Collecting ninja (from aqlm[cpu,gpu]==1.1.6->-r temp_requirements.txt (line 2))\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: fsspec in ./installer_files/env/lib/python3.11/site-packages (from gradio-client==0.15.1->gradio==4.26.*->-r temp_requirements.txt (line 8)) (2024.2.0)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.15.1->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting portalocker (from sacrebleu==1.5.0->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->-r temp_requirements.txt (line 6))\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading aiohttp-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->-r temp_requirements.txt (line 16))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->-r temp_requirements.txt (line 16))\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r temp_requirements.txt (line 16))\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->-r temp_requirements.txt (line 21))\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->-r temp_requirements.txt (line 21))\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->-r temp_requirements.txt (line 21))\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->-r temp_requirements.txt (line 21))\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->-r temp_requirements.txt (line 22))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->-r temp_requirements.txt (line 22))\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r temp_requirements.txt (line 26))\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r temp_requirements.txt (line 26))\n",
      "  Downloading grpcio-1.65.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting protobuf!=4.24.0,<5.0.0,>=3.19.6 (from tensorboard->-r temp_requirements.txt (line 26))\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./installer_files/env/lib/python3.11/site-packages (from tensorboard->-r temp_requirements.txt (line 26)) (69.5.1)\n",
      "Collecting six>1.9 (from tensorboard->-r temp_requirements.txt (line 26))\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r temp_requirements.txt (line 26))\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r temp_requirements.txt (line 26))\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb->-r temp_requirements.txt (line 29))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r temp_requirements.txt (line 29))\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r temp_requirements.txt (line 29))\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting platformdirs (from wandb->-r temp_requirements.txt (line 29))\n",
      "  Using cached platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->-r temp_requirements.txt (line 29))\n",
      "  Downloading sentry_sdk-2.12.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting setproctitle (from wandb->-r temp_requirements.txt (line 29))\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.85+cpuavx2->-r temp_requirements.txt (line 38))\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting fastparquet (from exllamav2==0.1.8+cu121.torch2.2.2->-r temp_requirements.txt (line 58))\n",
      "  Downloading fastparquet-2024.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: networkx in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./installer_files/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./installer_files/env/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.32.*->-r temp_requirements.txt (line 1)) (12.1.105)\n",
      "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask>=0.8->flask_cloudflared==0.0.14->-r temp_requirements.txt (line 33))\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask>=0.8->flask_cloudflared==0.0.14->-r temp_requirements.txt (line 33))\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading aiohappyeyeballs-2.3.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r temp_requirements.txt (line 6))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets->-r temp_requirements.txt (line 6))\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r temp_requirements.txt (line 6))\n",
      "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r temp_requirements.txt (line 29))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyio (from httpx>=0.24.1->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sniffio (from httpx>=0.24.1->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->-r temp_requirements.txt (line 22))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading fonttools-4.53.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=0.6.4->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic>=2.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting nltk (from rouge-score>=0.0.4->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.17.*->-r temp_requirements.txt (line 15))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting starlette (from sse-starlette==1.6.5->-r temp_requirements.txt (line 34))\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting cramjam>=2.3 (from fastparquet->exllamav2==0.1.8+cu121.torch2.2.2->-r temp_requirements.txt (line 58))\n",
      "  Downloading cramjam-2.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading pathvalidate-3.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./installer_files/env/lib/python3.11/site-packages (from sympy->optimum==1.17.*->-r temp_requirements.txt (line 15)) (1.3.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r temp_requirements.txt (line 29))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.26.*->-r temp_requirements.txt (line 8))\n",
      "  Downloading rpds_py-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.3.0->-r temp_requirements.txt (line 11))\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Using cached accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "Downloading aqlm-1.1.6-py3-none-any.whl (14 kB)\n",
      "Downloading auto_gptq-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio-4.26.0-py3-none-any.whl (17.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading lm_eval-0.3.0-py3-none-any.whl (178 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optimum-1.17.1-py3-none-any.whl (407 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.1/407.1 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flask_cloudflared-0.0.14-py3-none-any.whl (6.4 kB)\n",
      "Downloading sse_starlette-1.6.5-py3-none-any.whl (9.6 kB)\n",
      "Downloading gradio_client-0.15.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading matplotlib-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.38.0-py3-none-any.whl (335 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.9/335.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.8/238.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (786 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.6/786.6 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.5.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading sentry_sdk-2.12.0-py2.py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.5-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastparquet-2024.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numexpr-2.10.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (406 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.7/406.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.3.4-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (306 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cramjam-2.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading fonttools-4.53.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
      "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.5/355.5 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: hqq, rouge-score, sqlitedict\n",
      "  Building wheel for hqq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for hqq: filename=hqq-0.1.7.post3-py3-none-any.whl size=59171 sha256=6b1fa5857780a1332a9e9f576b1c0eda7914de1b808086a45c56cdf56d60f9b3\n",
      "  Stored in directory: /root/.cache/pip/wheels/26/81/bd/c13e1177aba48bfe34d6ba60b9d47b02e52ee742e9f40e8e19\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=b4424ad5258a8625a243936106ceecbc115c1e699271e4ba159fbf8f5503c99e\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=92dc49795fae3834c25de90ce66fff9513093502a666346a98ac903c53fb545d\n",
      "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
      "Successfully built hqq rouge-score sqlitedict\n",
      "Installing collected packages: sqlitedict, sentencepiece, pytz, pydub, ninja, zstandard, xxhash, werkzeug, websockets, urllib3, tzdata, tqdm, toolz, tomlkit, threadpoolctl, termcolor, tensorboard-data-server, tcolorpy, sniffio, smmap, six, shellingham, setproctitle, semantic-version, safetensors, ruff, rpds-py, regex, pyyaml, python-multipart, pyparsing, pygments, pydantic-core, pycountry, pybind11, pyarrow-hotfix, psutil, protobuf, portalocker, platformdirs, Pillow, pathvalidate, packaging, orjson, numpy, multidict, mdurl, markdown, llvmlite, kiwisolver, joblib, jinja2, itsdangerous, importlib-resources, idna, humanfriendly, h11, grpcio, frozenlist, fonttools, ffmpy, einops, distro, diskcache, dill, cycler, cramjam, colorama, click, charset-normalizer, chardet, certifi, blinker, attrs, annotated-types, aiohappyeyeballs, aiofiles, absl-py, yarl, uvicorn, tqdm-multiprocess, tensorboard, sentry-sdk, scipy, sacrebleu, rouge, requests, referencing, python-dateutil, pydantic, pyarrow, numexpr, numba, nltk, multiprocess, mbstrdecoder, markdown-it-py, llama-cpp-python-cuda-tensorcores, llama-cpp-python-cuda, llama-cpp-python, jsonlines, httpcore, gitdb, gekko, Flask, docker-pycreds, contourpy, coloredlogs, anyio, aiosignal, typepy, tiktoken, starlette, SpeechRecognition, scikit-learn, rouge-score, rich, pandas, matplotlib, jsonschema-specifications, huggingface-hub, httpx, gitpython, flask_cloudflared, aiohttp, wandb, typer, tokenizers, sse-starlette, openai, jsonschema, gradio-client, flash-attn, fastparquet, fastapi, bitsandbytes, autoawq-kernels, accelerate, transformers, exllamav2, datasets, DataProperty, altair, tabledata, peft, hqq, gradio, autoawq, aqlm, pytablewriter, optimum, auto-gptq, lm_eval\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: pillow 10.2.0\n",
      "    Uninstalling pillow-10.2.0:\n",
      "      Successfully uninstalled pillow-10.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.3\n",
      "    Uninstalling Jinja2-3.1.3:\n",
      "      Successfully uninstalled Jinja2-3.1.3\n",
      "Successfully installed DataProperty-1.0.1 Flask-3.0.3 Pillow-10.4.0 SpeechRecognition-3.10.0 absl-py-2.1.0 accelerate-0.32.1 aiofiles-23.2.1 aiohappyeyeballs-2.3.4 aiohttp-3.10.0 aiosignal-1.3.1 altair-5.3.0 annotated-types-0.7.0 anyio-4.4.0 aqlm-1.1.6 attrs-23.2.0 auto-gptq-0.7.1 autoawq-0.2.6 autoawq-kernels-0.0.7 bitsandbytes-0.43.3 blinker-1.8.2 certifi-2024.7.4 chardet-5.2.0 charset-normalizer-3.3.2 click-8.1.7 colorama-0.4.6 coloredlogs-15.0.1 contourpy-1.2.1 cramjam-2.8.3 cycler-0.12.1 datasets-2.20.0 dill-0.3.8 diskcache-5.6.3 distro-1.9.0 docker-pycreds-0.4.0 einops-0.8.0 exllamav2-0.1.8+cu121.torch2.2.2 fastapi-0.112.0 fastparquet-2024.5.0 ffmpy-0.4.0 flash-attn-2.6.1 flask_cloudflared-0.0.14 fonttools-4.53.1 frozenlist-1.4.1 gekko-1.2.1 gitdb-4.0.11 gitpython-3.1.43 gradio-4.26.0 gradio-client-0.15.1 grpcio-1.65.4 h11-0.14.0 hqq-0.1.7.post3 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.24.5 humanfriendly-10.0 idna-3.7 importlib-resources-6.4.0 itsdangerous-2.2.0 jinja2-3.1.4 joblib-1.4.2 jsonlines-4.0.0 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 kiwisolver-1.4.5 llama-cpp-python-0.2.85+cpuavx2 llama-cpp-python-cuda-0.2.85+cu121 llama-cpp-python-cuda-tensorcores-0.2.85+cu121 llvmlite-0.42.0 lm_eval-0.3.0 markdown-3.6 markdown-it-py-3.0.0 matplotlib-3.9.1 mbstrdecoder-1.1.3 mdurl-0.1.2 multidict-6.0.5 multiprocess-0.70.16 ninja-1.11.1.1 nltk-3.8.1 numba-0.59.1 numexpr-2.10.1 numpy-1.26.4 openai-1.38.0 optimum-1.17.1 orjson-3.10.6 packaging-24.1 pandas-2.2.2 pathvalidate-3.2.0 peft-0.8.2 platformdirs-4.2.2 portalocker-2.10.1 protobuf-4.25.4 psutil-6.0.0 pyarrow-17.0.0 pyarrow-hotfix-0.6 pybind11-2.13.1 pycountry-24.6.1 pydantic-2.8.2 pydantic-core-2.20.1 pydub-0.25.1 pygments-2.18.0 pyparsing-3.1.2 pytablewriter-1.2.0 python-dateutil-2.9.0.post0 python-multipart-0.0.9 pytz-2024.1 pyyaml-6.0.1 referencing-0.35.1 regex-2024.7.24 requests-2.32.3 rich-13.7.1 rouge-1.0.1 rouge-score-0.1.2 rpds-py-0.19.1 ruff-0.5.6 sacrebleu-1.5.0 safetensors-0.4.3 scikit-learn-1.5.1 scipy-1.14.0 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.12.0 setproctitle-1.3.3 shellingham-1.5.4 six-1.16.0 smmap-5.0.1 sniffio-1.3.1 sqlitedict-2.1.0 sse-starlette-1.6.5 starlette-0.37.2 tabledata-1.3.3 tcolorpy-0.1.6 tensorboard-2.17.0 tensorboard-data-server-0.7.2 termcolor-2.4.0 threadpoolctl-3.5.0 tiktoken-0.7.0 tokenizers-0.19.1 tomlkit-0.12.0 toolz-0.12.1 tqdm-4.66.4 tqdm-multiprocess-0.0.11 transformers-4.43.3 typepy-1.3.2 typer-0.12.3 tzdata-2024.1 urllib3-2.2.2 uvicorn-0.30.5 wandb-0.17.5 websockets-11.0.3 werkzeug-3.0.3 xxhash-3.4.1 yarl-1.9.4 zstandard-0.23.0\n",
      "Will remove 80 (164.2 MB) tarball(s).\n",
      "Will remove 1 index cache(s).\n",
      "Will remove 4 (408 KB) package(s).\n",
      "There are no tempfile(s) to remove.\n",
      "There are no logfile(s) to remove.\n",
      "Files removed: 3606\n",
      "\n",
      "\n",
      "*******************************************************************\n",
      "* Will now exit due to LAUNCH_AFTER_INSTALL.\n",
      "*******************************************************************\n",
      "\n",
      "\n",
      "Downloading the model to models/meta-llama_Meta-Llama-3.1-8B-Instruct\n",
      "USE_POLICY.md: 100% 4.58k/4.58k [00:00<00:00, 27.2MB/s]\n",
      "config.json: 100% 855/855 [00:00<00:00, 8.46MB/s]\n",
      "generation_config.json: 100% 184/184 [00:00<00:00, 1.47MB/s]\n",
      "README.md: 100% 43.0k/43.0k [00:00<00:00, 48.5MB/s]\n",
      "model-00004-of-00004.safetensors: 100% 1.09G/1.09G [00:10<00:00, 115MB/s]\n",
      "model.safetensors.index.json: 100% 23.4k/23.4k [00:00<00:00, 114kB/s]\n",
      "special_tokens_map.json: 100% 296/296 [00:00<00:00, 1.27MB/s]\n",
      "tokenizer.json: 100% 8.66M/8.66M [00:00<00:00, 20.8MB/s]\n",
      "tokenizer_config.json: 100% 54.1k/54.1k [00:00<00:00, 67.6MB/s]\n",
      "model-00003-of-00004.safetensors: 100% 4.58G/4.58G [00:39<00:00, 124MB/s]\n",
      "model-00002-of-00004.safetensors: 100% 4.66G/4.66G [00:39<00:00, 125MB/s]\n",
      "model-00001-of-00004.safetensors: 100% 4.63G/4.63G [00:40<00:00, 124MB/s] \n",
      "\u001b[2;36m23:51:39-976314\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting Text generation web UI                                            \n",
      "\u001b[2;36m23:51:39-987375\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading \u001b[32m\"meta-llama_Meta-Llama-3.1-8B-Instruct\"\u001b[0m                            \n",
      "\u001b[2;36m23:51:39-992560\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[33mTRANSFORMERS_PARAMS\u001b[0m=                                                       \n",
      "{   'low_cpu_mem_usage': True,\n",
      "    'torch_dtype': torch.bfloat16,\n",
      "    'device_map': 'auto',\n",
      "    'quantization_config': BitsAndBytesConfig {\n",
      "  \"_load_in_4bit\": true,\n",
      "  \"_load_in_8bit\": false,\n",
      "  \"bnb_4bit_compute_dtype\": \"float16\",\n",
      "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"llm_int8_enable_fp32_cpu_offload\": true,\n",
      "  \"llm_int8_has_fp16_weight\": false,\n",
      "  \"llm_int8_skip_modules\": null,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"quant_method\": \"bitsandbytes\"\n",
      "}\n",
      "}\n",
      "\n",
      "/content/text-generation-webui/installer_files/env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:577: UserWarning: `do_sample` is set to `False`. However, `min_p` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `min_p`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100% 4/4 [00:05<00:00,  1.40s/it]\n",
      "\u001b[2;36m23:51:46-891504\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded \u001b[32m\"meta-llama_Meta-Llama-3.1-8B-Instruct\"\u001b[0m in \u001b[1;36m6.90\u001b[0m seconds.            \n",
      "\u001b[2;36m23:51:46-892801\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m LOADER: \u001b[32m\"Transformers\"\u001b[0m                                                     \n",
      "\u001b[2;36m23:51:46-893717\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TRUNCATION LENGTH: \u001b[1;36m131072\u001b[0m                                                  \n",
      "\u001b[2;36m23:51:46-894557\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INSTRUCTION TEMPLATE: \u001b[32m\"Custom \u001b[0m\u001b[32m(\u001b[0m\u001b[32mobtained from model metadata\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m              \n",
      "\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Running on public URL: https://06c4b38535d9d72806.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "Output generated in 4.68 seconds (10.89 tokens/s, 51 tokens, context 111, seed 688271926)\n"
     ]
    }
   ],
   "source": [
    "#@title 2. Launch the web UI\n",
    "\n",
    "#@markdown If unsure about the branch, write \"main\" or leave it blank.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ.pop('PYTHONPATH', None)\n",
    "\n",
    "if Path.cwd().name != 'text-generation-webui':\n",
    "  print(\"\\033[1;32;1m\\n --> Installing the web UI. This will take a while, but after the initial setup, you can download and test as many models as you like.\\033[0;37;0m\\n\")\n",
    "\n",
    "  !git clone https://github.com/oobabooga/text-generation-webui\n",
    "  %cd text-generation-webui\n",
    "\n",
    "  # Install the project in an isolated environment\n",
    "  !GPU_CHOICE=A \\\n",
    "  USE_CUDA118=FALSE \\\n",
    "  LAUNCH_AFTER_INSTALL=FALSE \\\n",
    "  INSTALL_EXTENSIONS=FALSE \\\n",
    "  ./start_linux.sh\n",
    "\n",
    "# Parameters\n",
    "model_url = \"https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\" #@param {type:\"string\"}\n",
    "branch = \"main\" #@param {type:\"string\"}\n",
    "command_line_flags = \"--n-gpu-layers 128 --load-in-4bit --use_double_quant --no_flash_attn\" #@param {type:\"string\"}\n",
    "api = False #@param {type:\"boolean\"}\n",
    "\n",
    "if api:\n",
    "  for param in ['--api', '--public-api']:\n",
    "    if param not in command_line_flags:\n",
    "      command_line_flags += f\" {param}\"\n",
    "\n",
    "model_url = model_url.strip()\n",
    "if model_url != \"\":\n",
    "    if not model_url.startswith('http'):\n",
    "        model_url = 'https://huggingface.co/' + model_url\n",
    "\n",
    "    # Download the model\n",
    "    url_parts = model_url.strip('/').strip().split('/')\n",
    "    output_folder = f\"{url_parts[-2]}_{url_parts[-1]}\"\n",
    "    branch = branch.strip('\"\\' ')\n",
    "    if branch.strip() not in ['', 'main']:\n",
    "        output_folder += f\"_{branch}\"\n",
    "        !python download-model.py {model_url} --branch {branch}\n",
    "    else:\n",
    "        !python download-model.py {model_url}\n",
    "else:\n",
    "    output_folder = \"\"\n",
    "\n",
    "# Start the web UI\n",
    "cmd = f\"./start_linux.sh {command_line_flags} --share\"\n",
    "if output_folder != \"\":\n",
    "    cmd += f\" --model {output_folder}\"\n",
    "\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. LangChain Hugging Face\n",
    "\n",
    "Llama 3 8B requires around 16GB of disk space and 20GB of VRAM (GPU memory) in FP16. As for Llama 3 70B, it requires around 140GB of disk space and 160GB of VRAM in FP16. Take AWS for example, you must have at least `g5.2xlarge` for Llama 3 8b and `g5.12xlarge` for Llama 3 70b. \n",
    "\n",
    "- [HuggingChat](https://huggingface.co/chat/) for using community's best chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMOWiGB6boNr"
   },
   "outputs": [],
   "source": [
    "# Get models from Meta\n",
    "# !huggingface-cli download meta-llama/Meta-Llama-3.1-8B-Instruct --include \"original/*\" --local-dir models/meta-llama/Meta-Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain_community\n",
    "\n",
    "# `rope_scaling` must be a dictionary with two fields, `type` and `factor`, got {'factor': 8.0, 'low_freq_factor': 1.0, 'high_freq_factor': 4.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}\n",
    "# !pip install --upgrade transformers\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.chains import ConversationChain\n",
    "import transformers\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecd63adf0934e1cb39fb2b861c4be23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4-bit quantization\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "nf4_model = transformers.AutoModelForCausalLM.from_pretrained(model, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=nf4_model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=1000,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipeline, model_kwargs={ \"temperature\": 0.7, \"stop\": [\"<|eom_id|>\", \"<|start_header_id|>\", \"<|end_header_id|>\", \"<|eot_id|>\", \"<|reserved_special_token\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x78b16b3320f0>, model_kwargs={'temperature': 0.7, 'stop': ['<|eom_id|>', '<|start_header_id|>', '<|end_header_id|>', '<|eot_id|>', '<|reserved_special_token']})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n\\nEnvironment: ipython\\nTools: brave_search, wolfram_alpha\\n\\nCutting Knowledge Date: 01 March 2023\\nToday\\'s Date: 13 July 2024\\n\\n\\nYou are a helpful Assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWeather in Menlo Park, California<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nbrave_search.call(query=\"Menlo Park, California weather\")assistant\\n\\nThe current weather in Menlo Park, California is not available to me.  I can suggest some ways for you to find the current weather in Menlo Park, California.\\n\\nYou can check online weather websites such as AccuWeather or Weather.com for the current weather conditions and forecast in Menlo Park, California.\\n\\nAlternatively, you can also check the National Weather Service (NWS) website for the current weather conditions and forecast in Menlo Park, California.\\n\\nIf you want to get the current weather conditions and forecast in Menlo Park, California, I recommend checking these sources:\\n\\n1. AccuWeather - https://www.accuweather.com/\\n2. Weather.com - https://weather.com/\\n3. National Weather Service (NWS) - https://www.weather.gov/\\n\\nPlease note that the current weather conditions and forecast may change rapidly, so it\\'s always best to check these sources directly for the most up-to-date information.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imbued prompt template\n",
    "response = llm.invoke(\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "\n",
    "Cutting Knowledge Date: 01 March 2023\n",
    "Today's Date: 13 July 2024\n",
    "\n",
    "\n",
    "You are a helpful Assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Weather in Menlo Park, California<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "\n",
      "Environment: ipython\n",
      "Tools: brave_search, wolfram_alpha\n",
      "\n",
      "Cutting Knowledge Date: 01 March 2023\n",
      "Today's Date: 13 July 2024\n",
      "\n",
      "\n",
      "You are a helpful Assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Weather in Menlo Park, California<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "brave_search.call(query=\"Menlo Park, California weather\")assistant\n",
      "\n",
      "The current weather in Menlo Park, California is not available to me.  I can suggest some ways for you to find the current weather in Menlo Park, California.\n",
      "\n",
      "You can check online weather websites such as AccuWeather or Weather.com for the current weather conditions and forecast in Menlo Park, California.\n",
      "\n",
      "Alternatively, you can also check the National Weather Service (NWS) website for the current weather conditions and forecast in Menlo Park, California.\n",
      "\n",
      "If you want to get the current weather conditions and forecast in Menlo Park, California, I recommend checking these sources:\n",
      "\n",
      "1. AccuWeather - https://www.accuweather.com/\n",
      "2. Weather.com - https://weather.com/\n",
      "3. National Weather Service (NWS) - https://www.weather.gov/\n",
      "\n",
      "Please note that the current weather conditions and forecast may change rapidly, so it's always best to check these sources directly for the most up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPo7py0V2zTZ3vF0C+b7zra",
   "gpuType": "A100",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
