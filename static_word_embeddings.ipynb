{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f459f152-3b84-4384-af59-46c7559b53fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels\n",
       "0     Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1     Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2     Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3     High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4     Pernod takeover talk lifts Domecq\\n\\nShares in...  business\n",
       "...                                                 ...       ...\n",
       "2220  BT program to beat dialler scams\\n\\nBT is intr...      tech\n",
       "2221  Spam e-mails tempt net shoppers\\n\\nComputer us...      tech\n",
       "2222  Be careful how you code\\n\\nA new European dire...      tech\n",
       "2223  US cyber security chief resigns\\n\\nThe man mak...      tech\n",
       "2224  Losing yourself in online gaming\\n\\nOnline rol...      tech\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a pandas DataFrame using `read()`\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./datasets/bbc_text_cls.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3fcd51-318c-42f8-852c-375418a5e41f",
   "metadata": {},
   "source": [
    "# 1. Vocabulary\n",
    "Create **Vocabulary** dictionaries:\n",
    "- **word2idx:** All the unique words as keys with a corresponding unique ID as values.\n",
    "- **idx2word:** The reverse of word2idx. It has the unique IDs as keys and their corresponding words as values.\n",
    "## 1-1. word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb40706d-f1ae-4442-beab-903398d98fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(morrison', 'airline.', 'flamini,', 'sized', 'hungry,', 'macintosh', 'sing', 'thoroughness,', 'breakpoint', 'journals', 'unit.\"', 'michels,', 'pr&#233;cis', 'attackers', 'contributing', 'ever', 'art-form', 'semi-final,', 'future,\"', '1888', 'tobacco', 'misfit', 'permits.', 'now,', 'emerges', 'ubisense', 'reuniting', 'telcos,', 'synonymous', 'really,', 'reimbursement', 'book,\"', 'acclaim,', 'carla', 'non-nato', '2.9%', 'leeds,', 'discounted', 'premiership.\"', 'reckons', 'cory', 'mid-march,\"', 'projects,\"', 'hassan,', '$0.99', 'shield\".', \"contractors'\", 'unknowns', 'treasury', 'barred', 'baht', 'communicating,\"', '&#163;1.8m', 'paion,', 'scooted', 'emmanuelle', 'labelling', 'growth', \"isinbayeva's\", 'rods', 'consciously', '7:41.42.', 'exhibitor', 'queried', '40-30', 'random', 'bemoaning', 'vision,', 'marrying', 'periods.', 'centring', 'birkenhead', 'copenhagen', 'invested', 'trial,', 'samsung', 'pleasantly', 'rovers,', '(siac).', 'beckinsale', 'defined,', 'undelivered.', 'fit', 'skipper', 'excuse.', 'mehrtens', 'freer', 'sledge,', 'iconoclastic', 'governments', 'tiresome.', '3.6mbps', 'scale', 'jakobi', 'clerk', 'trainer', 'hybrid,', 'unsigned', 'sellafield,', '£2.5bn']\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words in the corpus\n",
    "import random\n",
    "\n",
    "unique_words = set()\n",
    "for doc in df[\"text\"]:\n",
    "    for word in doc.split():\n",
    "        unique_words.add(word.lower())\n",
    "\n",
    "unique_words.add('<unk>')\n",
    "unique_words.add('<pad>')\n",
    "\n",
    "# Sample 100 words\n",
    "print(random.sample(tuple(unique_words), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62b83f32-4e12-46af-b479-9443f1bfde0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hinckley,', 0), ('bucking', 1), ('stores.\"', 2), ('8.6bn', 3), ('12.37', 4), ('osborne', 5), ('egelton,', 6), ('path,', 7), ('pay-out', 8), ('miller.', 9), ('most,', 10), ('struggling', 11), (\"sender's\", 12), ('activities,', 13), ('satirist', 14), ('3,217', 15), ('(team', 16), ('original.', 17), ('mac,\"', 18), ('hughes.', 19), ('a$846m', 20), ('advanced,', 21), ('receivers', 22), ('intervention', 23), ('attack.\"', 24), ('\"audioblogs\"', 25), ('esson,', 26), ('assault,', 27), ('layout', 28), ('campaiging', 29), ('agency.', 30), ('kezman', 31), ('vein', 32), ('filmmaker', 33), (\"employee's\", 34), ('fatboy', 35), ('6,000-strong', 36), ('printers', 37), ('shield', 38), ('ingots', 39), ('leave.', 40), ('aid', 41), ('management.\"', 42), ('1920s.', 43), ('robber', 44), ('difference\"', 45), ('puzzlement', 46), ('\"musicians', 47), ('developed,', 48), ('aids,', 49), ('weh', 50), ('75p', 51), ('frisk,', 52), ('villagers', 53), ('lange', 54), ('serena)', 55), ('masayuki', 56), ('uk-controlled', 57), (\"march's\", 58), ('$2.9bn', 59), ('rubin', 60), ('decidedly', 61), ('untouched', 62), ('akaev,', 63), (\"net's\", 64), ('still,', 65), ('timing,', 66), ('congratulated.', 67), ('legalisation', 68), ('charges.', 69), ('tory', 70), ('underwrite', 71), ('promoter,', 72), ('tacit', 73), ('endorsed', 74), ('proud', 75), ('personally,', 76), ('anti-bribery', 77), ('ambition', 78), ('you,\"', 79), ('mellor', 80), ('martens,', 81), ('prevalence', 82), ('possible\",', 83), ('mcleish', 84), ('chance,\"', 85), ('missile,', 86), ('crystalline,', 87), ('lemar', 88), ('stir', 89), ('24:', 90), ('suitably', 91), ('panel,', 92), (\"westlife's\", 93), ('countryside', 94), (\"fox's\", 95), (\"sport.'\", 96), ('sneak', 97), ('gerrard?', 98), ('\"bebop\",', 99)]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map each unique word to an index\n",
    "import itertools\n",
    "\n",
    "word2idx = {}\n",
    "for idx, word in enumerate(unique_words):\n",
    "    word2idx[word] = idx\n",
    "\n",
    "# Return first 100 items\n",
    "print(list(itertools.islice(word2idx.items(), 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6709818-9b7b-49ef-ad38-e0d919c6dbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60618"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f1511-7074-4876-aef8-60c18f80e334",
   "metadata": {},
   "source": [
    "# 2. One-Hot Encoding\n",
    "The process of one-hot encoding involves **Vocabulary Creation** & **Vector Representation** two steps.\n",
    "\n",
    "1. Manual Implementation.\n",
    "2. `pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)`\n",
    "3. `sklearn.preprocessing.OneHotEncoder(*, categories='auto', drop=None, sparse_output=True, dtype=<class 'numpy.float64'>, handle_unknown='error', min_frequency=None, max_categories=None, feature_name_combiner='concat')`\n",
    "4. `tf.keras.utils.to_categorical(x, num_classes)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1879224a-9ed6-4e74-9da4-0b809c7bbae1",
   "metadata": {},
   "source": [
    "## 2-1. Manual One-Hot Encoding\n",
    "Each word is represented as a vector of `0`s and `1`s. The length of the vector is equal to the size of the vocabulary. Position in the vector corresponds to a specific word in the vocabulary. If the word is present in a particular text sample, its corresponding position in the vector is marked as `1`, and all other positions are `0`. This implies that each word is uniquely represented by a binary vector, with only one element being `1`, indicating its presence, and all others being `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de998795-c3ae-4924-8185-2a2c9d17a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Create one-hot encoded vectors for each word in the corpus\n",
    "import numpy as np\n",
    "\n",
    "one_hot_vec = []\n",
    "for doc in df['text']:\n",
    "    doc_vec = []\n",
    "    for word in doc.split():\n",
    "        vec = np.zeros(len(unique_words))\n",
    "        vec[word2idx[word.lower()]] = 1\n",
    "        doc_vec.append(vec)\n",
    "    one_hot_vec.append(doc_vec)\n",
    "\n",
    "# One-hot encoded vectors of the first 10 words from the first document\n",
    "for i in range(10):\n",
    "    print(one_hot_vec[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91709f2c-a762-4af0-a916-3abc7000b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n"
     ]
    }
   ],
   "source": [
    "print(len(one_hot_vec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58bc3ab1-8363-428d-b287-ba6e428ea479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60618\n"
     ]
    }
   ],
   "source": [
    "print(len(one_hot_vec[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0cedd-e489-4e72-9164-ba0e36e0563f",
   "metadata": {},
   "source": [
    "## 2-2. One-Hot Encoding with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8dfa3b7a-d7ee-4478-b8f0-0f2fd8ecae55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog of War</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat and Dog Man</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text    labels\n",
       "0       Dog of War  business\n",
       "1  Cat and Dog Man      tech"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'text': [\"Dog of War\", \"Cat and Dog Man\"], 'labels': [\"business\", \"tech\"]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "16216943-b3f1-4a0f-b782-64a0d512bef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      cat\n",
       "1       of\n",
       "2      man\n",
       "3    <unk>\n",
       "4      dog\n",
       "5      war\n",
       "6    <pad>\n",
       "7      and\n",
       "dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "unique_word_series = pd.Series(list(unique_words))\n",
    "unique_word_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "351a9d98-7d40-4d81-9b9e-4bba0b3c72cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;pad&gt;</th>\n",
       "      <th>&lt;unk&gt;</th>\n",
       "      <th>and</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>man</th>\n",
       "      <th>of</th>\n",
       "      <th>war</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   <pad>  <unk>    and    cat    dog    man     of    war\n",
       "0  False  False  False   True  False  False  False  False\n",
       "1  False  False  False  False  False  False   True  False\n",
       "2  False  False  False  False  False   True  False  False\n",
       "3  False   True  False  False  False  False  False  False\n",
       "4  False  False  False  False   True  False  False  False\n",
       "5  False  False  False  False  False  False  False   True\n",
       "6   True  False  False  False  False  False  False  False\n",
       "7  False  False   True  False  False  False  False  False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_dummies = pd.get_dummies(unique_word_series)\n",
    "unique_word_dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e78d1c38-9d1d-4dfd-b574-fb08b80adf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([False, False, False, False,  True, False, False, False]),\n",
       "  array([False,  True, False, False, False, False, False, False]),\n",
       "  array([False, False, False, False, False,  True, False, False])],\n",
       " [array([ True, False, False, False, False, False, False, False]),\n",
       "  array([False, False, False, False, False, False, False,  True]),\n",
       "  array([False, False, False, False,  True, False, False, False]),\n",
       "  array([False, False,  True, False, False, False, False, False])]]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vec = []\n",
    "for doc in df['text']:\n",
    "    doc_vec = []\n",
    "    for word in doc.split():\n",
    "        doc_vec.append(unique_word_dummies[word.lower()].values)\n",
    "    one_hot_vec.append(doc_vec)\n",
    "\n",
    "one_hot_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c0e82-64e8-49ca-8a16-66b391519ece",
   "metadata": {},
   "source": [
    "## 2-3. One-Hot Encoding with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4bab5af4-003e-4a52-adf0-d1477c8b1f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All lists have the same length.\n"
     ]
    }
   ],
   "source": [
    "# Pad each document manually\n",
    "doc_max_length = max(len(t) for t in token_ids)\n",
    "for t in token_ids:\n",
    "    t += [word2idx['<pad>']] * (doc_max_length - len(t))\n",
    "\n",
    "# Check paddings\n",
    "it = iter(token_ids)\n",
    "the_len = len(next(it))\n",
    "if not all(len(l) == the_len for l in it):\n",
    "    raise ValueError('not all lists have same length!')\n",
    "else:\n",
    "    print(\"All lists have the same length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "06e582a4-5e71-4408-a9c1-c359d0acfc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0    cat\n",
       "1     of\n",
       "2    man\n",
       "3  <unk>\n",
       "4    dog\n",
       "5    war\n",
       "6  <pad>\n",
       "7    and"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_df = unique_word_series.to_frame()\n",
    "unique_word_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "26da4979-34a6-44ba-9f04-819de345d5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(sparse_output=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse_output=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "# unique_word_encoded = ohe.fit_transform(unique_word_series.values.reshape(-1, 1))\n",
    "unique_word_encoded = ohe.fit(unique_word_df)\n",
    "unique_word_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "231f7b6b-afe7-428f-9008-d02d0ba17fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<pad>', '<unk>', 'and', 'cat', 'dog', 'man', 'of', 'war'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_encoded.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af56712a-cc00-48b7-bbd4-120cab4086b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[0., 0., 0., 0., 1., 0., 0., 0.]]),\n",
       "  array([[0., 0., 0., 0., 0., 0., 1., 0.]]),\n",
       "  array([[0., 0., 0., 0., 0., 0., 0., 1.]])],\n",
       " [array([[0., 0., 0., 1., 0., 0., 0., 0.]]),\n",
       "  array([[0., 0., 1., 0., 0., 0., 0., 0.]]),\n",
       "  array([[0., 0., 0., 0., 1., 0., 0., 0.]]),\n",
       "  array([[0., 0., 0., 0., 0., 1., 0., 0.]])]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vec = []\n",
    "for doc in df['text']:\n",
    "    doc_vec = []\n",
    "    for word in doc.lower().split():\n",
    "        doc_vec.append(ohe.transform(np.array(word).reshape(1, -1)))\n",
    "    one_hot_vec.append(doc_vec)\n",
    "\n",
    "one_hot_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4385e3-077b-4843-82f4-895ae6fe3a09",
   "metadata": {},
   "source": [
    "## 2-4. One-Hot Encoding with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1f0a5fdb-a16a-48f2-8c95-1fa3841f9efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0,\n",
       " 'of': 1,\n",
       " 'man': 2,\n",
       " '<unk>': 3,\n",
       " 'dog': 4,\n",
       " 'war': 5,\n",
       " '<pad>': 6,\n",
       " 'and': 7}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "428625ba-7bc4-402b-901c-98de08ef8351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1, 5], [0, 7, 4, 2]]\n"
     ]
    }
   ],
   "source": [
    "# Split documents to tokens\n",
    "tokens_docs = [doc.lower().split() for doc in df['text']]\n",
    "\n",
    "# Convert token lists to token-id lists\n",
    "token_ids = [[word2idx[token] for token in tokens_doc] for tokens_doc in tokens_docs]\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8bb858c2-9e7b-42bb-a57e-c68ef609e13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "a = keras.utils.to_categorical(list(range(len(unique_words))), num_classes=len(unique_words))\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c6271e8f-7f33-4ce5-b451-dc741c4a27c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       "  array([0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 1., 0., 0.])],\n",
       " [array([1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       "  array([0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       "  array([0., 0., 1., 0., 0., 0., 0., 0.])]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vec = []\n",
    "for doc in df['text']:\n",
    "    doc_vec = []\n",
    "    for word in doc.lower().split():\n",
    "        doc_vec.append(a[word2idx[word]])\n",
    "    one_hot_vec.append(doc_vec)\n",
    "\n",
    "one_hot_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3c670-d4c5-48a7-9d72-19151436fb66",
   "metadata": {},
   "source": [
    "# 2. Bag-of-Words (BoW)\n",
    "## 2-1. Manual Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4de3c2-4927-4a30-8bfe-aead84a9d764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6ed943f-34fa-4246-b475-4ff9e3504058",
   "metadata": {},
   "source": [
    "## 2-2. CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9250ef9-8f5f-47f0-bd41-e4e25aba2477",
   "metadata": {},
   "source": [
    "# 3. TF-IDF\n",
    "## 3-1. Manual Implementation\n",
    "### 3-1-1. word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87d7a6-e139-4316-afab-9243e3ea98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d9e24e-dbb8-4fa4-81c3-5536f23bc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "words = word_tokenize(df[\"text\"][0])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04404d24-600f-4253-a796-8f4702c50217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate word2idx\n",
    "# Convert documents into sequences of ints / ids / indices\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "tokenized_docs = []\n",
    "\n",
    "for doc in df[\"text\"]:\n",
    "    words = word_tokenize(doc.lower())\n",
    "    doc_as_int = []\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = idx\n",
    "            idx += 1\n",
    "        # Save for later\n",
    "        doc_as_int.append(word2idx[word])\n",
    "    tokenized_docs.append(doc_as_int)\n",
    "\n",
    "tokenized_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16232bb9-7f41-496a-bc5f-e5869744a8b6",
   "metadata": {},
   "source": [
    "### 3-1-2. idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382cd8a-042d-47bb-965e-80b1361d11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse mapping\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa798d-9c8d-4e2b-a094-3a04305db9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of documents\n",
    "N = len(df['text'])\n",
    "\n",
    "# Number of words\n",
    "V = len(word2idx)\n",
    "\n",
    "N, V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a923872-2faf-4055-907f-a33fa1d40c66",
   "metadata": {},
   "source": [
    "### 3-1-3. Term Frequency (TF)\n",
    "**Term frequency (TF)** means how often a term occurs in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260c138-d650-420b-80a6-334c89c60e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Instantiate term-frequency matrix\n",
    "tf = np.zeros((N, V))\n",
    "\n",
    "# Populate term-frequency counts\n",
    "for i, doc_as_int in enumerate(tokenized_docs):\n",
    "    for j in doc_as_int:\n",
    "        tf[i, j] += 1\n",
    "\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a3b36-b9f5-4c11-a017-8c33b8b9302e",
   "metadata": {},
   "source": [
    "### 3-1-4. Inverse Document Frequency (IDF)\n",
    "- **Document frequency (DF)** is the number of documents containing a particular term.\n",
    "- **Inverse Document Frequency (IDF)** is a weight indicating how commonly a word is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4dc56-5e6b-442c-a848-d79d4d41cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IDF\n",
    "# `axis=0` is the direction running downward the rows\n",
    "doc_freq = np.sum(tf > 0, axis=0)\n",
    "idf = np.log(N / doc_freq)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed263b90-46e6-4003-8a14-d682ca20524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f06d7-c1b5-4db2-a26c-2298429ae315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF\n",
    "tf_idf = tf * idf\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0aceff-5437-495d-bebd-e821fdce8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random document, show the top 5 terms (in terms of `tf_idf` score)\n",
    "np.random.seed(36)\n",
    "i = np.random.choice(N)\n",
    "row = df.iloc[i]\n",
    "print(\"Label:\", row['label'])\n",
    "print(\"Text:\", row['text'].split(\"\\n\", 1)[0])\n",
    "print(\"Top 5 terms:\")\n",
    "\n",
    "scores = tf_idf[i]\n",
    "# Add minus for descending\n",
    "indices = (-scores).argsort()\n",
    "for j in indices[:5]:\n",
    "    print(idx2word[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7e12b-c342-4d2a-8314-e8435b1eb019",
   "metadata": {},
   "source": [
    "## 3-2. CountVectorizer\n",
    "Derived term frequencies from `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07938bbb-ad58-456a-bde1-dba001bbc91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df[\"text\"]\n",
    "labels = df[\"label\"]\n",
    "\n",
    "labels.hist(figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed262a0-4dec-42cf-8eb3-53d39ccd8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tf = vectorizer.fit_transform(inputs)\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f22eb-171d-4160-a116-29360469dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d31f3-27a5-4d7e-af72-902028f29f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ca2a3-c137-43ab-81e4-1d5b73877370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fewer words than `nltk.word_tokenize()`\n",
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b91acc-4cc8-4890-9bf5-687b12b5fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default `lowercase=True`\n",
    "# np.where(words == \"India\")\n",
    "# (array([], dtype=int64),)\n",
    "\n",
    "# By default `token_pattern=r”(?u)\\b\\w\\w+\\b`\n",
    "# RegExp selects tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator)\n",
    "# np.where(words == \"$\")\n",
    "# (array([], dtype=int64),)\n",
    "\n",
    "np.where(words == \"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e2ae6-971d-402b-b635-50fc21226024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as `tf[0][0]` in the above section\n",
    "tf.toarray()[0][13907]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a4439-99b2-4bfb-b54d-d0df965546c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IDF\n",
    "doc_freq = np.sum(tf.toarray() > 0, axis=0)\n",
    "idf = np.log(N / doc_freq)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef44e38-03d7-4be8-9dd6-5f78eed1f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF\n",
    "tf_idf = tf.toarray() * idf\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86afeefb-b636-49c1-ad76-3c37264aec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf7d2d-9355-4a78-82dc-0a82fc1c3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as `tf_idf[0][0]` in the above section\n",
    "tf_idf[0][13907]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62243fee-26e5-4e3c-9c72-6ec2dce2ae8d",
   "metadata": {},
   "source": [
    "## 3-3. TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713c327-82d1-4f66-98bc-0cfc51e58826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "tf_idf = transformer.fit_transform(tf)\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90fd91-64f9-490e-b628-7dfc211e43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18576d3-a230-49af-8736-6df21fa993e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `sklearn` implementation of TF-IDF is different from our manual implementation \n",
    "print(tf_idf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46164149-3908-4c64-a94e-43f76019a69a",
   "metadata": {},
   "source": [
    "## 3-4. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83306771-b56c-46aa-9b54-d11e1ddf4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf = vectorizer.fit_transform(inputs)\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc7a7a-5e89-41a7-ab70-73e57d2905aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6129f297-ff06-4d94-976f-74605fc2a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as `CountVectorizer()` followed by `TfidfTransformer()`\n",
    "print(tf_idf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1e186-481e-41fd-8853-01e5a32deb90",
   "metadata": {},
   "source": [
    "Perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d20106-43a5-4377-ace3-c9d95896ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "inputs_train, inputs_test, y_train, y_test = train_test_split(inputs, labels, random_state=36)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "x_train = vectorizer.fit_transform(inputs_train)\n",
    "x_test = vectorizer.transform(inputs_test)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Train Score:\", model.score(x_train, y_train))\n",
    "print(\"Test Score:\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd88420-26b9-45a6-bd17-10002dfc6530",
   "metadata": {},
   "source": [
    "# 4. word2vec\n",
    "## 4-1. CBOW (Continuous Bag of Words)\n",
    "## 4-2. Skip-Gram\n",
    "# 5. GloVe\n",
    "# 6. FastText\n",
    "# 7. Gaussian Embedding\n",
    "# 8. Pointcare Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0bb1dd-560c-43ab-8846-6da417779f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
