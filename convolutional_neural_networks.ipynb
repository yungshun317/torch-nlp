{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce6fa10-e701-4e5c-b736-4b591d0040bc",
   "metadata": {},
   "source": [
    "# 1. Fully Connected Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a4398-bb91-4bac-8ab2-cf9d327d92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcfc5b-defc-483b-b9a4-410a64f63b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the data matrix\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d8a51-1074-4512-bb1c-1084d893f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data = data[:,1:]\n",
    "\n",
    "print(labels.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7be353-29e1-41fb-a45b-fce583bda80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a few random digits\n",
    "fig,axs = plt.subplots(3,4,figsize=(10,6))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "  # pick a random image\n",
    "  randimg2show = np.random.randint(0,high=data.shape[0])\n",
    "\n",
    "  # create the image (must be reshaped!)\n",
    "  img = np.reshape(data[randimg2show,:],(28,28))\n",
    "  ax.imshow(img,cmap='gray')\n",
    "\n",
    "  # title\n",
    "  ax.set_title('The number %i'%labels[randimg2show])\n",
    "\n",
    "plt.suptitle('How humans see the data',fontsize=20)\n",
    "plt.tight_layout(rect=[0,0,1,.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef3563-d4b6-48a2-96f3-b1bea3b40842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a few random digits\n",
    "fig,axs = plt.subplots(3,4,figsize=(10,6))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "  # pick a random image\n",
    "  randimg2show = np.random.randint(0,high=data.shape[0])\n",
    "\n",
    "  # create the image\n",
    "  ax.plot(data[randimg2show,:],'ko')\n",
    "\n",
    "  # title\n",
    "  ax.set_title('The number %i'%labels[randimg2show])\n",
    "\n",
    "plt.suptitle('How the FFN model sees the data',fontsize=20)\n",
    "plt.tight_layout(rect=[0,0,1,.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cde77-307c-4e6a-ab1c-cb12bbfc4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see some example 7s\n",
    "\n",
    "# find indices of all the 7's in the dataset\n",
    "the7s = np.where(labels==7)[0]\n",
    "\n",
    "# draw the first 12\n",
    "fig,axs = plt.subplots(2,6,figsize=(15,6))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  img = np.reshape(data[the7s[i],:],(28,28))\n",
    "  ax.imshow(img,cmap='gray')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"Example 7's\",fontsize=20)\n",
    "plt.tight_layout(rect=[0,0,1,.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62c3e9-ffe1-4777-b951-33cdeab758d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how similar are all the 7's? \n",
    "\n",
    "# how many 7's are there?\n",
    "print(data[the7s,:].shape)\n",
    "\n",
    "\n",
    "# let's see how they relate to each other by computing spatial correlations\n",
    "C = np.corrcoef(data[the7s,:])\n",
    "\n",
    "# and visualize\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,6))\n",
    "ax[0].imshow(C,vmin=0,vmax=1)\n",
    "ax[0].set_title(\"Correlation across all 7's\")\n",
    "\n",
    "# extract the unique correlations and show as a scatterplot\n",
    "uniqueCs = np.triu(C,k=1).flatten()\n",
    "ax[1].hist(uniqueCs[uniqueCs!=0],bins=100)\n",
    "ax[1].set_title('All unique correlations')\n",
    "ax[1].set_xlabel(\"Correlations of 7's\")\n",
    "ax[1].set_ylabel('Count')\n",
    "\n",
    "# show all 7's together\n",
    "aveAll7s = np.reshape( np.mean(data[the7s,:],axis=0) ,(28,28))\n",
    "ax[2].imshow(aveAll7s,cmap='gray')\n",
    "ax[2].set_title(\"All 7's averaged together\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c21c3-c3d4-472b-a715-4c91c9229ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].hist(data.flatten(),50)\n",
    "ax[0].set_xlabel('Pixel intensity values')\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[0].set_title('Histogram of original data')\n",
    "\n",
    "ax[1].hist(dataNorm.flatten(),50)\n",
    "ax[1].set_xlabel('Pixel intensity values')\n",
    "ax[1].set_ylabel('Count')\n",
    "ax[1].set_title('Histogram of normalized data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b27fcb-aecd-486e-9e5b-cd8f81b424ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long() # long = int64\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59059237-3ef9-4872-bd81-018c296113b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return torch.log_softmax( self.output(x),axis=1 )\n",
    "      # NEW HERE: log-softmax the output, because I'm using NLLLoss instead of CrossEntropyLoss\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.NLLLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29213c-41e9-436c-ae1f-a7990e1c3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "\n",
    "# values are log-probability of each number (0-9)\n",
    "# print(torch.exp(yHat))\n",
    "\n",
    "# now let's compute the loss\n",
    "loss = lossfun(yHat,y)\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532892a-d7db-430c-9d09-a842ad094fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 60\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f3abe-6129-40c9-b6d2-6948990984e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230285d7-044d-4a79-9a12-73e1e27fdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886a933-d150-4079-9e6a-0eac4dbd1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model through for the test data\n",
    "X,y = next(iter(test_loader))\n",
    "predictions = net(X).detach()\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f32617-c530-4134-98e4-cda01110b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evidence for all numbers from one sample\n",
    "sample2show = 120\n",
    "\n",
    "plt.bar(range(10),predictions[sample2show]) # try adding exp!\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel('Number')\n",
    "plt.ylabel('Evidence for that number')\n",
    "plt.title('True number was %s' %y[sample2show].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dea5c5-2cd2-453f-a5f0-1e6d2402bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the errors\n",
    "errors = np.where( torch.max(predictions,axis=1)[1] != y )[0]\n",
    "print(errors)\n",
    "\n",
    "# Evidence for all numbers from one sample\n",
    "sample2show = 10\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(14,5))\n",
    "\n",
    "ax[0].bar(range(10),np.exp(predictions[errors[sample2show]]))\n",
    "ax[0].set_xticks(range(10))\n",
    "ax[0].set_xlabel('Number')\n",
    "ax[0].set_ylabel('Evidence for that number')\n",
    "ax[0].set_title('True number: %s, model guessed %s' \n",
    "                %( y[errors[sample2show]].item(), torch.argmax(predictions[errors[sample2show]]).item() ))\n",
    "\n",
    "ax[1].imshow( np.reshape(X[errors[sample2show],:],(28,28)) ,cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33808902-9fd8-401b-ae58-81ce8788c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3]\n",
    "# create a class for the model\n",
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28806a0e-dc17-4428-9691-bab622468e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### exploring the \"innards\" of the model\n",
    "\n",
    "# create a temp model to explore\n",
    "net = createTheMNISTNet()[0]\n",
    "\n",
    "# summary of the entire model\n",
    "print('Summary of model:')\n",
    "print(net)\n",
    "print(' ')\n",
    "\n",
    "# # explore one of the layers\n",
    "# print('Summary of input layer:')\n",
    "# print( vars(net.input) )\n",
    "# print(' ')\n",
    "\n",
    "# # check out the matrix of weights\n",
    "# print('Input layer weights:')\n",
    "# print( net.input.weight.shape )\n",
    "# print( net.input.weight )\n",
    "# print(' ')\n",
    "\n",
    "# # finally, extract the weights and make a histogram\n",
    "# w = net.input.weight.detach().flatten()\n",
    "# plt.hist(w,40)\n",
    "# plt.xlabel('Weight value')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Distribution of initialized input-layer weights')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcb807-d67e-40bd-af63-6b81ace1b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that returns a histogram of all weights (across all layers)\n",
    "\n",
    "def weightsHistogram(net):\n",
    "\n",
    "  # initialize weight vector\n",
    "  W = np.array([])\n",
    "  \n",
    "  # concatenate each set of weights\n",
    "  for layer in net.parameters():\n",
    "    W = np.concatenate((W,layer.detach().flatten().numpy() ))\n",
    "\n",
    "  # compute their histogram (note: range is hard-coded)\n",
    "  histy,histx = np.histogram(W,bins=np.linspace(-.8,.8,101),density=True)\n",
    "  histx = (histx[1:]+histx[:-1])/2\n",
    "  return histx,histy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test it!\n",
    "histx,histy = weightsHistogram(net)\n",
    "plt.plot(histx,histy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f90efc-b2d2-4d28-a4d8-b07dd6cb585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 100\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses and accuracies\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "  # initialize histogram variables\n",
    "  histx = np.zeros((numepochs,100))\n",
    "  histy = np.zeros((numepochs,100))\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # get the weights distribution at the start of this epoch\n",
    "    histx,histy[epochi,:] = weightsHistogram(net)\n",
    "  \n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches        = torch.argmax(yHat,axis=1) == y # booleans (false/true)\n",
    "      matchesNumeric = matches.float()                # convert to numbers (0/1)\n",
    "      accuracyPct    = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )                  # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net,histx,histy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d356e73-5222-434b-891c-480e518e755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net,histx,histy = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79863250-a63d-4cad-9ac3-d8f0752b6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6642aa-787b-4137-b649-8201ef4aaeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the histogram of the weights\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "for i in range(histy.shape[0]):\n",
    "  ax[0].plot(histx,histy[i,:],color=[1-i/100,.3,i/100])\n",
    "\n",
    "ax[0].set_title('Histograms of weights')\n",
    "ax[0].set_xlabel('Weight value')\n",
    "ax[0].set_ylabel('Density')\n",
    "\n",
    "\n",
    "ax[1].imshow(histy,vmin=0,vmax=3,\n",
    "             extent=[histx[0],histx[-1],0,99],aspect='auto',origin='lower',cmap='hot')\n",
    "ax[1].set_xlabel('Weight value')\n",
    "ax[1].set_ylabel('Training epoch')\n",
    "ax[1].set_title('Image of weight histograms')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dab669-8258-4549-94c1-842326b48d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] Scrambled MNIST\n",
    "# randomly scramble the data,\n",
    "# preserving the re-ordering for each image\n",
    "eggs = np.random.permutation(data.shape[1])\n",
    "scrambled = dataNorm[:,eggs]\n",
    "\n",
    "\n",
    "# show a few random digits\n",
    "fig,axs = plt.subplots(3,4,figsize=(10,6))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "  # pick a random image\n",
    "  randimg2show = np.random.randint(0,high=data.shape[0])\n",
    "\n",
    "  # create the image (must be reshaped!)\n",
    "  img = np.reshape(scrambled[randimg2show,:],(28,28))\n",
    "  ax.imshow(img,cmap='gray')\n",
    "\n",
    "  # title\n",
    "  ax.set_title('The number %i'%labels[randimg2show])\n",
    "\n",
    "plt.suptitle('The scrambled data',fontsize=20)\n",
    "plt.tight_layout(rect=[0,0,1,.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e45806-efd8-40e3-9323-8c9a3317adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( scrambled ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ae039-9e89-40ef-bbfd-977ec19b3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd91ba-9dd0-460f-bac3-27557ab7d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] Shifted\n",
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d2857-dbf0-45fb-b675-094ca92368bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see how to shift a vectorized image\n",
    "\n",
    "# grab one image data\n",
    "tmp = test_loader.dataset.tensors[0][0,:]\n",
    "tmp = tmp.reshape(28,28) # reshape to 2D image\n",
    "\n",
    "# shift the image (pytorch calls it \"rolling\")\n",
    "tmpS = torch.roll(tmp,8,dims=1)\n",
    "\n",
    "\n",
    "# now show them both\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,6))\n",
    "ax[0].imshow(tmp, cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "\n",
    "ax[1].imshow(tmpS, cmap='gray')\n",
    "ax[1].set_title('Shifted (rolled)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba545d-0e49-4b1e-bcef-190b15d84619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repeat for all images in the test set\n",
    "\n",
    "for i in range(test_loader.dataset.tensors[0].shape[0]):\n",
    "  \n",
    "  # get the image\n",
    "  img = test_loader.dataset.tensors[0][i,:]\n",
    "  \n",
    "  # reshape and roll by max. 10 pixels\n",
    "  randroll = np.random.randint(-10,11)\n",
    "  img = torch.roll( img.reshape(28,28) ,randroll,dims=1 )\n",
    "\n",
    "  # re-vectorize and put back into the matrix\n",
    "  test_loader.dataset.tensors[0][i,:] = img.reshape(1,-1)\n",
    "\n",
    "\n",
    "# Note: now run the previous cell again to confirm the shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d3906-b404-4f89-905d-d8d145f3cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a099b60-a2d7-46d2-9d66-8ad10d01c56a",
   "metadata": {},
   "source": [
    "# 2. Convolution\n",
    "## 2-1. Convolution in SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9eafa-2fe4-46b1-9b92-3b5a4419c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image\n",
    "imgN = 20\n",
    "image = np.random.randn(imgN,imgN)\n",
    "\n",
    "# convolution kernel\n",
    "kernelN = 7\n",
    "Y,X = np.meshgrid(np.linspace(-3,3,kernelN),np.linspace(-3,3,kernelN))\n",
    "kernel = np.exp( -(X**2+Y**2)/7 )\n",
    "\n",
    "\n",
    "# let's see what they look like\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,6))\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title('Image')\n",
    "\n",
    "ax[1].imshow(kernel)\n",
    "ax[1].set_title('Convolution kernel')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02943d-0683-484c-a261-f1a0595e6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for the convolution\n",
    "convoutput = np.zeros((imgN,imgN))\n",
    "halfKr = kernelN//2\n",
    "\n",
    "for rowi in range(halfKr,imgN-halfKr):\n",
    "  for coli in range(halfKr,imgN-halfKr):\n",
    "\n",
    "    # cut out a piece of the image\n",
    "    pieceOfImg = image[rowi-halfKr:rowi+halfKr+1,:]      # get the rows\n",
    "    pieceOfImg = pieceOfImg[:,coli-halfKr:coli+halfKr+1] # extract the columns\n",
    "\n",
    "    # dot product: element-wise multiply and sum (and flip the kernel for \"real convolution\")\n",
    "    dotprod = np.sum( pieceOfImg*kernel[::-1,::-1] )\n",
    "\n",
    "    # store the result for this pixel\n",
    "    convoutput[rowi,coli] = dotprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5996ecf-cedd-42b2-b8d1-3da8f6dd7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scipy\n",
    "convoutput2 = convolve2d(image,kernel,mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbdff6-9abc-4a35-82c9-13454a44a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2,figsize=(8,8))\n",
    "\n",
    "ax[0,0].imshow(image)\n",
    "ax[0,0].set_title('Image')\n",
    "\n",
    "ax[0,1].imshow(kernel)\n",
    "ax[0,1].set_title('Convolution kernel')\n",
    "\n",
    "ax[1,0].imshow(convoutput)\n",
    "ax[1,0].set_title('Manual convolution')\n",
    "\n",
    "ax[1,1].imshow(convoutput2)\n",
    "ax[1,1].set_title(\"Scipy's convolution\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c3719-26e3-460d-800e-1316d1272069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [] Convolution with different kernels in a real image\n",
    "# read a pic from the web\n",
    "bathtub = imread('https://upload.wikimedia.org/wikipedia/commons/6/61/De_nieuwe_vleugel_van_het_Stedelijk_Museum_Amsterdam.jpg')\n",
    "\n",
    "# check the size\n",
    "print(bathtub.shape)\n",
    "\n",
    "# let's see what the famous Bathtub Museum looks like\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.imshow(bathtub);\n",
    "\n",
    "# transform image to 2D for convenience (not necessary for convolution!)\n",
    "bathtub = np.mean(bathtub,axis=2)\n",
    "bathtub = bathtub/np.max(bathtub)\n",
    "\n",
    "# check the size again\n",
    "print(bathtub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473f3d4-636e-41e3-a086-96ac71f507b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand-craft two convolution kernels\n",
    "\n",
    "# vertical kernel\n",
    "VK = np.array([ [1,0,-1],\n",
    "                [1,0,-1],\n",
    "                [1,0,-1] ])\n",
    "\n",
    "# horizontal kernel\n",
    "HK = np.array([ [ 1, 1, 1],\n",
    "                [ 0, 0, 0],\n",
    "                [-1,-1,-1] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ddab6-e19c-4c77-a2ac-3627b4b2bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2,figsize=(16,8))\n",
    "\n",
    "ax[0,0].imshow(VK)\n",
    "ax[0,0].set_title('Vertical kernel')\n",
    "\n",
    "ax[0,1].imshow(HK)\n",
    "ax[0,1].set_title('Horizontal kernel')\n",
    "\n",
    "\n",
    "# run convolution and show the result\n",
    "convres = convolve2d(bathtub,VK,mode='same')\n",
    "ax[1,0].imshow(convres,cmap='gray',vmin=0,vmax=.01)\n",
    "\n",
    "convres = convolve2d(bathtub,HK,mode='same')\n",
    "ax[1,1].imshow(convres,cmap='gray',vmin=0,vmax=.01)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600261c2-8482-4dea-97fa-397ae986b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] PyTorch\n",
    "# first, translate everything into a tensor\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "VK_t = torch.tensor(VK).view(1,1,3,3).double()\n",
    "HK_t = torch.tensor(HK).view(1,1,3,3).double()\n",
    "bathtub_t = torch.tensor(bathtub).view(1,1,bathtub.shape[0],bathtub.shape[1])\n",
    "\n",
    "print(VK_t.shape)\n",
    "print(bathtub_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f8ae6-e431-49d6-ad18-dd24d05a5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = F.conv2d(bathtub_t,VK_t)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60e6b9-e031-4ef2-aa63-30917ac52eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2,figsize=(16,8))\n",
    "\n",
    "ax[0,0].imshow(VK)\n",
    "ax[0,0].set_title('Vertical kernel')\n",
    "\n",
    "ax[0,1].imshow(HK)\n",
    "ax[0,1].set_title('Horizontal kernel')\n",
    "\n",
    "\n",
    "# run convolution and show the result\n",
    "convres = F.conv2d(bathtub_t,VK_t)\n",
    "img = torch.squeeze(convres.detach())\n",
    "ax[1,0].imshow(img,cmap='gray',vmin=0,vmax=.01)\n",
    "\n",
    "convres = F.conv2d(bathtub_t,HK_t)\n",
    "img = torch.squeeze(convres.detach())\n",
    "ax[1,1].imshow(img,cmap='gray',vmin=0,vmax=.01)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0482d-1291-4ef7-a718-0c1cb881a5df",
   "metadata": {},
   "source": [
    "# 2-2. Convolution in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e6a1a-fdbb-4b09-bf77-4cb844107e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a conv2d class instance with parameters\n",
    "\n",
    "# parameters\n",
    "inChans  = 3 # RGB\n",
    "outChans = 15\n",
    "krnSize  = 5 # should be an odd number\n",
    "stride   = 1\n",
    "padding  = 0\n",
    "\n",
    "# create the instance (cf nn.Linear)\n",
    "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# let's have a look at it\n",
    "print(c)\n",
    "print(' ')\n",
    "\n",
    "# check out its weight tensor; what are the dimensions?\n",
    "print( 'Size of weights: ' + str(c.weight.shape) )\n",
    "print( 'Size of bias: ' + str(c.bias.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a93471-32fc-472a-9455-d65ff8deaeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do these kernels look like?\n",
    "\n",
    "fig,axs = plt.subplots(3,5,figsize=(10,5))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  ax.imshow(torch.squeeze(c.weight[i,0,:,:]).detach(),cmap='Purples')\n",
    "  ax.set_title('L1(0)->L2(%s)'%i)\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ce1c9-9c19-4945-8662-eabdbc0108c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the image (N, RGB, height, width)\n",
    "imsize = (1,3,64,64)\n",
    "\n",
    "img = torch.rand(imsize)\n",
    "\n",
    "# pytorch wants channels first, but matplotlib wants channels last.\n",
    "# therefore, tensors must be permuted to visualize\n",
    "img2view = img.permute(2,3,1,0).numpy()\n",
    "print(img.shape)\n",
    "print(img2view.shape)\n",
    "\n",
    "plt.imshow(np.squeeze(img2view));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08855c43-3220-4e79-871f-47b375f78173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve the image with the filter bank (set of 'outChans' kernels)\n",
    "convRes = c(img)\n",
    "\n",
    "print(img.shape)\n",
    "print(convRes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc89c1-e033-406c-b3ab-bf833e629fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the convolved images look like? (Hint: think of the bathtub picture.)\n",
    "\n",
    "fig,axs = plt.subplots(3,5,figsize=(10,5))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "\n",
    "  # extract this \"layer\" of the convolution result\n",
    "  I = torch.squeeze(convRes[0,i,:,:]).detach()\n",
    "\n",
    "  # and visualize it\n",
    "  ax.imshow(I,cmap='Purples')\n",
    "  ax.set_title('Conv. w/ filter %s'%i)\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890059ce-5734-431a-8d39-b3ed12deb52f",
   "metadata": {},
   "source": [
    "# 2-3. Transpose Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad90456-3a68-4d8e-bd1a-2d09f7ecf67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ConvTranspose2d class instance with parameters\n",
    "\n",
    "# parameters\n",
    "inChans  = 3 # RGB\n",
    "outChans = 15\n",
    "krnSize  = 5 # should be an odd number\n",
    "stride   = 1\n",
    "padding  = 0\n",
    "\n",
    "# create the instance\n",
    "c = nn.ConvTranspose2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# let's have a look at it\n",
    "print(c)\n",
    "print(' ')\n",
    "\n",
    "# check out its weight tensor; what are the dimensions?\n",
    "print( 'Size of weights: ' + str(c.weight.shape) )\n",
    "print( 'Size of bias: ' + str(c.bias.shape) )\n",
    "\n",
    "# tip: Compare the sizes of these weights with those of \"forward\" convolution (DUDL_convolution_conv2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88309d-5b31-409e-b140-e19fbe41efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do these kernels look like?\n",
    "\n",
    "fig,axs = plt.subplots(3,5,figsize=(10,5))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  ax.imshow(torch.squeeze(c.weight[0,i,:,:]).detach(),cmap='Purples')\n",
    "  ax.set_title('L1(0)->L2(%s)'%i)\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b59e09-26a7-443c-bfd8-995f01d8058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the image (N, RGB, width, height)\n",
    "imsize = (1,3,64,64)\n",
    "\n",
    "img = torch.rand(imsize)\n",
    "\n",
    "# pytorch wants channels first, but matplotlib wants channels last.\n",
    "# therefore, tensors must be permuted to visualize\n",
    "img2view = img.permute(2,3,1,0).numpy()\n",
    "print(img.shape)\n",
    "print(img2view.shape)\n",
    "\n",
    "plt.imshow(np.squeeze(img2view));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828f0a4-4034-4475-9dc9-0d1d93a17366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve the image with the filter bank (set of 'outChans' kernels)\n",
    "convRes = c(img)\n",
    "\n",
    "print(img.shape)\n",
    "print(convRes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5fdb4-b4df-4582-bf80-3fbbcc59bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the convolved images look like? (Hint: think of the bathtub picture.)\n",
    "\n",
    "fig,axs = plt.subplots(3,5,figsize=(10,5))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "\n",
    "  # extract this \"layer\" of the convolution result\n",
    "  I = torch.squeeze(convRes[0,i,:,:]).detach()\n",
    "\n",
    "  # and visualize it\n",
    "  ax.imshow(I,cmap='Purples')\n",
    "  ax.set_title('Conv. w/ filter %s'%i)\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af970583-98b0-4b3c-90b1-ebac8472a597",
   "metadata": {},
   "source": [
    "# 3. Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055574e-8769-4bca-b45d-204da8eb28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pool class instance with parameters\n",
    "\n",
    "# parameters\n",
    "poolSize = 3\n",
    "stride   = 3\n",
    "\n",
    "# create the instance\n",
    "p2 = nn.MaxPool2d(poolSize,stride=3)\n",
    "p3 = nn.MaxPool3d(poolSize,stride=3)\n",
    "\n",
    "# let's have a look at them\n",
    "print(p2)\n",
    "print(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b1454-7d6c-43f9-b633-8e5e3a55730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image and apply maxpooling\n",
    "\n",
    "# create a 2D and a 3D image\n",
    "img2 = torch.randn(1,1,30,30)\n",
    "img3 = torch.randn(1,3,30,30)\n",
    "\n",
    "\n",
    "# all combinations of image and maxpool dimensionality\n",
    "img2Pool2 = p2(img2)\n",
    "print(f'2D image, 2D maxpool: {img2Pool2.shape}\\n' )\n",
    "\n",
    "# img2Pool3 = p3(img2)\n",
    "# print(f'2D image, 3D maxpool: {img2Pool3.shape}\\n' )\n",
    "\n",
    "img3Pool2 = p2(img3)\n",
    "print(f'3D image, 2D maxpool: {img3Pool2.shape}\\n' )\n",
    "\n",
    "img3Pool3 = p3(img3)\n",
    "print(f'3D image, 3D maxpool: {img3Pool3.shape}\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b548f83-d221-4557-9461-a5cd6aefb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "littlenet = nn.Sequential(\n",
    "    \n",
    "    ## the conv-pool block\n",
    "    nn.Conv2d(3,10,5,3,2), # convolution layer\n",
    "    nn.ReLU(),             # activation function\n",
    "    nn.AvgPool3d(3,3),     # average-pool\n",
    "    \n",
    "    ## the FFN block\n",
    "    nn.Flatten(),          # vectorize to get from image to linear\n",
    "    nn.Linear(588,1),      # FC linear layer\n",
    "    nn.Sigmoid()           # output activation\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e066410-2d43-4569-9980-1564a419b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with a bit of data\n",
    "img = torch.rand(1,3,128,128)\n",
    "littlenet(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f207817-be06-4513-880e-dd47471ac115",
   "metadata": {},
   "source": [
    "# 4. Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847569f8-57e6-45ac-acd7-76b9c95e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the CIFAR10 dataset\n",
    "cdata = torchvision.datasets.CIFAR10(root='cifar10', download=True)\n",
    "\n",
    "print(cdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df243d-24ab-4fe8-a81f-e78d96cbf95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the shape of the dataset\n",
    "print( cdata.data.shape )\n",
    "\n",
    "# the unique categories\n",
    "print( cdata.classes )\n",
    "\n",
    "# .targets is a list of targets converted to ints\n",
    "print( len(cdata.targets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c286e4f-a93d-4b10-a75d-bffa9a59ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a few random images\n",
    "\n",
    "fig,axs = plt.subplots(5,5,figsize=(10,10))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "\n",
    "  # select a random picture\n",
    "  randidx = np.random.choice(len(cdata.targets))\n",
    "\n",
    "  # extract that image\n",
    "  pic = cdata.data[randidx,:,:,:]\n",
    "  # and its label\n",
    "  label = cdata.classes[cdata.targets[randidx]]\n",
    "\n",
    "  # and show!\n",
    "  ax.imshow(pic)\n",
    "  ax.text(16,0,label,ha='center',fontweight='bold',color='k',backgroundcolor='y')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bdd95-068d-42ea-bb2a-377323e7433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = T.Compose([ T.ToTensor(),\n",
    "                 T.Resize(32*4),\n",
    "                 T.Grayscale(num_output_channels=1)  ])\n",
    "\n",
    "# include the transform in the dataset\n",
    "cdata.transform = Ts\n",
    "\n",
    "# you can also apply the transforms immediately when loading in the data\n",
    "# cdata = torchvision.datasets.CIFAR10(root='cifar10', download=True, transform=Ts)\n",
    "\n",
    "\n",
    "# Important! Adding a transform doesn't change the image data:\n",
    "print(cdata.data[123,:,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051534a-da7d-42b2-ad9c-dd445a470632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the transform\n",
    "\n",
    "# option 1a: apply the transform \"externally\" to an image\n",
    "img1 = Ts( cdata.data[123,:,:,:] )\n",
    "\n",
    "# option 1b: use the embedded transform\n",
    "img2 = cdata.transform( cdata.data[123,:,:,:] )\n",
    "\n",
    "# let's see what we've done!\n",
    "fig,ax = plt.subplots(1,3,figsize=(10,3))\n",
    "ax[0].imshow(cdata.data[123,:,:,:])\n",
    "ax[1].imshow(torch.squeeze(img1))\n",
    "ax[2].imshow(torch.squeeze(img2),cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de15c61-fa0f-45cf-b7db-9843bccfff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note about ToTensor() and normalization:\n",
    "??T.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554b61a-0f6e-480f-ba4f-c5d6c6534727",
   "metadata": {},
   "source": [
    "# 5. Convolutional Neural Networks (CNNs)\n",
    "## 5-1. Digit Recognition with LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58506181-30f4-4fa5-83d0-6d1d4aa6a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "# NEW: reshape to 2D!\n",
    "dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00587a73-9df2-4c55-8137-69c297c1020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558f110-896a-4e8c-82d9-e9df4be48945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea9c15-1284-41dd-a380-1092982d6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check size (should be images X channels X width X height)\n",
    "train_loader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf2319-622f-4a1d-937d-2e18e532c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet(printtoggle=False):\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self,printtoggle):\n",
    "      super().__init__()\n",
    "\n",
    "      ### convolution layers\n",
    "      self.conv1 = nn.Conv2d( 1,10,kernel_size=5,stride=1,padding=1)\n",
    "      # size: np.floor( (28+2*1-5)/1 )+1 = 26/2 = 13 (/2 b/c maxpool)\n",
    "\n",
    "      self.conv2 = nn.Conv2d(10,20,kernel_size=5,stride=1,padding=1)\n",
    "      # size: np.floor( (13+2*1-5)/1 )+1 = 11/2 = 5 (/2 b/c maxpool)\n",
    "\n",
    "      # compute the number of units in FClayer (number of outputs of conv2)\n",
    "      expectSize = np.floor( (5+2*0-1)/1 ) + 1 # fc1 layer has no padding or kernel, so set to 0/1\n",
    "      expectSize = 20*int(expectSize**2)\n",
    "\n",
    "      ### fully-connected layer\n",
    "      self.fc1 = nn.Linear(expectSize,50)\n",
    "\n",
    "      ### output layer\n",
    "      self.out = nn.Linear(50,10)\n",
    "\n",
    "      # toggle for printing out tensor sizes during forward prop\n",
    "      self.print = printtoggle\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "\n",
    "      print(f'Input: {x.shape}') if self.print else None\n",
    "\n",
    "      # convolution -> maxpool -> relu\n",
    "      x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "      print(f'Layer conv1/pool1: {x.shape}') if self.print else None\n",
    "\n",
    "      # and again: convolution -> maxpool -> relu\n",
    "      x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "      print(f'Layer conv2/pool2: {x.shape}') if self.print else None\n",
    "\n",
    "      # reshape for linear layer\n",
    "      nUnits = x.shape.numel()/x.shape[0]\n",
    "      x = x.view(-1,int(nUnits))\n",
    "      if self.print: print(f'Vectorize: {x.shape}')\n",
    "\n",
    "      # linear layers\n",
    "      x = F.relu(self.fc1(x))\n",
    "      if self.print: print(f'Layer fc1: {x.shape}')\n",
    "      x = self.out(x)\n",
    "      if self.print: print(f'Layer out: {x.shape}')\n",
    "\n",
    "      return x\n",
    "\n",
    "  # create the model instance\n",
    "  net = mnistNet(printtoggle)\n",
    "\n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfce3d-3fa8-47cb-a27d-63c88b250bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = createTheMNISTNet(True)\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "\n",
    "# check sizes of model outputs and target variable\n",
    "print(' ')\n",
    "print(yHat.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# now let's compute the loss\n",
    "loss = lossfun(yHat,y)\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8086e1-a334-4811-899a-ab978d7e57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the total number of parameters in the model\n",
    "summary(net,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b023c0-c7d4-4317-bdcb-0cb85d8b9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "\n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    net.train()\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "\n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f588f9d-bd3f-4e6d-a665-ae7c0a3b0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116d725-fb45-4aa4-bac6-5be0ba48bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses,'s-')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,'s-',label='Train')\n",
    "ax[1].plot(testAcc,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9866c9-1272-487d-a5d5-06284205fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] Shifted MNIST\n",
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data   = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "# NEW: reshape to 2D!\n",
    "dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d67f5-3696-4f0c-b791-644b05cb4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96514c9-cbed-47a2-acf2-13daea79aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see how to shift a vectorized image\n",
    "\n",
    "# grab one image data\n",
    "tmp = test_loader.dataset.tensors[0][0,:]\n",
    "# tmp = tmp.reshape(28,28) # reshape to 2D image\n",
    "\n",
    "# shift the image (pytorch calls it \"rolling\")\n",
    "tmpS = torch.roll(tmp,8,dims=1)\n",
    "\n",
    "\n",
    "# now show them both\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,6))\n",
    "ax[0].imshow(torch.squeeze(tmp), cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "\n",
    "ax[1].imshow(torch.squeeze(tmpS), cmap='gray')\n",
    "ax[1].set_title('Shifted (rolled)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db568da2-765f-4262-86cb-b84756dc14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repeat for all images in the training set\n",
    "\n",
    "for i in range(train_loader.dataset.tensors[0].shape[0]):\n",
    "  \n",
    "  # get the image\n",
    "  img = train_loader.dataset.tensors[0][i,:,:]\n",
    "  \n",
    "  # reshape and roll by 10 pixels\n",
    "  randroll = np.random.randint(-10,11)\n",
    "  img = torch.roll( img ,randroll,dims=1 )\n",
    "\n",
    "  # re-vectorize and put back into the matrix\n",
    "  train_loader.dataset.tensors[0][i,:,:] = img\n",
    "\n",
    "\n",
    "# Note: now run the previous cell again to confirm the shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6bc75-cec9-411a-819b-8b9be6f6aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repeat for all images in the test set\n",
    "\n",
    "for i in range(test_loader.dataset.tensors[0].shape[0]):\n",
    "  \n",
    "  # get the image\n",
    "  img = test_loader.dataset.tensors[0][i,:,:]\n",
    "  \n",
    "  # reshape and roll by 10 pixels\n",
    "  randroll = np.random.randint(-10,11)\n",
    "  img = torch.roll( img ,randroll,dims=1 )\n",
    "\n",
    "  # re-vectorize and put back into the matrix\n",
    "  test_loader.dataset.tensors[0][i,:,:] = img\n",
    "\n",
    "\n",
    "# Note: now run the previous cell again to confirm the shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ded7d-d276-4716-bac1-b962e049bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet(printtoggle=False):\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self,printtoggle):\n",
    "      super().__init__()\n",
    "\n",
    "      ### convolution layers\n",
    "      self.conv1 = nn.Conv2d( 1,10,kernel_size=5,stride=1,padding=1)\n",
    "      # size: np.floor( (28+2*1-5)/1 )+1 = 26/2 = 13 (/2 b/c maxpool)\n",
    "\n",
    "      self.conv2 = nn.Conv2d(10,20,kernel_size=5,stride=1,padding=1)\n",
    "      # size: np.floor( (13+2*1-5)/1 )+1 = 11/2 = 5 (/2 b/c maxpool)\n",
    "\n",
    "      # compute the number of units in FClayer (number of outputs of conv2)\n",
    "      expectSize = np.floor( (5+2*0-1)/1 ) + 1 # fc1 layer has no padding or kernel, so set to 0/1\n",
    "      expectSize = 20*int(expectSize**2)\n",
    "      \n",
    "      ### fully-connected layer\n",
    "      self.fc1 = nn.Linear(expectSize,50)\n",
    "\n",
    "      ### output layer\n",
    "      self.out = nn.Linear(50,10)\n",
    "\n",
    "      # toggle for printing out tensor sizes during forward prop\n",
    "      self.print = printtoggle\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      \n",
    "      print(f'Input: {x.shape}') if self.print else None\n",
    "\n",
    "      # convolution -> maxpool -> relu\n",
    "      x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "      print(f'Layer conv1: {x.shape}') if self.print else None\n",
    "\n",
    "      # and again: convolution -> maxpool -> relu\n",
    "      x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "      print(f'Layer conv2: {x.shape}') if self.print else None\n",
    "\n",
    "      # reshape for linear layer\n",
    "      nUnits = x.shape.numel()/x.shape[0]\n",
    "      x = x.view(-1,int(nUnits))\n",
    "      print(f'Vectorize: {x.shape}') if self.print else None\n",
    "      \n",
    "      # linear layers\n",
    "      x = F.relu(self.fc1(x))\n",
    "      print(f'Layer fc1: {x.shape}') if self.print else None\n",
    "      x = self.out(x)\n",
    "      print(f'Layer out: {x.shape}') if self.print else None\n",
    "\n",
    "      return x\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet(printtoggle)\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbfaff-5424-473d-a1b5-82a12653010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 30\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader))\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c008c03-3e43-4618-8e8c-d17f644a5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41757dc8-c4e4-4f0b-b577-2a56b211d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524e536-c03d-433e-a99b-5882b5efc22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9c18fb-d73c-4bd2-831b-e3df065207e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6bd9c9-8ef2-49a2-8bce-9b1342bc655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Pixel Value: 0 \n",
      "Max Pixel Value: 255\n",
      "Mean Pixel Value 33.31842041015625 \n",
      "Pixel Values Std: 78.56748962402344\n",
      "Scaled Mean Pixel Value 0.13066047430038452 \n",
      "Scaled Pixel Values Std: 0.30810779333114624\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='.', train=True, download=True)\n",
    "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(train_dataset.data.min(), train_dataset.data.max()))\n",
    "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(train_dataset.data.float().mean(), train_dataset.data.float().std()))\n",
    "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(train_dataset.data.float().mean() / 255, train_dataset.data.float().std() / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a0e7af-5bc1-4d21-a777-51170fa044a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Pixel Value: 0 \n",
      "Max Pixel Value: 255\n",
      "Mean Pixel Value 33.791221618652344 \n",
      "Pixel Values Std: 79.17247009277344\n",
      "Scaled Mean Pixel Value 0.1325145959854126 \n",
      "Scaled Pixel Values Std: 0.3104802668094635\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='.', train=False, download=True)\n",
    "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(test_dataset.data.min(), test_dataset.data.max()))\n",
    "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(test_dataset.data.float().mean(), test_dataset.data.float().std()))\n",
    "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(test_dataset.data.float().mean() / 255, test_dataset.data.float().std() / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a935a5-5147-4553-84ee-e7e05d2da9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True,\n",
    "                                           transform = torchvision.transforms.Compose([\n",
    "                                                  torchvision.transforms.Resize((32,32)),\n",
    "                                                  torchvision.transforms.ToTensor(),\n",
    "                                                  torchvision.transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = torchvision.transforms.Compose([\n",
    "                                                  torchvision.transforms.Resize((32,32)),\n",
    "                                                  torchvision.transforms.ToTensor(),\n",
    "                                                  torchvision.transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6dc8bec-0f2f-4be2-9aa0-c7907db49392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1d9f80-73bf-4b79-acf0-47b270aba109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02edf854-9d97-42ae-8200-8dbab7b22f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# number of classes\n",
    "K = len(set(train_dataset.targets.numpy()))\n",
    "print(\"number of classes:\", K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9478c522-7783-405f-b219-f8d078cbdb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense_layers): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        # http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html\n",
    "        # \"No zero padding, non-unit strides\"\n",
    "        # https://pytorch.org/docs/stable/nn.html\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(400, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, K)\n",
    "        )\n",
    "  \n",
    "    def forward(self, X):\n",
    "        out = self.conv_layers(X)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dense_layers(out)\n",
    "        return out\n",
    "\n",
    "model = LeNet5(num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44dbc429-5ff1-4d31-95a1-e6f41f3afb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a loss function for multi-class classification\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create an optimizer for multi-class classification\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "total_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f8c0ff-5064-4fe5-a400-a27540e19fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.0209\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0154\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0931\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0954\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0467\n",
      "Epoch [3/10], Step [800/938], Loss: 0.1767\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0360\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0144\n",
      "Epoch [5/10], Step [400/938], Loss: 0.1090\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0107\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0227\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0312\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0247\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0248\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0003\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0679\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0147\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0694\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0181\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0727\n"
     ]
    }
   ],
   "source": [
    "# Loop through data\n",
    "for epoch in range(num_epochs):\n",
    "  # Training\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(images)\n",
    "      loss = loss_fn(outputs, labels)\n",
    "\n",
    "      # Backward & optimize\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if (i + 1) % 400 == 0:\n",
    "          print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d5beca-1904-44bf-bef3-c494ab9602d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.56 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5065f32e-f289-467b-8153-06b9aafb71e0",
   "metadata": {},
   "source": [
    "## 5-2. Gaussian Blurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265e771-7f76-406b-8e23-4e937a2222c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPerClass = 1000\n",
    "imgSize   = 91\n",
    "\n",
    "x = np.linspace(-4,4,imgSize)\n",
    "X,Y = np.meshgrid(x,x)\n",
    "\n",
    "# the two widths (a.u.)\n",
    "widths = [1.8,2.4]\n",
    "\n",
    "# initialize tensors containing images and labels\n",
    "images = torch.zeros(2*nPerClass,1,imgSize,imgSize)\n",
    "labels = torch.zeros(2*nPerClass)\n",
    "\n",
    "for i in range(2*nPerClass):\n",
    "\n",
    "  # create the gaussian with random centers\n",
    "  ro = 2*np.random.randn(2) # ro = random offset\n",
    "  G  = np.exp( -( (X-ro[0])**2 + (Y-ro[1])**2) / (2*widths[i%2]**2) )\n",
    "  \n",
    "  # and add noise\n",
    "  G  = G + np.random.randn(imgSize,imgSize)/5\n",
    "  \n",
    "  # add to the tensor\n",
    "  images[i,:,:,:] = torch.Tensor(G).view(1,imgSize,imgSize)\n",
    "  labels[i] = i%2\n",
    "\n",
    "labels = labels[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1db8cc-3637-439c-8553-353e8ab08af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "fig,axs = plt.subplots(3,7,figsize=(13,6))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  whichpic = np.random.randint(2*nPerClass)\n",
    "  G = np.squeeze( images[whichpic,:,:] )\n",
    "  ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
    "  ax.set_title('Class %s'%int(labels[whichpic].item()))\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07465f-fc83-4527-bd97-52bdf3b69044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(images, labels, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbe1fa-f110-4d3c-8871-c65909f02dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check size (should be images X channels X width X height\n",
    "print( train_loader.dataset.tensors[0].shape )\n",
    "print( train_loader.dataset.tensors[1].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d59b5-c39d-4284-9ee5-1b85499f3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def makeTheNet():\n",
    "\n",
    "  class gausnet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      \n",
    "      # all layers in one go using nn.Sequential\n",
    "      self.enc = nn.Sequential(\n",
    "          nn.Conv2d(1,6,3,padding=1),  # output size: (91+2*1-3)/1 + 1 = 91\n",
    "          nn.ReLU(),                   # note that relu is treated like a \"layer\"\n",
    "          nn.AvgPool2d(2,2),           # output size: 91/2 = 45 \n",
    "          nn.Conv2d(6,4,3,padding=1),  # output size: (45+2*1-3)/1 + 1 = 45\n",
    "          nn.ReLU(),                   # \n",
    "          nn.AvgPool2d(2,2),           # output size: 45/2 = 22\n",
    "          nn.Flatten(),                # vectorize conv output\n",
    "          nn.Linear(22*22*4,50),       # output size: 50\n",
    "          nn.Linear(50,1),             # output size: 1\n",
    "      )\n",
    "      \n",
    "    def forward(self,x):\n",
    "      return self.enc(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = gausnet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186e525-305d-4953-abaf-5d12147de381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "\n",
    "# check size of output\n",
    "print(' ')\n",
    "print(yHat.shape)\n",
    "\n",
    "# # now let's compute the loss\n",
    "loss = lossfun(yHat,y)\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0841947-de22-452d-8a3f-6d3c2019bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the total number of parameters in the model\n",
    "summary(net,(1,imgSize,imgSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d75da0-eb05-4893-8af3-fe48bc4dda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "  # initialize losses\n",
    "  trainLoss = torch.zeros(numepochs)\n",
    "  testLoss  = torch.zeros(numepochs)\n",
    "  trainAcc  = torch.zeros(numepochs)\n",
    "  testAcc   = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchLoss = []\n",
    "    batchAcc  = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "      batchAcc.append( torch.mean(( (yHat>0) ==y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    trainLoss[epochi] = np.mean(batchLoss)\n",
    "    trainAcc[epochi]  = 100*np.mean(batchAcc)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testLoss[epochi] = loss.item()\n",
    "    testAcc[epochi]  = 100*torch.mean(( (yHat>0) ==y).float()).item()\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainLoss,testLoss,trainAcc,testAcc,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2380400-57a3-4386-95ed-353ef6009556",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoss,testLoss,trainAcc,testAcc,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc2501-424f-4733-85d1-fd525956dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(trainLoss,'s-',label='Train')\n",
    "ax[0].plot(testLoss,'o-',label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss (MSE)')\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,'s-',label='Train')\n",
    "ax[1].plot(testAcc,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3206db8-0363-41b4-a672-4455eec4fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "\n",
    "X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "yHat = net(X)\n",
    "\n",
    "fig,axs = plt.subplots(2,10,figsize=(15,4))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  G = torch.squeeze( X[i,0,:,:] ).detach()\n",
    "  ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
    "  t = ( int(y[i].item()) , int(yHat[i].item()>0) )\n",
    "  ax.set_title('T:%s, P:%s'%t)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52bd38-5b7f-4291-b38d-c4017a9c64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the filters\n",
    "print(net)\n",
    "\n",
    "layer1W = net.enc[0].weight\n",
    "layer3W = net.enc[3].weight\n",
    "\n",
    "print(' ')\n",
    "print(layer1W.shape)\n",
    "print(layer3W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4190b1-df35-4b11-a235-da7e1b3d8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,6,figsize=(15,3))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  ax.imshow( torch.squeeze(layer1W[i,:,:,:]).detach() ,cmap='Purples')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.suptitle('First convolution layer filters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288071c2-8328-484b-abb6-4885dd6bc9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4,6,figsize=(15,9))\n",
    "\n",
    "for i in range(6*4):\n",
    "  idx = np.unravel_index(i,(4,6))\n",
    "  axs[idx].imshow( torch.squeeze(layer3W[idx[0],idx[1],:,:]).detach() ,cmap='Purples')\n",
    "  axs[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Second convolution layer filters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37b5d4-24ac-4123-820f-712ed897af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] Feature map activations\n",
    "nPerClass = 1000\n",
    "imgSize   = 91\n",
    "\n",
    "x = np.linspace(-4,4,imgSize)\n",
    "X,Y = np.meshgrid(x,x)\n",
    "\n",
    "# the two widths (a.u.)\n",
    "widths = [1.8,2.4]\n",
    "\n",
    "# initialize tensors containing images and labels\n",
    "images = torch.zeros(2*nPerClass,1,imgSize,imgSize)\n",
    "labels = torch.zeros(2*nPerClass)\n",
    "\n",
    "for i in range(2*nPerClass):\n",
    "\n",
    "  # create the gaussian with random centers\n",
    "  ro = 2*np.random.randn(2) # ro = random offset\n",
    "  G  = np.exp( -( (X-ro[0])**2 + (Y-ro[1])**2) / (2*widths[i%2]**2) )\n",
    "  \n",
    "  # and add noise\n",
    "  G  = G + np.random.randn(imgSize,imgSize)/5\n",
    "  \n",
    "  # add to the tensor\n",
    "  images[i,:,:,:] = torch.Tensor(G).view(1,imgSize,imgSize)\n",
    "  labels[i] = i%2\n",
    "\n",
    "labels = labels[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaa187-6ab2-4c03-9d21-a2a7bfb98f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "fig,axs = plt.subplots(3,7,figsize=(13,6))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  whichpic = np.random.randint(2*nPerClass)\n",
    "  G = np.squeeze( images[whichpic,:,:] )\n",
    "  ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
    "  ax.set_title('Class %s'%int(labels[whichpic].item()))\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08650531-8aaa-4b66-92f8-396ab94dc804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(images, labels, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7b704-2f58-42f9-90c6-9bcb1ee0c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def makeTheNet():\n",
    "\n",
    "  class gausnet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      \n",
    "      # conv1\n",
    "      self.conv1 = nn.Conv2d(1,6,3,padding=1)\n",
    "      # output size: (91+2*1-3)/1 + 1 = 91\n",
    "      # post-pooling: 91/2 = 45\n",
    "\n",
    "      # conv2\n",
    "      self.conv2 = nn.Conv2d(6,4,3,padding=1)\n",
    "      # output size: (45+2*1-3)/1 + 1 = 45\n",
    "      # post-pooling: 45/2 = 22\n",
    "\n",
    "      # fc1\n",
    "      self.fc1 = nn.Linear(22*22*4,50)\n",
    "\n",
    "      # fc2 (output)\n",
    "      self.fc2 = nn.Linear(50,1)\n",
    "      \n",
    "    def forward(self,x):\n",
    "      # first conv-pool set\n",
    "      conv1act = F.relu(self.conv1(x))\n",
    "      x = F.avg_pool2d(conv1act,(2,2))\n",
    "      \n",
    "      # second conv-pool set\n",
    "      conv2act = F.relu(self.conv2(x))\n",
    "      x = F.avg_pool2d(conv2act,(2,2))\n",
    "\n",
    "      # ANN part\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      return x,conv1act,conv2act\n",
    "  \n",
    "  # create the model instance\n",
    "  net = gausnet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03320107-859d-4e12-be65-1ce2a4eacf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "# test that the model runs and can compute a loss\n",
    "X,y = next(iter(train_loader))\n",
    "yHat,featmap1,featmap2 = net(X)\n",
    "loss = lossfun(yHat,y)\n",
    "\n",
    "# check sizes of outputs\n",
    "print('Predicted category:')\n",
    "print(yHat.shape)\n",
    "print('\\nFeature map after conv1')\n",
    "print(featmap1.shape)\n",
    "print('\\nFeature map after conv2')\n",
    "print(featmap2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a213a-7f04-4934-b095-73b86a91c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the total number of parameters in the model\n",
    "summary(net,(1,imgSize,imgSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acceb03-ac65-4733-a0c8-78def5ce2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "  # initialize losses\n",
    "  trainLoss = torch.zeros(numepochs)\n",
    "  testLoss  = torch.zeros(numepochs)\n",
    "  trainAcc  = torch.zeros(numepochs)\n",
    "  testAcc   = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchLoss = []\n",
    "    batchAcc  = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)[0] # we only need the first output\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "      batchAcc.append( torch.mean(( (yHat>0) ==y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    trainLoss[epochi] = np.mean(batchLoss)\n",
    "    trainAcc[epochi]  = 100*np.mean(batchAcc)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)[0] # we only need the first output\n",
    "      loss = lossfun(yHat,y)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testLoss[epochi] = loss.item()\n",
    "    testAcc[epochi]  = 100*torch.mean(( (yHat>0) ==y).float()).item()\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainLoss,testLoss,trainAcc,testAcc,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0e32d-f947-40fb-ab6a-45e7b1af0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoss,testLoss,trainAcc,testAcc,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcefc9f-c36b-4e42-bca6-ddb52d5c393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(trainLoss,'s-',label='Train')\n",
    "ax[0].plot(testLoss,'o-',label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss (MSE)')\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,'s-',label='Train')\n",
    "ax[1].plot(testAcc,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791641ba-762f-4d69-909a-f459874e8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "\n",
    "X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "yHat,featmap1,featmap2 = net(X)\n",
    "\n",
    "fig,axs = plt.subplots(2,10,figsize=(15,4))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  G = torch.squeeze( X[i,0,:,:] ).detach()\n",
    "  ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
    "  t = ( int(y[i].item()) , int(yHat[i].item()>.5) )\n",
    "  ax.set_title('T:%s, P:%s'%t)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c24d41-f0cb-4c89-b6ac-8828f1995be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature maps from the conv1 layer\n",
    "\n",
    "fig,axs = plt.subplots(7,10,figsize=(12,6))\n",
    "\n",
    "for pici in range(10):\n",
    "\n",
    "  # show the original picture\n",
    "  img = X[pici,0,:,:].detach()\n",
    "  axs[0,pici].imshow(img,cmap='jet',vmin=0,vmax=1)\n",
    "  axs[0,pici].axis('off')\n",
    "  axs[0,pici].text(2,2,'T:%s'%int(y[pici].item()),ha='left',va='top',color='w',fontweight='bold')\n",
    "\n",
    "  for feati in range(6):\n",
    "    # extract the feature map from this image\n",
    "    img = featmap1[pici,feati,:,:].detach()\n",
    "    axs[feati+1,pici].imshow(img,cmap='inferno',vmin=0,vmax=torch.max(img)*.9)\n",
    "    axs[feati+1,pici].axis('off')\n",
    "    axs[feati+1,pici].text(-5,45,feati,ha='right') if pici==0 else None\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('First set of feature map activations for 10 test images',x=.5,y=1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138af9a-5f57-4226-a44b-7b78603bea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for feature2 maps\n",
    "\n",
    "fig,axs = plt.subplots(5,10,figsize=(12,6))\n",
    "\n",
    "for pici in range(10):\n",
    "\n",
    "  # show the original picture\n",
    "  img = X[pici,0,:,:].detach()\n",
    "  axs[0,pici].imshow(img,cmap='jet',vmin=0,vmax=1)\n",
    "  axs[0,pici].axis('off')\n",
    "\n",
    "  for feati in range(4):\n",
    "    # extract the feature map from this image\n",
    "    img = featmap2[pici,feati,:,:].detach()\n",
    "    axs[feati+1,pici].imshow(img,cmap='inferno',vmin=0,vmax=torch.max(img)*.9)\n",
    "    axs[feati+1,pici].axis('off')\n",
    "    axs[feati+1,pici].text(-5,22,feati,ha='right') if pici==0 else None\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Second set of feature map activations for 10 test images',x=.5,y=1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce848b-1f53-46fc-978c-60bc06be1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] Spatial correlations across the feature maps\n",
    "### correlations across the SECOND convolution layer\n",
    "\n",
    "# convenient variables\n",
    "nStim = featmap2.shape[0]\n",
    "nMaps = featmap2.shape[1]\n",
    "nCors = (nMaps*(nMaps-1))//2\n",
    "\n",
    "# initialze the matrix of all correlation values\n",
    "allrs = np.zeros((nStim,nCors))\n",
    "Call  = np.zeros((nMaps,nMaps))\n",
    "\n",
    "# loop over each stimulus\n",
    "for i in range(nStim):\n",
    "\n",
    "  # extract the vectorized feature maps from this image\n",
    "  featmaps = featmap2[i,:,:,:].view(nMaps,-1).detach()\n",
    "\n",
    "  # compute the correlation matrix\n",
    "  C = np.corrcoef(featmaps)\n",
    "  Call += C\n",
    "\n",
    "  # extract the unique correlations from the matrix\n",
    "  idx = np.nonzero(np.triu(C,1))\n",
    "  allrs[i,:] = C[idx]\n",
    "\n",
    "\n",
    "# define the x-axis labels\n",
    "xlab = []*nCors\n",
    "for i in range(nCors):\n",
    "  xlab.append('%s-%s' %(idx[0][i],idx[1][i]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# now visualize the correlations\n",
    "fig = plt.figure(figsize=(16,5))\n",
    "ax0 = fig.add_axes([.1,.1,.55,.9]) # [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([.68,.1,.3,.9])\n",
    "cax = fig.add_axes([.98,.1,.01,.9])\n",
    "\n",
    "for i in range(nCors):\n",
    "  ax0.plot(i+np.random.randn(nStim)/30,allrs[:,i],'o',markerfacecolor='w',markersize=10)\n",
    "\n",
    "# make the plot more interpretable\n",
    "ax0.set_xlim([-.5,nCors-.5])\n",
    "ax0.set_ylim([-1.05,1.05])\n",
    "ax0.set_xticks(range(nCors))\n",
    "ax0.set_xticklabels(xlab)\n",
    "ax0.set_xlabel('Feature map pair')\n",
    "ax0.set_ylabel('Correlation coefficient')\n",
    "ax0.set_title('Correlations for each image')\n",
    "\n",
    "\n",
    "# now show the average correlation matrix\n",
    "h = ax1.imshow(Call/nStim,vmin=-1,vmax=1)\n",
    "ax1.set_title('Correlation matrix')\n",
    "ax1.set_xlabel('Feature map')\n",
    "ax1.set_ylabel('Feature map')\n",
    "# add a colorbar\n",
    "fig.colorbar(h,cax=cax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55308f65-0028-4690-9083-c6db4426bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### correlations across the FIRST convolution layer\n",
    "\n",
    "# convenient variables\n",
    "nStim = featmap1.shape[0]\n",
    "nMaps = featmap1.shape[1]\n",
    "nCors = (nMaps*(nMaps-1))//2\n",
    "\n",
    "# initialze the matrix of all correlation values\n",
    "allrs = np.zeros((nStim,nCors))\n",
    "Call  = np.zeros((nMaps,nMaps))\n",
    "\n",
    "# loop over each stimulus\n",
    "for i in range(nStim):\n",
    "\n",
    "  # extract the vectorized feature maps from this image\n",
    "  featmaps = featmap1[i,:,:,:].view(nMaps,-1).detach()\n",
    "\n",
    "  # compute the correlation matrix\n",
    "  C = np.corrcoef(featmaps)\n",
    "  Call += C\n",
    "\n",
    "  # extract the unique correlations from the matrix\n",
    "  idx = np.nonzero(np.triu(C,1))\n",
    "  allrs[i,:] = C[idx]\n",
    "\n",
    "\n",
    "# define the x-axis labels\n",
    "xlab = []*nCors\n",
    "for i in range(nCors):\n",
    "  xlab.append('%s-%s' %(idx[0][i],idx[1][i]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# now visualize the correlations\n",
    "fig = plt.figure(figsize=(16,5))\n",
    "ax0 = fig.add_axes([.1,.1,.55,.9]) # [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([.68,.1,.3,.9])\n",
    "cax = fig.add_axes([.98,.1,.01,.9])\n",
    "\n",
    "for i in range(nCors):\n",
    "  ax0.plot(i+np.random.randn(nStim)/30,allrs[:,i],'o',markerfacecolor='w',markersize=10)\n",
    "\n",
    "# make the plot more interpretable\n",
    "ax0.set_xlim([-.5,nCors-.5])\n",
    "ax0.set_ylim([-1.05,1.05])\n",
    "ax0.set_xticks(range(nCors))\n",
    "ax0.set_xticklabels(xlab)\n",
    "ax0.set_xlabel('Feature map pair')\n",
    "ax0.set_ylabel('Correlation coefficient')\n",
    "ax0.set_title('Correlations for each image')\n",
    "\n",
    "\n",
    "# now show the average correlation matrix\n",
    "h = ax1.imshow(Call/nStim,vmin=-1,vmax=1)\n",
    "ax1.set_title('Correlation matrix')\n",
    "ax1.set_xlabel('Feature map')\n",
    "ax1.set_ylabel('Feature map')\n",
    "# add a colorbar\n",
    "fig.colorbar(h,cax=cax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a60f38-8d3e-43b5-ae7f-0f20043f42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] Gaussian parameters\n",
    "nGauss  = 1000\n",
    "imgSize = 91\n",
    "\n",
    "x = np.linspace(-4,4,imgSize)\n",
    "X,Y = np.meshgrid(x,x)\n",
    "\n",
    "# initialize tensors containing images and labels\n",
    "images = torch.zeros(nGauss,1,imgSize,imgSize)\n",
    "labels = torch.zeros(nGauss,3)\n",
    "\n",
    "for i in range(nGauss):\n",
    "\n",
    "  # location and width parameters\n",
    "  loc = np.max(x)/2 * np.random.randn(2) # center coordinate\n",
    "  wid = np.random.rand()*10 + 5 # width of Gaussian\n",
    "\n",
    "  # create the gaussian with random centers\n",
    "  G  = np.exp( -( (X-loc[0])**2 + (Y-loc[1])**2) / wid )\n",
    "  G  = G + np.random.randn(imgSize,imgSize)/10\n",
    "  \n",
    "  # add to the tensor\n",
    "  images[i,:,:,:] = torch.Tensor(G).view(1,imgSize,imgSize)\n",
    "  labels[i,:] = torch.Tensor( [loc[0],loc[1],wid] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492f5b6-9040-4938-b750-310cbb9b1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "fig,axs = plt.subplots(3,7,figsize=(15,7))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  whichpic = np.random.randint(nGauss)\n",
    "  G = np.squeeze( images[whichpic,:,:] )\n",
    "  ax.imshow(G,vmin=-1,vmax=1,cmap='jet',extent=[-4,4,-4,4],origin='top')\n",
    "  ax.set_title(f'XY=({labels[whichpic,0]:.0f},{labels[whichpic,1]:.0f}), W={labels[whichpic,2]:.0f}')\n",
    "  ax.plot([-4,4],[0,0],'w--')\n",
    "  ax.plot([0,0],[-4,4],'w--')\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef146bb-24fc-4c8f-8869-db9b4e77807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(images, labels, test_size=.1)\n",
    "\n",
    "# convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# translate into dataloader objects\n",
    "batchsize    = 16\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee83d7b-a76b-4a61-b141-5af1594c116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check size (should be images X channels X width X height\n",
    "print( train_loader.dataset.tensors[0].shape )\n",
    "print( train_loader.dataset.tensors[1].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78966fe-94f2-4750-8fc5-0a4723f561f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def makeTheNet():\n",
    "\n",
    "  class gausnet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      \n",
    "      # all layers in one go using nn.Sequential\n",
    "      self.enc = nn.Sequential(\n",
    "          \n",
    "          # conv/pool block 1\n",
    "          nn.Conv2d(1,6,3,padding=1),  # output size: (91+2*1-3)/1 + 1 = 91\n",
    "          nn.ReLU(),                   # \n",
    "          nn.AvgPool2d(2,2),           # output size: 91/2 = 45\n",
    "          \n",
    "          # conv/pool block 2\n",
    "          nn.Conv2d(6,4,3,padding=1),  # output size: (45+2*1-3)/1 + 1 = 45\n",
    "          nn.ReLU(),                   # \n",
    "          nn.AvgPool2d(2,2),           # output size: 45/2 = 22\n",
    "          \n",
    "          # linear decision layer\n",
    "          nn.Flatten(),                # vectorize conv2 block output\n",
    "          nn.Linear(22*22*4,50),       # output size: 50\n",
    "          nn.Linear(50,3),             # output size: 3\n",
    "      )\n",
    "      \n",
    "    def forward(self,x):\n",
    "      return self.enc(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = gausnet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.MSELoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25602384-6fb9-4551-af43-20293ae26335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "\n",
    "# check size of output\n",
    "print(yHat)\n",
    "print(' ')\n",
    "print(yHat.shape)\n",
    "\n",
    "# # now let's compute the loss\n",
    "loss = lossfun(yHat,y)\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dacd9c9-24d1-43b3-b352-7a21b4fc4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the total number of parameters in the model\n",
    "summary(net,(1,imgSize,imgSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77defcaf-af7e-4400-b8fc-a0cf395724ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 30\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "  # initialize losses\n",
    "  trainLoss = torch.zeros(numepochs)\n",
    "  testLoss  = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "    # end of batch loop...\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    trainLoss[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "      \n",
    "    # extract the loss for this test epoch\n",
    "    testLoss[epochi] = loss.item()\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainLoss,testLoss,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff26b4-32d1-4de7-b926-b7051c76f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoss,testLoss,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a66f70-053e-4781-9fb5-65a2c37f82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainLoss,'s-',label='Train')\n",
    "plt.plot(testLoss,'o-',label='Test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.title('Model loss (final test loss: %.2f)'%testLoss[-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f929e-b333-4ad3-9054-09c2cdf2d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "\n",
    "X,Y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "yHat = net(X)\n",
    "\n",
    "fig,axs = plt.subplots(2,10,figsize=(16,4))\n",
    "\n",
    "th = np.linspace(0,2*np.pi)\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "\n",
    "  # get the Gaussian and draw it, and draw the white guide-lines\n",
    "  G = torch.squeeze( X[i,0,:,:] ).detach()\n",
    "  ax.imshow(G,vmin=-1,vmax=1,cmap='jet',extent=[-4,4,-4,4],origin='lower')\n",
    "  ax.plot([-4,4],[0,0],'w--')\n",
    "  ax.plot([0,0],[-4,4],'w--')\n",
    "\n",
    "  # compute the model's prediction\n",
    "  cx = yHat[i][0].item() # center X\n",
    "  cy = yHat[i][1].item() # center Y\n",
    "  rd = yHat[i][2].item() # radius\n",
    "\n",
    "  # and draw it\n",
    "  x = cx + np.cos(th)*np.sqrt(rd)\n",
    "  y = cy + np.sin(th)*np.sqrt(rd)\n",
    "  ax.plot(x,y,'b')\n",
    "  ax.plot(cx,cy,'bo')\n",
    "  \n",
    "  # some final plotting niceties\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  ax.set_xlim([-4,4])\n",
    "  ax.set_ylim([-4,4])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85cbcc-ad9a-4a06-9995-408f42dd31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "paramNames = ['Cx','Cy','rad.']\n",
    "\n",
    "for i in range(3):\n",
    "  \n",
    "  # extract parameters and compute correlation\n",
    "  yy = Y[:,i].detach()\n",
    "  yh = yHat[:,i].detach()\n",
    "  cr = np.corrcoef(yy,yh)[0,1]\n",
    "\n",
    "  # plot with label\n",
    "  plt.plot(yy,yh,'o',label=f'{paramNames[i]}, r={cr:.3f}')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e92fbbb-0edb-467a-b9f3-25d2c24e58b5",
   "metadata": {},
   "source": [
    "## 5-3. Letter Recognition\n",
    "[EMNIST](https://www.nist.gov/itl/products-and-services/emnist-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c2231-5b19-4fa5-94f9-689a9eec009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "cdata = torchvision.datasets.EMNIST(root='emnist',split='letters',download=True)\n",
    "\n",
    "# more info: https://www.nist.gov/itl/products-and-services/emnist-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844dec05-b902-4970-bda5-a895c0c403a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the data\n",
    "\n",
    "# the categories (but how many letters??)\n",
    "print(cdata.classes)\n",
    "print(str(len(cdata.classes)) + ' classes')\n",
    "\n",
    "print('\\nData size:')\n",
    "print(cdata.data.shape)\n",
    "\n",
    "# transform to 4D tensor for conv layers (and transform from int8 to float)\n",
    "images = cdata.data.view([124800,1,28,28]).float()\n",
    "print('\\nTensor data:')\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e251d0f-d06c-4139-8036-36127b68032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief aside: class 'N/A' doesn't exist in the data.\n",
    "print( torch.sum(cdata.targets==0) )\n",
    "\n",
    "# However, it causes problems in one-hot encoding...\n",
    "torch.unique(cdata.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0c580-3588-4cb8-8d14-6e211137c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a3b40-ddd3-40b1-8ae3-d459e1388dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so therefore we'll eliminate it and subtract 1 from the original\n",
    "\n",
    "# remove the first class category\n",
    "letterCategories = cdata.classes[1:]\n",
    "\n",
    "# relabel labels to start at 0\n",
    "labels = copy.deepcopy(cdata.targets)-1\n",
    "print(labels.shape)\n",
    "\n",
    "### \n",
    "print( torch.sum(labels==0) )\n",
    "torch.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61baeb67-72fc-499e-977d-1b9de550f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next issue: do we need to normalize the images?\n",
    "plt.hist(images[:10,:,:,:].view(1,-1).detach(),40);\n",
    "plt.title('Raw values')\n",
    "plt.show()\n",
    "\n",
    "# yarp.\n",
    "images /= torch.max(images)\n",
    "\n",
    "plt.hist(images[:10,:,:,:].view(1,-1).detach(),40);\n",
    "plt.title('After normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c04414-6803-4943-9c44-ed24fd072d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images\n",
    "fig,axs = plt.subplots(3,7,figsize=(13,6))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "\n",
    "  # pick a random pic\n",
    "  whichpic = np.random.randint(images.shape[0])\n",
    "  \n",
    "  # extract the image and its target letter\n",
    "  I = np.squeeze( images[whichpic,:,:] )\n",
    "  letter = letterCategories[labels[whichpic]]\n",
    "  \n",
    "  # visualize\n",
    "  ax.imshow(I.T,cmap='gray')\n",
    "  ax.set_title('The letter \"%s\"'%letter)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8b92e-c1d0-4058-b763-ed1fbcb802dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(images, labels, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45555a74-ba13-4bf1-b6fc-4939ac61f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check size (should be images X channels X width X height\n",
    "print( train_loader.dataset.tensors[0].shape )\n",
    "print( train_loader.dataset.tensors[1].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3dcde-b134-4788-8840-4acbc0785464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def makeTheNet(printtoggle=False):\n",
    "\n",
    "  class emnistnet(nn.Module):\n",
    "    def __init__(self,printtoggle):\n",
    "      super().__init__()\n",
    "      \n",
    "      # print toggle\n",
    "      self.print = printtoggle\n",
    "\n",
    "      ### -------------- feature map layers -------------- ###\n",
    "      # first convolution layer\n",
    "      self.conv1  = nn.Conv2d(1,6,3,padding=1)\n",
    "      self.bnorm1 = nn.BatchNorm2d(6) # input the number of channels in this layer\n",
    "      # output size: (28+2*1-3)/1 + 1 = 28/2 = 14 (/2 b/c maxpool)\n",
    "\n",
    "      # second convolution layer\n",
    "      self.conv2  = nn.Conv2d(6,6,3,padding=1)\n",
    "      self.bnorm2 = nn.BatchNorm2d(6) # input the number of channels in this layer\n",
    "      # output size: (14+2*1-3)/1 + 1 = 14/2 = 7 (/2 b/c maxpool)\n",
    "\n",
    "      \n",
    "      ### -------------- linear decision layers -------------- ###\n",
    "      self.fc1 = nn.Linear(7*7*6,50)\n",
    "      self.fc2 = nn.Linear(50,26)\n",
    "\n",
    "    def forward(self,x):\n",
    "      \n",
    "      if self.print: print(f'Input: {list(x.shape)}')\n",
    "      \n",
    "      # first block: convolution -> maxpool -> batchnorm -> relu\n",
    "      x = F.max_pool2d(self.conv1(x),2)\n",
    "      x = F.leaky_relu(self.bnorm1(x))\n",
    "      if self.print: print(f'First CPR block: {list(x.shape)}')\n",
    "\n",
    "      # second block: convolution -> maxpool -> batchnorm -> relu\n",
    "      x = F.max_pool2d(self.conv2(x),2)\n",
    "      x = F.leaky_relu(self.bnorm2(x))\n",
    "      if self.print: print(f'Second CPR block: {list(x.shape)}')\n",
    "\n",
    "      # reshape for linear layer\n",
    "      nUnits = x.shape.numel()/x.shape[0]\n",
    "      x = x.view(-1,int(nUnits))\n",
    "      if self.print: print(f'Vectorized: {list(x.shape)}')\n",
    "      \n",
    "      # linear layers\n",
    "      x = F.leaky_relu(self.fc1(x))\n",
    "      x = self.fc2(x)\n",
    "      if self.print: print(f'Final output: {list(x.shape)}')\n",
    "\n",
    "      return x\n",
    "\n",
    "  # create the model instance\n",
    "  net = emnistnet(printtoggle)\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ed6ab-0758-4e5b-9262-84741e0bf151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = makeTheNet(True)\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "\n",
    "# check size of output\n",
    "print('\\nOutput size:')\n",
    "print(yHat.shape)\n",
    "\n",
    "# # now let's compute the loss\n",
    "loss = lossfun(yHat,torch.squeeze(y))\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93883054-268d-4e14-a92e-fa4975497582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "  # send the model to the GPU\n",
    "  net.to(device)\n",
    "\n",
    "  # initialize losses\n",
    "  trainLoss = torch.zeros(numepochs)\n",
    "  testLoss  = torch.zeros(numepochs)\n",
    "  trainErr  = torch.zeros(numepochs)\n",
    "  testErr   = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    net.train()\n",
    "    batchLoss = []\n",
    "    batchErr  = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # push data to GPU\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss and error from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "      batchErr.append( torch.mean((torch.argmax(yHat,axis=1) != y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # and get average losses and error rates across the batches\n",
    "    trainLoss[epochi] = np.mean(batchLoss)\n",
    "    trainErr[epochi]  = 100*np.mean(batchErr)\n",
    "\n",
    "\n",
    "\n",
    "    ### test performance\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "\n",
    "    # push data to GPU\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "      \n",
    "    # get loss and error rate from the test batch\n",
    "    testLoss[epochi] = loss.item()\n",
    "    testErr[epochi]  = 100*torch.mean((torch.argmax(yHat,axis=1) != y).float()).item()\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainLoss,testLoss,trainErr,testErr,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7a898-1ee9-4fa0-9f19-0b16820c8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~2 minutes with 10 epochs on GPU (8 mins on the CPU!)\n",
    "trainLoss,testLoss,trainErr,testErr,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4daf0d2-73b3-4110-9e38-b68207f5251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(trainLoss,'s-',label='Train')\n",
    "ax[0].plot(testLoss,'o-',label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss (MSE)')\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainErr,'s-',label='Train')\n",
    "ax[1].plot(testErr,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Error rates (%)')\n",
    "ax[1].set_title(f'Final model test error rate: {testErr[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44300908-13f4-41d7-8782-7c9e6547ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize some images\n",
    "\n",
    "# extract X,y from test dataloader\n",
    "X,y = next(iter(test_loader))\n",
    "X = X.to(device) # push data to GPU\n",
    "y = y.to(device) # push data to GPU\n",
    "yHat = net(X)\n",
    "\n",
    "# pick some examples at random to show\n",
    "randex = np.random.choice(len(y),size=21,replace=False)\n",
    "\n",
    "# visualize some images\n",
    "fig,axs = plt.subplots(3,7,figsize=(15,6))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "\n",
    "  # extract the image and its target letter\n",
    "  I = np.squeeze( X[randex[i],0,:,:] ).cpu() # .cpu() to transfer back from GPU!\n",
    "  trueLetter = letterCategories[ y[randex[i]] ]\n",
    "  predLetter = letterCategories[ torch.argmax(yHat[randex[i],:]) ]\n",
    "  \n",
    "  # color-code the accuracy (using ternary operator)\n",
    "  col = 'gray' if trueLetter==predLetter else 'hot'\n",
    "  \n",
    "  # visualize\n",
    "  ax.imshow(I.T,cmap=col)\n",
    "  ax.set_title('True %s, predicted %s' %(trueLetter,predLetter),fontsize=10)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175f894-5761-40eb-8df2-11f1192b34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "\n",
    "# compute the confusion matrix\n",
    "C = skm.confusion_matrix(y.cpu(),torch.argmax(yHat.cpu(),axis=1),normalize='true')\n",
    "\n",
    "# visualize it\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.imshow(C,'Blues',vmax=.05)\n",
    "\n",
    "# make the plot look nicer\n",
    "plt.xticks(range(26),labels=letterCategories)\n",
    "plt.yticks(range(26),labels=letterCategories)\n",
    "plt.title('TEST confusion matrix')\n",
    "plt.xlabel('True number')\n",
    "plt.xlabel('Predicted number')\n",
    "plt.ylabel('True number')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07375b96-bc31-46e1-bf5a-4e54667e6f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27783947-695b-46e5-a969-9d6f2d28b5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
