{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b554b61a-0f6e-480f-ba4f-c5d6c6534727",
   "metadata": {},
   "source": [
    "# 11. Convolutional Neural Networks (CNNs)\n",
    "## 11-1. Image Classification with LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9c18fb-d73c-4bd2-831b-e3df065207e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6bd9c9-8ef2-49a2-8bce-9b1342bc655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Pixel Value: 0 \n",
      "Max Pixel Value: 255\n",
      "Mean Pixel Value 33.31842041015625 \n",
      "Pixel Values Std: 78.56748962402344\n",
      "Scaled Mean Pixel Value 0.13066047430038452 \n",
      "Scaled Pixel Values Std: 0.30810779333114624\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='.', train=True, download=True)\n",
    "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(train_dataset.data.min(), train_dataset.data.max()))\n",
    "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(train_dataset.data.float().mean(), train_dataset.data.float().std()))\n",
    "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(train_dataset.data.float().mean() / 255, train_dataset.data.float().std() / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a0e7af-5bc1-4d21-a777-51170fa044a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Pixel Value: 0 \n",
      "Max Pixel Value: 255\n",
      "Mean Pixel Value 33.791221618652344 \n",
      "Pixel Values Std: 79.17247009277344\n",
      "Scaled Mean Pixel Value 0.1325145959854126 \n",
      "Scaled Pixel Values Std: 0.3104802668094635\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='.', train=False, download=True)\n",
    "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(test_dataset.data.min(), test_dataset.data.max()))\n",
    "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(test_dataset.data.float().mean(), test_dataset.data.float().std()))\n",
    "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(test_dataset.data.float().mean() / 255, test_dataset.data.float().std() / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a935a5-5147-4553-84ee-e7e05d2da9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True,\n",
    "                                           transform = torchvision.transforms.Compose([\n",
    "                                                  torchvision.transforms.Resize((32,32)),\n",
    "                                                  torchvision.transforms.ToTensor(),\n",
    "                                                  torchvision.transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = torchvision.transforms.Compose([\n",
    "                                                  torchvision.transforms.Resize((32,32)),\n",
    "                                                  torchvision.transforms.ToTensor(),\n",
    "                                                  torchvision.transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6dc8bec-0f2f-4be2-9aa0-c7907db49392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1d9f80-73bf-4b79-acf0-47b270aba109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02edf854-9d97-42ae-8200-8dbab7b22f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# number of classes\n",
    "K = len(set(train_dataset.targets.numpy()))\n",
    "print(\"number of classes:\", K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9478c522-7783-405f-b219-f8d078cbdb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense_layers): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        # http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html\n",
    "        # \"No zero padding, non-unit strides\"\n",
    "        # https://pytorch.org/docs/stable/nn.html\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(400, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, K)\n",
    "        )\n",
    "  \n",
    "    def forward(self, X):\n",
    "        out = self.conv_layers(X)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dense_layers(out)\n",
    "        return out\n",
    "\n",
    "model = LeNet5(num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44dbc429-5ff1-4d31-95a1-e6f41f3afb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a loss function for multi-class classification\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create an optimizer for multi-class classification\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "total_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f8c0ff-5064-4fe5-a400-a27540e19fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.0209\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0154\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0931\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0954\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0467\n",
      "Epoch [3/10], Step [800/938], Loss: 0.1767\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0360\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0144\n",
      "Epoch [5/10], Step [400/938], Loss: 0.1090\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0107\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0227\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0312\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0247\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0248\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0003\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0679\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0147\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0694\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0181\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0727\n"
     ]
    }
   ],
   "source": [
    "# Loop through data\n",
    "for epoch in range(num_epochs):\n",
    "  # Training\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(images)\n",
    "      loss = loss_fn(outputs, labels)\n",
    "\n",
    "      # Backward & optimize\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if (i + 1) % 400 == 0:\n",
    "          print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d5beca-1904-44bf-bef3-c494ab9602d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.56 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512193-998a-41f1-8a16-5de2368a3cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
