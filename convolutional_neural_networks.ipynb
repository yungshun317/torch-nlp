{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce6fa10-e701-4e5c-b736-4b591d0040bc",
   "metadata": {},
   "source": [
    "# 1. Fully Connected Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a4398-bb91-4bac-8ab2-cf9d327d92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcfc5b-defc-483b-b9a4-410a64f63b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the data matrix\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d8a51-1074-4512-bb1c-1084d893f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels (number IDs) and remove from data\n",
    "labels = data[:,0]\n",
    "data = data[:,1:]\n",
    "\n",
    "print(labels.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7be353-29e1-41fb-a45b-fce583bda80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a few random digits\n",
    "fig,axs = plt.subplots(3,4,figsize=(10,6))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "  # pick a random image\n",
    "  randimg2show = np.random.randint(0,high=data.shape[0])\n",
    "\n",
    "  # create the image (must be reshaped!)\n",
    "  img = np.reshape(data[randimg2show,:],(28,28))\n",
    "  ax.imshow(img,cmap='gray')\n",
    "\n",
    "  # title\n",
    "  ax.set_title('The number %i'%labels[randimg2show])\n",
    "\n",
    "plt.suptitle('How humans see the data',fontsize=20)\n",
    "plt.tight_layout(rect=[0,0,1,.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef3563-d4b6-48a2-96f3-b1bea3b40842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a few random digits\n",
    "fig,axs = plt.subplots(3,4,figsize=(10,6))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "  # pick a random image\n",
    "  randimg2show = np.random.randint(0,high=data.shape[0])\n",
    "\n",
    "  # create the image\n",
    "  ax.plot(data[randimg2show,:],'ko')\n",
    "\n",
    "  # title\n",
    "  ax.set_title('The number %i'%labels[randimg2show])\n",
    "\n",
    "plt.suptitle('How the FFN model sees the data',fontsize=20)\n",
    "plt.tight_layout(rect=[0,0,1,.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cde77-307c-4e6a-ab1c-cb12bbfc4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see some example 7s\n",
    "\n",
    "# find indices of all the 7's in the dataset\n",
    "the7s = np.where(labels==7)[0]\n",
    "\n",
    "# draw the first 12\n",
    "fig,axs = plt.subplots(2,6,figsize=(15,6))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  img = np.reshape(data[the7s[i],:],(28,28))\n",
    "  ax.imshow(img,cmap='gray')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"Example 7's\",fontsize=20)\n",
    "plt.tight_layout(rect=[0,0,1,.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62c3e9-ffe1-4777-b951-33cdeab758d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how similar are all the 7's? \n",
    "\n",
    "# how many 7's are there?\n",
    "print(data[the7s,:].shape)\n",
    "\n",
    "\n",
    "# let's see how they relate to each other by computing spatial correlations\n",
    "C = np.corrcoef(data[the7s,:])\n",
    "\n",
    "# and visualize\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,6))\n",
    "ax[0].imshow(C,vmin=0,vmax=1)\n",
    "ax[0].set_title(\"Correlation across all 7's\")\n",
    "\n",
    "# extract the unique correlations and show as a scatterplot\n",
    "uniqueCs = np.triu(C,k=1).flatten()\n",
    "ax[1].hist(uniqueCs[uniqueCs!=0],bins=100)\n",
    "ax[1].set_title('All unique correlations')\n",
    "ax[1].set_xlabel(\"Correlations of 7's\")\n",
    "ax[1].set_ylabel('Count')\n",
    "\n",
    "# show all 7's together\n",
    "aveAll7s = np.reshape( np.mean(data[the7s,:],axis=0) ,(28,28))\n",
    "ax[2].imshow(aveAll7s,cmap='gray')\n",
    "ax[2].set_title(\"All 7's averaged together\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c21c3-c3d4-472b-a715-4c91c9229ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].hist(data.flatten(),50)\n",
    "ax[0].set_xlabel('Pixel intensity values')\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[0].set_title('Histogram of original data')\n",
    "\n",
    "ax[1].hist(dataNorm.flatten(),50)\n",
    "ax[1].set_xlabel('Pixel intensity values')\n",
    "ax[1].set_ylabel('Count')\n",
    "ax[1].set_title('Histogram of normalized data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b27fcb-aecd-486e-9e5b-cd8f81b424ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long() # long = int64\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59059237-3ef9-4872-bd81-018c296113b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return torch.log_softmax( self.output(x),axis=1 )\n",
    "      # NEW HERE: log-softmax the output, because I'm using NLLLoss instead of CrossEntropyLoss\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.NLLLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29213c-41e9-436c-ae1f-a7990e1c3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with one batch\n",
    "net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "\n",
    "# values are log-probability of each number (0-9)\n",
    "# print(torch.exp(yHat))\n",
    "\n",
    "# now let's compute the loss\n",
    "loss = lossfun(yHat,y)\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532892a-d7db-430c-9d09-a842ad094fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 60\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f3abe-6129-40c9-b6d2-6948990984e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230285d7-044d-4a79-9a12-73e1e27fdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886a933-d150-4079-9e6a-0eac4dbd1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model through for the test data\n",
    "X,y = next(iter(test_loader))\n",
    "predictions = net(X).detach()\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f32617-c530-4134-98e4-cda01110b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evidence for all numbers from one sample\n",
    "sample2show = 120\n",
    "\n",
    "plt.bar(range(10),predictions[sample2show]) # try adding exp!\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel('Number')\n",
    "plt.ylabel('Evidence for that number')\n",
    "plt.title('True number was %s' %y[sample2show].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dea5c5-2cd2-453f-a5f0-1e6d2402bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the errors\n",
    "errors = np.where( torch.max(predictions,axis=1)[1] != y )[0]\n",
    "print(errors)\n",
    "\n",
    "# Evidence for all numbers from one sample\n",
    "sample2show = 10\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(14,5))\n",
    "\n",
    "ax[0].bar(range(10),np.exp(predictions[errors[sample2show]]))\n",
    "ax[0].set_xticks(range(10))\n",
    "ax[0].set_xlabel('Number')\n",
    "ax[0].set_ylabel('Evidence for that number')\n",
    "ax[0].set_title('True number: %s, model guessed %s' \n",
    "                %( y[errors[sample2show]].item(), torch.argmax(predictions[errors[sample2show]]).item() ))\n",
    "\n",
    "ax[1].imshow( np.reshape(X[errors[sample2show],:],(28,28)) ,cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33808902-9fd8-401b-ae58-81ce8788c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3]\n",
    "# create a class for the model\n",
    "def createTheMNISTNet():\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,64)\n",
    "      \n",
    "      ### hidden layer\n",
    "      self.fc1 = nn.Linear(64,32)\n",
    "      self.fc2 = nn.Linear(32,32)\n",
    "\n",
    "      ### output layer\n",
    "      self.output = nn.Linear(32,10)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.fc1(x) )\n",
    "      x = F.relu( self.fc2(x) )\n",
    "      return self.output(x)\n",
    "  \n",
    "  # create the model instance\n",
    "  net = mnistNet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(net.parameters(),lr=.01)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28806a0e-dc17-4428-9691-bab622468e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### exploring the \"innards\" of the model\n",
    "\n",
    "# create a temp model to explore\n",
    "net = createTheMNISTNet()[0]\n",
    "\n",
    "# summary of the entire model\n",
    "print('Summary of model:')\n",
    "print(net)\n",
    "print(' ')\n",
    "\n",
    "# # explore one of the layers\n",
    "# print('Summary of input layer:')\n",
    "# print( vars(net.input) )\n",
    "# print(' ')\n",
    "\n",
    "# # check out the matrix of weights\n",
    "# print('Input layer weights:')\n",
    "# print( net.input.weight.shape )\n",
    "# print( net.input.weight )\n",
    "# print(' ')\n",
    "\n",
    "# # finally, extract the weights and make a histogram\n",
    "# w = net.input.weight.detach().flatten()\n",
    "# plt.hist(w,40)\n",
    "# plt.xlabel('Weight value')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Distribution of initialized input-layer weights')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcb807-d67e-40bd-af63-6b81ace1b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that returns a histogram of all weights (across all layers)\n",
    "\n",
    "def weightsHistogram(net):\n",
    "\n",
    "  # initialize weight vector\n",
    "  W = np.array([])\n",
    "  \n",
    "  # concatenate each set of weights\n",
    "  for layer in net.parameters():\n",
    "    W = np.concatenate((W,layer.detach().flatten().numpy() ))\n",
    "\n",
    "  # compute their histogram (note: range is hard-coded)\n",
    "  histy,histx = np.histogram(W,bins=np.linspace(-.8,.8,101),density=True)\n",
    "  histx = (histx[1:]+histx[:-1])/2\n",
    "  return histx,histy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test it!\n",
    "histx,histy = weightsHistogram(net)\n",
    "plt.plot(histx,histy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f90efc-b2d2-4d28-a4d8-b07dd6cb585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 100\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses and accuracies\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "  # initialize histogram variables\n",
    "  histx = np.zeros((numepochs,100))\n",
    "  histy = np.zeros((numepochs,100))\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # get the weights distribution at the start of this epoch\n",
    "    histx,histy[epochi,:] = weightsHistogram(net)\n",
    "  \n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches        = torch.argmax(yHat,axis=1) == y # booleans (false/true)\n",
    "      matchesNumeric = matches.float()                # convert to numbers (0/1)\n",
    "      accuracyPct    = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )                  # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net,histx,histy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d356e73-5222-434b-891c-480e518e755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net,histx,histy = function2trainTheModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79863250-a63d-4cad-9ac3-d8f0752b6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6642aa-787b-4137-b649-8201ef4aaeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the histogram of the weights\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "for i in range(histy.shape[0]):\n",
    "  ax[0].plot(histx,histy[i,:],color=[1-i/100,.3,i/100])\n",
    "\n",
    "ax[0].set_title('Histograms of weights')\n",
    "ax[0].set_xlabel('Weight value')\n",
    "ax[0].set_ylabel('Density')\n",
    "\n",
    "\n",
    "ax[1].imshow(histy,vmin=0,vmax=3,\n",
    "             extent=[histx[0],histx[-1],0,99],aspect='auto',origin='lower',cmap='hot')\n",
    "ax[1].set_xlabel('Weight value')\n",
    "ax[1].set_ylabel('Training epoch')\n",
    "ax[1].set_title('Image of weight histograms')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dab669-8258-4549-94c1-842326b48d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] Scrambled MNIST\n",
    "# randomly scramble the data,\n",
    "# preserving the re-ordering for each image\n",
    "eggs = np.random.permutation(data.shape[1])\n",
    "scrambled = dataNorm[:,eggs]\n",
    "\n",
    "\n",
    "# show a few random digits\n",
    "fig,axs = plt.subplots(3,4,figsize=(10,6))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "  # pick a random image\n",
    "  randimg2show = np.random.randint(0,high=data.shape[0])\n",
    "\n",
    "  # create the image (must be reshaped!)\n",
    "  img = np.reshape(scrambled[randimg2show,:],(28,28))\n",
    "  ax.imshow(img,cmap='gray')\n",
    "\n",
    "  # title\n",
    "  ax.set_title('The number %i'%labels[randimg2show])\n",
    "\n",
    "plt.suptitle('The scrambled data',fontsize=20)\n",
    "plt.tight_layout(rect=[0,0,1,.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e45806-efd8-40e3-9323-8c9a3317adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( scrambled ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ae039-9e89-40ef-bbfd-977ec19b3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd91ba-9dd0-460f-bac3-27557ab7d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] Shifted\n",
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d2857-dbf0-45fb-b675-094ca92368bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see how to shift a vectorized image\n",
    "\n",
    "# grab one image data\n",
    "tmp = test_loader.dataset.tensors[0][0,:]\n",
    "tmp = tmp.reshape(28,28) # reshape to 2D image\n",
    "\n",
    "# shift the image (pytorch calls it \"rolling\")\n",
    "tmpS = torch.roll(tmp,8,dims=1)\n",
    "\n",
    "\n",
    "# now show them both\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,6))\n",
    "ax[0].imshow(tmp, cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "\n",
    "ax[1].imshow(tmpS, cmap='gray')\n",
    "ax[1].set_title('Shifted (rolled)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba545d-0e49-4b1e-bcef-190b15d84619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repeat for all images in the test set\n",
    "\n",
    "for i in range(test_loader.dataset.tensors[0].shape[0]):\n",
    "  \n",
    "  # get the image\n",
    "  img = test_loader.dataset.tensors[0][i,:]\n",
    "  \n",
    "  # reshape and roll by max. 10 pixels\n",
    "  randroll = np.random.randint(-10,11)\n",
    "  img = torch.roll( img.reshape(28,28) ,randroll,dims=1 )\n",
    "\n",
    "  # re-vectorize and put back into the matrix\n",
    "  test_loader.dataset.tensors[0][i,:] = img.reshape(1,-1)\n",
    "\n",
    "\n",
    "# Note: now run the previous cell again to confirm the shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d3906-b404-4f89-905d-d8d145f3cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc,testAcc,losses,net = function2trainTheModel()\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_ylim([0,3])\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,label='Train')\n",
    "ax[1].plot(testAcc,label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_ylim([10,100])\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02943d-0683-484c-a261-f1a0595e6549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b554b61a-0f6e-480f-ba4f-c5d6c6534727",
   "metadata": {},
   "source": [
    "# 2. Convolutional Neural Networks (CNNs)\n",
    "## 2-1. Image Classification with LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9c18fb-d73c-4bd2-831b-e3df065207e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6bd9c9-8ef2-49a2-8bce-9b1342bc655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Pixel Value: 0 \n",
      "Max Pixel Value: 255\n",
      "Mean Pixel Value 33.31842041015625 \n",
      "Pixel Values Std: 78.56748962402344\n",
      "Scaled Mean Pixel Value 0.13066047430038452 \n",
      "Scaled Pixel Values Std: 0.30810779333114624\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='.', train=True, download=True)\n",
    "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(train_dataset.data.min(), train_dataset.data.max()))\n",
    "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(train_dataset.data.float().mean(), train_dataset.data.float().std()))\n",
    "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(train_dataset.data.float().mean() / 255, train_dataset.data.float().std() / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a0e7af-5bc1-4d21-a777-51170fa044a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Pixel Value: 0 \n",
      "Max Pixel Value: 255\n",
      "Mean Pixel Value 33.791221618652344 \n",
      "Pixel Values Std: 79.17247009277344\n",
      "Scaled Mean Pixel Value 0.1325145959854126 \n",
      "Scaled Pixel Values Std: 0.3104802668094635\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='.', train=False, download=True)\n",
    "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(test_dataset.data.min(), test_dataset.data.max()))\n",
    "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(test_dataset.data.float().mean(), test_dataset.data.float().std()))\n",
    "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(test_dataset.data.float().mean() / 255, test_dataset.data.float().std() / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a935a5-5147-4553-84ee-e7e05d2da9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True,\n",
    "                                           transform = torchvision.transforms.Compose([\n",
    "                                                  torchvision.transforms.Resize((32,32)),\n",
    "                                                  torchvision.transforms.ToTensor(),\n",
    "                                                  torchvision.transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = torchvision.transforms.Compose([\n",
    "                                                  torchvision.transforms.Resize((32,32)),\n",
    "                                                  torchvision.transforms.ToTensor(),\n",
    "                                                  torchvision.transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6dc8bec-0f2f-4be2-9aa0-c7907db49392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1d9f80-73bf-4b79-acf0-47b270aba109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02edf854-9d97-42ae-8200-8dbab7b22f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# number of classes\n",
    "K = len(set(train_dataset.targets.numpy()))\n",
    "print(\"number of classes:\", K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9478c522-7783-405f-b219-f8d078cbdb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense_layers): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        # http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html\n",
    "        # \"No zero padding, non-unit strides\"\n",
    "        # https://pytorch.org/docs/stable/nn.html\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(400, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, K)\n",
    "        )\n",
    "  \n",
    "    def forward(self, X):\n",
    "        out = self.conv_layers(X)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dense_layers(out)\n",
    "        return out\n",
    "\n",
    "model = LeNet5(num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44dbc429-5ff1-4d31-95a1-e6f41f3afb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a loss function for multi-class classification\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create an optimizer for multi-class classification\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "total_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f8c0ff-5064-4fe5-a400-a27540e19fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.0209\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0154\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0931\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0954\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0467\n",
      "Epoch [3/10], Step [800/938], Loss: 0.1767\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0360\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0144\n",
      "Epoch [5/10], Step [400/938], Loss: 0.1090\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0107\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0227\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0312\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0247\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0248\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0003\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0679\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0147\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0694\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0181\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0727\n"
     ]
    }
   ],
   "source": [
    "# Loop through data\n",
    "for epoch in range(num_epochs):\n",
    "  # Training\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(images)\n",
    "      loss = loss_fn(outputs, labels)\n",
    "\n",
    "      # Backward & optimize\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if (i + 1) % 400 == 0:\n",
    "          print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d5beca-1904-44bf-bef3-c494ab9602d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.56 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512193-998a-41f1-8a16-5de2368a3cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
